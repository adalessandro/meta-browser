From c50ab494fcedd0bd17eb39c9173c2ecbbeb89466 Mon Sep 17 00:00:00 2001
From: Ariel D'Alessandro <ariel.dalessandro@collabora.com>
Date: Sun, 27 Apr 2025 23:57:04 -0300
Subject: [PATCH] third_party/libavif: Add missing source files

In the current release, libavif was dropped and no longer shipped in the
source tarball. Let's re-enable and add its sources again, so we can use
it as the replacement of crabbyavif.

Signed-off-by: Ariel D'Alessandro <ariel.dalessandro@collabora.com>
---
 third_party/libavif/BUILD.gn                  |  170 +
 third_party/libavif/DIR_METADATA              |    6 +
 third_party/libavif/LICENSE                   |   46 +
 third_party/libavif/OWNERS                    |    2 +
 third_party/libavif/README.chromium           |   13 +
 third_party/libavif/avif_apps_shared_stubs.c  |   50 +
 third_party/libavif/src/.clang-format         |  125 +
 third_party/libavif/src/.cmake-format.py      |   28 +
 third_party/libavif/src/.gitattributes        |    3 +
 third_party/libavif/src/.gitignore            |   24 +
 third_party/libavif/src/CHANGELOG.md          | 1227 +++
 third_party/libavif/src/CMakeLists.txt        |  926 +++
 third_party/libavif/src/LICENSE               |  387 +
 third_party/libavif/src/README.md             |  195 +
 third_party/libavif/src/SECURITY.md           |   16 +
 third_party/libavif/src/apps/avifdec.c        |  410 +
 third_party/libavif/src/apps/avifenc.c        | 2558 +++++++
 .../src/apps/avifgainmaputil/.clang-format    |    6 +
 .../apps/avifgainmaputil/avifgainmaputil.cc   |  111 +
 .../apps/avifgainmaputil/combine_command.cc   |  143 +
 .../apps/avifgainmaputil/combine_command.h    |   33 +
 .../apps/avifgainmaputil/convert_command.cc   |  124 +
 .../apps/avifgainmaputil/convert_command.h    |   32 +
 .../avifgainmaputil/extractgainmap_command.cc |   43 +
 .../avifgainmaputil/extractgainmap_command.h  |   25 +
 .../src/apps/avifgainmaputil/imageio.cc       |  171 +
 .../src/apps/avifgainmaputil/imageio.h        |   33 +
 .../avifgainmaputil/printmetadata_command.cc  |   89 +
 .../avifgainmaputil/printmetadata_command.h   |   23 +
 .../apps/avifgainmaputil/program_command.cc   |   66 +
 .../apps/avifgainmaputil/program_command.h    |  142 +
 .../apps/avifgainmaputil/swapbase_command.cc  |  192 +
 .../apps/avifgainmaputil/swapbase_command.h   |   32 +
 .../apps/avifgainmaputil/tonemap_command.cc   |  220 +
 .../apps/avifgainmaputil/tonemap_command.h    |   30 +
 .../libavif/src/apps/shared/avifexif.c        |   63 +
 .../libavif/src/apps/shared/avifexif.h        |   23 +
 .../libavif/src/apps/shared/avifjpeg.c        | 1384 ++++
 .../libavif/src/apps/shared/avifjpeg.h        |   41 +
 third_party/libavif/src/apps/shared/avifpng.c |  756 ++
 third_party/libavif/src/apps/shared/avifpng.h |   35 +
 .../libavif/src/apps/shared/avifutil.c        |  464 ++
 .../libavif/src/apps/shared/avifutil.h        |  101 +
 .../libavif/src/apps/shared/iccmaker.c        |  480 ++
 .../libavif/src/apps/shared/iccmaker.h        |   23 +
 third_party/libavif/src/apps/shared/y4m.c     |  611 ++
 third_party/libavif/src/apps/shared/y4m.h     |   32 +
 third_party/libavif/src/apps/utf8.manifest    |    8 +
 third_party/libavif/src/apps/utf8.rc          |    3 +
 .../src/cmake/Meson/crossfile-apple.meson.in  |   16 +
 .../Modules/AvifExternalProjectUtils.cmake    |   13 +
 .../libavif/src/cmake/Modules/Findaom.cmake   |   56 +
 .../libavif/src/cmake/Modules/Finddav1d.cmake |   50 +
 .../src/cmake/Modules/Findlibgav1.cmake       |   49 +
 .../src/cmake/Modules/Findlibsharpyuv.cmake   |   53 +
 .../src/cmake/Modules/Findlibyuv.cmake        |   71 +
 .../libavif/src/cmake/Modules/Findrav1e.cmake |   71 +
 .../libavif/src/cmake/Modules/Findsvt.cmake   |   48 +
 .../libavif/src/cmake/Modules/LocalAom.cmake  |  177 +
 .../libavif/src/cmake/Modules/LocalAvm.cmake  |    1 +
 .../src/cmake/Modules/LocalDav1d.cmake        |  132 +
 .../src/cmake/Modules/LocalGTest.cmake        |   52 +
 .../libavif/src/cmake/Modules/LocalJpeg.cmake |   63 +
 .../src/cmake/Modules/LocalLibXml2.cmake      |   46 +
 .../src/cmake/Modules/LocalLibargparse.cmake  |   35 +
 .../src/cmake/Modules/LocalLibgav1.cmake      |   54 +
 .../src/cmake/Modules/LocalLibsharpyuv.cmake  |   62 +
 .../src/cmake/Modules/LocalLibyuv.cmake       |   79 +
 .../src/cmake/Modules/LocalRav1e.cmake        |  108 +
 .../libavif/src/cmake/Modules/LocalSvt.cmake  |   95 +
 .../src/cmake/Modules/LocalZlibpng.cmake      |  107 +
 .../src/cmake/Modules/merge_static_libs.cmake |  128 +
 .../libavif/src/contrib/CMakeLists.txt        |    4 +
 third_party/libavif/src/contrib/README.md     |    9 +
 .../src/contrib/gdk-pixbuf/.clang-format      |   23 +
 .../src/contrib/gdk-pixbuf/CMakeLists.txt     |   29 +
 .../contrib/gdk-pixbuf/avif.thumbnailer.in    |    4 +
 .../libavif/src/contrib/gdk-pixbuf/loader.c   |  526 ++
 .../libavif/src/contrib/irefmerge.coffee      |  212 +
 third_party/libavif/src/doc/README.md         |    8 +
 third_party/libavif/src/doc/avifdec.1.md      |  135 +
 third_party/libavif/src/doc/avifenc.1.md      |  262 +
 .../src/examples/avif_example_decode_file.c   |   94 +
 .../src/examples/avif_example_decode_memory.c |  120 +
 .../examples/avif_example_decode_streaming.c  |  232 +
 .../src/examples/avif_example_encode.c        |  139 +
 third_party/libavif/src/ext/README.md         |   14 +
 third_party/libavif/src/ext/aom.cmd           |   19 +
 third_party/libavif/src/ext/avm.cmd           |   20 +
 .../libavif/src/ext/compliance_warden.sh      |   21 +
 third_party/libavif/src/ext/dav1d.cmd         |   24 +
 third_party/libavif/src/ext/dav1d_android.sh  |   44 +
 third_party/libavif/src/ext/fuzztest.cmd      |   22 +
 third_party/libavif/src/ext/googletest.cmd    |   19 +
 third_party/libavif/src/ext/libargparse.cmd   |   20 +
 third_party/libavif/src/ext/libgav1.cmd       |   20 +
 .../libavif/src/ext/libgav1_android.sh        |   44 +
 third_party/libavif/src/ext/libjpeg.cmd       |   17 +
 third_party/libavif/src/ext/libsharpyuv.cmd   |   19 +
 third_party/libavif/src/ext/libxml2.cmd       |   14 +
 third_party/libavif/src/ext/libyuv.cmd        |   27 +
 third_party/libavif/src/ext/libyuv_android.sh |   40 +
 third_party/libavif/src/ext/mp4box.sh         |   16 +
 third_party/libavif/src/ext/rav1e.cmd         |   20 +
 third_party/libavif/src/ext/svt.cmd           |   24 +
 third_party/libavif/src/ext/svt.sh            |   17 +
 third_party/libavif/src/ext/zlibpng.cmd       |    8 +
 third_party/libavif/src/include/avif/avif.h   | 1648 ++++
 .../libavif/src/include/avif/avif_cxx.h       |   40 +
 .../libavif/src/include/avif/internal.h       |  793 ++
 third_party/libavif/src/libavif.pc.cmake      |   13 +
 third_party/libavif/src/src/alpha.c           |  389 +
 third_party/libavif/src/src/avif.c            | 1227 +++
 third_party/libavif/src/src/codec_aom.c       | 1247 +++
 third_party/libavif/src/src/codec_avm.c       | 1111 +++
 third_party/libavif/src/src/codec_dav1d.c     |  255 +
 third_party/libavif/src/src/codec_libgav1.c   |  174 +
 third_party/libavif/src/src/codec_rav1e.c     |  322 +
 third_party/libavif/src/src/codec_svt.c       |  397 +
 third_party/libavif/src/src/colr.c            |  534 ++
 third_party/libavif/src/src/colrconvert.c     |  186 +
 third_party/libavif/src/src/compliance.cc     |   54 +
 third_party/libavif/src/src/diag.c            |   34 +
 third_party/libavif/src/src/exif.c            |  200 +
 third_party/libavif/src/src/gainmap.c         |  852 +++
 third_party/libavif/src/src/io.c              |  170 +
 third_party/libavif/src/src/mem.c             |   18 +
 third_party/libavif/src/src/obu.c             |  487 ++
 third_party/libavif/src/src/rawdata.c         |   39 +
 third_party/libavif/src/src/read.c            | 6690 +++++++++++++++++
 third_party/libavif/src/src/reformat.c        | 1822 +++++
 .../libavif/src/src/reformat_libsharpyuv.c    |   84 +
 third_party/libavif/src/src/reformat_libyuv.c | 1171 +++
 third_party/libavif/src/src/sampletransform.c |  401 +
 third_party/libavif/src/src/scale.c           |  200 +
 third_party/libavif/src/src/stream.c          |  509 ++
 third_party/libavif/src/src/utils.c           |  288 +
 third_party/libavif/src/src/write.c           | 3854 ++++++++++
 third_party/libavif/src/third_party/README.md |   25 +
 .../libavif/src/third_party/iccjpeg/iccjpeg.c |  248 +
 .../libavif/src/third_party/iccjpeg/iccjpeg.h |   73 +
 .../libavif/src/third_party/libyuv/AUTHORS    |    6 +
 .../src/third_party/libyuv/include/libyuv.h   |   21 +
 .../libyuv/include/libyuv/basic_types.h       |   68 +
 .../libyuv/include/libyuv/planar_functions.h  |   30 +
 .../third_party/libyuv/include/libyuv/row.h   |   41 +
 .../third_party/libyuv/include/libyuv/scale.h |   54 +
 .../libyuv/include/libyuv/scale_row.h         |  147 +
 .../libyuv/include/libyuv/version.h           |   16 +
 .../libyuv/source/planar_functions.c          |   64 +
 .../third_party/libyuv/source/row_common.c    |  105 +
 .../src/third_party/libyuv/source/scale.c     | 1007 +++
 .../src/third_party/libyuv/source/scale_any.c |   85 +
 .../third_party/libyuv/source/scale_common.c  |  555 ++
 154 files changed, 43311 insertions(+)
 create mode 100644 third_party/libavif/BUILD.gn
 create mode 100644 third_party/libavif/DIR_METADATA
 create mode 100644 third_party/libavif/LICENSE
 create mode 100644 third_party/libavif/OWNERS
 create mode 100644 third_party/libavif/README.chromium
 create mode 100644 third_party/libavif/avif_apps_shared_stubs.c
 create mode 100644 third_party/libavif/src/.clang-format
 create mode 100644 third_party/libavif/src/.cmake-format.py
 create mode 100644 third_party/libavif/src/.gitattributes
 create mode 100644 third_party/libavif/src/.gitignore
 create mode 100644 third_party/libavif/src/CHANGELOG.md
 create mode 100644 third_party/libavif/src/CMakeLists.txt
 create mode 100644 third_party/libavif/src/LICENSE
 create mode 100644 third_party/libavif/src/README.md
 create mode 100644 third_party/libavif/src/SECURITY.md
 create mode 100644 third_party/libavif/src/apps/avifdec.c
 create mode 100644 third_party/libavif/src/apps/avifenc.c
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/.clang-format
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/avifgainmaputil.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/combine_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/combine_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/convert_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/convert_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/imageio.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/imageio.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/program_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/program_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/swapbase_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/swapbase_command.h
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/tonemap_command.cc
 create mode 100644 third_party/libavif/src/apps/avifgainmaputil/tonemap_command.h
 create mode 100644 third_party/libavif/src/apps/shared/avifexif.c
 create mode 100644 third_party/libavif/src/apps/shared/avifexif.h
 create mode 100644 third_party/libavif/src/apps/shared/avifjpeg.c
 create mode 100644 third_party/libavif/src/apps/shared/avifjpeg.h
 create mode 100644 third_party/libavif/src/apps/shared/avifpng.c
 create mode 100644 third_party/libavif/src/apps/shared/avifpng.h
 create mode 100644 third_party/libavif/src/apps/shared/avifutil.c
 create mode 100644 third_party/libavif/src/apps/shared/avifutil.h
 create mode 100644 third_party/libavif/src/apps/shared/iccmaker.c
 create mode 100644 third_party/libavif/src/apps/shared/iccmaker.h
 create mode 100644 third_party/libavif/src/apps/shared/y4m.c
 create mode 100644 third_party/libavif/src/apps/shared/y4m.h
 create mode 100755 third_party/libavif/src/apps/utf8.manifest
 create mode 100755 third_party/libavif/src/apps/utf8.rc
 create mode 100644 third_party/libavif/src/cmake/Meson/crossfile-apple.meson.in
 create mode 100644 third_party/libavif/src/cmake/Modules/AvifExternalProjectUtils.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findaom.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Finddav1d.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findlibgav1.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findlibsharpyuv.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findlibyuv.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findrav1e.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/Findsvt.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalAom.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalAvm.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalDav1d.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalGTest.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalJpeg.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalLibXml2.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalLibargparse.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalLibgav1.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalLibsharpyuv.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalLibyuv.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalRav1e.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalSvt.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/LocalZlibpng.cmake
 create mode 100644 third_party/libavif/src/cmake/Modules/merge_static_libs.cmake
 create mode 100644 third_party/libavif/src/contrib/CMakeLists.txt
 create mode 100644 third_party/libavif/src/contrib/README.md
 create mode 100644 third_party/libavif/src/contrib/gdk-pixbuf/.clang-format
 create mode 100644 third_party/libavif/src/contrib/gdk-pixbuf/CMakeLists.txt
 create mode 100644 third_party/libavif/src/contrib/gdk-pixbuf/avif.thumbnailer.in
 create mode 100644 third_party/libavif/src/contrib/gdk-pixbuf/loader.c
 create mode 100644 third_party/libavif/src/contrib/irefmerge.coffee
 create mode 100644 third_party/libavif/src/doc/README.md
 create mode 100644 third_party/libavif/src/doc/avifdec.1.md
 create mode 100644 third_party/libavif/src/doc/avifenc.1.md
 create mode 100644 third_party/libavif/src/examples/avif_example_decode_file.c
 create mode 100644 third_party/libavif/src/examples/avif_example_decode_memory.c
 create mode 100644 third_party/libavif/src/examples/avif_example_decode_streaming.c
 create mode 100644 third_party/libavif/src/examples/avif_example_encode.c
 create mode 100644 third_party/libavif/src/ext/README.md
 create mode 100755 third_party/libavif/src/ext/aom.cmd
 create mode 100755 third_party/libavif/src/ext/avm.cmd
 create mode 100755 third_party/libavif/src/ext/compliance_warden.sh
 create mode 100755 third_party/libavif/src/ext/dav1d.cmd
 create mode 100755 third_party/libavif/src/ext/dav1d_android.sh
 create mode 100755 third_party/libavif/src/ext/fuzztest.cmd
 create mode 100755 third_party/libavif/src/ext/googletest.cmd
 create mode 100755 third_party/libavif/src/ext/libargparse.cmd
 create mode 100755 third_party/libavif/src/ext/libgav1.cmd
 create mode 100755 third_party/libavif/src/ext/libgav1_android.sh
 create mode 100755 third_party/libavif/src/ext/libjpeg.cmd
 create mode 100755 third_party/libavif/src/ext/libsharpyuv.cmd
 create mode 100755 third_party/libavif/src/ext/libxml2.cmd
 create mode 100755 third_party/libavif/src/ext/libyuv.cmd
 create mode 100755 third_party/libavif/src/ext/libyuv_android.sh
 create mode 100755 third_party/libavif/src/ext/mp4box.sh
 create mode 100755 third_party/libavif/src/ext/rav1e.cmd
 create mode 100755 third_party/libavif/src/ext/svt.cmd
 create mode 100644 third_party/libavif/src/ext/svt.sh
 create mode 100755 third_party/libavif/src/ext/zlibpng.cmd
 create mode 100644 third_party/libavif/src/include/avif/avif.h
 create mode 100644 third_party/libavif/src/include/avif/avif_cxx.h
 create mode 100644 third_party/libavif/src/include/avif/internal.h
 create mode 100644 third_party/libavif/src/libavif.pc.cmake
 create mode 100644 third_party/libavif/src/src/alpha.c
 create mode 100644 third_party/libavif/src/src/avif.c
 create mode 100644 third_party/libavif/src/src/codec_aom.c
 create mode 100644 third_party/libavif/src/src/codec_avm.c
 create mode 100644 third_party/libavif/src/src/codec_dav1d.c
 create mode 100644 third_party/libavif/src/src/codec_libgav1.c
 create mode 100644 third_party/libavif/src/src/codec_rav1e.c
 create mode 100644 third_party/libavif/src/src/codec_svt.c
 create mode 100644 third_party/libavif/src/src/colr.c
 create mode 100644 third_party/libavif/src/src/colrconvert.c
 create mode 100644 third_party/libavif/src/src/compliance.cc
 create mode 100644 third_party/libavif/src/src/diag.c
 create mode 100644 third_party/libavif/src/src/exif.c
 create mode 100644 third_party/libavif/src/src/gainmap.c
 create mode 100644 third_party/libavif/src/src/io.c
 create mode 100644 third_party/libavif/src/src/mem.c
 create mode 100644 third_party/libavif/src/src/obu.c
 create mode 100644 third_party/libavif/src/src/rawdata.c
 create mode 100644 third_party/libavif/src/src/read.c
 create mode 100644 third_party/libavif/src/src/reformat.c
 create mode 100644 third_party/libavif/src/src/reformat_libsharpyuv.c
 create mode 100644 third_party/libavif/src/src/reformat_libyuv.c
 create mode 100644 third_party/libavif/src/src/sampletransform.c
 create mode 100644 third_party/libavif/src/src/scale.c
 create mode 100644 third_party/libavif/src/src/stream.c
 create mode 100644 third_party/libavif/src/src/utils.c
 create mode 100644 third_party/libavif/src/src/write.c
 create mode 100644 third_party/libavif/src/third_party/README.md
 create mode 100644 third_party/libavif/src/third_party/iccjpeg/iccjpeg.c
 create mode 100644 third_party/libavif/src/third_party/iccjpeg/iccjpeg.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/AUTHORS
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/basic_types.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/planar_functions.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/row.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/scale.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/scale_row.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/include/libyuv/version.h
 create mode 100644 third_party/libavif/src/third_party/libyuv/source/planar_functions.c
 create mode 100644 third_party/libavif/src/third_party/libyuv/source/row_common.c
 create mode 100644 third_party/libavif/src/third_party/libyuv/source/scale.c
 create mode 100644 third_party/libavif/src/third_party/libyuv/source/scale_any.c
 create mode 100644 third_party/libavif/src/third_party/libyuv/source/scale_common.c

diff --git a/third_party/libavif/BUILD.gn b/third_party/libavif/BUILD.gn
new file mode 100644
index 0000000000..8a50c8cc90
--- /dev/null
+++ b/third_party/libavif/BUILD.gn
@@ -0,0 +1,170 @@
+# Copyright 2020 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//media/media_options.gni")
+import("//testing/libfuzzer/fuzzer_test.gni")
+
+# Public configuration exported to users of the libavif target.
+config("avif_public_config") {
+  defines = [ "AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP" ]
+  if (is_component_build) {
+    defines += [ "AVIF_DLL" ]
+  }
+}
+
+# Private configuration used in building libavif.
+config("avif_config") {
+  include_dirs = [ "src/include/" ]
+  defines = [ "AVIF_LIBYUV_ENABLED" ]
+  if (is_component_build) {
+    defines += [ "AVIF_BUILDING_SHARED_LIBS" ]
+  }
+
+  if (enable_dav1d_decoder) {
+    include_dirs += [ "../dav1d/libdav1d/include/" ]
+    defines += [ "AVIF_CODEC_DAV1D" ]
+  }
+}
+
+libavif_decoder_sources = [
+  "src/include/avif/internal.h",
+  "src/src/alpha.c",
+  "src/src/avif.c",
+  "src/src/colr.c",
+  "src/src/colrconvert.c",
+  "src/src/diag.c",
+  "src/src/exif.c",
+  "src/src/gainmap.c",
+  "src/src/io.c",
+  "src/src/mem.c",
+  "src/src/obu.c",
+  "src/src/rawdata.c",
+  "src/src/read.c",
+  "src/src/reformat.c",
+  "src/src/reformat_libsharpyuv.c",
+  "src/src/reformat_libyuv.c",
+  "src/src/scale.c",
+  "src/src/stream.c",
+  "src/src/utils.c",
+]
+
+component("libavif") {
+  public = [ "src/include/avif/avif.h" ]
+  public_configs = [ ":avif_public_config" ]
+
+  sources = libavif_decoder_sources
+
+  configs += [ ":avif_config" ]
+
+  deps = [ "//third_party/libyuv" ]
+
+  if (enable_dav1d_decoder) {
+    sources += [ "src/src/codec_dav1d.c" ]
+    deps += [ "//third_party/dav1d" ]
+  }
+}
+
+# Note only the decoder fuzzers are enabled as only the decoder is being used
+# in Chrome. avif_fuzztest_read_image is not enabled due to libpng not having
+# PNG_READ_iTXt_SUPPORTED enabled.
+config("avif_fuzztest_config") {
+  include_dirs = [
+    "src/include",
+    "src/apps/shared",
+  ]
+}
+
+# This is used to satisfy dependencies in avif_fuzztest_helpers. The encoder
+# functions are not used.
+component("libavif_enc") {
+  public = [ "src/include/avif/avif.h" ]
+  public_configs = [ ":avif_public_config" ]
+
+  sources = libavif_decoder_sources + [
+              "src/src/write.c",
+            ]
+  testonly = true
+
+  configs += [ ":avif_config" ]
+
+  deps = [
+    "//third_party/libwebp:libwebp_sharpyuv",
+    "//third_party/libyuv",
+  ]
+  defines = [ "AVIF_LIBSHARPYUV_ENABLED" ]
+
+  if (enable_dav1d_decoder) {
+    sources += [ "src/src/codec_dav1d.c" ]
+    deps += [ "//third_party/dav1d" ]
+  }
+}
+
+source_set("avif_apps_shared") {
+  sources = [
+    "avif_apps_shared_stubs.c",
+    "src/apps/shared/avifjpeg.h",
+    "src/apps/shared/avifpng.h",
+    "src/apps/shared/avifutil.c",
+    "src/apps/shared/avifutil.h",
+    "src/apps/shared/y4m.c",
+    "src/apps/shared/y4m.h",
+  ]
+  testonly = true
+  configs += [ ":avif_fuzztest_config" ]
+  deps = [ ":libavif_enc" ]
+}
+
+source_set("avif_fuzztest_helpers") {
+  sources = [
+    "src/tests/gtest/avif_fuzztest_helpers.cc",
+    "src/tests/gtest/avifincrtest_helpers.cc",
+    "src/tests/gtest/aviftest_helpers.cc",
+  ]
+  testonly = true
+  configs += [ ":avif_fuzztest_config" ]
+  deps = [
+    ":avif_apps_shared",
+    ":libavif_enc",
+    "//testing/gtest",
+    "//third_party/fuzztest:fuzztest",
+  ]
+}
+
+# TODO: b/308013905 - These tests require seeds from
+# third_party/libavif/src/tests/data which
+# aren't available in the fuzzing environment. These targets can be enabled if
+# they are made hermetic.
+#
+# test("avif_fuzztest_dec") {
+#   sources = [ "src/tests/gtest/avif_fuzztest_dec.cc" ]
+#   fuzztests = [ "DecodeAvifTest.Decode" ]
+#   configs += [ ":avif_fuzztest_config" ]
+#   deps = [
+#     ":avif_fuzztest_helpers",
+#     ":libavif_enc",
+#     "//third_party/fuzztest:fuzztest_gtest_main",
+#   ]
+# }
+#
+# test("avif_fuzztest_dec_incr") {
+#   sources = [ "src/tests/gtest/avif_fuzztest_dec_incr.cc" ]
+#   fuzztests = [ "DecodeAvifFuzzTest.DecodeIncr" ]
+#   configs += [ ":avif_fuzztest_config" ]
+#   deps = [
+#     ":avif_fuzztest_helpers",
+#     ":libavif_enc",
+#     "//third_party/fuzztest:fuzztest_gtest_main",
+#   ]
+# }
+
+test("avif_fuzztest_yuvrgb") {
+  sources = [ "src/tests/gtest/avif_fuzztest_yuvrgb.cc" ]
+  fuzztests = [ "YuvRgbFuzzTest.Convert" ]
+  configs += [ ":avif_fuzztest_config" ]
+  deps = [
+    ":avif_fuzztest_helpers",
+    ":libavif_enc",
+    "//third_party/fuzztest:fuzztest_gtest_main",
+  ]
+}
diff --git a/third_party/libavif/DIR_METADATA b/third_party/libavif/DIR_METADATA
new file mode 100644
index 0000000000..beadfa62dc
--- /dev/null
+++ b/third_party/libavif/DIR_METADATA
@@ -0,0 +1,6 @@
+monorail: {
+  component: "Internals>Images>Codecs"
+}
+buganizer_public: {
+  component_id: 1456316
+}
diff --git a/third_party/libavif/LICENSE b/third_party/libavif/LICENSE
new file mode 100644
index 0000000000..5b188d7d91
--- /dev/null
+++ b/third_party/libavif/LICENSE
@@ -0,0 +1,46 @@
+Copyright 2019 Joe Drago. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+this list of conditions and the following disclaimer in the documentation
+and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+------------------------------------------------------------------------------
+
+Files: tests/cJSON.*
+
+Copyright (c) 2009-2017 Dave Gamble and cJSON contributors
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in
+all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+THE SOFTWARE.
diff --git a/third_party/libavif/OWNERS b/third_party/libavif/OWNERS
new file mode 100644
index 0000000000..6946c0b778
--- /dev/null
+++ b/third_party/libavif/OWNERS
@@ -0,0 +1,2 @@
+file://media/OWNERS
+wtc@google.com
diff --git a/third_party/libavif/README.chromium b/third_party/libavif/README.chromium
new file mode 100644
index 0000000000..a139d5f51a
--- /dev/null
+++ b/third_party/libavif/README.chromium
@@ -0,0 +1,13 @@
+Name: libavif - Library for encoding and decoding .avif files
+Short Name: libavif
+URL: https://github.com/AOMediaCodec/libavif
+Version: N/A
+Revision: DEPS
+License: 2-Clause BSD
+License File: LICENSE
+Security Critical: yes
+Shipped: yes
+
+Description:
+This contains the source to the AV1 image format demuxer; used for demuxing and
+decoding .avif files in Chromium.
diff --git a/third_party/libavif/avif_apps_shared_stubs.c b/third_party/libavif/avif_apps_shared_stubs.c
new file mode 100644
index 0000000000..18980cbc5b
--- /dev/null
+++ b/third_party/libavif/avif_apps_shared_stubs.c
@@ -0,0 +1,50 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// This file provides functions necessary to link the decoder fuzz tests. The
+// functions are not used by the tests being built, but their dependencies in
+// apps/shared and avif_*_helpers.cc unconditionally reference them.
+
+#include <stdio.h>
+
+#include "src/apps/shared/avifjpeg.h"
+#include "src/apps/shared/avifpng.h"
+
+avifBool avifJPEGRead(const char * inputFilename,
+                      avifImage * avif,
+                      avifPixelFormat requestedFormat,
+                      uint32_t requestedDepth,
+                      avifChromaDownsampling chromaDownsampling,
+                      avifBool ignoreColorProfile,
+                      avifBool ignoreExif,
+                      avifBool ignoreXMP,
+                      avifBool ignoreGainMap,
+                      uint32_t imageSizeLimit) {
+  fprintf(stderr, "The tests were built without JPEG support!\n");
+  return AVIF_FALSE;
+}
+
+avifBool avifPNGRead(const char * inputFilename,
+                     avifImage * avif,
+                     avifPixelFormat requestedFormat,
+                     uint32_t requestedDepth,
+                     avifChromaDownsampling chromaDownsampling,
+                     avifBool ignoreColorProfile,
+                     avifBool ignoreExif,
+                     avifBool ignoreXMP,
+                     avifBool allowChangingCicp,
+                     uint32_t imageSizeLimit,
+                     uint32_t * outPNGDepth) {
+  fprintf(stderr, "The tests were built without PNG support!\n");
+  return AVIF_FALSE;
+}
+
+avifBool avifPNGWrite(const char * outputFilename,
+                      const avifImage * avif,
+                      uint32_t requestedDepth,
+                      avifChromaUpsampling chromaUpsampling,
+                      int compressionLevel) {
+  fprintf(stderr, "The tests were built without PNG support!\n");
+  return AVIF_FALSE;
+}
diff --git a/third_party/libavif/src/.clang-format b/third_party/libavif/src/.clang-format
new file mode 100644
index 0000000000..a058f89908
--- /dev/null
+++ b/third_party/libavif/src/.clang-format
@@ -0,0 +1,125 @@
+---
+Language:        Cpp
+AccessModifierOffset: -4
+AlignAfterOpenBracket: Align
+AlignConsecutiveAssignments: false
+AlignConsecutiveDeclarations: false
+AlignEscapedNewlines: Left
+AlignOperands:   true
+AlignTrailingComments: true
+# AllowAllArgumentsOnNextLine: false
+# AllowAllConstructorInitializersOnNextLine: false
+AllowAllParametersOfDeclarationOnNextLine: false
+AllowShortBlocksOnASingleLine: false
+AllowShortCaseLabelsOnASingleLine: false
+AllowShortFunctionsOnASingleLine: InlineOnly
+# AllowShortLambdasOnASingleLine: All
+# AllowShortIfStatementsOnASingleLine: WithoutElse
+AllowShortLoopsOnASingleLine: false
+AlwaysBreakAfterDefinitionReturnType: None
+AlwaysBreakAfterReturnType: None
+AlwaysBreakBeforeMultilineStrings: false
+AlwaysBreakTemplateDeclarations: Yes
+BinPackArguments: false
+BinPackParameters: false
+BraceWrapping:
+#  AfterCaseLabel:  false
+  AfterClass:      true
+  AfterControlStatement: false
+  AfterEnum:       true
+  AfterFunction:   true
+  AfterNamespace:  true
+  AfterObjCDeclaration: false
+  AfterStruct:     true
+  AfterUnion:      true
+  AfterExternBlock: false
+  BeforeCatch:     false
+  BeforeElse:      false
+  IndentBraces:    false
+  SplitEmptyFunction: true
+  SplitEmptyRecord: true
+  SplitEmptyNamespace: true
+BreakBeforeBinaryOperators: None
+BreakBeforeBraces: Custom
+BreakBeforeInheritanceComma: false
+BreakInheritanceList: BeforeColon
+BreakBeforeTernaryOperators: true
+BreakConstructorInitializersBeforeComma: false
+BreakConstructorInitializers: BeforeComma
+BreakAfterJavaFieldAnnotations: false
+BreakStringLiterals: false
+ColumnLimit:     130
+CommentPragmas:  '.'
+CompactNamespaces: true
+ConstructorInitializerAllOnOneLineOrOnePerLine: true
+ConstructorInitializerIndentWidth: 4
+ContinuationIndentWidth: 4
+Cpp11BracedListStyle: false
+DerivePointerAlignment: false
+DisableFormat:   false
+ExperimentalAutoDetectBinPacking: false
+FixNamespaceComments: true
+ForEachMacros:
+  - foreach
+  - Q_FOREACH
+  - BOOST_FOREACH
+IncludeBlocks:   Preserve
+IncludeCategories:
+  - Regex:           '^"(llvm|llvm-c|clang|clang-c)/'
+    Priority:        2
+  - Regex:           '^(<|"(gtest|gmock|isl|json)/)'
+    Priority:        3
+  - Regex:           '.*'
+    Priority:        1
+IncludeIsMainRegex: '(Test)?$'
+IndentCaseLabels: true
+IndentPPDirectives: None
+IndentWidth:     4
+IndentWrappedFunctionNames: false
+JavaScriptQuotes: Leave
+JavaScriptWrapImports: true
+KeepEmptyLinesAtTheStartOfBlocks: false
+MacroBlockBegin: ''
+MacroBlockEnd:   ''
+MaxEmptyLinesToKeep: 1
+NamespaceIndentation: None
+ObjCBinPackProtocolList: Auto
+ObjCBlockIndentWidth: 2
+ObjCSpaceAfterProperty: false
+ObjCSpaceBeforeProtocolList: true
+PenaltyBreakAssignment: 10
+PenaltyBreakBeforeFirstCallParameter: 9999
+PenaltyBreakComment: 0
+PenaltyBreakFirstLessLess: 0
+PenaltyBreakString: 0
+PenaltyBreakTemplateDeclaration: 10
+PenaltyExcessCharacter: 2
+PenaltyReturnTypeOnItsOwnLine: 9999999
+PointerAlignment: Middle
+ReflowComments:  false
+SortIncludes:    true
+SortUsingDeclarations: true
+SpaceAfterCStyleCast: false
+# SpaceAfterLogicalNot: false
+SpaceAfterTemplateKeyword: true
+SpaceBeforeAssignmentOperators: true
+SpaceBeforeCpp11BracedList: true
+SpaceBeforeCtorInitializerColon: true
+SpaceBeforeInheritanceColon: true
+SpaceBeforeParens: ControlStatements
+SpaceBeforeRangeBasedForLoopColon: true
+SpaceInEmptyParentheses: false
+SpacesBeforeTrailingComments: 1
+SpacesInAngles:  false
+SpacesInContainerLiterals: true
+SpacesInCStyleCastParentheses: false
+SpacesInParentheses: false
+SpacesInSquareBrackets: false
+Standard:        Cpp11
+StatementMacros:
+  - Q_UNUSED
+  - QT_REQUIRE_VERSION
+TabWidth:        4
+UseTab:          Never
+...
+
diff --git a/third_party/libavif/src/.cmake-format.py b/third_party/libavif/src/.cmake-format.py
new file mode 100644
index 0000000000..cbd6182ae9
--- /dev/null
+++ b/third_party/libavif/src/.cmake-format.py
@@ -0,0 +1,28 @@
+# -----------------------------
+# Options affecting formatting.
+# -----------------------------
+with section("format"):
+  # How wide to allow formatted cmake files
+  line_width = 130
+
+  # How many spaces to tab for indent
+  tab_size = 4
+
+  # If an argument group contains more than this many sub-groups (parg or kwarg
+  # groups) then force it to a vertical layout.
+  max_subgroups_hwrap = 3
+
+  # If a positional argument group contains more than this many arguments, then
+  # force it to a vertical layout.
+  max_pargs_hwrap = 10
+
+  # If a statement is wrapped to more than one line, than dangle the closing
+  # parenthesis on its own line.
+  dangle_parens = True
+
+# ------------------------------------------------
+# Options affecting comment reflow and formatting.
+# ------------------------------------------------
+with section("markup"):
+  # enable comment markup parsing and reflow
+  enable_markup = False
diff --git a/third_party/libavif/src/.gitattributes b/third_party/libavif/src/.gitattributes
new file mode 100644
index 0000000000..4fb4d2197a
--- /dev/null
+++ b/third_party/libavif/src/.gitattributes
@@ -0,0 +1,3 @@
+* text=auto
+*.sh text eol=lf
+*.y4m -text -diff
diff --git a/third_party/libavif/src/.gitignore b/third_party/libavif/src/.gitignore
new file mode 100644
index 0000000000..797db2e802
--- /dev/null
+++ b/third_party/libavif/src/.gitignore
@@ -0,0 +1,24 @@
+/build*
+/obj*
+/ext/aom
+/ext/avm
+/ext/ComplianceWarden
+/ext/dav1d
+/ext/fuzztest
+/ext/googletest
+/ext/gpac
+/ext/libargparse
+/ext/libjpeg
+/ext/libjpeg-turbo
+/ext/libgav1
+/ext/libpng
+/ext/libwebp
+/ext/libxml2
+/ext/libyuv
+/ext/rav1e
+/ext/SVT-AV1
+/ext/zlib
+.clangd/
+.vscode/
+cscope.*
+tags
diff --git a/third_party/libavif/src/CHANGELOG.md b/third_party/libavif/src/CHANGELOG.md
new file mode 100644
index 0000000000..1d40eb9d24
--- /dev/null
+++ b/third_party/libavif/src/CHANGELOG.md
@@ -0,0 +1,1227 @@
+# Changelog
+All notable changes to this project will be documented in this file.
+
+The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
+and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
+
+The changes are relative to the previous release, unless the baseline is specified.
+
+## [Unreleased]
+
+### Changed since 1.1.1
+* avifenc: Allow large images to be encoded.
+* Fix empty CMAKE_CXX_FLAGS_RELEASE if -DAVIF_CODEC_AOM=LOCAL -DAVIF_LIBYUV=OFF
+  is specified. https://github.com/AOMediaCodec/libavif/issues/2365.
+* Renamed AVIF_ENABLE_EXPERIMENTAL_METAV1 to AVIF_ENABLE_EXPERIMENTAL_MINI and
+  updated the experimental reduced header feature to the latest specification
+  draft.
+* Ignore gain maps with unsupported metadata. Handle gain maps with
+  writer_version > 0 correctly.
+  Simplify gain map API: remove the enableParsingGainMapMetadata setting, now gain
+  map metadata is always parsed if present and if this feature is compiled in.
+  Replace enableDecodingGainMap and ignoreColorAndAlpha with a bit field to choose
+  image content to decode. Remove gainMapPresent: users can check if
+  decoder->image->gainMap != NULL instead.
+* Write an empty HandlerBox name field instead of "libavif" (saves 7 bytes).
+* Update aom.cmd/LocalAom.cmake: v3.10.0
+* Update avm.cmd: research-v8.0.0
+* Update dav1d.cmd/dav1d_android.sh/LocalDav1d.cmake: 1.5.0
+* Update libjpeg.cmd/LocalJpeg.cmake: v3.0.4
+* Update libxml2.cmd/LocalLibXml2.cmake: v2.13.4
+* Update svt.cmd/svt.sh/LocalSvt.cmake: v2.2.1
+* Change experimental gainmap API: remove avifGainMapMetadata and
+  avifGainMapMetadataDouble structs.
+* Add avif(Un)SignedFraction structs and avifDoubleTo(Un)SignedFraction
+  utility functions.
+
+## [1.1.1] - 2024-07-30
+
+### Changed since 1.1.0
+* In avif.h, change "AVIF_API AVIF_NODISCARD" back to "AVIF_NODISCARD AVIF_API"
+  to fix clang-cl and MSVC compilation errors in the shared library build on
+  Windows.
+* Fix -DAVIF_GTEST=SYSTEM, https://github.com/AOMediaCodec/libavif/issues/2258.
+* Fix infe_type and codec_config_type wrongly read as byte-aligned fields in the
+  experimental feature AVIF_ENABLE_EXPERIMENTAL_METAV1.
+* When building aom as a local dependency, runtime CPU detection
+  (`CONFIG_RUNTIME_CPU_DETECT`) is now always `ON`; in 1.1.0 it had been
+  disabled for non-native builds.
+* Fix CMake config shared library leaks
+  https://github.com/AOMediaCodec/libavif/issues/2264.
+* Fix clang-cl compilation.
+* Update gain map metadata to current ISO 21496-1 draft.
+* cmake: Only search for ASM_NASM language on x86_64 platforms.
+* Fix "No known features for CXX compiler" CMake error.
+* Fix aom link flags so that transitive library link flags are included when
+  aom is a static library
+  https://github.com/AOMediaCodec/libavif/issues/2274.
+* Fix out-of-order 'dimg' grid associations
+  https://github.com/AOMediaCodec/libavif/issues/2311.
+* Report files with an item used in multiple 'dimg' boxes with
+  AVIF_RESULT_NOT_IMPLEMENTED instead of AVIF_RESULT_INVALID_IMAGE_GRID.
+
+## [1.1.0] - 2024-07-11
+
+### Added since 1.0.0
+* Add experimental API for reading and writing gain maps in AVIF files.
+  If enabled at compile time, add `gainMap` field to `avifImage`,
+  add `qualityGainMap` field to `avifEncoder`, add `gainMapPresent`,
+  `enableDecodingGainMap`, `enableParsingGainMapMetadata` and
+  `ignoreColorAndAlpha` to `avifDecoder`.
+  Utility functions for working with gain maps are also added.
+  Gain maps allow readers that support them to display HDR images that look
+  good on both HDR and SDR displays.
+  This feature is highly experimental. The API might change or be removed
+  in the future. Files created now might not decode in a future version.
+  This feature is off by default and must be enabled with the
+  AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP compilation flag.
+* Add experimental support for converting jpeg files with gain maps to AVIF
+  files with gain maps. Requires libxml2, and the AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+  compilation flag.
+  Add a --qgain-map flag to control the gain map quality in avifenc.
+* Add the headerFormat member of new type avifHeaderFormat to avifEncoder.
+* Add experimental API for reading and writing "mif3"-branded AVIF files
+  behind the compilation flag AVIF_ENABLE_EXPERIMENTAL_METAV1.
+* Implement avifImageScale() fallback when libyuv is not available.
+* Partial import of libyuv to third_party/libyuv (new LICENSE).
+* Add avifenc flag suffixes ":update" and ":u". Quality-relative,
+  tiling-relative and codec-specific flags can now be positional, relative to
+  input files.
+* Add experimental support for layered AVIF encoding in avifenc.
+  Use the --layered flag to enable layered AVIF encoding.
+  Layered AVIF has multiple layers, which works like frame of animated AVIF,
+  and layers can be rendered in progressive manner on supported viewers
+  (e.g. Chrome 94 or newer).
+  Only aom supports layered AVIF encoding at the time of writing.
+  Add --scaling-mode flag to set scaling mode of each layer.
+  This part of AV1 encoder is not as thoroughly tested, so there are higher
+  possibility encoder may crash when given certain configuration or input.
+* Add imageSequenceTrackPresent flag to the avifDecoder struct.
+* avifImageScale() function was made part of the public ABI.
+* Add avif_cxx.h as a C++ header with basic functionality.
+* Add enum aliases AVIF_COLOR_PRIMARIES_SRGB, AVIF_COLOR_PRIMARIES_BT2100,
+  AVIF_COLOR_PRIMARIES_DCI_P3, AVIF_TRANSFER_CHARACTERISTICS_PQ.
+* Add avifResult enum entry AVIF_RESULT_INTERNAL_ERROR.
+* Require libyuv by default (but it can still be disabled with
+  -DAVIF_LIBYUV=OFF).
+* Add avifdec --icc flag to override the output color profile.
+* Add experimental API for reading and writing 16-bit AVIF files behind the
+  compilation flag AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM.
+* Add AVIF_CHROMA_SAMPLE_POSITION_RESERVED to avifChromaSamplePosition enum.
+
+### Changed since 1.0.0
+* Update aom.cmd: v3.9.1
+* Update avm.cmd: research-v7.0.1
+* Update dav1d.cmd: 1.4.3
+* Update libgav1.cmd: v0.19.0
+* Update libjpeg.cmd: v3.0.3
+* Update libxml2.cmd: v2.12.7
+* Update libyuv.cmd: a6a2ec65
+* Update mp4box.sh: v2.4.0
+* Update rav1e.cmd: v0.7.1
+* Update svt.cmd/svt.sh: v2.1.1
+* Update zlibpng.cmd: zlib 1.3.1 and libpng 1.6.40
+* AVIF sequences encoded by libavif will now also have the "avio" brand when
+  there is at least one track made only of AV1 keyframes.
+* Fix SVT-AV1 codec interface which was not setting video range at encoding.
+* Any item ID being 0 in an "iref" box with version 0 or 1 is now treated as an
+  error instead of being ignored.
+* API calls now return AVIF_RESULT_OUT_OF_MEMORY instead of aborting on memory
+  allocation failure.
+* avifdec and avifenc: Change the default value of the --jobs option from 1 to
+  "all".
+* Update avifCropRectConvertCleanApertureBox() to the revised requirements in
+  ISO/IEC 23000-22:2019/Amd. 2:2021 Section 7.3.6.7.
+* AVIF files with an exif_tiff_header_offset pointing at another byte than the
+  first II or MM tag in the Exif metadata payload will now fail to be decoded.
+  Set decoder->ignoreExif to true to skip the issue and decode the image.
+* Fix memory errors reported in crbug.com/1501766, crbug.com/1501770, and
+  crbug.com/1504792 by [Fudan University](https://secsys.fudan.edu.cn/).
+* For codecs, AVIF_CODEC_* and AVIF_LOCAL_* are now merged into AVIF_CODEC_*
+  that can only take the values: OFF, LOCAL or SYSTEM.
+* For the gtest, jpeg, libsharpyuv, libxml2, libyuv and zlibpng dependencies,
+  AVIF_LOCAL_* is now replaced by flags AVIF_* that can take the values:
+  OFF, LOCAL or SYSTEM.
+* src/reformat.c: Allocate the threadData array directly.
+* AVIF_ENABLE_WERROR is set to OFF by default.
+* Fix wrong alpha plane deallocation when decoded tile pixel format does not
+  match reconstructed output image pixel format (b/320234262).
+* Fix identical chunk skipping optimization when writing animation data
+  (b/321189607).
+* Fix ID selection for artificial grid alpha item when decoding a grid of tiles
+  which each have an associated auxiliary alpha image item
+  (https://crbug.com/oss-fuzz/65657).
+* ext/libjpeg.cmd now pulls libjpeg-turbo instead of libjpeg and AVIF_JPEG=LOCAL
+  now expects the library dependency in ext/libjpeg-turbo/build.libavif.
+* Fix 'iloc' box parsing bugs that may have wrongly accepted, rejected or parsed
+  some files with rare values of offset_size, length_size, base_offset_size and
+  index_size.
+* 'infe' boxes with an item_type different from 'mime' and without a
+  null-terminated item_name are now considered invalid as per ISO/IEC 14496-12.
+
+## [1.0.4] - 2024-02-08
+
+### Changed
+* AVIF_ENABLE_WERROR is set to OFF by default.
+* Fix wrong alpha plane deallocation when decoded tile pixel format does not
+  match reconstructed output image pixel format (b/320234262).
+* Fix identical chunk skipping optimization when writing animation data
+  (b/321189607).
+* Fix ID selection for artificial grid alpha item when decoding a grid of tiles
+  which each have an associated auxiliary alpha image item
+  (https://crbug.com/oss-fuzz/65657).
+
+## [1.0.3] - 2023-12-03
+
+### Changed
+* Rewrite the fix for memory errors reported in crbug.com/1501770.
+* Fix memory errors reported in crbug.com/1504792 by [Fudan
+  University](https://secsys.fudan.edu.cn/).
+* src/reformat.c: Allocate the threadData array directly.
+
+## [1.0.2] - 2023-11-16
+
+### Changed
+* Update avifCropRectConvertCleanApertureBox() to the revised requirements in
+  ISO/IEC 23000-22:2019/Amd. 2:2021 Section 7.3.6.7.
+* Fix memory errors reported in crbug.com/1501766 and crbug.com/1501770 by
+  [Fudan University](https://secsys.fudan.edu.cn/).
+
+## [1.0.1] - 2023-08-29
+
+### Changed
+* gdk-pixbuf: Explicitly pass link directories
+* gdk-pixbuf: Fix build failure after imir.mode -> imir.axis rename
+
+## [1.0.0] - 2023-08-24
+
+With the 1.0.0 release, the ABI will be more stable from now on. Please note
+the allocation and initialization requirements for avifImage, avifDecoder,
+avifEncoder, and avifRGBImage in the "avif/avif.h" header.
+
+List of incompatible ABI changes in this release:
+
+* The clli member was added to the avifImage struct.
+* The repetitionCount member was added to the avifEncoder and avifDecoder
+  structs.
+* The quality and qualityAlpha members were added to the avifEncoder struct.
+* Check that functions returning pointers do not return NULL before accessing
+  those pointers.
+* Check the return value of avifEncoderSetCodecSpecificOption().
+* The maxThreads member was added to the avifRGBImage struct.
+* Check the return value of avifRGBImageAllocatePixels(), avifRWDataRealloc(),
+  avifRWDataSet(), avifImageSetProfileICC(), avifImageSetMetadataExif() and
+  avifImageSetMetadataXMP().
+* The meaning of the keyframeInterval member of avifEncoder struct has changed
+  slightly. When set to a value of "n",
+    * Before: It forces a keyframe on every nth frame.
+    * After: Any set of "n" consecutive frame will have at least one keyframe
+      (every nth frame may or may not be a keyframe).
+
+### Added
+* Add STATIC library target avif_internal to allow tests to access functions
+  from internal.h when BUILD_SHARED_LIBS is ON.
+* Add clli metadata read and write support
+* Add repetitionCount member to avifEncoder and avifDecoder structs to specify
+  the number of repetitions for animated image sequences.
+* Add quality and qualityAlpha to avifEncoder. Note: minQuantizer,
+  maxQuantizer, minQuantizerAlpha, and maxQuantizerAlpha are deprecated. Code
+  should be updated to set quality (and qualityAlpha if applicable) and leave
+  minQuantizer, maxQuantizer, minQuantizerAlpha, and maxQuantizerAlpha
+  initialized to the default values.
+* The --target-size flag in avifenc was added to adapt the quality so that the
+  output file size is as close to the given number of bytes as possible.
+* Add the public API function avifImageIsOpaque() in avif.h.
+* Add the public API functions avifImagePlane(), avifImagePlaneRowBytes(),
+  avifImagePlaneWidth(), and avifImagePlaneHeight() in avif.h.
+* Add experimental API for progressive AVIF encoding.
+* Add API for multi-threaded YUV to RGB color conversion.
+* Add experimental support for AV2 behind the compilation flag AVIF_CODEC_AVM.
+  AVIF_CODEC_CHOICE_AVM is now part of avifCodecChoice.
+* Add experimental YCgCo-R support behind the compilation flag
+  AVIF_ENABLE_EXPERIMENTAL_YCGCO_R.
+* Allow lossless 4:0:0 on grayscale input.
+* Add avifenc --no-overwrite flag to avoid overwriting output file.
+* Add avifenc --clli flag to set clli.
+* Add support for all transfer functions when using libsharpyuv.
+
+### Changed
+* Enable the libaom AV1E_SET_SKIP_POSTPROC_FILTERING codec control by default.
+* Use the constant rate factor (CRF) instead of the constant quantization
+  parameter (CQP) rate control mode with the SVT-AV1 encoder.
+* Exif and XMP metadata is exported to PNG and JPEG files by default,
+  except XMP payloads larger than 65502 bytes in JPEG.
+* The --grid flag in avifenc can be used for images that are not evenly divided
+  into cells.
+* Apps must be built with libpng version 1.6.32 or above.
+* Change the encoder to write the boxes within the "stbl" box in the order of
+  stsd, stts, stsc, stsz, stco, stss.
+* avifImageCopy() no longer accepts source U and V channels to be NULL for
+  non-4:0:0 input if Y is not NULL and if AVIF_PLANES_YUV is specified.
+* The default values of the maxQuantizer and maxQuantizerAlpha members of
+  avifEncoder changed from AVIF_QUANTIZER_LOSSLESS (0) to
+  AVIF_QUANTIZER_WORST_QUALITY (63). The behavior changed if minQuantizer and
+  maxQuantizer are left initialized to the default values. Code should be
+  updated to set the quality member. Similarly for the alpha quantizers and
+  qualityAlpha.
+* avifImageRGBToYUV() and avifImageYUVToRGB() handle avifImage bit depths 8, 10,
+  12 and now also 16. Files read by apps/shared/ can output 16-bit avifImage
+  instances.
+* Update aom.cmd: v3.6.1
+* Update dav1d.cmd: 1.2.1
+* Update libsharpyuv: 0.4.0
+* Update rav1e.cmd: v0.6.6
+* Update svt.cmd/svt.sh: v1.6.0
+* Update zlibpng.cmd: zlib 1.2.13 and libpng 1.6.39
+* avifImageCreate(), avifImageCreateEmpty(), avifEncoderCreate() and other
+  internal functions now return NULL if a memory allocation failed.
+* avifEncoderSetCodecSpecificOption() now returns avifResult instead of void to
+  report memory allocation failures.
+* At decoding, avifIOStats now returns the same values as at encoding.
+* avifRGBImageAllocatePixels(), avifRWDataRealloc(), avifRWDataSet(),
+  avifImageSetProfileICC(), avifImageSetMetadataExif() and
+  avifImageSetMetadataXMP() now return avifResult instead of void to report
+  memory allocation failures.
+* avifReadImage(), avifJPEGRead() and avifPNGRead() now remove the trailing zero
+  byte from read XMP chunks, if any. See avifImageFixXMP().
+* Force keyframe for alpha if color is a keyframe.
+* Write primaries and transfer characteritics info in decoded PNG.
+* Add support for reading PNG gAMA, cHRM and sRGB chunks.
+* The 'mode' member of the avifImageMirror struct was renamed 'axis'.
+* Change the type of the 'depth' parameter from int to uint32_t in
+  avifFullToLimitedY(), avifFullToLimitedUV(), avifLimitedToFullY(), and
+  avifLimitedToFullUV().
+
+## [0.11.1] - 2022-10-19
+
+### Changed
+* avifincrtest_helpers: Cast 64-bit offset to size_t
+* avifmetadatatest: don't include avif/internal.h
+* avifrgbtoyuvtest: skip if no libsharpyuv
+* Disable tests that may fail if the codec is not aom (#1176)
+
+## [0.11.0] - 2022-10-12
+
+There are incompatible ABI changes in this release. The alphaRange member was
+removed from the avifImage struct. The chromaDownsampling and avoidLibYUV
+members were added to the avifRGBImage struct. The imageDimensionLimit member
+was added to the avifDecoder struct. avifImageCopy() and
+avifImageAllocatePlanes() signatures changed. It is necessary to recompile your
+code. Also check the return values of avifImageCopy() and
+avifImageAllocatePlanes().
+
+### Added
+* Add man pages for avifenc and avifdec
+* Add the avifChannelIndex type alias for enum avifChannelIndex
+* Add avifChromaDownsampling enum
+* Add chromaDownsampling field to avifRGBImage struct
+* Add support for AVIF_RGB_FORMAT_RGB_565
+* Add imageDimensionLimit field to avifDecoder struct
+* Add autoTiling field to avifEncoder struct
+* Add new avifResult codes AVIF_RESULT_CANNOT_CHANGE_SETTING and
+  AVIF_RESULT_INCOMPATIBLE_IMAGE
+* Add new enum constants AVIF_PIXEL_FORMAT_COUNT and AVIF_RGB_FORMAT_COUNT
+* avifdec: Add --dimension-limit, which specifies the image dimension limit
+  (width or height) that should be tolerated
+* avifenc: Add --sharpyuv, which enables "sharp" RGB to YUV420 conversion, which
+  reduces artifacts caused by 420 chroma downsampling. Needs libsharpyuv (part
+  of the libwebp repository) at compile time.
+* avifenc: Add --ignore-exif and --ignore-xmp flags.
+* avifenc: Add --autotiling, which sets --tilerowslog2 and --tilecolslog2
+  automatically.
+* avifenc: Input Exif orientation is converted to irot/imir by default.
+
+### Changed
+* Fix memory leaks of metadata on avifenc exit
+* Update the handling of 'lsel' and progressive decoding to AVIF spec v1.1.0
+* Treat an absent lsel and layer_id == 0xFFFF equivalently for backward
+  compatibility with earlier drafts of AVIF spec v1.1.0
+* Set libavif's own default value of cfg.rc_end_usage for libaom
+* Fix https://github.com/AOMediaCodec/libavif/issues/953
+* Set the libaom-specific option -a tune=ssim by default
+* Bump cmake_minimum_required from 3.5 to 3.13
+* Fix https://crbug.com/oss-fuzz/48135
+* Use several new libyuv functions in reformat_libyuv.c
+* Fix SVT-AV1's issue 1957 related to uninitialized variables crashing the
+  encoder
+* Fix https://github.com/AOMediaCodec/libavif/issues/787
+* Update aom.cmd: v3.5.0
+* Update rav1e.cmd: v0.5.1
+* Update svt.cmd/svt.sh: v1.2.1
+* Update libgav1.cmd: v0.18.0
+* Update libyuv.cmd: f9fda6e7 (version 1844)
+* avifImageCopy() and avifImageAllocatePlanes() now return avifResult instead of
+  void to report invalid parameters or memory allocation failures.
+* avifImageRGBToYUV() now uses libyuv fast paths by default. It may slightly
+  change conversion results. The old behavior can be restored by setting
+  avifRGBImage::chromaDownsampling to AVIF_CHROMA_DOWNSAMPLING_BEST_QUALITY
+  and avifRGBImage::avoidLibYUV to AVIF_TRUE.
+* avifRGBImage::chromaUpsampling now only applies to conversions that need
+  upsampling chroma from 4:2:0 or 4:2:2 and has no impact on the use of libyuv.
+  Set avifRGBImage::avoidLibYUV accordingly to control the use of libyuv.
+* avifenc: Set the YUV format to 4:0:0 for grayscale PNGs
+* Support updating encoder settings and codec-specific options during encoding
+* Disable AVIF_STRICT_CLAP_VALID and AVIF_STRICT_PIXI_REQUIRED in the JNI
+  wrapper
+* avifdec: Return proper exit code in "info" mode
+* In avifenc and avifdec, treat all arguments that start with '-' as options
+* Fix https://github.com/AOMediaCodec/libavif/issues/1086
+* Exif and XMP metadata is imported from PNG and JPEG files.
+* avifImageSetMetadataExif() parses the Exif metadata and converts any Exif
+  orientation found into transformFlags, irot and imir values.
+* Write 'auxi' box for animated images with alpha channel
+* Write 'auxv' as handler_type for alpha channel track
+* Use PNG_COLOR_TYPE_GRAY for 8-bit grayscale output
+* Replace repeated subtraction by modulo in calcGCD (fix b/246649620)
+* Change avifImageCreate to take uint32_t instead of int parameters
+* When writing an image sequence, check if it's safe to cast width and height to
+  uint16_t
+* Allow clamped grid cells in avifEncoderAddImageGrid()
+
+### Removed
+* alphaRange field was removed from the avifImage struct. It it presumed that
+  alpha plane is always full range.
+* The avifCodecConfigurationBox struct becomes a private type for libavif
+  internal use
+
+## [0.10.1] - 2022-04-11
+
+### Changed
+* tests/docker/build.sh: Build SVT-AV1 using cmake and ninja directly
+* Fix a Visual Studio 2017 compiler warning in src\reformat.c: warning C4204:
+  nonstandard extension used: non-constant aggregate initializer
+* Fix the help message of avifdec: --index takes a value
+
+## [0.10.0] - 2022-04-06
+
+There is an incompatible ABI change in this release. New members were added to
+the avifDecoder and avifRGBImage structs. It is necessary to recompile your
+code.
+
+### Added
+* Support F16 Half Float conversion in avifRGBImage: new isFloat member
+* Incremental decoding of AVIF grid tiles: new allowIncremental member in
+  avifDecoder and new avifDecoderDecodedRowCount() function
+* Support parsing of version 3 of ItemInfoEntry
+* Add new avifResult code AVIF_RESULT_OUT_OF_MEMORY
+* Document the "[Strict]" prefix in error strings
+* Document that SVT-AV1 doesn't support lossless yet
+* CI: Add CIFuzz integration
+* Add Docker build CI pipeline
+* Add SVT-AV1 to CI and build scripts
+* ci.yml: Build examples and apps
+
+### Changed
+* Print the item type in the diagnostic messages for missing mandatory av1C or
+  pixi property
+* Update aom.cmd: v3.3.0
+* Update dav1d.cmd: 1.0.0
+* Update libgav1.cmd: 0.17.0
+* Update rav1e.cmd: 0.5.0
+* Update svt.cmd/svt.sh: v0.9.1
+* Update zlibpng.cmd: zlib v1.2.12
+* findrav1e: add LDFLAGS to LIBRARIES
+* rav1e: add bcrypt.lib to list of extra libs
+* Fix y4m read/write for images of non-standard dimensions
+* Fix y4mRead() and y4mWrite() for 4:0:0
+* Fix compilation with Clang 13 and 14
+* Remove the obsolete script fuzz.sh
+* Support local android builds for libgav1
+* Add Android JNI bindings
+* Delay failures of AV1 codecs not existing to frame decoding, to allow libavif
+  to perform AVIF parsing without any AV1 codecs
+* Change encoder speed in gdk-pixbuf plug-in
+* Fix compilation with 1755 <= LIBYUV_VERSION < 1774
+* Remove JSON-based tests (as they are unreliable), along with associated
+  helper code (cJSON, compare)
+* CMakeLists.txt: Move codec enabled message after check passed
+* Fix alpha copy in aomCodecEncodeImage()
+* Support SVT-AV1 v0.9.0 or later
+* Call svt_av1_get_version() for SVT-AV1 v0.9.0 or later
+* Handle avifArrayCreate() failures
+* Only consider a frame index to be a keyframe if all tiles/planes are sync
+  frames
+* Move checks to avifAreGridDimensionsValid()
+* avifArrayPop() should zero the popped element
+* avifDecoderReset() should not return AVIF_FALSE
+* Handle avifDecoderDataCreateTile() failures
+* Fix endian dependent parameters to avifRWStreamWrite
+* Mark the input images of an image grid as hidden
+* Write ccst box in Sample Entry for animated images
+* Add iso8 to compatible_brands for animated images
+* Compare with snapshot of AOM_EXT_PART_ABI_VERSION
+* Handle the new AOM_IMG_FMT_NV12 enum conditionally in a switch statement in
+  aomCodecGetNextImage()
+* Fix avifpng.c for libpng 1.4
+* Fix -Wformat / -Wformat-non-iso on MinGW UCRT
+* Replace some memcpy calls with struct assignments
+* Remove unnecessary memcpy() calls in src/utils.c
+* Split CMakeLists.txt into tests/CMakeLists.txt
+* Use bilinear chroma upsampling in libyuv when possible
+* Call libyuv functions to convert 10bpc YUV to 8bpc RGB
+* Prepare avif example for non-aborting avifAlloc()
+* Handle the tileRowsLog2 and tileColsLog2 members of avifEncoder correctly for
+  SVT-AV1.
+
+## [0.9.3] - 2021-10-20
+
+### Added
+* Support for progressive AVIFs and operating point selection
+* Add automatic tile scaling to the item's ispe or track's dims
+* Add diagnostic messages for AV1 decode failures
+* avifdec: Add PNG compression level arg
+* Make image size limit configurable, expose to avifdec
+* Add the AVIF_STRICT_ALPHA_ISPE_REQUIRED flag
+
+### Changed
+* Mandate ispe and disallow zero width or height (#640).
+* Re-map libavif speed 7-10 to libaom speed 7-9 (#682)
+*  Refer to https://aomedia-review.googlesource.com/c/aom/+/140624
+*  If you were using libaom with the following avif speed setting:
+*   - speed 0-6: no change is needed
+*   - speed 7:   change to speed 6 for the same results
+*   - speed 8-9: re-test and re-adjust speed according to your app needs
+* Update aom.cmd: v3.2.0
+* Update dav1d.cmd: 0.9.2
+* Update svt-av1.cmd: v0.9.0
+* Pass TestCase's minQuantizer, maxQuantizer, speed to encoder.
+* Regenerate tests.json
+* Disable JSON-based tests for now, the metrics are inconsistent/unreliable
+* Set diagnostic message for aom_codec_set_option()
+* Re-map libavif-libaom speed settings (#682)
+* Bump of version in CMakeLists.txt was forgotten
+* avifdec: Better message for unsupported file extension
+* Do not copy input image when encoding with libaom unless width or height is 1
+* Fix the comment for AVIF_STRICT_PIXI_REQUIRED
+* Update libavif.pc.cmake (#692)
+* In 32-bit builds set dav1d's frame_size_limit setting to 8192*8192
+* Allocate alpha alongside YUV (if necessary) during y4m decode to avoid incorrect alphaRowBytes math
+* Change avif_decode_fuzzer to be more like Chrome
+* Update codec_dav1d.c for the new threading model
+* Generalized ipco property deduplication
+* Rename avifParseMoovBox to avifParseMovieBox for consistency
+* Simplify idat storage for avifMeta structure (#756)
+* Fix oss-fuzz coverage build failure of dav1d
+* Redesign AVIF_DECODER_SOURCE_AUTO to honor the FileTypeBox's major brand
+* Use "C420" as default Y4M color space parameter
+
+## [0.9.2] - 2021-06-23
+
+### Added
+* avifenc, avifdec: Allow "-j all" to automatically use all of the cores on the machine (#670)
+
+### Changed
+* Refactor imir implementation to match HEIF Draft Amendment 2 (#665)
+* Merge avifCodec's open call with its getNextImage call to avoid codec init during parse, and simplify the codec API (#637)
+* Update aom.cmd: v3.1.1 (#674)
+* Update svt-av1: v0.8.7 (#627)
+* Make tests/compare.h and tests/testcase.h C++ safe (#678)
+* Print width and height as %ux%u instead of %u/%u (#676)
+* Allocate codec->internal->svt_config statically (#675)
+* Cleanup related to avifDiagnosticsClearError() (#673)
+* Cleanup avifutil.h comment to match libavif style (#671)
+* Fix the clang -Wunused-macros warning (#672)
+* Check for int32_t overflows in 'clap' code (#663)
+* Have avifdec print chroma sample position for 420 (#666)
+* Enable CMake configs in VCPKG mode (#659)
+* Avoid multiplying widthN and heightN by 2 (#662)
+* Correct AVIF_PIXEL_FORMAT_NONE handling logic (#654)
+* Cast extent->offset (a uint64_t) to size_t safely (#660)
+* Disallow negative clap width or height (#656)
+* Check for int32_t cast and unsigned add overflows (#655)
+* Some straightforward changes to clapFraction code (#653)
+* Fix box name of avifParseChunkOffsetBox (#652)
+* No need to pass diag to functions that have 'data' (#651)
+* Simplify the assertion in avifROStreamStart() (#650)
+* Don't clear error in avifEncoderSetCodecSpecificOp (#648)
+* Simplify avifCodecConfigurationBoxGetFormat (#646)
+* Print the fraction in "not an integer" messages (#641)
+* Fix a typo in the diagnostic context for 'ipco' (#644)
+* Remove const from non-pointer function parameters (#634)
+* Declare the param of avifDumpDiagnostics as const (#633)
+* Adjust gdk-pixbuf loader for new API change (#668)
+* Fix gdk-pixbuf loader install path (#615)
+
+## [0.9.1] - 2021-05-19
+
+### Added
+* Added strict mode/flags (enabled by default): `AVIF_STRICT_PIXI_REQUIRED`, `AVIF_STRICT_CLAP_VALID`
+* avifdec: Added `--no-strict` to disable all strict flags
+* avifdec: Added `-r` (`--raw-color`), which avoids multiplying against AVIF alpha channel before packing into non-alpha formats (JPEG)
+* avifenc: Recognize the Y4M format string "C420mpeg2"
+* avifenc: Add `--crop` convenient alternative arg to the difficult-to-use `--clap` arg
+* avifenc: New default for `--yuv`: `"auto"`, which will use a source JPEG's internal YUV format instead of YUV444, if detected
+  * Uses: Prevent colorspace conversion when reading from JPEG if possible (tongyuantongyu)
+* avifenc/avifdec: Add helpful values/calculations when dumping clap box
+* Added avifDiagnostics, which allows for a detailed, freeform error string upon decode or encode error
+* Create helper avifCropRect struct and methods for helping to manipulate/populate/validate avifCleanApertureBox
+* Added ability to set codec-specific options for color or alpha only
+* Support for libaom's ALL_INTRA mode (if available)
+* Create avifDecoder.imageCountLimit as a sanity check against malformed files
+* SVT: Image sequence encoding support (tongyuantongyu)
+* Added rav1e to AppVeyor builds
+
+### Changed
+* avifenc/avifdec: Link AOM_LIBRARIES and use CXX if vmaf is present (1480c1)
+* Ensure that an AVIF has a ftyp box, and based on ftyp, has other appropriate toplevel boxes present as well
+* Avoid linking against libyuv if it is too old / incompatible
+* Always require a primary item when decoding items
+* Add some strictness around ipma box parsing (version/flags tuples must be unique across ipma boxes in a file)
+* Fix alpha grids by properly writing alpha grid metadata payload
+* A HandlerBox (hdlr) of type 'pict' must be the first box within the MetaBox (meta)
+* Add some typedefs for various flag decls in avif.h to self-document which flags should be used in which function arguments
+* When encoding single-frame images using libaom, clean up the encoder immediately after encoding the frame to cut down on resources high watermarks
+* Fail on reformat Identity (MC=0) with subsampling (not using YUV444)
+* Warn if alpha is limited range (deprecated)
+* Validate the first_chunk fields in the stsc box
+* In libaom all intra mode, set cq-level for user
+* Check the return values of some aom_codec_ calls and add diagnostics output (wantehchang)
+* Use aom_codec_set_option() if available (allows for future compat with libaom 3.0+ advanced features)
+* rav1e: Use cargo cinstall in local builds to ensure consistency in target output, as cbuild no longer builds directly into target/release
+* Tweaks to compiler flags (analyze related)
+* Use libyuv BT.709 & 2020 full range YuvConstants (wantehchang)
+* Multiply color with alpha for opaque RGB format during conversion (see #520)
+* Switch docker to ubuntu 20.04, fix tzdata install (paskal)
+* Added an "Understanding maxThreads" explanatory comment block in avif.h
+* Minor fixes to support AVIF_CODEC_AOM_ENCODE
+* Various minor code/comments cleanup
+* CI tweaks, macOS build, and caching / speed increases (EwoutH)
+* Update aom.cmd: v3.1.0
+* Update dav1d.cmd: 0.9.0
+* Update libgav1: v0.16.3
+* Update libyuv.cmd: 2f0cbb9
+
+## [0.9.0] - 2021-02-22
+
+### Added
+* Image grid encoding
+* Premultiplied alpha support (tongyuantongyu)
+* avifenc: Image grid encoding (`-g`, `--grid`)
+* avifenc: Harvest framerate from y4m headers as the "default", if present
+* avifenc: Recognize the Y4M format string "C420mpeg2" (wantehchang)
+* Basic deduplication when writing mdat chunks
+
+### Changed
+* avifenc: Adjusted min/max/speed/fps defaults
+* Better handling for export headers (tongyuantongyu)
+* Use procedure specified in H.273 to quantize YUV (tongyuantongyu)
+* Impose a maximum of 4096 bytes on searchSampleSize (wantehchang, fixes oss-fuzz perf issue / timeout)
+* Update aom.cmd: v2.0.2
+* Update dav1d.cmd: 0.8.2
+* Update libgav1.cmd: 4a89dc3 / lts_2020_09_23
+* Update rav1e.cmd: 0.4
+* Update svt.cmd/svt.sh: v0.8.6
+* Force libjpeg to output in RGB Colorspace (bugfix)
+* Minor other compilation/linking/formatting/comment fixes
+
+## [0.8.4] - 2020-11-23
+
+### Added
+* YCgCo support (full-range only, wantehchang)
+* Expose `maxThreads` to `avifDecoder`, add `--jobs` to `avifdec`
+* Add `avifDecoderNthImageMaxExtent()` streaming helper function to determine future reads
+* Create AVIF_VERSION_DEVEL, which allows for in-development changes to be detected during the build
+* New avifResult values: `AVIF_RESULT_INVALID_ARGUMENT`, `AVIF_RESULT_NOT_IMPLEMENTED`
+
+### Changed
+* Read/write one of each type of colr box, as allowed in HEIF 6.5.5.1 Amendment 3 (also now supported in libheif)
+* avifenc/avifdec: Now guesses input file format by header inspection instead of extension
+* avifenc: Fix y4m/stdin corner cases when trying to detect a "single image" encode
+* Add some protections against improperly using AVIF_ADD_IMAGE_FLAG_SINGLE
+* imir transformation: Disambiguate all usages of "vertical" and "horizontal" across comments and tooling
+* Print MC value when warning resetting to defaults (wantehchang)
+* Fix grid image rows/cols parsing on invalid data
+* Allow override of HAVE_POISON_SYSTEM_DIRECTORIES_WARNING (bnason-nf)
+* Lots of comments clarifications in avif.h
+
+## [0.8.3] - 2020-11-09
+
+### Added
+* SVT-AV1 encode support (jonsneyers)
+* Basic libyuv support (8bpc only, see usage/limitations in avif.h)
+* Refactor avifChromaUpsampling for ease in high level decision making and adding more filters in the future (minor, benign breaking change due to enum reordering)
+* New CMake options: `AVIF_CODEC_AOM_DECODE`, `AVIF_CODEC_AOM_ENCODE`
+* New examples in `examples/` dir (encode, decode_file, decode_memory, decode_streaming) to replace stale, not-compiled examples in README
+
+### Changed
+* avifenc: Explicitly signal SRGB CP/TC if the source image and user don't specify, and no ICC profile is present
+* Set g_lag_in_frames to 1 if encoding single image (encode memory optimization, wantehchang)
+* Early-out with OK in avifParse() if the expected top-level boxes were already parsed (streaming optimization)
+* Check increading item_ID and ipmaSeen in ipma box (wantehchang)
+* Fail gracefully in avifEncoderAddImage() if libavif wasn't compiled with encoding support
+* Add size_t casts to fix MSVC x86 compiler warnings (wantehchang)
+* Link with {ZLIB_LIBRARY} after ${PNG_LIBRARY} (wantehchang)
+* Fix a crash in avifJPEGRead() on fopen() failure (wantehchang)
+* No need to include `${ZLIB_INCLUDE_DIR}` (wantehchang)
+* Put the value of `ZLIB_INCLUDE_DIR` in the cache (wantehchang)
+* Don't set image->alphaRange to yuvRange (wantehchang)
+* Expose chroma sample position in decoded images (wantehchang)
+* avifDecoderNthImage: tighten decoder flush (wantehchang)
+* Cleanup avifIOReadFunc comments for clarity (wantehchang)
+* Minor code cleanup
+* Minor CMake cleanup
+
+### Removed
+
+* Remove disableGridImages from avifDecoder (wantehchang)
+
+## [0.8.2] - 2020-10-14
+### Added
+* `avifIO` reader API: allowing for parsing / image decoding without having the entire AVIF payload yet
+* Codec-specific options plumbing for advanced encoding settings
+* Add libaom codec-specific options (wantehchang)
+* avifenc: Allow endusers to ignore an AVIF's ICC profile during conversion (`--ignore-icc`)
+* avifenc: Allow the setting/overriding of XMP, Exif, and ICC profiles
+* Add the `disableGridImages` setting to `avifDecoder`
+* Add AVIF_FMT_ZU to fix compiling with non-standard/old compilers
+* Add `AVIF_ENABLE_WERROR` (ON by default)
+* Add `AVIF_ENABLE_COVERAGE` for basic llvm coverage report generation
+
+### Changed
+* Support multiple extents in an ItemLocationBox
+* Store all alpha payloads before color payloads in mdat
+* Perform 0.5 UV bias with integers, as 128/512/2048 aren't exactly 0.5, but are expected to behave as such
+* Avoid libpng's complaints about specific ICC profiles
+* Disable receiving one-frame-per-layer when decoding scalable AVIFs with aom and dav1d
+* Fix incorrect 8-to-16 monochrome YUV conversion
+* Set max image size to 16384 * 16384
+* Remove range and sample position from avifImageStealPlanes()
+* Ensure only one of each mandatory-unique box in a meta box exists
+* Ensure each item ID is cited once in an iloc box
+* Sanity check merged extents item size against the file size
+* Various image grid bugfixes
+* Error out with AVIF_RESULT_REFORMAT_FAILED if request uses an unsupported MC
+* Fix memory leak in avifenc when encoding image sequences
+* Move oss-fuzz fuzzer implementation into `tests/oss-fuzz`
+* avifdec: actually propagate the commandline codecChoice to the avifDecoder
+* Fix an infinite loop in codec_dav1d on a carefully-malformed AV1 payload
+* Fix a few issues with warnings in gcc/clang
+* Various comments tweaks
+
+## [0.8.1] - 2020-08-05
+
+### Added
+* Add `ignoreAlpha` field to avifRGBImage (linkmauve)
+* Save support in gdk-pixbuf component (novomesk)
+
+### Changed
+* Only ever create one iref box, filled with multiple cdsc boxes (#247)
+* Fix incorrect 16-to-8 monochrome YUV conversion
+* Make decoding optional in CMake, like encoding is
+* Include avif INTERFACE_INCLUDE_DIRECTORIES first (cryptomilk)
+* Set C standard to C99, adjust flags for dav1d (1480c1)
+* Minor cleanup/fixes in reformat.c (wantehchang)
+* Fix a crash in the gdk-pixbuf loader, removed unnecessary asserts (novomesk)
+
+## [0.8.0] - 2020-07-14
+
+### Added
+* Monochrome (YUV400) support **
+  * All encoding/decoding and internal memory savings are done/functional
+  * libaom has a bug in chroma_check() which crashes when encoding monochrome, to be fixed in a future (>v2.0.0) version
+  * rav1e didn't implement CS400 until rav1e v0.4.0
+  * libavif safely falls back to YUV420 when these earlier codec versions are detected
+    * NOTE: If you want to do heavy monochrome testing, wait for newer versions to libaom/rav1e!
+* Image sequence encoding support
+  * Required medium-sized refactors in the codec layers
+  * Image sequences (tracks) now fully support all metadata properly (Exif/XMP/transforms)
+  * avifenc can now encode a series of same-sized images with a consistent framerate, or each with their own custom duration
+* Bilinear upsampling support
+* avifenc: Add --ignore-icc, which avoids embedding the ICC profile found in the source image
+* avifdec: Add --info, which attempts to decode all frames and display their basic info (merge of avifdump)
+* avifenc: add --tilerowslog2 and --tilecolslog2 (wantehchang)
+* Added `contrib` dir for any unofficially supported code contributions (e.g. gdk-pixbuf)
+
+### Changed
+* CICP Refactor (breaking change!)
+  * Remove most references to "NCLX", as it is mostly an implementation detail, and the values are really from MPEG-CICP
+  * Eliminate avifProfileFormat: having an ICC profile is not mutually exclusive with signaling CICP
+  * CICP is now always available in an avifImage, set to unspecified by default
+  * Added --cicp as an alias for --nclx (semi-deprecated)
+  * Setting CICP via avifenc no longer overrides ICC profiles, they co-exist
+  * Simplified avifenc argument parsing / warnings logic
+  * avifenc/avifdec/avifdump now all display CICP when dumping AVIF information
+  * nclx colr box contents are guaranteed to override AV1 bitstream CICP (as MIAF standard specifies)
+  * Added comments explaining various decisions and citing standards
+  * Removed ICC inspection code regarding chroma-derived mtxCoeffs; this was overdesigned. Now just honor the assoc. colorPrimaries enum
+  * Reworked all examples in the README to reflect the new state of things, and clean out some cruft
+  * Harvest CICP from AV1 bitstream as a fallback in avifDecoderParse() if nclx box is absent
+* All data other than actual pixel data should be available and valid after a call to avifDecoderParse()
+* Refactor avifDecoder internal structures to properly handle meta boxes in trak boxes (see avifMeta)
+* Update libaom.cmd to point at the v2.0.0 tag
+* Update dav1d.cmd to point at the 0.7.1 tag
+* Re-enable cpu-used=7+ in codec_aom when libaom major version > 1
+* Memory allocation failures now cause libavif to abort the process (rather than undefined behavior)
+* Fix to maintain alpha range when decoding an image grid with alpha
+* Improvements to avifyuv to show drift when yuv and rgb depths differ
+* Remove any references to (incorrect) "av01" brand (wantehchang)
+* Set up libaom to use reduced_still_picture_header (wantehchang)
+* Use libaom cpu_used 6 in "good quality" usage mode (wantehchang)
+* Update avifBitsReadUleb128 with latest dav1d code (wantehchang)
+* Set encoder chroma sample position (wantehchang)
+
+## [0.7.3] - 2020-05-04
+### Added
+- avifenc: Lossless (--lossless, -l) mode, which sets new defaults and warns when anything would cause the AVIF to not be lossless
+
+### Changed
+- Minor cleanup for -Wclobbered warnings
+- Minor fixes to README and code (fallout from enum rework)
+- Protect against oversized (out of bounds) samples in avif sample tables
+- Optimization: avoid AV1 sample copying when feeding data to dav1d
+
+## [0.7.2] - 2020-04-24
+### Added
+- Recognize extensions with capital letters / capslock
+- Proper support for AVIF_NCLX_MATRIX_COEFFICIENTS_IDENTITY
+
+### Changed
+- Large nclx enum refactor (breaking change), reworking all 3 enums to better match AV1 codec enums
+- Fixes to 'essential' item properties (marking av1C as essential, ignoring any items containing unsupported essential props)
+- avifenc - Allow --nclx to override embedded ICC profiles (with a warning), instead of --nclx being ignored
+- avifenc - Choose high-quality-but-lossy QP defaults, and a default speed of 8
+- avifdump - Fix format specifiers for 32bit
+- Now prioritizing libaom over rav1e when both are present
+- Remove `-Wclobbered` dodging (volatile) and instead just disable the warning in avifpng/avifjpeg
+- avifyuv: extra testing modes
+- Cleanup to avifCodecVersions()
+- Reorganize iccjpeg code back into its own files for licensing conveniences
+
+## [0.7.1] - 2020-04-16
+### Changed
+- avifenc: Set nclx/range values in avifImage earlier so proper YUV coefficients are used when converting JPEG/PNG
+
+## [0.7.0] - 2020-04-16
+### Added
+- avifenc and avifdec JPEG support
+- Docker test script to build avifenc + deps in a shared libs (distro-like) env
+- Added simple `avifdump` tool for aiding in AVIF debugging
+- Added some comments in `avif.h` to clarify `avifDecoderSetSource()` usage
+
+### Changed
+- avifRange cleanup/refactor (breaking change)
+- avifenc now has `-r` to set YUV range (when using JPEG/PNG), `--nclx` now takes 3 arguments as a result
+
+## [0.6.4] - 2020-04-14
+### Added
+- Added `avifDecoderNthImageTiming()` for querying frame timing without needing to decode the frame
+- Added some comments explaining `avifDecoderSetSource()`
+
+### Changed
+- Fix clang warning (switch clamp to min)
+- Fix a few clang analyzer issues
+- Avoid incorrect YUV range cast
+- Call dav1d_data_unref in dav1dCodecDestroyInternal (wantehchang)
+- Declare some avifSampleTable * pointers as const (wantehchang)
+- Update to cJSON v1.7.13 (wantehchang)
+- Minor code cleanup
+
+## [0.6.3] - 2020-03-30
+### Changed
+- Avoid throwing away const unnecessarily in `avifROStreamReadString()`
+- Re-enable a bunch of clang warnings
+- Set dav1dSettings.frame_size_limit to avoid OOM (wantehchang)
+- Refactor write.c to use a similar Data/Item design as read.c
+- YUV to RGB optimizations
+
+## [0.6.2] - 2020-03-11
+### Changed
+- Fix 16bpc PNG output
+- Compile fixes to avoid -Wclobbered in PNG code
+- GitHub automatic deployment from AppVeyor (EwoutH)
+
+## [0.6.1] - 2020-03-11
+### Added
+- PNG support for avifenc/avifdec
+
+### Changed
+- Fixed Clang10 build warning
+- Fix SOVERSION in cmake (cryptomilk)
+- Minor tweaks to avifBool usage (wantehchang)
+
+## [0.6.0] - 2020-03-09
+### Added
+- `avifRGBImage` structure and associated routines (BREAKING CHANGE)
+- avifImage alphaRange support
+- Support pasp, clap, irot, imir metadata for encode/decode
+
+### Changed
+- Large RGB conversion refactor (BREAKING CHANGE), see README for new examples
+- Minor fixes to make Clang 10 happy
+- pkg-config fixes
+- Lots of minor cleanup in code/CMake (wantehchang)
+- Fix to NCLX color profile plumbing (ledyba-z)
+- Cleanup unnecessary avifBool ternary expressions
+- Update default dav1d version to 0.6.0
+- Update default rav1e version to v0.3.1
+
+## [0.5.7] - 2020-03-03
+### Added
+- libgav1 decode codec support. (wantehchang @Google)
+- Expose codec selection to avifdec/avifenc, speed to avifenc
+- Image grid support (Summer_in_Tomsk_720p_5x4_grid)
+- `minQuantizerAlpha`/`maxQuantizerAlpha` support in avifEncoder, avifenc
+- 444alpha support in y4m layer (avifenc, avifdec)
+- pkg-config support (cryptomilk)
+- Proper support of NCLX matrix coefficients enum (link-u)
+
+### Changed
+- AppVeyor builds now compile with dav1d (EwoutH)
+- Lots of minor CMake/code cleanup (wantehchang @Google)
+- cJSON license note for aviftest (wantehchang @Google)
+
+## [0.5.6] - 2020-02-19
+### Added
+- Added CMake Find modules for aom, dav1d, rav1e (cryptomilk)
+
+### Changed
+- use right-most and bottom-most UV pixels in images with odd-dimensions (ledyba-z)
+- avoid libaom crash when encoding >8bpc images at high speed
+
+## [0.5.5] - 2020-02-13
+### Added
+- Enable still picture mode with rav1e >= 0.3.0 (cryptomilk)
+- Basic test suite (aviftest, rough draft)
+
+### Changed
+- Explicitly cast unorms to float during YUV conversion, fixing clang warning
+- Optimize SampleSizeBox parsing when sample_size>0, fixes OOM oss-fuzz issue #5192805347753984
+- Fix memory leak when using avifDecoderReset(), fixes oss-fuzz issue #5770230506979328
+- Update default rav1e version from 0.2.1 to 0.3.0
+- Remove a null check for codec->internal->image (wantehchang)
+
+## [0.5.4] - 2020-01-21
+### Changed
+- Fix monochrome inputs on avifImageCopy. Monochrome still isn't really a first-class citizen in libavif, but this should at least honor the incoming data better.
+- Updated README's Basic Decoding section reminding of avifDecoderRead's tradeoffs
+- build: avoid -ldl if not required or not supported (jbeich)
+- apps: convert ADVANCE to an expression (jbeich)
+
+## [0.5.3] - 2019-12-03
+### Added
+- Honor CMake's builtin `CMAKE_SKIP_INSTALL_RULES`
+
+### Changed
+- avifenc - Removed accidental double-delete of avifImage when failing to read a y4m file input
+- Round dimensions down when decoding subsampled YUV with odd dimensions
+
+## [0.5.2] - 2019-11-23
+### Changed
+- Fix incorrect free in 0-case for `avifRWDataSet()`
+
+## [0.5.1] - 2019-11-21
+### Changed
+- Fix expectations for Exif payload to better match normal usage
+
+## [0.5.0] - 2019-11-21
+### Added
+- Define version and SO-version for shared library
+- Use -DBUILD_SHARED_LIBS=OFF for building a static lib
+- avifImage can now hold Exif and XMP metadata (`avifImageSetMetadataExif`, `avifImageSetMetadataXMP`)
+- Support for reading/writing Exif and XMP items
+- Now tracking idat boxes across meta boxes
+- Support for iloc construction_method 1 (idat)
+
+### Changed
+- Proper handling of the primary item box (pitm) on read
+- avifROStreamReadString() now allows string skipping by passing a NULL output buffer
+- Updated README to show Exif/XMP support
+
+## [0.4.8] - 2019-11-19
+### Added
+- avifEncoder now has a speed setting
+- codec_aom only flushes encoder when necessary (avoids lost frame packets)
+- shared library compilation (build shared by default, use `-DAVIF_BUILD_STATIC=1` for static lib)
+- make install support
+- cmake fixes/support for find_package (cryptomilk)
+
+### Changed
+- Updated libaom to more recent SHA in aom.cmd
+- Tweaked AVIF_LOCAL_AOM settings to play nice with libaom's usage of CMake's option()
+- Remove all libaom special cases from libavif's CMakefiles, and have it work the same way dav1d and rav1e do
+- Minor cleanup
+
+## [0.4.7] - 2019-11-11
+### Changed
+- Fix memory leak in rav1e codec (PR20, AurelC2G)
+- Bump rav1e version in rav1e.cmd, implement `avifCodecVersionRav1e()`
+- Display versions in avifenc and avifdec
+
+## [0.4.6] - 2019-10-30
+### Changed
+- Fix rav1e build on Linux x64, and eliminate pseudo-dependency on cargo-c
+
+## [0.4.5] - 2019-10-30
+### Changed
+- Fix rav1e codec's alpha encoding (monochrome asserts, might be unsupported still)
+
+## [0.4.4] - 2019-10-30
+### Changed
+- Fix QP range for rav1e encodes (rav1e uses [0-255], not [0-63])
+- Distribute out and share code populating av01 config box across codecs
+
+## [0.4.3] - 2019-10-28
+### Added
+- rav1e codec support (encode-only)
+- `rav1e.cmd` and `dav1d.cmd` to ext
+
+### Changed
+- All codecs can coexist peacefully now, and can be queried for availability or specifically chosen at encode/decode time
+- Updated README to indicate changes to CMake which facilitate codec reorg
+
+## [0.4.2] - 2019-10-17
+### Changed
+- Populate nclx box inside of OBU in addition to AVIF container
+
+## [0.4.1] - 2019-10-17
+### Added
+- Added `containerDepth` to avifDecoder for surfacing 10bpc/12bpc flags from av1C boxes, if present
+- Added `avifCodecVersions()` for getting version strings of internal AV1 codecs
+
+### Changed
+- Fixed warning with CHECK macro (additional semicolon)
+
+## [0.4.0] - 2019-10-02
+### Added
+- exposed util functions: `avifFullToLimitedY`, `avifFullToLimitedUV`, `avifLimitedToFullY`, `avifLimitedToFullUV`, `avifPrepareReformatState`
+
+### Changed
+- Renamed ispeWidth/ispeHeight to containerWidth/containerHeight; they now can hold tkhd's width/height
+- Split avifImageYUVToRGB into faster internal functions (estimated gain: 3.5x)
+- Fixed a few memory leaks, one in the README, one in codec_dav1d (AurelC2G)
+
+## [0.3.11] - 2019-09-26
+### Added
+- Exposed ispeWidth/ispeHeight to decoder if decoding items with an associated ispe box
+- Now parsing/tracking sample description formats to filter non-av01 type tracks
+- Allow brand 'av01' to be decoded
+
+### Changed
+- Fixed bug in sync sample table element sizing
+- Pass through starting sample index to codec when flushing with NthImage
+
+## [0.3.10] - 2019-09-26
+### Added
+- stss box parsing for keyframe information
+- avifBool avifDecoderIsKeyframe(avifDecoder * decoder, uint32_t frameIndex);
+- uint32_t avifDecoderNearestKeyframe(avifDecoder * decoder, uint32_t frameIndex);
+- avifResult avifDecoderNthImage(avifDecoder * decoder, uint32_t frameIndex);
+- aviffuzz prints keyframe information as it repeatedly decodes
+
+### Changed
+- internally renamed codec function "decode" to "open", as that's all it does
+- dav1d codec's open function no longer does an initial unnecessary feed
+- avifCodecDecodeInput now stores an array of avifSample which know if they're keyframes
+- moved codec flushing code into avifDecoderFlush() so it is available to avifDecoderNthImage
+- ptsInTimescales is now calculated independently of frame decode order
+
+## [0.3.9] - 2019-09-25
+### Changed
+- Split avifRawData and avifStream into read-only (const) and read/write versions, updated code accordingly
+- Fix a few clang/macOS warnings
+
+## [0.3.8] - 2019-09-04
+### Changed
+- Reverted codec_aom and libaom to use previous SHA (v1.0.0-errata1 is ancient)
+
+## [0.3.7] - 2019-09-04 - *DO NOT USE THIS VERSION*
+### Added
+- Check for proper width/height/depth when decoding alpha with dav1d, matching libaom's impl
+
+### Changed
+- Updated codec_aom and libaom to use v1.0.0-errata1
+
+## [0.3.6] - 2019-07-25
+### Added
+- Exposed tile encoding to avifEncoder
+
+## [0.3.5] - 2019-07-25
+### Changed
+- Fixed copypasta bug in libaom encoding quantizer setup
+
+## [0.3.4] - 2019-07-25
+### Added
+- When the AVIF container does not contain a color profile, fallback to the color OBU's nclx
+
+## [0.3.3] - 2019-07-24
+### Added
+- new helper function `avifPeekCompatibleFileType()`
+- expose ioStats on avifDecoder again (currently only interesting when reading items)
+
+### Changed
+- Fixed some warnings (removed unused variables and a bad cast)
+- Add a define in dav1d layer for supporting older dav1d codecs
+- Enabled tons of warnings, and warnings-as-errors; Fixed associated fallout
+- codec_dav1d: disambiguate "needs more data" and "no more frames" in feed data pump
+
+## [0.3.2] - 2019-07-23
+### Added
+- Added `ext/aom.cmd` to perform a local checkout of the aom codebase, as an alternative to a real submodule. This allows downstream projects to use libavif without recursive submodule issues.
+- AppVeyor and Travis scripts now explicitly clone libaom into ext/ as an alternative to a submodule.
+
+### Changed
+- Remove `ext/aom` as a submodule. If libavif users want to build aom from ext/, they must enable `AVIF_BUILD_AOM` and supply their own local copy.
+- Move the handful of public domain gb_math functions used by colr.c and eliminate the dependence on the gb library
+- Detect when libaom or libdav1d is being included by a parent CMake project and allow it
+- Offer libavif's include dir alongside the library in CMake (target_include_directories)
+
+## [0.3.1] - 2019-07-22
+### Changed
+- Moved dependency on libm to avif executables, instead of directly on the library
+- Minor changes to README examples
+
+## [0.3.0] - 2019-07-22
+### Added
+- new CMake option `AVIF_CODEC_AOM` to enable/disable the usage of AOM's codec (default: on)
+- new CMake option `AVIF_CODEC_DAV1D` to enable/disable the usage of dav1d's codec (default: off)
+- `codec_dav1d.c`, which provides decoding via `libdav1d`
+- fuzz.sh which builds with afl-clang and runs afl-fuzz
+- aviffuzz tool, used in fuzzing script
+- fuzz inputs made with colorist
+- `.clang-format` file
+- `avifArray*()` functions for basic dynamic arrays when parsing
+- `moov` box parsing
+- now reads 'avis' brands
+- Split avifDecoderRead() into components for image sequences:
+  - avifDecoderSetSource()
+  - avifDecoderParse()
+  - avifDecoderNextImage()
+  - avifImageCopy()
+  - avifDecoderReset()
+- Added decoder and image timings for image sequences
+
+### Changed
+- Reorganized internal struct avifCodec to accommodate multiple codecs simultaneously (compile time; not exposed to API)
+- Fix some compiler warnings
+- Sanity check offsets and sizes in items table before using
+- Bail out of box header advertises an impossible size
+- Ran clang-format on all of src and include
+- Fix copypasta leading to a memory leak in RGB planes
+- Switched items and properties during parse to use dynamic arrays
+- Refactored codec API to not require each codec to maintain per-plane decoder instances
+- avifImage can now "not own" its planes and directly point at decoder planes to avoid copies
+- aviffuzz attempts to decode all images in source material twice (using avifDecoderReset())
+- Switch decoder->quality to explicit [minQuantizer, maxQuantizer], update assoc. constants
+- Add examples to README
+
+## [0.2.0] - 2019-06-12
+### Added
+- Added `avifEncoder` and `avifDecoder` to match `avifImage`'s pattern and allow for easier future parameterization
+
+### Changed
+- Renamed project in cmake to `libavif` to match new official repo naming
+- Updated appveyor script to use `libavif`
+- Updated examples and apps to use new encoder/decoder pattern
+
+## [0.1.4] - 2019-06-11
+### Added
+- `avifPixelFormatToString()` convenience function for debugging/printing
+- `avifenc` and `avifdec` "apps" which show basic bidirectional conversion to y4m
+
+### Changed
+- Make calling `avifImageYUVToRGB()` upon reading an avif optional
+- Moved `ext/aom` submodule to use official remote
+- Update `ext/aom` submodule to commit [38711e7fe](https://aomedia.googlesource.com/aom/+/38711e7fe1eff68296b0324a9809804aec359fa5)
+
+### Removed
+- Remove all calls to `convertXYZToXYY()` as they were all unnecessary
+
+## [0.1.3] - 2019-04-23
+### Changed
+- `ftyp` - Change `major_brand` to `avif`
+- `ftyp` - Reorder `compatible_brands`, add `MA1A` or `MA1B` when appropriate
+- Write `meta` box before `mdat` box for streaming friendliness
+
+## [0.1.2] - 2019-04-18
+### Added
+- `AVIF_NCLX_COLOUR_PRIMARIES_P3` (convenient mirrored value)
+- `avifNclxColourPrimariesFind()` - Finds a builtin avifNclxColourPrimaries and name by a set of primaries
+
+### Changed
+- Fixed enum name copypasta for `AVIF_NCLX_COLOUR_PRIMARIES_EG432_1`
+- Fix UV limited ranges when doing full<->limited range conversion
+
+## [0.1.1] - 2019-04-15
+### Added
+- Added `appveyor.yml` (exported from Appveyor)
+- Move `ext/aom` to a proper submodule
+- Update AOM to commit [3e3b9342a](https://aomedia.googlesource.com/aom/+/3e3b9342a20147ec6e4f89aa290e20277c1260ce) with minor CMake changes
+
+### Changed
+- Added static library artifact zip to Windows x64 builds (Appveyor)
+- Updated README to explain libavif's goals and a little more build info
+- Fix clang warning in `avifVersion()` signature
+
+## [0.1.0] - 2019-04-12
+### Added
+- First version. Plenty of bugfixes and features await!
+- `ext/aom` based off AOM commit [3563b12b](https://aomedia.googlesource.com/aom/+/3563b12b766639ba445eb0e62a225a4419594aef) with minor CMake changes
+- An interest and willingness to maintain this file.
+- Constants `AVIF_VERSION`, `AVIF_VERSION_MAJOR`, `AVIF_VERSION_MINOR`, `AVIF_VERSION_PATCH`
+- `avifVersion()` function
+
+[Unreleased]: https://github.com/AOMediaCodec/libavif/compare/v1.1.1...HEAD
+[1.1.1]: https://github.com/AOMediaCodec/libavif/compare/v1.1.0...v1.1.1
+[1.1.0]: https://github.com/AOMediaCodec/libavif/compare/v1.0.0...v1.1.0
+[1.0.4]: https://github.com/AOMediaCodec/libavif/compare/v1.0.3...v1.0.4
+[1.0.3]: https://github.com/AOMediaCodec/libavif/compare/v1.0.2...v1.0.3
+[1.0.2]: https://github.com/AOMediaCodec/libavif/compare/v1.0.1...v1.0.2
+[1.0.1]: https://github.com/AOMediaCodec/libavif/compare/v1.0.0...v1.0.1
+[1.0.0]: https://github.com/AOMediaCodec/libavif/compare/v0.11.1...v1.0.0
+[0.11.1]: https://github.com/AOMediaCodec/libavif/compare/v0.11.0...v0.11.1
+[0.11.0]: https://github.com/AOMediaCodec/libavif/compare/v0.10.1...v0.11.0
+[0.10.1]: https://github.com/AOMediaCodec/libavif/compare/v0.10.0...v0.10.1
+[0.10.0]: https://github.com/AOMediaCodec/libavif/compare/v0.9.3...v0.10.0
+[0.9.3]: https://github.com/AOMediaCodec/libavif/compare/v0.9.2...v0.9.3
+[0.9.2]: https://github.com/AOMediaCodec/libavif/compare/v0.9.1...v0.9.2
+[0.9.1]: https://github.com/AOMediaCodec/libavif/compare/v0.9.0...v0.9.1
+[0.9.0]: https://github.com/AOMediaCodec/libavif/compare/v0.8.4...v0.9.0
+[0.8.4]: https://github.com/AOMediaCodec/libavif/compare/v0.8.3...v0.8.4
+[0.8.3]: https://github.com/AOMediaCodec/libavif/compare/v0.8.2...v0.8.3
+[0.8.2]: https://github.com/AOMediaCodec/libavif/compare/v0.8.1...v0.8.2
+[0.8.1]: https://github.com/AOMediaCodec/libavif/compare/v0.8.0...v0.8.1
+[0.8.0]: https://github.com/AOMediaCodec/libavif/compare/v0.7.3...v0.8.0
+[0.7.3]: https://github.com/AOMediaCodec/libavif/compare/v0.7.2...v0.7.3
+[0.7.2]: https://github.com/AOMediaCodec/libavif/compare/v0.7.1...v0.7.2
+[0.7.1]: https://github.com/AOMediaCodec/libavif/compare/v0.7.0...v0.7.1
+[0.7.0]: https://github.com/AOMediaCodec/libavif/compare/v0.6.4...v0.7.0
+[0.6.4]: https://github.com/AOMediaCodec/libavif/compare/v0.6.3...v0.6.4
+[0.6.3]: https://github.com/AOMediaCodec/libavif/compare/v0.6.2...v0.6.3
+[0.6.2]: https://github.com/AOMediaCodec/libavif/compare/v0.6.1...v0.6.2
+[0.6.1]: https://github.com/AOMediaCodec/libavif/compare/v0.6.0...v0.6.1
+[0.6.0]: https://github.com/AOMediaCodec/libavif/compare/v0.5.7...v0.6.0
+[0.5.7]: https://github.com/AOMediaCodec/libavif/compare/v0.5.6...v0.5.7
+[0.5.6]: https://github.com/AOMediaCodec/libavif/compare/v0.5.5...v0.5.6
+[0.5.5]: https://github.com/AOMediaCodec/libavif/compare/v0.5.4...v0.5.5
+[0.5.4]: https://github.com/AOMediaCodec/libavif/compare/v0.5.3...v0.5.4
+[0.5.3]: https://github.com/AOMediaCodec/libavif/compare/v0.5.2...v0.5.3
+[0.5.2]: https://github.com/AOMediaCodec/libavif/compare/v0.5.1...v0.5.2
+[0.5.1]: https://github.com/AOMediaCodec/libavif/compare/v0.5.0...v0.5.1
+[0.5.0]: https://github.com/AOMediaCodec/libavif/compare/v0.4.8...v0.5.0
+[0.4.8]: https://github.com/AOMediaCodec/libavif/compare/v0.4.7...v0.4.8
+[0.4.7]: https://github.com/AOMediaCodec/libavif/compare/v0.4.6...v0.4.7
+[0.4.6]: https://github.com/AOMediaCodec/libavif/compare/v0.4.5...v0.4.6
+[0.4.5]: https://github.com/AOMediaCodec/libavif/compare/v0.4.4...v0.4.5
+[0.4.4]: https://github.com/AOMediaCodec/libavif/compare/v0.4.3...v0.4.4
+[0.4.3]: https://github.com/AOMediaCodec/libavif/compare/v0.4.2...v0.4.3
+[0.4.2]: https://github.com/AOMediaCodec/libavif/compare/v0.4.1...v0.4.2
+[0.4.1]: https://github.com/AOMediaCodec/libavif/compare/v0.4.0...v0.4.1
+[0.4.0]: https://github.com/AOMediaCodec/libavif/compare/v0.3.11...v0.4.0
+[0.3.11]: https://github.com/AOMediaCodec/libavif/compare/v0.3.10...v0.3.11
+[0.3.10]: https://github.com/AOMediaCodec/libavif/compare/v0.3.9...v0.3.10
+[0.3.9]: https://github.com/AOMediaCodec/libavif/compare/v0.3.8...v0.3.9
+[0.3.8]: https://github.com/AOMediaCodec/libavif/compare/v0.3.7...v0.3.8
+[0.3.7]: https://github.com/AOMediaCodec/libavif/compare/v0.3.6...v0.3.7
+[0.3.6]: https://github.com/AOMediaCodec/libavif/compare/v0.3.5...v0.3.6
+[0.3.5]: https://github.com/AOMediaCodec/libavif/compare/v0.3.4...v0.3.5
+[0.3.4]: https://github.com/AOMediaCodec/libavif/compare/v0.3.3...v0.3.4
+[0.3.3]: https://github.com/AOMediaCodec/libavif/compare/v0.3.2...v0.3.3
+[0.3.2]: https://github.com/AOMediaCodec/libavif/compare/v0.3.1...v0.3.2
+[0.3.1]: https://github.com/AOMediaCodec/libavif/compare/v0.3.0...v0.3.1
+[0.3.0]: https://github.com/AOMediaCodec/libavif/compare/v0.2.0...v0.3.0
+[0.2.0]: https://github.com/AOMediaCodec/libavif/compare/v0.1.4...v0.2.0
+[0.1.4]: https://github.com/AOMediaCodec/libavif/compare/v0.1.3...v0.1.4
+[0.1.3]: https://github.com/AOMediaCodec/libavif/compare/v0.1.2...v0.1.3
+[0.1.2]: https://github.com/AOMediaCodec/libavif/compare/v0.1.1...v0.1.2
+[0.1.1]: https://github.com/AOMediaCodec/libavif/compare/v0.1.0...v0.1.1
+[0.1.0]: https://github.com/AOMediaCodec/libavif/releases/tag/v0.1.0
diff --git a/third_party/libavif/src/CMakeLists.txt b/third_party/libavif/src/CMakeLists.txt
new file mode 100644
index 0000000000..b54a208b57
--- /dev/null
+++ b/third_party/libavif/src/CMakeLists.txt
@@ -0,0 +1,926 @@
+# Copyright 2019 Joe Drago. All rights reserved.
+# SPDX-License-Identifier: BSD-2-Clause
+
+cmake_minimum_required(VERSION 3.13)
+
+# New in CMake version 3.15. MSVC warning flags are not in CMAKE_<LANG>_FLAGS by default.
+if(POLICY CMP0092)
+    cmake_policy(SET CMP0092 NEW)
+endif()
+
+# Prevent warnings in CMake>=3.24 for ExternalProject_Add()
+# see https://cmake.org/cmake/help/latest/policy/CMP0135.html
+if(POLICY CMP0135)
+    cmake_policy(SET CMP0135 NEW) # valid for DOWNLOAD_EXTRACT_TIMESTAMP option in CMake 3.24 and later
+endif()
+
+# New in CMake version 3.30. FetchContent_Populate(<name>) is deprecated, call
+# FetchContent_MakeAvailable(<name>) instead.
+if(POLICY CMP0169)
+    cmake_policy(SET CMP0169 OLD)
+endif()
+
+project(libavif LANGUAGES C VERSION 1.1.1)
+
+# The root directory of the avif source
+set(AVIF_SOURCE_DIR "${CMAKE_CURRENT_SOURCE_DIR}")
+
+# Specify search path for CMake modules to be loaded by include() and find_package()
+list(APPEND CMAKE_MODULE_PATH "${CMAKE_CURRENT_SOURCE_DIR}/cmake/Modules")
+
+include(ExternalProject)
+include(FetchContent)
+include(FindPkgConfig)
+include(AvifExternalProjectUtils)
+
+option(AVIF_ENABLE_NODISCARD "Add [[nodiscard]] to some functions. CMake must be at least 3.21 to force C23." OFF)
+
+# Set C99 as the default
+if(AVIF_ENABLE_NODISCARD)
+    # [[nodiscard]] requires C23.
+    if(CMAKE_VERSION VERSION_LESS 3.21.0)
+        message(FATAL_ERROR "CMake must be at least 3.21 to force C23, bailing out")
+    endif()
+    set(CMAKE_C_STANDARD 23)
+    set(CMAKE_C_STANDARD_REQUIRED ON)
+else()
+    set(CMAKE_C_STANDARD 99)
+endif()
+
+# SOVERSION scheme: MAJOR.MINOR.PATCH
+#   If there was an incompatible interface change:
+#     Increment MAJOR. Set MINOR and PATCH to 0
+#   If there was a compatible interface change:
+#     Increment MINOR. Set PATCH to 0
+#   If the source code was changed, but there were no interface changes:
+#     Increment PATCH.
+set(LIBRARY_VERSION_MAJOR 16)
+set(LIBRARY_VERSION_MINOR 1)
+set(LIBRARY_VERSION_PATCH 1)
+set(LIBRARY_VERSION "${LIBRARY_VERSION_MAJOR}.${LIBRARY_VERSION_MINOR}.${LIBRARY_VERSION_PATCH}")
+set(LIBRARY_SOVERSION ${LIBRARY_VERSION_MAJOR})
+
+option(BUILD_SHARED_LIBS "Build shared avif library" ON)
+
+option(AVIF_ENABLE_WERROR "Treat all compiler warnings as errors" OFF)
+
+option(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R "Enable experimental YCgCo-R matrix code" OFF)
+option(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+       "Enable experimental gain map code (for HDR images that look good both on HDR and SDR displays)" OFF
+)
+option(AVIF_ENABLE_EXPERIMENTAL_MINI "Enable experimental reduced header" OFF)
+option(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM "Enable experimental sample transform code" OFF)
+
+set(AVIF_PKG_CONFIG_EXTRA_LIBS_PRIVATE "")
+set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "")
+
+function(set_local_or_system_option VAR DEFAULT TEXT)
+    # Deal with the older way of setting options.
+    if(DEFINED AVIF_LOCAL_${VAR})
+        if(AVIF_LOCAL_${VAR})
+            set(DEFAULT "LOCAL")
+        else()
+            set(DEFAULT "SYSTEM")
+        endif()
+        message(WARNING "Setting AVIF_LOCAL_${VAR} is deprecated. " "Set AVIF_${VAR} to ${DEFAULT} instead.")
+    elseif(DEFINED AVIF_${VAR})
+        set(DEFAULT ${AVIF_${VAR}})
+    endif()
+    set(AVIF_${VAR} ${DEFAULT} CACHE STRING ${TEXT} FORCE)
+    set_property(CACHE AVIF_${VAR} PROPERTY STRINGS OFF LOCAL SYSTEM)
+endfunction()
+function(set_codec_option CODEC NAME ENCDEC EXTRA)
+    if(DEFINED AVIF_CODEC_${CODEC})
+        set(DEFAULT ${AVIF_CODEC_${CODEC}})
+        # Deal with the older way of setting options.
+        if(AVIF_CODEC_${CODEC} STREQUAL "ON")
+            if(AVIF_LOCAL_${CODEC})
+                set(DEFAULT "LOCAL")
+            else()
+                set(DEFAULT "SYSTEM")
+            endif()
+            message(WARNING "Setting AVIF_CODEC_${CODEC} and AVIF_LOCAL_${CODEC} is deprecated. "
+                            "Set AVIF_CODEC_${CODEC} to ${DEFAULT} instead."
+            )
+        endif()
+    else()
+        set(DEFAULT "OFF")
+    endif()
+    if(AVIF_CODEC_${CODEC} STREQUAL "OFF" AND AVIF_LOCAL_${CODEC} STREQUAL "OFF")
+        message(WARNING "Setting AVIF_LOCAL_${CODEC} is deprecated. " "Only set AVIF_CODEC_${CODEC} to OFF instead.")
+    endif()
+    set(AVIF_CODEC_${CODEC} ${DEFAULT} CACHE STRING "Use the ${NAME} codec for ${ENCDEC}${EXTRA}" FORCE)
+    set_property(CACHE AVIF_CODEC_${CODEC} PROPERTY STRINGS OFF LOCAL SYSTEM)
+endfunction()
+set_codec_option(AOM "AOM" "encoding/decoding" " (see AVIF_CODEC_AOM_DECODE/AVIF_CODEC_AOM_ENCODE)")
+set_codec_option(DAV1D "dav1d" "decoding" "")
+set_codec_option(LIBGAV1 "libgav1" "decoding" "")
+set_codec_option(RAV1E "rav1e" "encoding" "")
+set_codec_option(SVT "SVT-AV1" "encoding" "")
+set_codec_option(AVM "AVM (AV2)" "encoding/decoding" " (EXPERIMENTAL)")
+
+# These options allow libavif to only link against / use libaom's encoder or decoder, instead of being forced to use both
+include(CMakeDependentOption)
+cmake_dependent_option(
+    AVIF_CODEC_AOM_DECODE "if AVIF_CODEC_AOM is on, use/offer libaom's decoder" ON "NOT AVIF_CODEC_AOM STREQUAL OFF" OFF
+)
+cmake_dependent_option(
+    AVIF_CODEC_AOM_ENCODE "if AVIF_CODEC_AOM is on, use/offer libaom's encoder" ON "NOT AVIF_CODEC_AOM STREQUAL OFF" OFF
+)
+
+set_local_or_system_option(
+    "GTEST" OFF
+    "Build the GoogleTest framework by providing your own copy of the repo in ext/googletest (see Local Builds in README)"
+)
+option(AVIF_BUILD_APPS "Build avif apps." OFF)
+option(AVIF_BUILD_TESTS "Build avif tests." OFF)
+option(
+    AVIF_ENABLE_COMPLIANCE_WARDEN
+    "Check all avifEncoderFinish() output for AVIF specification compliance. Depends on gpac/ComplianceWarden which can be added with ext/compliance_warden.sh"
+    OFF
+)
+option(
+    AVIF_ENABLE_GOLDEN_TESTS
+    "Build tests that compare encoding outputs to golden files. Needs AVIF_BUILD_APPS=ON and AVIF_BUILD_TESTS=ON, and depends on MP4box which can be built with ext/mp4box.sh"
+    OFF
+)
+option(AVIF_ENABLE_GTEST
+       "Build avif C++ tests, which depend on GoogleTest. Requires GoogleTest. Has no effect unless AVIF_BUILD_TESTS is ON." ON
+)
+option(AVIF_ENABLE_FUZZTEST "Build avif fuzztest targets. Requires Google FuzzTest. Has no effect unless AVIF_BUILD_TESTS is ON."
+       OFF
+)
+option(
+    AVIF_LOCAL_FUZZTEST
+    "Build the Google FuzzTest framework by providing your own copy of the repo in ext/fuzztest (see Local Builds in README). CMake must be at least 3.25."
+    OFF
+)
+
+# Whether the libavif library uses c++ indirectly (e.g. through linking to libyuv).
+set(AVIF_LIB_USE_CXX OFF)
+
+if(APPLE)
+    set(XCRUN xcrun)
+else()
+    set(XCRUN)
+endif()
+
+# This is also needed to get shared libraries (e.g. pixbufloader-avif) to compile against a static libavif.
+set(CMAKE_POSITION_INDEPENDENT_CODE ON)
+if(BUILD_SHARED_LIBS)
+    set(AVIF_LIBRARY_PREFIX "${CMAKE_SHARED_LIBRARY_PREFIX}")
+else()
+    set(AVIF_LIBRARY_PREFIX "${CMAKE_STATIC_LIBRARY_PREFIX}")
+endif()
+
+add_library(avif_obj OBJECT)
+add_library(avif)
+
+# Adds <target> to avif_obj's public link libraries for build, and adds
+# the <target> library as an install link library for export in case a consumer
+# needs to include that library alongside libavif when statically linking.
+function(avif_target_link_library target)
+    target_link_libraries(avif_obj PUBLIC $<BUILD_INTERFACE:${target}>)
+    get_target_property(target_is_local ${target} AVIF_LOCAL)
+    if(target_is_local)
+        return()
+    endif()
+    get_target_property(install_target ${target} IMPORTED_SONAME)
+    if(NOT install_target)
+        set(install_target ${target})
+    endif()
+    # The transitive dependency needs to be an export link library in a static build.
+    if(NOT BUILD_SHARED_LIBS)
+        target_link_libraries(avif PUBLIC $<INSTALL_INTERFACE:${install_target}>)
+    endif()
+endfunction()
+
+#[[
+check_avif_option(<option> TARGET <target> PKG_NAME <PackageName>)
+
+If <option> is equal to "SYSTEM", uses <target> if it already exists, otherwise calls find_package(<PackageName>). If <option>
+is "LOCAL", includes Local<PackageName>.cmake. Sets <option>_ENABLED to ON if the option is enabled and the target is usable.
+]]
+macro(check_avif_option _VAR)
+    set(_oneValueArgs TARGET PKG_NAME)
+    cmake_parse_arguments(_AVIF_OPTION "" "${_oneValueArgs}" "" ${ARGN})
+    string(SUBSTRING ${_AVIF_OPTION_PKG_NAME} 0 1 FIRST_LETTER)
+    string(TOUPPER ${FIRST_LETTER} FIRST_LETTER)
+    string(REGEX REPLACE "^.(.*)" "Local${FIRST_LETTER}\\1" _LOCAL_INCLUDE "${_AVIF_OPTION_PKG_NAME}")
+    set(${_VAR}_ENABLED OFF)
+    if(${_VAR} STREQUAL "LOCAL" OR ${_VAR} STREQUAL "SYSTEM")
+        if(${_VAR} STREQUAL "LOCAL" AND TARGET ${_AVIF_OPTION_TARGET})
+            message(ERROR "${_AVIF_OPTION_TARGET} is already defined and ${_VAR} should be set to SYSTEM to use it")
+            return()
+        endif()
+        set(${_VAR}_ENABLED ON)
+        if(NOT TARGET ${_AVIF_OPTION_TARGET})
+            if(${_VAR} STREQUAL "LOCAL")
+                include(${_LOCAL_INCLUDE})
+            elseif(${_VAR} STREQUAL "SYSTEM")
+                find_package(${_AVIF_OPTION_PKG_NAME} REQUIRED)
+            endif()
+        endif()
+    endif()
+endmacro()
+
+set_local_or_system_option("ZLIBPNG" "SYSTEM" "Use zlib and libpng.")
+if(AVIF_ZLIBPNG STREQUAL "LOCAL")
+    include(LocalZlibpng)
+endif()
+
+set_local_or_system_option("JPEG" "SYSTEM" "Use jpeg.")
+if(AVIF_JPEG STREQUAL "LOCAL")
+    include(LocalJpeg)
+endif()
+
+set_local_or_system_option("LIBYUV" "SYSTEM" "Use libyuv.")
+# check_avif_option libyuv must precede libaom because the latter needs to link against the former
+# when building libaom locally
+check_avif_option(AVIF_LIBYUV TARGET yuv::yuv PKG_NAME libyuv)
+if(AVIF_LIBYUV_ENABLED)
+    # libyuv 1755 exposed all of the I*Matrix() functions, which libavif relies on.
+    # libyuv 1774 exposed ScalePlane_12 function, which libavif can use for some additional optimizations.
+    # libyuv 1813 added the I*ToARGBMatrixFilter() functions, which libavif can use with the bilinear filter.
+    if(NOT LIBYUV_VERSION)
+        message(STATUS "libavif: libyuv found, but version unknown; libyuv-based fast paths disabled.")
+        unset(AVIF_LIBYUV_ENABLED)
+    elseif(LIBYUV_VERSION LESS 1755)
+        message(STATUS "libavif: libyuv (${LIBYUV_VERSION}) found, but is too old; libyuv-based fast paths disabled.")
+        unset(AVIF_LIBYUV_ENABLED)
+    else()
+        message(STATUS "libavif: libyuv (${LIBYUV_VERSION}) found; libyuv-based fast paths enabled.")
+        if(LIBYUV_VERSION LESS 1813)
+            message(STATUS "libavif: some libyuv optimizations require at least version 1813 to work.")
+        endif()
+    endif()
+endif()
+if(AVIF_LIBYUV_ENABLED)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_LIBYUV_ENABLED=1)
+    avif_target_link_library(yuv::yuv)
+    set(AVIF_PKG_CONFIG_EXTRA_LIBS_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_LIBS_PRIVATE} -lyuv")
+    set(AVIF_LIB_USE_CXX ON)
+endif(AVIF_LIBYUV_ENABLED)
+
+set_local_or_system_option("LIBSHARPYUV" "OFF" "Use libsharpyuv.")
+check_avif_option(AVIF_LIBSHARPYUV TARGET sharpyuv::sharpyuv PKG_NAME libsharpyuv)
+if(AVIF_LIBSHARPYUV_ENABLED)
+    message(STATUS "libavif: libsharpyuv found; sharp rgb to yuv conversion enabled.")
+    set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE} libsharpyuv")
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_LIBSHARPYUV_ENABLED=1)
+    avif_target_link_library(sharpyuv::sharpyuv)
+endif(AVIF_LIBSHARPYUV_ENABLED)
+
+set_local_or_system_option(
+    "LIBXML2" "OFF" "Build libxml2 by providing your own copy inside the ext subdir. \
+libxml2 is used when AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is ON"
+)
+
+if(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    check_avif_option(AVIF_LIBXML2 TARGET LibXml2::LibXml2 PKG_NAME LibXml2)
+endif()
+# ---------------------------------------------------------------------------------------
+
+# Enable all warnings
+include(CheckCCompilerFlag)
+# avif_enable_warnings is a CMake interface library. It has no source files.
+# Its only purpose is to serve as a carrier of warning-related compiler options
+# and macro definitions. We set them by calling target_compile_options() and
+# target_compile_definitions() on avif_enable_warnings. We enable compiler
+# warnings in a target by linking the target with avif_enable_warnings using
+# target_link_libraries().
+add_library(avif_enable_warnings INTERFACE)
+if(MSVC)
+    message(STATUS "libavif: Enabling warnings for MSVC")
+    target_compile_options(
+        avif_enable_warnings
+        INTERFACE /W4 # For clang-cl, /W4 enables -Wall and -Wextra
+                  /wd4232 # Disable: address of dllimport 'dllimport' is not static,
+                          # identity not guaranteed
+                  /wd4324 # Disable: structure was padded due to alignment specifier
+    )
+    # Disable deprecation warnings about POSIX function names such as setmode (replaced by the ISO C and C++ conformant name _setmode).
+    # Disable deprecation warnings about unsafe CRT library functions such as fopen (replaced by fopen_s).
+    target_compile_definitions(avif_enable_warnings INTERFACE _CRT_NONSTDC_NO_WARNINGS _CRT_SECURE_NO_WARNINGS)
+
+    # clang-cl documentation says:
+    #   /execution-charset:<value>
+    #                           Runtime encoding, supports only UTF-8
+    #   ...
+    #   /source-charset:<value> Source encoding, supports only UTF-8
+    # So we don't need to pass /source-charset:utf-8 to clang-cl, and we cannot pass /execution-charset:us-ascii to clang-cl.
+    if(CMAKE_C_COMPILER_ID MATCHES "MSVC")
+        target_compile_options(
+            avif_obj
+            PUBLIC $<BUILD_INTERFACE:
+                   # This tells MSVC to read source code as UTF-8 and assume console can only use ASCII (minimal safe).
+                   # libavif uses ANSI API to print to console, which is not portable between systems using different
+                   # languages and results in mojibake unless we only use codes shared by every code page: ASCII.
+                   # A C4556 warning will be generated on violation.
+                   # Commonly used /utf-8 flag assumes UTF-8 for both source and console, which is usually not the case.
+                   # Warnings can be suppressed but there will still be random characters printed to the console.
+                   /source-charset:utf-8
+                   /execution-charset:us-ascii
+                   >
+        )
+    endif()
+elseif(CMAKE_C_COMPILER_ID MATCHES "Clang")
+    message(STATUS "libavif: Enabling warnings for Clang")
+    target_compile_options(avif_enable_warnings INTERFACE -Wall -Wextra -Wshorten-64-to-32)
+elseif(CMAKE_C_COMPILER_ID MATCHES "GNU")
+    message(STATUS "libavif: Enabling warnings for GCC")
+    target_compile_options(avif_enable_warnings INTERFACE -Wall -Wextra)
+else()
+    message(FATAL_ERROR "libavif: Unknown compiler, bailing out")
+endif()
+
+if(AVIF_ENABLE_WERROR)
+    # Warnings as errors
+    if(MSVC)
+        target_compile_options(avif_enable_warnings INTERFACE /WX)
+    elseif(CMAKE_C_COMPILER_ID MATCHES "Clang" OR CMAKE_C_COMPILER_ID MATCHES "GNU")
+        target_compile_options(avif_enable_warnings INTERFACE -Werror)
+    else()
+        message(FATAL_ERROR "libavif: Unknown compiler, bailing out")
+    endif()
+endif()
+
+target_link_libraries(avif_obj PRIVATE avif_enable_warnings)
+
+if(AVIF_ENABLE_COVERAGE)
+    if(CMAKE_C_COMPILER_ID MATCHES "Clang" OR CMAKE_C_COMPILER_ID MATCHES "GNU")
+        message(STATUS "libavif: Enabling coverage for Clang")
+        target_compile_options(avif_obj PUBLIC $<BUILD_INTERFACE:-fprofile-instr-generate -fcoverage-mapping -O0>)
+        target_compile_options(avif PUBLIC $<BUILD_INTERFACE:-fprofile-instr-generate -fcoverage-mapping -O0>)
+        set(CMAKE_EXE_LINKER_FLAGS ${CMAKE_EXE_LINKER_FLAGS} "-fprofile-instr-generate -fcoverage-mapping")
+    else()
+        # TODO: Add support for other compilers
+        message(WARNING "libavif: Ignoring request for coverage (AVIF_ENABLE_COVERAGE); only clang is currently supported.")
+        set(AVIF_ENABLE_COVERAGE OFF)
+    endif()
+endif()
+
+if(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    add_compile_definitions(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+endif()
+
+if(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    add_compile_definitions(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+endif()
+
+if(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    add_compile_definitions(AVIF_ENABLE_EXPERIMENTAL_MINI)
+endif()
+
+if(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    add_compile_definitions(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+endif()
+
+set(AVIF_SRCS
+    src/alpha.c
+    src/avif.c
+    src/colr.c
+    src/colrconvert.c
+    src/diag.c
+    src/exif.c
+    src/io.c
+    src/mem.c
+    src/obu.c
+    src/rawdata.c
+    src/read.c
+    src/reformat.c
+    src/reformat_libsharpyuv.c
+    src/reformat_libyuv.c
+    src/scale.c
+    src/stream.c
+    src/utils.c
+    src/write.c
+)
+if(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    list(APPEND AVIF_SRCS src/gainmap.c)
+endif()
+if(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    list(APPEND AVIF_SRCS src/sampletransform.c)
+endif()
+
+if(AVIF_ENABLE_COMPLIANCE_WARDEN)
+    if(NOT EXISTS "${CMAKE_CURRENT_SOURCE_DIR}/ext/ComplianceWarden")
+        message(FATAL_ERROR "AVIF_ENABLE_COMPLIANCE_WARDEN: ext/ComplianceWarden is missing, bailing out")
+    endif()
+
+    set(AVIF_LIB_USE_CXX ON)
+    target_compile_definitions(avif_obj PRIVATE AVIF_ENABLE_COMPLIANCE_WARDEN)
+
+    list(
+        APPEND
+        AVIF_SRCS
+        src/compliance.cc
+        ext/ComplianceWarden/src/app/cw.cpp
+        ext/ComplianceWarden/src/app/options.cpp
+        ext/ComplianceWarden/src/app/report_std.cpp
+        ext/ComplianceWarden/src/app/report_json.cpp
+        ext/ComplianceWarden/src/utils/common_boxes.cpp
+        ext/ComplianceWarden/src/utils/tools.cpp
+        ext/ComplianceWarden/src/utils/av1_utils.cpp
+        ext/ComplianceWarden/src/utils/isobmff_utils.cpp
+        ext/ComplianceWarden/src/utils/isobmff_derivations.cpp
+        ext/ComplianceWarden/src/utils/spec_utils.cpp
+        ext/ComplianceWarden/src/specs/av1_hdr10plus/av1_hdr10plus.cpp
+        ext/ComplianceWarden/src/specs/avif/avif.cpp
+        ext/ComplianceWarden/src/specs/avif/profiles.cpp
+        ext/ComplianceWarden/src/specs/avif/utils.cpp
+        ext/ComplianceWarden/src/specs/isobmff/isobmff.cpp
+        ext/ComplianceWarden/src/specs/heif/heif.cpp
+        ext/ComplianceWarden/src/specs/miaf/miaf.cpp
+        ext/ComplianceWarden/src/specs/miaf/audio.cpp
+        ext/ComplianceWarden/src/specs/miaf/brands.cpp
+        ext/ComplianceWarden/src/specs/miaf/derivations.cpp
+        ext/ComplianceWarden/src/specs/miaf/colours.cpp
+        ext/ComplianceWarden/src/specs/miaf/num_pixels.cpp
+        ext/ComplianceWarden/src/specs/miaf/profiles.cpp
+        ext/ComplianceWarden/src/cw_version.cpp
+    )
+endif()
+
+target_sources(avif_obj PRIVATE ${AVIF_SRCS})
+
+# Only applicable to macOS. In GitHub CI's macos-latest os image, this prevents using the libpng
+# and libjpeg headers from /Library/Frameworks/Mono.framework/Headers instead of
+# /usr/local/include.
+set(CMAKE_FIND_FRAMEWORK LAST)
+
+if(UNIX OR MINGW)
+    # Find out if we have threading available
+    set(THREADS_PREFER_PTHREAD_FLAG ON)
+    find_package(Threads)
+    target_link_libraries(avif_obj PRIVATE m Threads::Threads)
+endif()
+
+if(NOT AVIF_LIBYUV_ENABLED)
+    target_sources(
+        avif_obj
+        PRIVATE third_party/libyuv/source/scale.c third_party/libyuv/source/scale_common.c third_party/libyuv/source/scale_any.c
+                third_party/libyuv/source/row_common.c third_party/libyuv/source/planar_functions.c
+    )
+    if(DEFINED ANDROID_ABI OR DEFINED APPLE)
+        # When building third_party/libyuv/source/scale.c, some functions use
+        # some of the parameters only inside an assert statement. This causes
+        # unused parameter warnings when building for Android. Suppress the
+        # warning in that case.
+        target_compile_options(avif_obj PRIVATE -Wno-unused-parameter)
+    endif()
+endif()
+
+check_avif_option(AVIF_CODEC_DAV1D TARGET dav1d::dav1d PKG_NAME dav1d)
+if(AVIF_CODEC_DAV1D_ENABLED)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_DAV1D=1)
+    target_sources(avif_obj PRIVATE src/codec_dav1d.c)
+
+    if(UNIX AND NOT APPLE)
+        target_link_libraries(dav1d::dav1d INTERFACE ${CMAKE_DL_LIBS}) # for dlsym
+    endif()
+
+    avif_target_link_library(dav1d::dav1d)
+
+    message(STATUS "libavif: Codec enabled: dav1d (decode)")
+    set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE} dav1d")
+endif()
+
+check_avif_option(AVIF_CODEC_LIBGAV1 TARGET libgav1::libgav1 PKG_NAME libgav1)
+if(AVIF_CODEC_LIBGAV1_ENABLED)
+    set(AVIF_LIB_USE_CXX ON)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_LIBGAV1=1)
+    target_sources(avif_obj PRIVATE src/codec_libgav1.c)
+    avif_target_link_library(libgav1::libgav1)
+
+    message(STATUS "libavif: Codec enabled: libgav1 (decode)")
+endif()
+
+check_avif_option(AVIF_CODEC_RAV1E TARGET rav1e::rav1e PKG_NAME rav1e)
+if(AVIF_CODEC_RAV1E_ENABLED)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_RAV1E=1)
+    target_sources(avif_obj PRIVATE src/codec_rav1e.c)
+
+    # Unfortunately, rav1e requires a few more libraries
+    # first check that RAV1E_LIBRARIES hasn't been populated by the LocalRav1e module
+    if(NOT RAV1E_LIBRARIES)
+        if(WIN32)
+            target_link_libraries(rav1e::rav1e INTERFACE ntdll.lib userenv.lib ws2_32.lib bcrypt.lib)
+        elseif(UNIX AND NOT APPLE)
+            target_link_libraries(rav1e::rav1e INTERFACE ${CMAKE_DL_LIBS}) # for backtrace
+        endif()
+    endif()
+
+    avif_target_link_library(rav1e::rav1e)
+
+    message(STATUS "libavif: Codec enabled: rav1e (encode)")
+    set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE} rav1e")
+endif()
+
+check_avif_option(AVIF_CODEC_SVT TARGET SvtAv1Enc PKG_NAME svt)
+if(AVIF_CODEC_SVT_ENABLED)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_SVT=1)
+    target_sources(avif_obj PRIVATE src/codec_svt.c)
+    avif_target_link_library(SvtAv1Enc)
+
+    message(STATUS "libavif: Codec enabled: svt (encode)")
+    set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE} SvtAv1Enc")
+endif()
+
+check_avif_option(AVIF_CODEC_AOM TARGET aom PKG_NAME aom)
+if(AVIF_CODEC_AOM_ENABLED)
+    target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_AOM=1)
+    if(AVIF_CODEC_AOM_ENCODE AND AVIF_CODEC_AOM_DECODE)
+        set(AVIF_CODEC_AOM_ENCODE_DECODE_CONFIG "encode/decode")
+        target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_AOM_ENCODE=1 -DAVIF_CODEC_AOM_DECODE=1)
+    elseif(AVIF_CODEC_AOM_ENCODE)
+        set(AVIF_CODEC_AOM_ENCODE_DECODE_CONFIG "encode only")
+        target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_AOM_ENCODE=1)
+    elseif(AVIF_CODEC_AOM_DECODE)
+        set(AVIF_CODEC_AOM_ENCODE_DECODE_CONFIG "decode only")
+        target_compile_definitions(avif_obj PRIVATE -DAVIF_CODEC_AOM_DECODE=1)
+    else()
+        message(
+            FATAL_ERROR
+                "libavif: AVIF_CODEC_AOM is on, but both AVIF_CODEC_AOM_ENCODE and AVIF_CODEC_AOM_DECODE are off. Disable AVIF_CODEC_AOM to disable both parts of the codec."
+        )
+    endif()
+    target_sources(avif_obj PRIVATE src/codec_aom.c)
+
+    avif_target_link_library(aom)
+
+    message(STATUS "libavif: Codec enabled: aom (${AVIF_CODEC_AOM_ENCODE_DECODE_CONFIG})")
+    set(AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE "${AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE} aom")
+
+    get_target_property(AOM_INTERFACE_LINK_LIBRARIES aom INTERFACE_LINK_LIBRARIES)
+    if(AOM_INTERFACE_LINK_LIBRARIES MATCHES vmaf)
+        set(AVIF_LIB_USE_CXX ON)
+    endif()
+endif()
+
+check_avif_option(AVIF_CODEC_AVM TARGET aom PKG_NAME avm)
+if(AVIF_CODEC_AVM_ENABLED)
+    message(WARNING "libavif: AV2 support with avm is experimental. Only use for testing.")
+
+    # The avm repository is a fork of aom and inherited a lot of folders, files and build artifacts named the same way.
+    # Having both dependencies at the same time generates conflicts in includes, binary lookups etc.
+    if(AVIF_CODEC_AOM_ENABLED)
+        message(FATAL_ERROR "libavif: aom conflicts with avm, bailing out")
+    endif()
+
+    target_compile_definitions(avif_obj PUBLIC -DAVIF_CODEC_AVM=1)
+    target_sources(avif_obj PRIVATE src/codec_avm.c)
+
+    avif_target_link_library(aom)
+
+    message(STATUS "libavif: Codec enabled: avm (encode/decode)")
+endif()
+
+if(NOT AVIF_CODEC_AOM_ENABLED
+   AND NOT AVIF_CODEC_DAV1D_ENABLED
+   AND NOT AVIF_CODEC_LIBGAV1_ENABLED
+   AND NOT AVIF_CODEC_AVM_ENABLED
+)
+    message(WARNING "libavif: No decoding library is enabled.")
+endif()
+
+if(AVIF_LIB_USE_CXX OR (AVIF_BUILD_APPS AND AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP) OR (AVIF_BUILD_TESTS AND (AVIF_ENABLE_FUZZTEST
+                                                                                                         OR AVIF_ENABLE_GTEST))
+)
+    enable_language(CXX)
+    if(AVIF_ENABLE_NODISCARD)
+        # [[nodiscard]] requires C++17.
+        set(CMAKE_CXX_STANDARD 17)
+        set(CMAKE_CXX_STANDARD_REQUIRED ON)
+    else()
+        set(CMAKE_CXX_STANDARD 14)
+    endif()
+endif()
+
+set_target_properties(avif_obj PROPERTIES C_VISIBILITY_PRESET hidden)
+target_include_directories(avif_obj PUBLIC $<BUILD_INTERFACE:${libavif_SOURCE_DIR}/include>)
+if(NOT AVIF_LIBYUV_ENABLED)
+    target_include_directories(avif_obj PRIVATE ${libavif_SOURCE_DIR}/third_party/libyuv/include/)
+endif()
+if(AVIF_ENABLE_COMPLIANCE_WARDEN)
+    target_include_directories(avif_obj PRIVATE ${libavif_SOURCE_DIR}/ext/ComplianceWarden/src/utils/)
+endif()
+set(AVIF_PKG_CONFIG_EXTRA_CFLAGS "")
+if(BUILD_SHARED_LIBS)
+    target_compile_definitions(avif_obj PRIVATE AVIF_DLL AVIF_BUILDING_SHARED_LIBS)
+    set(AVIF_PKG_CONFIG_EXTRA_CFLAGS " -DAVIF_DLL")
+endif()
+
+# Main avif library.
+set_target_properties(avif PROPERTIES VERSION ${LIBRARY_VERSION} SOVERSION ${LIBRARY_SOVERSION})
+target_link_libraries(avif PRIVATE avif_obj)
+target_include_directories(avif PUBLIC $<BUILD_INTERFACE:${libavif_SOURCE_DIR}/include> $<INSTALL_INTERFACE:include>)
+if(BUILD_SHARED_LIBS)
+    target_compile_definitions(avif INTERFACE AVIF_DLL)
+    if(AVIF_LIB_USE_CXX)
+        set_target_properties(avif PROPERTIES LINKER_LANGUAGE "CXX")
+    endif()
+endif()
+
+# Give access to functions defined in internal.h when BUILD_SHARED_LIBS is ON, to tests for example.
+# The avif_internal target should not be used by external code.
+if(BUILD_SHARED_LIBS)
+    add_library(avif_internal STATIC)
+    target_link_libraries(avif_internal PRIVATE avif_obj)
+    target_include_directories(avif_internal PUBLIC ${libavif_SOURCE_DIR}/include)
+    # Define the following to avoid linking against avif and avif_internal at the same time.
+    target_compile_definitions(avif_internal PUBLIC AVIF_USING_STATIC_LIBS)
+else()
+    include(merge_static_libs)
+    set_target_properties(avif PROPERTIES AVIF_LOCAL ON)
+    merge_static_libs(avif_static avif)
+    # Set the avif target's output to "avif_internal" and set the output name of
+    # the combined static archive target (avif_static)) to avif, so that libavif.a
+    # is the merged archive.
+    set_target_properties(avif_static PROPERTIES OUTPUT_NAME avif EXPORT_NAME avif)
+    set_target_properties(avif PROPERTIES OUTPUT_NAME avif_internal EXPORT_NAME avif_internal)
+    add_library(avif_internal ALIAS avif)
+endif()
+
+option(AVIF_BUILD_EXAMPLES "Build avif examples." OFF)
+if(AVIF_BUILD_EXAMPLES)
+    set(AVIF_EXAMPLES avif_example_decode_memory avif_example_decode_file avif_example_decode_streaming avif_example_encode)
+
+    foreach(EXAMPLE ${AVIF_EXAMPLES})
+        add_executable(${EXAMPLE} examples/${EXAMPLE}.c)
+        if(AVIF_LIB_USE_CXX)
+            set_target_properties(${EXAMPLE} PROPERTIES LINKER_LANGUAGE "CXX")
+        endif()
+        target_link_libraries(${EXAMPLE} avif avif_enable_warnings)
+    endforeach()
+endif()
+
+if(CMAKE_SKIP_INSTALL_RULES)
+    set(SKIP_INSTALL_ALL TRUE)
+endif()
+
+if(NOT SKIP_INSTALL_ALL)
+    include(GNUInstallDirs)
+endif()
+
+if(AVIF_BUILD_APPS OR (AVIF_BUILD_TESTS AND (AVIF_ENABLE_FUZZTEST OR AVIF_ENABLE_GTEST)))
+    if(AVIF_ZLIBPNG STREQUAL "OFF")
+        message(FATAL_ERROR "libavif: AVIF_ZLIBPNG cannot be OFF when AVIF_BUILD_APPS or AVIF_BUILD_TESTS is ON")
+    elseif(AVIF_ZLIBPNG STREQUAL "SYSTEM")
+        find_package(ZLIB REQUIRED)
+        find_package(PNG 1.6.32 REQUIRED) # 1.6.32 or above for png_get_eXIf_1()/png_set_eXIf_1() and iTXt (for XMP).
+    endif()
+    if(AVIF_JPEG STREQUAL "OFF")
+        message(FATAL_ERROR "libavif: AVIF_JPEG cannot be OFF when AVIF_BUILD_APPS or AVIF_BUILD_TESTS is ON")
+    elseif(AVIF_JPEG STREQUAL "SYSTEM")
+        find_package(JPEG REQUIRED)
+    endif()
+
+    if(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if(TARGET LibXml2::LibXml2)
+            set(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION TRUE)
+            add_compile_definitions(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+        else()
+            message(STATUS "libavif: libxml2 not found; avifenc will ignore any gain map in jpeg files")
+        endif()
+    endif()
+
+    set(AVIF_APPS_SRCS apps/shared/avifexif.c apps/shared/avifjpeg.c apps/shared/avifpng.c apps/shared/avifutil.c
+                       apps/shared/iccmaker.c apps/shared/y4m.c third_party/iccjpeg/iccjpeg.c
+    )
+
+    macro(add_avif_apps_library suffix)
+        add_library(avif_apps${suffix} STATIC ${AVIF_APPS_SRCS})
+        target_link_libraries(avif_apps${suffix} PUBLIC avif${suffix} PRIVATE PNG::PNG ZLIB::ZLIB JPEG::JPEG avif_enable_warnings)
+        if(CMAKE_SYSTEM_NAME STREQUAL "Linux")
+            target_link_libraries(avif_apps${suffix} PRIVATE m)
+        endif()
+        if(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+            target_link_libraries(avif_apps${suffix} PRIVATE LibXml2::LibXml2)
+        endif()
+        target_include_directories(avif_apps${suffix} INTERFACE apps/shared)
+        # In GitHub CI's macos-latest os image, /usr/local/include has not only the headers of libpng
+        # and libjpeg but also the headers of an older version of libavif. Put the avif include
+        # directory before ${PNG_PNG_INCLUDE_DIR} ${JPEG_INCLUDE_DIR} to prevent picking up old libavif
+        # headers from /usr/local/include.
+        target_include_directories(avif_apps${suffix} PRIVATE third_party/iccjpeg)
+        target_include_directories(avif_apps${suffix} SYSTEM PRIVATE ${PNG_PNG_INCLUDE_DIR} ${JPEG_INCLUDE_DIR})
+    endmacro()
+
+    # Main avif_apps library.
+    add_avif_apps_library("")
+
+    # avif_apps_internal is to use when linking to avif_internal.
+    if(BUILD_SHARED_LIBS)
+        add_avif_apps_library(_internal)
+    else()
+        add_library(avif_apps_internal ALIAS avif_apps)
+    endif()
+endif()
+
+if(AVIF_BUILD_APPS)
+    add_executable(avifenc apps/avifenc.c)
+    if(WIN32)
+        if(MSVC)
+            target_sources(avifenc PRIVATE apps/utf8.manifest)
+        elseif(MINGW)
+            # MinGW doesn't have a manifest tool (mt.exe), so we need to wrap
+            # utf8.manifest in a resource-definition script (.rc file).
+            target_sources(avifenc PRIVATE apps/utf8.rc)
+        endif()
+    endif()
+    if(AVIF_LIB_USE_CXX)
+        set_target_properties(avifenc PROPERTIES LINKER_LANGUAGE "CXX")
+    endif()
+    target_link_libraries(avifenc avif_apps avif avif_enable_warnings)
+    add_executable(avifdec apps/avifdec.c)
+    if(WIN32)
+        if(MSVC)
+            target_sources(avifdec PRIVATE apps/utf8.manifest)
+        elseif(MINGW)
+            target_sources(avifdec PRIVATE apps/utf8.rc)
+        endif()
+    endif()
+    if(AVIF_LIB_USE_CXX)
+        set_target_properties(avifdec PROPERTIES LINKER_LANGUAGE "CXX")
+    endif()
+    target_link_libraries(avifdec avif_apps avif avif_enable_warnings)
+
+    if(NOT SKIP_INSTALL_APPS AND NOT SKIP_INSTALL_ALL)
+        install(
+            TARGETS avifenc avifdec
+            RUNTIME DESTINATION "${CMAKE_INSTALL_BINDIR}"
+            ARCHIVE DESTINATION "${CMAKE_INSTALL_LIBDIR}"
+            LIBRARY DESTINATION "${CMAKE_INSTALL_LIBDIR}"
+        )
+    endif()
+    if(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        include(LocalLibargparse)
+        set(AVIF_ENABLE_AVIFGAINMAPUTIL TRUE)
+
+        set(AVIFGAINMAPUTIL_SRCS
+            apps/avifgainmaputil/avifgainmaputil.cc
+            apps/avifgainmaputil/convert_command.cc
+            apps/avifgainmaputil/combine_command.cc
+            apps/avifgainmaputil/extractgainmap_command.cc
+            apps/avifgainmaputil/imageio.cc
+            apps/avifgainmaputil/printmetadata_command.cc
+            apps/avifgainmaputil/tonemap_command.cc
+            apps/avifgainmaputil/program_command.cc
+            apps/avifgainmaputil/swapbase_command.cc
+        )
+
+        add_executable(avifgainmaputil "${AVIFGAINMAPUTIL_SRCS}")
+        if(WIN32)
+            if(MSVC)
+                target_sources(avifgainmaputil PRIVATE apps/utf8.manifest)
+            elseif(MINGW)
+                target_sources(avifgainmaputil PRIVATE apps/utf8.rc)
+            endif()
+        endif()
+        set_target_properties(avifgainmaputil PROPERTIES LINKER_LANGUAGE "CXX")
+        target_include_directories(avifgainmaputil PRIVATE apps/avifgainmaputil/)
+        target_link_libraries(avifgainmaputil libargparse avif_apps avif avif_enable_warnings)
+        # Don't add avifgainmaputil to installed apps for now.
+    endif()
+endif()
+
+if(AVIF_BUILD_TESTS)
+    enable_testing() # Allow ctest to be called from top-level directory.
+    add_subdirectory(tests)
+    # An executable on Windows searches for DLLs it is linked with in the same
+    # directory where it resides and in the directories listed in the Path
+    # environment variable. For convenience, copy avif.dll to the tests binary
+    # directory to allow are_images_equal.exe and the test programs find it.
+    if(WIN32 AND BUILD_SHARED_LIBS)
+        add_custom_command(
+            TARGET avif
+            POST_BUILD
+            COMMAND ${CMAKE_COMMAND} -E copy "$<TARGET_FILE:avif>" ${CMAKE_CURRENT_BINARY_DIR}/tests
+            COMMENT "Copying avif.dll to the tests binary directory"
+        )
+    endif()
+endif()
+
+option(AVIF_BUILD_MAN_PAGES "Build avif man pages." OFF)
+if(AVIF_BUILD_MAN_PAGES)
+    if(AVIF_BUILD_APPS)
+        find_program(PANDOC_EXE pandoc)
+        if(PANDOC_EXE)
+            message(STATUS "libavif: Using pandoc: ${PANDOC_EXE}")
+        else()
+            message(FATAL_ERROR "libavif: Pandoc is missing, bailing out")
+        endif()
+
+        set(MAN_PAGES avifenc.1 avifdec.1)
+
+        foreach(MAN_PAGE ${MAN_PAGES})
+            add_custom_command(
+                OUTPUT ${MAN_PAGE}
+                COMMAND ${PANDOC_EXE} -s -V "footer=libavif ${PROJECT_VERSION}" -f markdown -t man -o
+                        "${CMAKE_CURRENT_BINARY_DIR}/${MAN_PAGE}" "${CMAKE_CURRENT_SOURCE_DIR}/doc/${MAN_PAGE}.md"
+                DEPENDS "${CMAKE_CURRENT_SOURCE_DIR}/doc/${MAN_PAGE}.md"
+                VERBATIM
+            )
+        endforeach()
+        add_custom_target(man_pages ALL DEPENDS ${MAN_PAGES})
+
+        foreach(MAN_PAGE ${MAN_PAGES})
+            install(FILES "${CMAKE_CURRENT_BINARY_DIR}/${MAN_PAGE}" DESTINATION "${CMAKE_INSTALL_MANDIR}/man1")
+        endforeach()
+    else()
+        message(WARNING "libavif: No man pages are built (AVIF_BUILD_MAN_PAGES); AVIF_BUILD_APPS must be on.")
+    endif()
+endif()
+
+if(NOT SKIP_INSTALL_LIBRARIES AND NOT SKIP_INSTALL_ALL)
+    if(BUILD_SHARED_LIBS)
+        set(LIBAVIF_INSTALL_TARGET avif)
+    else()
+        set(LIBAVIF_INSTALL_TARGET avif_static)
+    endif()
+    install(
+        TARGETS ${LIBAVIF_INSTALL_TARGET}
+        EXPORT ${PROJECT_NAME}-config
+        RUNTIME DESTINATION "${CMAKE_INSTALL_BINDIR}"
+        ARCHIVE DESTINATION "${CMAKE_INSTALL_LIBDIR}"
+        LIBRARY DESTINATION "${CMAKE_INSTALL_LIBDIR}"
+    )
+
+    # Enable CMake configs in VCPKG mode
+    if(BUILD_SHARED_LIBS OR VCPKG_TARGET_TRIPLET)
+        install(EXPORT ${PROJECT_NAME}-config DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/${PROJECT_NAME})
+
+        include(CMakePackageConfigHelpers)
+        write_basic_package_version_file(
+            ${PROJECT_NAME}-config-version.cmake VERSION ${PROJECT_VERSION} COMPATIBILITY SameMajorVersion
+        )
+        install(FILES ${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}-config-version.cmake
+                DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/${PROJECT_NAME}
+        )
+    endif()
+
+    # Handle both relative and absolute paths (e.g. NixOS) for a relocatable package
+    if(IS_ABSOLUTE "${CMAKE_INSTALL_INCLUDEDIR}")
+        set(PC_INCLUDEDIR "${CMAKE_INSTALL_INCLUDEDIR}")
+    else()
+        set(PC_INCLUDEDIR "\${prefix}/${CMAKE_INSTALL_INCLUDEDIR}")
+    endif()
+    if(IS_ABSOLUTE "${CMAKE_INSTALL_LIBDIR}")
+        set(PC_LIBDIR "${CMAKE_INSTALL_LIBDIR}")
+    else()
+        set(PC_LIBDIR "\${exec_prefix}/${CMAKE_INSTALL_LIBDIR}")
+    endif()
+    configure_file(libavif.pc.cmake ${CMAKE_CURRENT_BINARY_DIR}/libavif.pc @ONLY)
+    install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libavif.pc DESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig)
+endif()
+if(NOT SKIP_INSTALL_HEADERS AND NOT SKIP_INSTALL_ALL)
+    install(FILES include/avif/avif.h include/avif/avif_cxx.h DESTINATION "${CMAKE_INSTALL_INCLUDEDIR}/avif")
+endif()
+
+# ---------------------------------------------------------------------------------------
+# Win32 (Visual Studio) fixups
+
+macro(avif_set_folder_safe target folder)
+    if(TARGET ${target})
+        set_target_properties(${target} PROPERTIES FOLDER ${folder})
+    endif()
+endmacro()
+
+macro(avif_exclude_safe target)
+    if(TARGET ${target})
+        set_target_properties(${target} PROPERTIES EXCLUDE_FROM_DEFAULT_BUILD True)
+    endif()
+endmacro()
+
+if(WIN32)
+    set_property(GLOBAL PROPERTY USE_FOLDERS ON)
+
+    avif_set_folder_safe(avif "ext/avif")
+    if(AVIF_BUILD_EXAMPLES)
+        foreach(EXAMPLE ${AVIF_EXAMPLES})
+            avif_set_folder_safe(${EXAMPLE} "ext/avif/examples")
+        endforeach()
+    endif()
+    if(AVIF_ZLIBPNG STREQUAL "LOCAL")
+        avif_set_folder_safe(example "ext/zlibpng")
+        avif_set_folder_safe(genfiles "ext/zlibpng")
+        avif_set_folder_safe(minigzip "ext/zlibpng")
+        avif_set_folder_safe(png_static "ext/zlibpng")
+        avif_set_folder_safe(zlib "ext/zlibpng")
+        avif_set_folder_safe(zlibstatic "ext/zlibpng")
+
+        # Don't bother building these targets
+        avif_exclude_safe(example)
+        avif_exclude_safe(genfiles)
+        avif_exclude_safe(minigzip)
+    endif()
+    if(AVIF_JPEG STREQUAL "LOCAL")
+        avif_set_folder_safe(JPEG::JPEG "ext/libjpeg-turbo")
+    endif()
+    if(AVIF_LIBXML2 STREQUAL "LOCAL")
+        avif_set_folder_safe(xml2 "ext/libxml2")
+    endif()
+endif()
+
+add_subdirectory(contrib)
diff --git a/third_party/libavif/src/LICENSE b/third_party/libavif/src/LICENSE
new file mode 100644
index 0000000000..350eb9d15c
--- /dev/null
+++ b/third_party/libavif/src/LICENSE
@@ -0,0 +1,387 @@
+Copyright 2019 Joe Drago. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+this list of conditions and the following disclaimer in the documentation
+and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+------------------------------------------------------------------------------
+
+Files: src/obu.c
+
+Copyright  2018-2019, VideoLAN and dav1d authors
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+   list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+   this list of conditions and the following disclaimer in the documentation
+   and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+------------------------------------------------------------------------------
+
+Files: third_party/iccjpeg/*
+
+In plain English:
+
+1. We don't promise that this software works.  (But if you find any bugs,
+   please let us know!)
+2. You can use this software for whatever you want.  You don't have to pay us.
+3. You may not pretend that you wrote this software.  If you use it in a
+   program, you must acknowledge somewhere in your documentation that
+   you've used the IJG code.
+
+In legalese:
+
+The authors make NO WARRANTY or representation, either express or implied,
+with respect to this software, its quality, accuracy, merchantability, or
+fitness for a particular purpose.  This software is provided "AS IS", and you,
+its user, assume the entire risk as to its quality and accuracy.
+
+This software is copyright (C) 1991-2013, Thomas G. Lane, Guido Vollbeding.
+All Rights Reserved except as specified below.
+
+Permission is hereby granted to use, copy, modify, and distribute this
+software (or portions thereof) for any purpose, without fee, subject to these
+conditions:
+(1) If any part of the source code for this software is distributed, then this
+README file must be included, with this copyright and no-warranty notice
+unaltered; and any additions, deletions, or changes to the original files
+must be clearly indicated in accompanying documentation.
+(2) If only executable code is distributed, then the accompanying
+documentation must state that "this software is based in part on the work of
+the Independent JPEG Group".
+(3) Permission for use of this software is granted only if the user accepts
+full responsibility for any undesirable consequences; the authors accept
+NO LIABILITY for damages of any kind.
+
+These conditions apply to any software derived from or based on the IJG code,
+not just to the unmodified library.  If you use our work, you ought to
+acknowledge us.
+
+Permission is NOT granted for the use of any IJG author's name or company name
+in advertising or publicity relating to this software or products derived from
+it.  This software may be referred to only as "the Independent JPEG Group's
+software".
+
+We specifically permit and encourage the use of this software as the basis of
+commercial products, provided that all warranty or liability claims are
+assumed by the product vendor.
+
+
+The Unix configuration script "configure" was produced with GNU Autoconf.
+It is copyright by the Free Software Foundation but is freely distributable.
+The same holds for its supporting scripts (config.guess, config.sub,
+ltmain.sh).  Another support script, install-sh, is copyright by X Consortium
+but is also freely distributable.
+
+The IJG distribution formerly included code to read and write GIF files.
+To avoid entanglement with the Unisys LZW patent, GIF reading support has
+been removed altogether, and the GIF writer has been simplified to produce
+"uncompressed GIFs".  This technique does not use the LZW algorithm; the
+resulting GIF files are larger than usual, but are readable by all standard
+GIF decoders.
+
+We are required to state that
+    "The Graphics Interchange Format(c) is the Copyright property of
+    CompuServe Incorporated.  GIF(sm) is a Service Mark property of
+    CompuServe Incorporated."
+
+------------------------------------------------------------------------------
+
+Files: contrib/gdk-pixbuf/*
+
+Copyright 2020 Emmanuel Gil Peyrot. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+this list of conditions and the following disclaimer in the documentation
+and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+------------------------------------------------------------------------------
+
+Files: android_jni/gradlew*
+
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
+------------------------------------------------------------------------------
+
+Files: third_party/libyuv/*
+
+Copyright 2011 The LibYuv Project Authors. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+
+  * Redistributions of source code must retain the above copyright
+    notice, this list of conditions and the following disclaimer.
+
+  * Redistributions in binary form must reproduce the above copyright
+    notice, this list of conditions and the following disclaimer in
+    the documentation and/or other materials provided with the
+    distribution.
+
+  * Neither the name of Google nor the names of its contributors may
+    be used to endorse or promote products derived from this software
+    without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/third_party/libavif/src/README.md b/third_party/libavif/src/README.md
new file mode 100644
index 0000000000..c49d24626d
--- /dev/null
+++ b/third_party/libavif/src/README.md
@@ -0,0 +1,195 @@
+# libavif
+
+This library aims to be a friendly, portable C implementation of the AV1 Image
+File Format, as described here:
+
+<https://aomediacodec.github.io/av1-avif/>
+
+It can encode and decode all AV1 supported YUV formats and bit depths (with
+alpha).
+
+It is recommended that you check out/use
+[tagged releases](https://github.com/AOMediaCodec/libavif/releases) instead of
+just using the main branch. We will regularly create new versions as bug fixes
+and features are added.
+
+## Usage
+
+Please see the examples in the "examples" directory. If you're already building
+`libavif`, enable the CMake option `AVIF_BUILD_EXAMPLES` in order to build and
+run the examples too.
+
+## Installation
+
+`libavif` is a package in most major OSs.
+
+### Windows
+
+```sh
+vcpkg install libavif
+```
+You can also download the official windows binaries on the
+[release](https://github.com/AOMediaCodec/libavif/releases) page.
+
+### macOS
+
+Homebrew:
+```sh
+brew install libavif
+```
+MacPorts:
+```sh
+sudo port install libavif
+```
+
+### Linux
+
+Debian-based distributions:
+```sh
+sudo apt install libavif-dev
+```
+Red Hat-based distributions:
+```sh
+sudo yum -y install libavif
+```
+
+### MinGW
+
+For the "default" MSYS2 UCRT64 environment:
+```sh
+pacman -S mingw-w64-ucrt-x86_64-libavif
+```
+
+## Build Notes
+
+Building libavif requires [CMake](https://cmake.org/).
+
+No AV1 codecs are enabled by default. Enable them by setting any of the
+following CMake options to `LOCAL` or `SYSTEM` whether you want to use a
+locally built or a system installed version (e.g. `-DAVIF_CODEC_AOM=LOCAL`):
+
+* `AVIF_CODEC_AOM` for [libaom](https://aomedia.googlesource.com/aom/) (encoder
+  and decoder)
+* `AVIF_CODEC_DAV1D` for [dav1d](https://code.videolan.org/videolan/dav1d)
+  (decoder)
+* `AVIF_CODEC_LIBGAV1` for
+  [libgav1](https://chromium.googlesource.com/codecs/libgav1/) (decoder)
+* `AVIF_CODEC_RAV1E` for [rav1e](https://github.com/xiph/rav1e) (encoder)
+* `AVIF_CODEC_SVT` for [SVT-AV1](https://gitlab.com/AOMediaCodec/SVT-AV1)
+  (encoder)
+
+When set to `SYSTEM`, these libraries (in their C API form) must be externally
+available (discoverable via CMake's `FIND_LIBRARY`) to use them, or if libavif
+is a child CMake project, the appropriate CMake target must already exist
+by the time libavif's CMake scripts are executed.
+
+### Static Builds
+
+When set to `LOCAL`, these libraries and the other dependencies will be pulled
+locally by CMake to known-good versions.
+
+To override a local dependency version or to use a custom build of a dependency,
+first run the associated script in the `ext/` subdirectory.
+
+### Tests
+
+A few tests written in C can be built by enabling the `AVIF_BUILD_TESTS` CMake
+option.
+
+The remaining tests can be built by enabling the `AVIF_BUILD_TESTS` and
+`AVIF_ENABLE_GTEST` CMake options. They require GoogleTest
+(`-DAVIF_GTEST=SYSTEM` or `-DAVIF_GTEST=LOCAL`).
+
+### Command Lines
+
+The following instructions can be used to build the libavif library and the
+`avifenc` and `avifdec` tools.
+
+#### Build using installed dependencies
+
+To link against the already installed `aom`, `libjpeg` and `libpng` dependency
+libraries (recommended):
+
+```sh
+git clone -b v1.1.1 https://github.com/AOMediaCodec/libavif.git
+cmake -S libavif -B libavif/build -DAVIF_CODEC_AOM=SYSTEM -DAVIF_BUILD_APPS=ON
+cmake --build libavif/build --parallel
+```
+
+#### Build everything from scratch
+
+For development and debugging purposes, or to generate fully static binaries:
+
+```sh
+git clone -b v1.1.1 https://github.com/AOMediaCodec/libavif.git
+cmake -S libavif -B libavif/build -DBUILD_SHARED_LIBS=OFF -DAVIF_CODEC_AOM=LOCAL -DAVIF_LIBYUV=LOCAL -DAVIF_LIBSHARPYUV=LOCAL -DAVIF_JPEG=LOCAL -DAVIF_ZLIBPNG=LOCAL -DAVIF_BUILD_APPS=ON -DCMAKE_C_FLAGS_RELEASE="-static" -DCMAKE_EXE_LINKER_FLAGS="-static"
+cmake --build libavif/build --parallel
+```
+
+## Prebuilt Binaries (Windows)
+
+Statically-linked `avifenc.exe` and `avifdec.exe` can be downloaded from the
+[Releases](https://github.com/AOMediaCodec/libavif/releases) page.
+
+## Development Notes
+
+Please check the [wiki](https://github.com/AOMediaCodec/libavif/wiki) for extra
+resources on libavif, such as the Release Checklist.
+
+The libavif library is written in C99. Most of the tests are written in C++14.
+
+### Formatting
+
+Use [clang-format](https://clang.llvm.org/docs/ClangFormat.html) to format the
+sources from the top-level folder (`clang-format-16` preferred):
+
+```sh
+clang-format -style=file -i \
+  apps/*.c apps/*/*.c apps/*/*.cc apps/*/*.h examples/*.c \
+  include/avif/*.h src/*.c src/*.cc \
+  tests/*.c tests/*/*.cc tests/*/*.h
+```
+
+Use [cmake-format](https://github.com/cheshirekow/cmake_format) to format the
+CMakeLists.txt files from the top-level folder:
+
+```sh
+cmake-format -i \
+  CMakeLists.txt \
+  tests/CMakeLists.txt \
+  cmake/Modules/*.cmake \
+  contrib/CMakeLists.txt \
+  contrib/gdk-pixbuf/CMakeLists.txt \
+  android_jni/avifandroidjni/src/main/jni/CMakeLists.txt
+```
+
+---
+
+## License
+
+Released under the BSD License.
+
+```markdown
+Copyright 2019 Joe Drago. All rights reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this
+list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice,
+this list of conditions and the following disclaimer in the documentation
+and/or other materials provided with the distribution.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+```
diff --git a/third_party/libavif/src/SECURITY.md b/third_party/libavif/src/SECURITY.md
new file mode 100644
index 0000000000..5623beb3db
--- /dev/null
+++ b/third_party/libavif/src/SECURITY.md
@@ -0,0 +1,16 @@
+# Security Policy
+
+If you have discovered a security vulnerability in this project, please report it
+privately. **Do not disclose it as a public issue.** This gives us time to work with you
+to fix the issue before public exposure, reducing the chance that the exploit will be
+used before a patch is released.
+
+Please submit the report through [here](https://github.com/AOMediaCodec/libavif/security/advisories/new).
+
+Please provide the following information in your report:
+
+- Which version you're using
+- How to reproduce the issue
+- A description of the vulnerability and its impact (optional but appreciated)
+
+We ask that you give us 90 days to work on a fix before public exposure.
diff --git a/third_party/libavif/src/apps/avifdec.c b/third_party/libavif/src/apps/avifdec.c
new file mode 100644
index 0000000000..1a6006d206
--- /dev/null
+++ b/third_party/libavif/src/apps/avifdec.c
@@ -0,0 +1,410 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include "avifjpeg.h"
+#include "avifpng.h"
+#include "avifutil.h"
+#include "y4m.h"
+
+#include <assert.h>
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#define DEFAULT_JPEG_QUALITY 90
+
+#define NEXTARG()                                                     \
+    if (((argIndex + 1) == argc) || (argv[argIndex + 1][0] == '-')) { \
+        fprintf(stderr, "%s requires an argument.", arg);             \
+        return 1;                                                     \
+    }                                                                 \
+    arg = argv[++argIndex]
+
+static void syntax(void)
+{
+    printf("Syntax: avifdec [options] input.avif output.[jpg|jpeg|png|y4m]\n");
+    printf("        avifdec --info    input.avif\n");
+    printf("Options:\n");
+    printf("    -h,--help         : Show syntax help\n");
+    printf("    -V,--version      : Show the version number\n");
+    printf("    -j,--jobs J       : Number of jobs (worker threads). Use \"all\" to potentially use as many cores as possible (default: all)\n");
+    printf("    -c,--codec C      : Codec to use (choose from versions list below)\n");
+    printf("    -d,--depth D      : Output depth [8,16]. (PNG only; For y4m, depth is retained, and JPEG is always 8bpc)\n");
+    printf("    -q,--quality Q    : Output quality [0-100]. (JPEG only, default: %d)\n", DEFAULT_JPEG_QUALITY);
+    printf("    --png-compress L  : Set PNG compression level (PNG only; 0-9, 0=none, 9=max). Defaults to libpng's builtin default.\n");
+    printf("    -u,--upsampling U : Chroma upsampling (for 420/422). automatic (default), fastest, best, nearest, or bilinear\n");
+    printf("    -r,--raw-color    : Output raw RGB values instead of multiplying by alpha when saving to opaque formats\n");
+    printf("                        (JPEG only; not applicable to y4m)\n");
+    printf("    --index I         : When decoding an image sequence or progressive image, specify which frame index to decode (Default: 0)\n");
+    printf("    --progressive     : Enable progressive AVIF processing. If a progressive image is encountered and --progressive is passed,\n");
+    printf("                        avifdec will use --index to choose which layer to decode (in progressive order).\n");
+    printf("    --no-strict       : Disable strict decoding, which disables strict validation checks and errors\n");
+    printf("    -i,--info         : Decode all frames and display all image information instead of saving to disk\n");
+    printf("    --icc FILENAME    : Provide an ICC profile payload (implies --ignore-icc)\n");
+    printf("    --ignore-icc      : If the input file contains an embedded ICC profile, ignore it (no-op if absent)\n");
+    printf("    --size-limit C    : Specifies the image size limit (in total pixels) that should be tolerated.\n");
+    printf("                        Default: %u, set to a smaller value to further restrict.\n", AVIF_DEFAULT_IMAGE_SIZE_LIMIT);
+    printf("  --dimension-limit C : Specifies the image dimension limit (width or height) that should be tolerated.\n");
+    printf("                        Default: %u, set to 0 to ignore.\n", AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT);
+    printf("    --                : Signals the end of options. Everything after this is interpreted as file names.\n");
+    printf("\n");
+    avifPrintVersions();
+}
+
+int main(int argc, char * argv[])
+{
+    const char * inputFilename = NULL;
+    const char * outputFilename = NULL;
+    int requestedDepth = 0;
+    int jobs = -1;
+    int jpegQuality = DEFAULT_JPEG_QUALITY;
+    int pngCompressionLevel = -1; // -1 is a sentinel to avifPNGWrite() to skip calling png_set_compression_level()
+    avifCodecChoice codecChoice = AVIF_CODEC_CHOICE_AUTO;
+    avifBool infoOnly = AVIF_FALSE;
+    avifChromaUpsampling chromaUpsampling = AVIF_CHROMA_UPSAMPLING_AUTOMATIC;
+    const char * iccOverrideFilename = NULL;
+    avifBool ignoreICC = AVIF_FALSE;
+    avifBool rawColor = AVIF_FALSE;
+    avifBool allowProgressive = AVIF_FALSE;
+    avifStrictFlags strictFlags = AVIF_STRICT_ENABLED;
+    uint32_t frameIndex = 0;
+    uint32_t imageSizeLimit = AVIF_DEFAULT_IMAGE_SIZE_LIMIT;
+    uint32_t imageDimensionLimit = AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT;
+
+    if (argc < 2) {
+        syntax();
+        return 1;
+    }
+
+    int argIndex = 1;
+    while (argIndex < argc) {
+        const char * arg = argv[argIndex];
+
+        if (!strcmp(arg, "--")) {
+            // Stop parsing flags, everything after this is positional arguments
+            ++argIndex;
+            // Parse additional positional arguments if any.
+            while (argIndex < argc) {
+                arg = argv[argIndex];
+                if (!inputFilename) {
+                    inputFilename = arg;
+                } else if (!outputFilename) {
+                    outputFilename = arg;
+                } else {
+                    fprintf(stderr, "Too many positional arguments: %s\n\n", arg);
+                    syntax();
+                    return 1;
+                }
+                ++argIndex;
+            }
+            break;
+        } else if (!strcmp(arg, "-h") || !strcmp(arg, "--help")) {
+            syntax();
+            return 0;
+        } else if (!strcmp(arg, "-V") || !strcmp(arg, "--version")) {
+            avifPrintVersions();
+            return 0;
+        } else if (!strcmp(arg, "-j") || !strcmp(arg, "--jobs")) {
+            NEXTARG();
+            if (!strcmp(arg, "all")) {
+                jobs = avifQueryCPUCount();
+            } else {
+                jobs = atoi(arg);
+                if (jobs < 1) {
+                    jobs = 1;
+                }
+            }
+        } else if (!strcmp(arg, "-c") || !strcmp(arg, "--codec")) {
+            NEXTARG();
+            codecChoice = avifCodecChoiceFromName(arg);
+            if (codecChoice == AVIF_CODEC_CHOICE_AUTO) {
+                fprintf(stderr, "ERROR: Unrecognized codec: %s\n", arg);
+                return 1;
+            } else {
+                const char * codecName = avifCodecName(codecChoice, AVIF_CODEC_FLAG_CAN_DECODE);
+                if (codecName == NULL) {
+                    fprintf(stderr, "ERROR: Codec cannot decode: %s\n", arg);
+                    return 1;
+                }
+            }
+        } else if (!strcmp(arg, "-d") || !strcmp(arg, "--depth")) {
+            NEXTARG();
+            requestedDepth = atoi(arg);
+            if ((requestedDepth != 8) && (requestedDepth != 16)) {
+                fprintf(stderr, "ERROR: invalid depth: %s\n", arg);
+                return 1;
+            }
+        } else if (!strcmp(arg, "-q") || !strcmp(arg, "--quality")) {
+            NEXTARG();
+            jpegQuality = atoi(arg);
+            if (jpegQuality < 0) {
+                jpegQuality = 0;
+            } else if (jpegQuality > 100) {
+                jpegQuality = 100;
+            }
+        } else if (!strcmp(arg, "--png-compress")) {
+            NEXTARG();
+            pngCompressionLevel = atoi(arg);
+            if (pngCompressionLevel < 0) {
+                pngCompressionLevel = 0;
+            } else if (pngCompressionLevel > 9) {
+                pngCompressionLevel = 9;
+            }
+        } else if (!strcmp(arg, "-u") || !strcmp(arg, "--upsampling")) {
+            NEXTARG();
+            if (!strcmp(arg, "automatic")) {
+                chromaUpsampling = AVIF_CHROMA_UPSAMPLING_AUTOMATIC;
+            } else if (!strcmp(arg, "fastest")) {
+                chromaUpsampling = AVIF_CHROMA_UPSAMPLING_FASTEST;
+            } else if (!strcmp(arg, "best")) {
+                chromaUpsampling = AVIF_CHROMA_UPSAMPLING_BEST_QUALITY;
+            } else if (!strcmp(arg, "nearest")) {
+                chromaUpsampling = AVIF_CHROMA_UPSAMPLING_NEAREST;
+            } else if (!strcmp(arg, "bilinear")) {
+                chromaUpsampling = AVIF_CHROMA_UPSAMPLING_BILINEAR;
+            } else {
+                fprintf(stderr, "ERROR: invalid upsampling: %s\n", arg);
+                return 1;
+            }
+        } else if (!strcmp(arg, "-r") || !strcmp(arg, "--raw-color")) {
+            rawColor = AVIF_TRUE;
+        } else if (!strcmp(arg, "--progressive")) {
+            allowProgressive = AVIF_TRUE;
+        } else if (!strcmp(arg, "--index")) {
+            NEXTARG();
+            frameIndex = (uint32_t)atoi(arg);
+        } else if (!strcmp(arg, "--no-strict")) {
+            strictFlags = AVIF_STRICT_DISABLED;
+        } else if (!strcmp(arg, "-i") || !strcmp(arg, "--info")) {
+            infoOnly = AVIF_TRUE;
+        } else if (!strcmp(arg, "--icc")) {
+            NEXTARG();
+            iccOverrideFilename = arg;
+            ignoreICC = AVIF_TRUE;
+        } else if (!strcmp(arg, "--ignore-icc")) {
+            ignoreICC = AVIF_TRUE;
+        } else if (!strcmp(arg, "--size-limit")) {
+            NEXTARG();
+            unsigned long value = strtoul(arg, NULL, 10);
+            if ((value > AVIF_DEFAULT_IMAGE_SIZE_LIMIT) || (value == 0)) {
+                fprintf(stderr, "ERROR: invalid image size limit: %s\n", arg);
+                return 1;
+            }
+            imageSizeLimit = (uint32_t)value;
+        } else if (!strcmp(arg, "--dimension-limit")) {
+            NEXTARG();
+            unsigned long value = strtoul(arg, NULL, 10);
+            if (value > UINT32_MAX) {
+                fprintf(stderr, "ERROR: invalid image dimension limit: %s\n", arg);
+                return 1;
+            }
+            imageDimensionLimit = (uint32_t)value;
+        } else if (arg[0] == '-') {
+            fprintf(stderr, "ERROR: unrecognized option %s\n\n", arg);
+            syntax();
+            return 1;
+        } else {
+            // Positional argument
+            if (!inputFilename) {
+                inputFilename = arg;
+            } else if (!outputFilename) {
+                outputFilename = arg;
+            } else {
+                fprintf(stderr, "Too many positional arguments: %s\n\n", arg);
+                syntax();
+                return 1;
+            }
+        }
+
+        ++argIndex;
+    }
+
+    if (jobs == -1) {
+        jobs = avifQueryCPUCount();
+    }
+
+    if (!inputFilename) {
+        syntax();
+        return 1;
+    }
+
+    if (infoOnly) {
+        if (!inputFilename || outputFilename) {
+            syntax();
+            return 1;
+        }
+
+        avifDecoder * decoder = avifDecoderCreate();
+        if (!decoder) {
+            fprintf(stderr, "Memory allocation failure\n");
+            return 1;
+        }
+        decoder->maxThreads = jobs;
+        decoder->codecChoice = codecChoice;
+        decoder->imageSizeLimit = imageSizeLimit;
+        decoder->imageDimensionLimit = imageDimensionLimit;
+        decoder->strictFlags = strictFlags;
+        decoder->allowProgressive = allowProgressive;
+        decoder->imageContentToDecode = AVIF_IMAGE_CONTENT_ALL;
+
+        avifResult result = avifDecoderSetIOFile(decoder, inputFilename);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+            avifDecoderDestroy(decoder);
+            return 1;
+        }
+        result = avifDecoderParse(decoder);
+        if (result == AVIF_RESULT_OK) {
+            printf("Image decoded: %s\n", inputFilename);
+            avifContainerDump(decoder);
+
+            printf(" * %" PRIu64 " timescales per second, %2.2f seconds (%" PRIu64 " timescales), %d frame%s\n",
+                   decoder->timescale,
+                   decoder->duration,
+                   decoder->durationInTimescales,
+                   decoder->imageCount,
+                   (decoder->imageCount == 1) ? "" : "s");
+            if (decoder->imageCount > 1) {
+                printf(" * %s Frames: (%u expected frames)\n",
+                       (decoder->progressiveState != AVIF_PROGRESSIVE_STATE_UNAVAILABLE) ? "Progressive Image" : "Image Sequence",
+                       decoder->imageCount);
+            } else {
+                printf(" * Frame:\n");
+            }
+
+            int currIndex = 0;
+            while ((result = avifDecoderNextImage(decoder)) == AVIF_RESULT_OK) {
+                printf("   * Decoded frame [%d] [pts %2.2f (%" PRIu64 " timescales)] [duration %2.2f (%" PRIu64 " timescales)] [%ux%u]\n",
+                       currIndex,
+                       decoder->imageTiming.pts,
+                       decoder->imageTiming.ptsInTimescales,
+                       decoder->imageTiming.duration,
+                       decoder->imageTiming.durationInTimescales,
+                       decoder->image->width,
+                       decoder->image->height);
+                ++currIndex;
+            }
+            if (result == AVIF_RESULT_NO_IMAGES_REMAINING) {
+                result = AVIF_RESULT_OK;
+            } else {
+                fprintf(stderr, "ERROR: Failed to decode frame: %s\n", avifResultToString(result));
+                avifDumpDiagnostics(&decoder->diag);
+            }
+        } else {
+            fprintf(stderr, "ERROR: Failed to parse image: %s\n", avifResultToString(result));
+            avifDumpDiagnostics(&decoder->diag);
+        }
+
+        avifDecoderDestroy(decoder);
+        return result != AVIF_RESULT_OK;
+    } else {
+        if (!inputFilename || !outputFilename) {
+            syntax();
+            return 1;
+        }
+    }
+
+    printf("Decoding with codec '%s' (%d worker thread%s), please wait...\n",
+           avifCodecName(codecChoice, AVIF_CODEC_FLAG_CAN_DECODE),
+           jobs,
+           (jobs == 1) ? "" : "s");
+
+    int returnCode = 1;
+    avifDecoder * decoder = avifDecoderCreate();
+    if (!decoder) {
+        fprintf(stderr, "Memory allocation failure\n");
+        goto cleanup;
+    }
+    decoder->maxThreads = jobs;
+    decoder->codecChoice = codecChoice;
+    decoder->imageSizeLimit = imageSizeLimit;
+    decoder->imageDimensionLimit = imageDimensionLimit;
+    decoder->strictFlags = strictFlags;
+    decoder->allowProgressive = allowProgressive;
+
+    avifResult result = avifDecoderSetIOFile(decoder, inputFilename);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    result = avifDecoderParse(decoder);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "ERROR: Failed to parse image: %s\n", avifResultToString(result));
+        goto cleanup;
+    }
+
+    result = avifDecoderNthImage(decoder, frameIndex);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "ERROR: Failed to decode image: %s\n", avifResultToString(result));
+        goto cleanup;
+    }
+
+    printf("Image decoded: %s\n", inputFilename);
+    printf("Image details:\n");
+    avifImageDump(decoder->image, 0, 0, decoder->progressiveState);
+
+    if (ignoreICC && (decoder->image->icc.size > 0)) {
+        printf("[--ignore-icc] Discarding ICC profile.\n");
+        // This cannot fail.
+        result = avifImageSetProfileICC(decoder->image, NULL, 0);
+        assert(result == AVIF_RESULT_OK);
+    }
+
+    if (iccOverrideFilename) {
+        avifRWData iccOverride = AVIF_DATA_EMPTY;
+        if (!avifReadEntireFile(iccOverrideFilename, &iccOverride)) {
+            fprintf(stderr, "ERROR: Unable to read ICC: %s\n", iccOverrideFilename);
+            avifRWDataFree(&iccOverride);
+            goto cleanup;
+        }
+        printf("[--icc] Setting ICC profile: %s\n", iccOverrideFilename);
+        result = avifImageSetProfileICC(decoder->image, iccOverride.data, iccOverride.size);
+        avifRWDataFree(&iccOverride);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "ERROR: Failed to set ICC: %s\n", avifResultToString(result));
+            goto cleanup;
+        }
+    }
+
+    avifAppFileFormat outputFormat = avifGuessFileFormat(outputFilename);
+    if (outputFormat == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+        fprintf(stderr, "Cannot determine output file extension: %s\n", outputFilename);
+        goto cleanup;
+    } else if (outputFormat == AVIF_APP_FILE_FORMAT_Y4M) {
+        if (decoder->image->icc.size || decoder->image->exif.size || decoder->image->xmp.size) {
+            printf("Warning: metadata dropped when saving to y4m.\n");
+        }
+        if (!y4mWrite(outputFilename, decoder->image)) {
+            goto cleanup;
+        }
+    } else if (outputFormat == AVIF_APP_FILE_FORMAT_JPEG) {
+        // Bypass alpha multiply step during conversion
+        if (rawColor) {
+            decoder->image->alphaPremultiplied = AVIF_TRUE;
+        }
+        if (!avifJPEGWrite(outputFilename, decoder->image, jpegQuality, chromaUpsampling)) {
+            goto cleanup;
+        }
+    } else if (outputFormat == AVIF_APP_FILE_FORMAT_PNG) {
+        if (!avifPNGWrite(outputFilename, decoder->image, requestedDepth, chromaUpsampling, pngCompressionLevel)) {
+            goto cleanup;
+        }
+    } else {
+        fprintf(stderr, "Unsupported output file extension: %s\n", outputFilename);
+        goto cleanup;
+    }
+    returnCode = 0;
+
+cleanup:
+    if (decoder != NULL) {
+        if (returnCode != 0) {
+            avifDumpDiagnostics(&decoder->diag);
+        }
+        avifDecoderDestroy(decoder);
+    }
+    return returnCode;
+}
diff --git a/third_party/libavif/src/apps/avifenc.c b/third_party/libavif/src/apps/avifenc.c
new file mode 100644
index 0000000000..9836a06f87
--- /dev/null
+++ b/third_party/libavif/src/apps/avifenc.c
@@ -0,0 +1,2558 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include "avifjpeg.h"
+#include "avifpng.h"
+#include "avifutil.h"
+#include "y4m.h"
+
+#include <assert.h>
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#if defined(_WIN32)
+// for setmode()
+#include <fcntl.h>
+#include <io.h>
+#endif
+
+#define NEXTARG()                                                     \
+    if (((argIndex + 1) == argc) || (argv[argIndex + 1][0] == '-')) { \
+        fprintf(stderr, "%s requires an argument.", arg);             \
+        goto cleanup;                                                 \
+    }                                                                 \
+    arg = argv[++argIndex]
+
+typedef struct
+{
+    avifCodecChoice codecChoice;
+    int jobs;
+    int targetSize;
+    avifBool qualityIsConstrained;      // true if quality explicitly set by the user
+    avifBool qualityAlphaIsConstrained; // true if qualityAlpha explicitly set by the user
+    int overrideQuality;
+    int overrideQualityAlpha;
+    avifBool progressive; // automatic layered encoding (progressive) with single input
+    avifBool layered;     // manual layered encoding by specifying each layer
+    int layers;
+    int speed;
+    avifHeaderFormat headerFormat;
+
+    avifBool paspPresent;
+    uint32_t paspValues[2];
+    avifBool clapValid; // clapValues may contain 4 crop values and need conversion. In this case clapValid is also false.
+    uint32_t clapValues[8];
+    avifBool gridDimsPresent;
+    uint32_t gridDims[2];
+    avifBool clliPresent;
+    uint32_t clliValues[2];
+
+    int repetitionCount;
+    int keyframeInterval;
+    avifBool ignoreExif;
+    avifBool ignoreXMP;
+    avifBool ignoreColorProfile;
+
+    // These settings are only relevant when compiled with AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION
+    // (which also implies AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP).
+    avifBool qualityGainMapIsConstrained; // true if qualityGainMap explicitly set by the user
+    int qualityGainMap;
+    avifBool ignoreGainMap; // ignore any gain map present in the input file.
+
+    // This holds the output timing for image sequences. The timescale member in this struct will
+    // become the timescale set on avifEncoder, and the duration member will be the default duration
+    // for any frame that doesn't have a specific duration set on the commandline. See the
+    // declaration of avifAppSourceTiming for more documentation.
+    avifAppSourceTiming outputTiming;
+
+    avifBool cicpExplicitlySet;
+    avifColorPrimaries colorPrimaries;
+    avifTransferCharacteristics transferCharacteristics;
+    avifMatrixCoefficients matrixCoefficients;
+    avifChromaDownsampling chromaDownsampling;
+} avifSettings;
+
+typedef struct
+{
+    char ** keys;
+    char ** values;
+    int count;
+} avifCodecSpecificOptions;
+
+typedef struct avifSettingsEntryInt
+{
+    int value;
+    avifBool set;
+} avifSettingsEntryInt;
+
+static avifSettingsEntryInt intSettingsEntryOf(int value)
+{
+    avifSettingsEntryInt entry = { value, AVIF_TRUE };
+    return entry;
+}
+
+typedef avifSettingsEntryInt avifSettingsEntryBool;
+
+static avifSettingsEntryBool boolSettingsEntryOf(avifBool value)
+{
+    return intSettingsEntryOf(value);
+}
+
+typedef struct avifSettingsEntryScalingMode
+{
+    avifScalingMode value;
+    avifBool set;
+} avifSettingsEntryScalingMode;
+
+static avifSettingsEntryScalingMode scalingModeSettingsEntryOf(uint32_t n, uint32_t d)
+{
+    avifFraction mode = { (int32_t)n, (int32_t)d };
+    avifSettingsEntryScalingMode entry = { { mode, mode }, AVIF_TRUE };
+    return entry;
+}
+
+// Each entry records an "update" action to the corresponding field in avifEncoder.
+// Fields in avifEncoder are not reset after encoding an image,
+// so updates naturally apply to all following inputs,
+// and is only recorded once on the first applicable input.
+typedef struct avifInputFileSettings
+{
+    avifSettingsEntryInt quality;
+    avifSettingsEntryInt qualityAlpha;
+    avifSettingsEntryInt minQuantizer;
+    avifSettingsEntryInt maxQuantizer;
+    avifSettingsEntryInt minQuantizerAlpha;
+    avifSettingsEntryInt maxQuantizerAlpha;
+    avifSettingsEntryInt tileRowsLog2;
+    avifSettingsEntryInt tileColsLog2;
+    avifSettingsEntryBool autoTiling;
+    avifSettingsEntryScalingMode scalingMode;
+
+    avifCodecSpecificOptions codecSpecificOptions;
+} avifInputFileSettings;
+
+typedef struct avifInputFile
+{
+    const char * filename;
+    uint64_t duration; // If 0, use the default duration
+    avifInputFileSettings settings;
+} avifInputFile;
+static avifInputFile stdinFile;
+
+typedef struct
+{
+    int fileIndex;
+    avifImage * image;
+    const avifInputFileSettings * settings;
+    uint32_t fileBitDepth;
+    avifBool fileIsRGB;
+    avifAppSourceTiming sourceTiming;
+} avifInputCacheEntry;
+
+typedef struct avifInput
+{
+    avifInputFile * files;
+    int filesCount;
+    int fileIndex;
+    struct y4mFrameIterator * frameIter;
+    avifPixelFormat requestedFormat;
+    int requestedDepth;
+    avifBool useStdin;
+
+    avifBool cacheEnabled;
+    avifInputCacheEntry * cache;
+    int cacheCount;
+} avifInput;
+
+typedef struct avifEncodedByteSizes
+{
+    size_t colorSizeBytes;
+    size_t alphaSizeBytes;
+    size_t gainMapSizeBytes;
+} avifEncodedByteSizes;
+
+static void syntaxShort(void)
+{
+    printf("Syntax: avifenc [options] -q quality input.[jpg|jpeg|png|y4m] output.avif\n");
+    printf("where quality is between %d (worst quality) and %d (lossless).\n", AVIF_QUALITY_WORST, AVIF_QUALITY_LOSSLESS);
+    printf("Typical value is 60-80.\n\n");
+    printf("Try -h for an exhaustive list of options.\n");
+}
+
+static void syntaxLong(void)
+{
+    printf("Syntax: avifenc [options] input.[jpg|jpeg|png|y4m] output.avif\n");
+    printf("Standard options:\n");
+    printf("    -h,--help                         : Show syntax help (this page)\n");
+    printf("    -V,--version                      : Show the version number\n");
+    printf("\n");
+    printf("Basic options:\n");
+    printf("    -q,--qcolor Q                     : Set quality for color (%d-%d, where %d is lossless)\n",
+           AVIF_QUALITY_WORST,
+           AVIF_QUALITY_BEST,
+           AVIF_QUALITY_LOSSLESS);
+    printf("    --qalpha Q                        : Set quality for alpha (%d-%d, where %d is lossless)\n",
+           AVIF_QUALITY_WORST,
+           AVIF_QUALITY_BEST,
+           AVIF_QUALITY_LOSSLESS);
+    printf("    -s,--speed S                      : Encoder speed (%d-%d, slowest-fastest, 'default' or 'd' for codec internal defaults. default speed: 6)\n",
+           AVIF_SPEED_SLOWEST,
+           AVIF_SPEED_FASTEST);
+    printf("\n");
+    printf("Advanced options:\n");
+    printf("    -j,--jobs J                       : Number of jobs (worker threads). Use \"all\" to potentially use as many cores as possible (default: all)\n");
+    printf("    --no-overwrite                    : Never overwrite existing output file\n");
+    printf("    -o,--output FILENAME              : Instead of using the last filename given as output, use this filename\n");
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    printf("    --mini                            : Use reduced header if possible (experimental, backward-incompatible)\n");
+#endif
+    printf("    -l,--lossless                     : Set all defaults to encode losslessly, and emit warnings when settings/input don't allow for it\n");
+    printf("    -d,--depth D                      : Output depth [8,10,12]. (JPEG/PNG only; For y4m or stdin, depth is retained)\n");
+    printf("    -y,--yuv FORMAT                   : Output format [default=auto, 444, 422, 420, 400]. Ignored for y4m or stdin (y4m format is retained)\n");
+    printf("                                        For JPEG, auto honors the JPEG's internal format, if possible. For grayscale PNG, auto defaults to 400. For all other cases, auto defaults to 444\n");
+    printf("    -p,--premultiply                  : Premultiply color by the alpha channel and signal this in the AVIF\n");
+    printf("    --sharpyuv                        : Use sharp RGB to YUV420 conversion (if supported). Ignored for y4m or if output is not 420.\n");
+    printf("    --stdin                           : Read y4m frames from stdin instead of files; no input filenames allowed, must set before offering output filename\n");
+    printf("    --cicp,--nclx P/T/M               : Set CICP values (nclx colr box) (3 raw numbers, use -r to set range flag)\n");
+    printf("                                        P = color primaries\n");
+    printf("                                        T = transfer characteristics\n");
+    printf("                                        M = matrix coefficients\n");
+    printf("                                        (use 2 for any you wish to leave unspecified)\n");
+    printf("    -r,--range RANGE                  : YUV range [limited or l, full or f]. (JPEG/PNG only, default: full; For y4m or stdin, range is retained)\n");
+    printf("    --target-size S                   : Set target file size in bytes (up to 7 times slower)\n");
+    printf("    --progressive                     : EXPERIMENTAL: Auto set parameters to encode a simple layered image supporting progressive rendering from a single input frame.\n");
+    printf("    --layered                         : EXPERIMENTAL: Encode a layered AVIF. Each input is encoded as one layer and at most %d layers can be encoded.\n",
+           AVIF_MAX_AV1_LAYER_COUNT);
+    printf("    -g,--grid MxN                     : Encode a single-image grid AVIF with M cols & N rows. Either supply MxN identical W/H/D images, or a single\n");
+    printf("                                        image that can be evenly split into the MxN grid and follow AVIF grid image restrictions. The grid will adopt\n");
+    printf("                                        the color profile of the first image supplied.\n");
+    printf("    -c,--codec C                      : codec to use (choose from versions list below)\n");
+    printf("    --exif FILENAME                   : Provide an Exif metadata payload to be associated with the primary item (implies --ignore-exif)\n");
+    printf("    --xmp FILENAME                    : Provide an XMP metadata payload to be associated with the primary item (implies --ignore-xmp)\n");
+    printf("    --icc FILENAME                    : Provide an ICC profile payload to be associated with the primary item (implies --ignore-icc)\n");
+    printf("    --timescale,--fps V               : Set the timescale to V. If all frames are 1 timescale in length, this is equivalent to frames per second (Default: 30)\n");
+    printf("                                        If neither duration nor timescale are set, avifenc will attempt to use the framerate stored in a y4m header, if present.\n");
+    printf("    -k,--keyframe INTERVAL            : Set the maximum keyframe interval (any set of INTERVAL consecutive frames will have at least one keyframe). Set to 0 to disable (default).\n");
+    printf("    --ignore-exif                     : If the input file contains embedded Exif metadata, ignore it (no-op if absent)\n");
+    printf("    --ignore-xmp                      : If the input file contains embedded XMP metadata, ignore it (no-op if absent)\n");
+    printf("    --ignore-profile,--ignore-icc     : If the input file contains an embedded color profile, ignore it (no-op if absent)\n");
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    printf("    --ignore-gain-map                 : If the input file contains an embedded gain map, ignore it (no-op if absent)\n");
+    printf("    --qgain-map Q                      : Set quality for the gain map (%d-%d, where %d is lossless)\n",
+           AVIF_QUALITY_WORST,
+           AVIF_QUALITY_BEST,
+           AVIF_QUALITY_LOSSLESS);
+    // TODO(maryla): add quality setting for the gain map.
+#endif
+    printf("    --pasp H,V                        : Add pasp property (aspect ratio). H=horizontal spacing, V=vertical spacing\n");
+    printf("    --crop CROPX,CROPY,CROPW,CROPH    : Add clap property (clean aperture), but calculated from a crop rectangle\n");
+    printf("    --clap WN,WD,HN,HD,HON,HOD,VON,VOD: Add clap property (clean aperture). Width, Height, HOffset, VOffset (in num/denom pairs)\n");
+    printf("    --irot ANGLE                      : Add irot property (rotation). [0-3], makes (90 * ANGLE) degree rotation anti-clockwise\n");
+    printf("    --imir AXIS                       : Add imir property (mirroring). 0=top-to-bottom, 1=left-to-right\n");
+    printf("    --clli MaxCLL,MaxPALL             : Add clli property (content light level information).\n");
+    printf("    --repetition-count N or infinite  : Number of times an animated image sequence will be repeated. Use 'infinite' for infinite repetitions (Default: infinite)\n");
+    printf("    --                                : Signals the end of options. Everything after this is interpreted as file names.\n");
+    printf("\n");
+    printf("  The following options can optionally have a :u (or :update) suffix like `-q:u Q`, to apply only to input files appearing after the option:\n");
+    printf("    -q,--qcolor Q                     : Set quality for color (%d-%d, where %d is lossless)\n",
+           AVIF_QUALITY_WORST,
+           AVIF_QUALITY_BEST,
+           AVIF_QUALITY_LOSSLESS);
+    printf("    --qalpha Q                        : Set quality for alpha (%d-%d, where %d is lossless)\n",
+           AVIF_QUALITY_WORST,
+           AVIF_QUALITY_BEST,
+           AVIF_QUALITY_LOSSLESS);
+    printf("    --tilerowslog2 R                  : Set log2 of number of tile rows (0-6, default: 0)\n");
+    printf("    --tilecolslog2 C                  : Set log2 of number of tile columns (0-6, default: 0)\n");
+    printf("    --autotiling                      : Set --tilerowslog2 and --tilecolslog2 automatically\n");
+    printf("    --min QP                          : Set min quantizer for color (%d-%d, where %d is lossless)\n",
+           AVIF_QUANTIZER_BEST_QUALITY,
+           AVIF_QUANTIZER_WORST_QUALITY,
+           AVIF_QUANTIZER_LOSSLESS);
+    printf("    --max QP                          : Set max quantizer for color (%d-%d, where %d is lossless)\n",
+           AVIF_QUANTIZER_BEST_QUALITY,
+           AVIF_QUANTIZER_WORST_QUALITY,
+           AVIF_QUANTIZER_LOSSLESS);
+    printf("    --minalpha QP                     : Set min quantizer for alpha (%d-%d, where %d is lossless)\n",
+           AVIF_QUANTIZER_BEST_QUALITY,
+           AVIF_QUANTIZER_WORST_QUALITY,
+           AVIF_QUANTIZER_LOSSLESS);
+    printf("    --maxalpha QP                     : Set max quantizer for alpha (%d-%d, where %d is lossless)\n",
+           AVIF_QUANTIZER_BEST_QUALITY,
+           AVIF_QUANTIZER_WORST_QUALITY,
+           AVIF_QUANTIZER_LOSSLESS);
+    printf("    --scaling-mode N[/D]              : EXPERIMENTAL: Set frame (layer) scaling mode as given fraction. If omitted, D default to 1. (Default: 1/1)\n");
+    printf("    --duration D                      : Set frame durations (in timescales) to D; default 1. This option always apply to following inputs with or without suffix.\n");
+    printf("    -a,--advanced KEY[=VALUE]         : Pass an advanced, codec-specific key/value string pair directly to the codec. avifenc will warn on any not used by the codec.\n");
+    printf("\n");
+    if (avifCodecName(AVIF_CODEC_CHOICE_AOM, 0)) {
+        printf("aom-specific advanced options:\n");
+        printf("    1. <key>=<value> applies to both the color (YUV) planes and the alpha plane (if present).\n");
+        printf("    2. color:<key>=<value> or c:<key>=<value> applies only to the color (YUV) planes.\n");
+        printf("    3. alpha:<key>=<value> or a:<key>=<value> applies only to the alpha plane (if present).\n");
+        printf("       Since the alpha plane is encoded as a monochrome image, the options that refer to the chroma planes,\n");
+        printf("       such as enable-chroma-deltaq=B, should not be used with the alpha plane. In addition, the film grain\n");
+        printf("       options are unlikely to make sense for the alpha plane.\n");
+        printf("\n");
+        printf("    When used with libaom 3.0.0 or later, any key-value pairs supported by the aom_codec_set_option() function\n");
+        printf("    can be used. When used with libaom 2.0.x or older, the following key-value pairs can be used:\n");
+        printf("\n");
+        printf("    aq-mode=M                         : Adaptive quantization mode (0: off (default), 1: variance, 2: complexity, 3: cyclic refresh)\n");
+        printf("    cq-level=Q                        : Constant/Constrained Quality level (0-63, end-usage must be set to cq or q)\n");
+        printf("    enable-chroma-deltaq=B            : Enable delta quantization in chroma planes (0: disable (default), 1: enable)\n");
+        printf("    end-usage=MODE                    : Rate control mode (vbr, cbr, cq, or q)\n");
+        printf("    sharpness=S                       : Bias towards block sharpness in rate-distortion optimization of transform coefficients (0-7, default: 0)\n");
+        printf("    tune=METRIC                       : Tune the encoder for distortion metric (psnr or ssim, default: psnr)\n");
+        printf("    film-grain-test=TEST              : Film grain test vectors (0: none (default), 1: test-1  2: test-2, ... 16: test-16)\n");
+        printf("    film-grain-table=FILENAME         : Path to file containing film grain parameters\n");
+        printf("\n");
+    }
+    avifPrintVersions();
+}
+
+// This is *very* arbitrary, I just want to set people's expectations a bit
+static const char * qualityString(int quality)
+{
+    if (quality == AVIF_QUALITY_LOSSLESS) {
+        return "Lossless";
+    }
+    if (quality >= 80) {
+        return "High";
+    }
+    if (quality >= 50) {
+        return "Medium";
+    }
+    if (quality == AVIF_QUALITY_WORST) {
+        return "Worst";
+    }
+    return "Low";
+}
+
+// Parse exactly n uint32_t from arg with separator character delim.
+// Output must be able to hold at least n elements.
+// Length of arg shall not exceed 127 characters or result can be truncated.
+static avifBool parseU32List(uint32_t output[], int n, const char * arg, const char delim)
+{
+    char buffer[128];
+    strncpy(buffer, arg, 127);
+    buffer[127] = 0;
+
+    // strtok wants a string for delim, so build a single character string here.
+    const char delims[2] = { delim, '\0' };
+
+    int index = 0;
+    char * token = buffer;
+    if (n > 1) {
+        token = strtok(buffer, delims);
+    }
+    while (token != NULL) {
+        output[index] = (uint32_t)atoi(token);
+        ++index;
+        if (index >= n) {
+            break;
+        }
+
+        token = strtok(NULL, delims);
+    }
+
+    // Exactly n, and no more separator character
+    if (index == n && strchr(token, delim) == NULL) {
+        return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+typedef enum avifOptionSuffixType
+{
+    AVIF_OPTION_SUFFIX_NONE,
+    AVIF_OPTION_SUFFIX_UPDATE,
+    AVIF_OPTION_SUFFIX_INVALID,
+} avifOptionSuffixType;
+
+static avifOptionSuffixType parseOptionSuffix(const char * arg, avifBool warnNoSuffix)
+{
+    const char * suffix = strchr(arg, ':');
+
+    if (suffix == NULL) {
+        if (warnNoSuffix) {
+            fprintf(stderr,
+                    "WARNING: %s is applying to all inputs. Use %s:u to apply only to inputs after it, "
+                    "or move it before first input to avoid ambiguity.\n",
+                    arg,
+                    arg);
+        }
+        return AVIF_OPTION_SUFFIX_NONE;
+    }
+
+    if (!strcmp(suffix, ":u") || !strcmp(suffix, ":update")) {
+        return AVIF_OPTION_SUFFIX_UPDATE;
+    }
+
+    fprintf(stderr, "ERROR: Unknown option suffix in flag %s.\n", arg);
+    return AVIF_OPTION_SUFFIX_INVALID;
+}
+
+static avifBool strpre(const char * str, const char * prefix)
+{
+    return strncmp(str, prefix, strlen(prefix)) == 0;
+}
+
+static avifBool convertCropToClap(uint32_t srcW, uint32_t srcH, avifPixelFormat yuvFormat, uint32_t clapValues[8])
+{
+    avifCleanApertureBox clap;
+    avifCropRect cropRect;
+    cropRect.x = clapValues[0];
+    cropRect.y = clapValues[1];
+    cropRect.width = clapValues[2];
+    cropRect.height = clapValues[3];
+
+    avifDiagnostics diag;
+    avifDiagnosticsClearError(&diag);
+    avifBool convertResult = avifCleanApertureBoxConvertCropRect(&clap, &cropRect, srcW, srcH, yuvFormat, &diag);
+    if (!convertResult) {
+        fprintf(stderr,
+                "ERROR: Impossible crop rect: imageSize:[%ux%u], pixelFormat:%s, cropRect:[%u,%u, %ux%u] - %s\n",
+                srcW,
+                srcH,
+                avifPixelFormatToString(yuvFormat),
+                cropRect.x,
+                cropRect.y,
+                cropRect.width,
+                cropRect.height,
+                diag.error);
+        return convertResult;
+    }
+
+    clapValues[0] = clap.widthN;
+    clapValues[1] = clap.widthD;
+    clapValues[2] = clap.heightN;
+    clapValues[3] = clap.heightD;
+    clapValues[4] = clap.horizOffN;
+    clapValues[5] = clap.horizOffD;
+    clapValues[6] = clap.vertOffN;
+    clapValues[7] = clap.vertOffD;
+    return AVIF_TRUE;
+}
+
+static avifBool avifInputAddCachedImage(avifInput * input)
+{
+    avifImage * newImage = avifImageCreateEmpty();
+    if (!newImage) {
+        return AVIF_FALSE;
+    }
+    avifInputCacheEntry * newCachedImages = malloc((input->cacheCount + 1) * sizeof(*input->cache));
+    if (!newCachedImages) {
+        avifImageDestroy(newImage);
+        return AVIF_FALSE;
+    }
+    avifInputCacheEntry * oldCachedImages = input->cache;
+    input->cache = newCachedImages;
+    if (input->cacheCount) {
+        memcpy(input->cache, oldCachedImages, input->cacheCount * sizeof(*input->cache));
+    }
+    memset(&input->cache[input->cacheCount], 0, sizeof(input->cache[input->cacheCount]));
+    input->cache[input->cacheCount].fileIndex = input->fileIndex;
+    input->cache[input->cacheCount].image = newImage;
+    ++input->cacheCount;
+    free(oldCachedImages);
+    return AVIF_TRUE;
+}
+
+static avifBool fileExists(const char * filename)
+{
+    FILE * outfile = fopen(filename, "rb");
+    if (outfile) {
+        fclose(outfile);
+        return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+static const avifInputFile * avifInputGetFile(const avifInput * input, int imageIndex)
+{
+    if (imageIndex < input->cacheCount) {
+        return &input->files[input->cache[imageIndex].fileIndex];
+    }
+
+    if (input->useStdin) {
+        ungetc(fgetc(stdin), stdin); // Kick stdin to force EOF
+
+        if (feof(stdin)) {
+            return NULL;
+        }
+        return &stdinFile;
+    }
+
+    if (input->fileIndex >= input->filesCount) {
+        return NULL;
+    }
+    return &input->files[input->fileIndex];
+}
+
+static avifBool avifInputHasRemainingData(const avifInput * input, int imageIndex)
+{
+    if (imageIndex < input->cacheCount) {
+        return AVIF_TRUE;
+    }
+
+    if (input->useStdin) {
+        return !feof(stdin);
+    }
+    return (input->fileIndex < input->filesCount);
+}
+
+static avifBool avifInputReadImage(avifInput * input,
+                                   int imageIndex,
+                                   avifBool ignoreColorProfile,
+                                   avifBool ignoreExif,
+                                   avifBool ignoreXMP,
+                                   avifBool allowChangingCicp,
+                                   avifBool ignoreGainMap,
+                                   avifImage * image,
+                                   const avifInputFileSettings ** settings,
+                                   uint32_t * outDepth,
+                                   avifBool * sourceIsRGB,
+                                   avifAppSourceTiming * sourceTiming,
+                                   avifChromaDownsampling chromaDownsampling)
+{
+    if (imageIndex < input->cacheCount) {
+        const avifInputCacheEntry * cached = &input->cache[imageIndex];
+        const avifCropRect rect = { 0, 0, cached->image->width, cached->image->height };
+        if (avifImageSetViewRect(image, cached->image, &rect) != AVIF_RESULT_OK) {
+            assert(AVIF_FALSE);
+        }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+        if (cached->image->gainMap && cached->image->gainMap->image) {
+            image->gainMap->image = avifImageCreateEmpty();
+            const avifCropRect gainMapRect = { 0, 0, cached->image->gainMap->image->width, cached->image->gainMap->image->height };
+            if (avifImageSetViewRect(image->gainMap->image, cached->image->gainMap->image, &gainMapRect) != AVIF_RESULT_OK) {
+                assert(AVIF_FALSE);
+            }
+        }
+#endif
+        if (settings) {
+            *settings = cached->settings;
+        }
+        if (outDepth) {
+            *outDepth = cached->fileBitDepth;
+        }
+        if (sourceIsRGB) {
+            *sourceIsRGB = cached->fileIsRGB;
+        }
+        if (sourceTiming) {
+            *sourceTiming = cached->sourceTiming;
+        }
+        return AVIF_TRUE;
+    }
+
+    avifImage * dstImage = image;
+    const avifInputFileSettings ** dstSettings = settings;
+    uint32_t * dstDepth = outDepth;
+    avifBool * dstSourceIsRGB = sourceIsRGB;
+    avifAppSourceTiming * dstSourceTiming = sourceTiming;
+    if (input->cacheEnabled) {
+        if (!avifInputAddCachedImage(input)) {
+            fprintf(stderr, "ERROR: Out of memory");
+            return AVIF_FALSE;
+        }
+        assert(imageIndex + 1 == input->cacheCount);
+        dstImage = input->cache[imageIndex].image;
+        // Copy CICP, clap etc.
+        if (avifImageCopy(dstImage, image, /*planes=*/0) != AVIF_RESULT_OK) {
+            assert(AVIF_FALSE);
+        }
+        dstSettings = &input->cache[imageIndex].settings;
+        dstDepth = &input->cache[imageIndex].fileBitDepth;
+        dstSourceIsRGB = &input->cache[imageIndex].fileIsRGB;
+        dstSourceTiming = &input->cache[imageIndex].sourceTiming;
+    }
+
+    if (dstSourceTiming) {
+        // A source timing of all 0s is a sentinel value hinting that the value is unset / should be
+        // ignored. This is memset here as many of the paths in avifInputReadImage() do not set these
+        // values. See the declaration for avifAppSourceTiming for more information.
+        memset(dstSourceTiming, 0, sizeof(avifAppSourceTiming));
+    }
+
+    if (input->useStdin) {
+        if (feof(stdin)) {
+            return AVIF_FALSE;
+        }
+        if (!y4mRead(NULL, UINT32_MAX, dstImage, dstSourceTiming, &input->frameIter)) {
+            fprintf(stderr, "ERROR: Cannot read y4m through standard input");
+            return AVIF_FALSE;
+        }
+        if (dstSettings) {
+            *dstSettings = &input->files[0].settings;
+        }
+        if (dstDepth) {
+            *dstDepth = dstImage->depth;
+        }
+        assert(dstImage->yuvFormat != AVIF_PIXEL_FORMAT_NONE);
+        if (dstSourceIsRGB) {
+            *dstSourceIsRGB = AVIF_FALSE;
+        }
+    } else {
+        if (input->fileIndex >= input->filesCount) {
+            return AVIF_FALSE;
+        }
+
+        const avifInputFile * currentFile = &input->files[input->fileIndex];
+        const avifAppFileFormat inputFormat = avifReadImage(currentFile->filename,
+                                                            input->requestedFormat,
+                                                            input->requestedDepth,
+                                                            chromaDownsampling,
+                                                            ignoreColorProfile,
+                                                            ignoreExif,
+                                                            ignoreXMP,
+                                                            allowChangingCicp,
+                                                            ignoreGainMap,
+                                                            UINT32_MAX,
+                                                            dstImage,
+                                                            dstDepth,
+                                                            dstSourceTiming,
+                                                            &input->frameIter);
+        if (inputFormat == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+            fprintf(stderr, "Cannot read input file: %s\n", currentFile->filename);
+            return AVIF_FALSE;
+        }
+        if (dstSourceIsRGB) {
+            *dstSourceIsRGB = (inputFormat != AVIF_APP_FILE_FORMAT_Y4M);
+        }
+        if (!input->frameIter) {
+            ++input->fileIndex;
+        }
+        if (dstSettings) {
+            *dstSettings = &currentFile->settings;
+        }
+
+        assert(dstImage->yuvFormat != AVIF_PIXEL_FORMAT_NONE);
+    }
+
+    if (input->cacheEnabled) {
+        // Reuse the just created cache entry.
+        assert(imageIndex < input->cacheCount);
+        return avifInputReadImage(input,
+                                  imageIndex,
+                                  ignoreColorProfile,
+                                  ignoreExif,
+                                  ignoreXMP,
+                                  allowChangingCicp,
+                                  ignoreGainMap,
+                                  image,
+                                  settings,
+                                  outDepth,
+                                  sourceIsRGB,
+                                  sourceTiming,
+                                  chromaDownsampling);
+    }
+    return AVIF_TRUE;
+}
+
+// Returns NULL if a memory allocation failed. The return value should be freed with free().
+static char * avifStrdup(const char * str)
+{
+    size_t len = strlen(str);
+    char * dup = malloc(len + 1);
+    if (!dup) {
+        return NULL;
+    }
+    memcpy(dup, str, len + 1);
+    return dup;
+}
+
+static avifBool avifCodecSpecificOptionsAdd(avifCodecSpecificOptions * options, const char * keyValue)
+{
+    avifBool success = AVIF_FALSE;
+    char ** oldKeys = options->keys;
+    char ** oldValues = options->values;
+    options->keys = malloc((options->count + 1) * sizeof(*options->keys));
+    options->values = malloc((options->count + 1) * sizeof(*options->values));
+    if (!options->keys || !options->values) {
+        free(options->keys);
+        free(options->values);
+        options->keys = oldKeys;
+        options->values = oldValues;
+        return AVIF_FALSE;
+    }
+    if (options->count) {
+        memcpy(options->keys, oldKeys, options->count * sizeof(*options->keys));
+        memcpy(options->values, oldValues, options->count * sizeof(*options->values));
+    }
+
+    const char * value = strchr(keyValue, '=');
+    if (value) {
+        // Keep the parts on the left and on the right of the equal sign,
+        // but not the equal sign itself.
+        options->values[options->count] = avifStrdup(value + 1);
+        const size_t keyLength = strlen(keyValue) - strlen(value);
+        options->keys[options->count] = malloc(keyLength + 1);
+        if (!options->values[options->count] || !options->keys[options->count]) {
+            goto cleanup;
+        }
+        memcpy(options->keys[options->count], keyValue, keyLength);
+        options->keys[options->count][keyLength] = '\0';
+    } else {
+        // Pass in a non-NULL, empty string. Codecs can use the mere existence of a key as a boolean value.
+        options->values[options->count] = avifStrdup("");
+        options->keys[options->count] = avifStrdup(keyValue);
+        if (!options->values[options->count] || !options->keys[options->count]) {
+            goto cleanup;
+        }
+    }
+    success = AVIF_TRUE;
+cleanup:
+    ++options->count;
+    free(oldKeys);
+    free(oldValues);
+    return success;
+}
+
+static void avifCodecSpecificOptionsFree(avifCodecSpecificOptions * options)
+{
+    while (options->count) {
+        --options->count;
+        free(options->keys[options->count]);
+        free(options->values[options->count]);
+    }
+    free(options->keys);
+    free(options->values);
+    options->keys = NULL;
+    options->values = NULL;
+}
+
+// Returns the best cell size for a given horizontal or vertical dimension.
+static avifBool avifGetBestCellSize(const char * dimensionStr, uint32_t numPixels, uint32_t numCells, avifBool isSubsampled, uint32_t * cellSize)
+{
+    assert(numPixels);
+    assert(numCells);
+
+    // ISO/IEC 23008-12:2017, Section 6.6.2.3.1:
+    //   The reconstructed image is formed by tiling the input images into a grid with a column width
+    //   (potentially excluding the right-most column) equal to tile_width and a row height (potentially
+    //   excluding the bottom-most row) equal to tile_height, without gap or overlap, and then
+    //   trimming on the right and the bottom to the indicated output_width and output_height.
+    // The priority could be to use a cell size that is a multiple of 64, but there is not always a valid one,
+    // even though it is recommended by MIAF. Just use ceil(numPixels/numCells) for simplicity and to avoid
+    // as much padding in the right-most and bottom-most cells as possible.
+    // Use uint64_t computation to avoid a potential uint32_t overflow.
+    *cellSize = (uint32_t)(((uint64_t)numPixels + numCells - 1) / numCells);
+
+    // ISO/IEC 23000-22:2019, Section 7.3.11.4.2:
+    //   - the tile_width shall be greater than or equal to 64, and should be a multiple of 64
+    //   - the tile_height shall be greater than or equal to 64, and should be a multiple of 64
+    if (*cellSize < 64) {
+        *cellSize = 64;
+        if ((uint64_t)(numCells - 1) * *cellSize >= (uint64_t)numPixels) {
+            // Some cells would be entirely off-canvas.
+            fprintf(stderr, "ERROR: There are too many cells %s (%u) to have at least 64 pixels per cell.\n", dimensionStr, numCells);
+            return AVIF_FALSE;
+        }
+    }
+
+    // The maximum AV1 frame size is 65536 pixels inclusive.
+    if (*cellSize > 65536) {
+        fprintf(stderr, "ERROR: Cell size %u is bigger %s than the maximum frame size 65536.\n", *cellSize, dimensionStr);
+        return AVIF_FALSE;
+    }
+
+    // ISO/IEC 23000-22:2019, Section 7.3.11.4.2:
+    //   - when the images are in the 4:2:2 chroma sampling format the horizontal tile offsets and widths,
+    //     and the output width, shall be even numbers;
+    //   - when the images are in the 4:2:0 chroma sampling format both the horizontal and vertical tile
+    //     offsets and widths, and the output width and height, shall be even numbers.
+    if (isSubsampled && (*cellSize & 1)) {
+        ++*cellSize;
+        if ((uint64_t)(numCells - 1) * *cellSize >= (uint64_t)numPixels) {
+            // Some cells would be entirely off-canvas.
+            fprintf(stderr, "ERROR: Odd cell size %u is forbidden on a %s subsampled image.\n", *cellSize - 1, dimensionStr);
+            return AVIF_FALSE;
+        }
+    }
+
+    // Each pixel is covered by exactly one cell, and each cell contains at least one pixel.
+    assert(((uint64_t)(numCells - 1) * *cellSize < (uint64_t)numPixels) && ((uint64_t)numCells * *cellSize >= (uint64_t)numPixels));
+    return AVIF_TRUE;
+}
+
+static avifBool avifImageSplitGrid(const avifImage * gridSplitImage, uint32_t gridCols, uint32_t gridRows, avifImage ** gridCells)
+{
+    uint32_t cellWidth, cellHeight;
+    avifPixelFormatInfo formatInfo;
+    avifGetPixelFormatInfo(gridSplitImage->yuvFormat, &formatInfo);
+    const avifBool isSubsampledX = !formatInfo.monochrome && formatInfo.chromaShiftX;
+    const avifBool isSubsampledY = !formatInfo.monochrome && formatInfo.chromaShiftY;
+    if (!avifGetBestCellSize("horizontally", gridSplitImage->width, gridCols, isSubsampledX, &cellWidth) ||
+        !avifGetBestCellSize("vertically", gridSplitImage->height, gridRows, isSubsampledY, &cellHeight)) {
+        return AVIF_FALSE;
+    }
+
+    for (uint32_t gridY = 0; gridY < gridRows; ++gridY) {
+        for (uint32_t gridX = 0; gridX < gridCols; ++gridX) {
+            uint32_t gridIndex = gridX + (gridY * gridCols);
+            avifImage * cellImage = avifImageCreateEmpty();
+            if (!cellImage) {
+                fprintf(stderr, "ERROR: Cell creation failed: out of memory\n");
+                return AVIF_FALSE;
+            }
+            gridCells[gridIndex] = cellImage;
+
+            avifCropRect cellRect = { gridX * cellWidth, gridY * cellHeight, cellWidth, cellHeight };
+            if (cellRect.x + cellRect.width > gridSplitImage->width) {
+                cellRect.width = gridSplitImage->width - cellRect.x;
+            }
+            if (cellRect.y + cellRect.height > gridSplitImage->height) {
+                cellRect.height = gridSplitImage->height - cellRect.y;
+            }
+            const avifResult copyResult = avifImageSetViewRect(cellImage, gridSplitImage, &cellRect);
+            if (copyResult != AVIF_RESULT_OK) {
+                fprintf(stderr, "ERROR: Cell creation failed: %s\n", avifResultToString(copyResult));
+                return AVIF_FALSE;
+            }
+        }
+    }
+    return AVIF_TRUE;
+}
+
+#define INVALID_QUALITY (-1)
+#define DEFAULT_QUALITY 60 // Maps to a quantizer (QP) of 25.
+#define DEFAULT_QUALITY_ALPHA AVIF_QUALITY_LOSSLESS
+#define DEFAULT_QUALITY_GAIN_MAP DEFAULT_QUALITY
+#define PROGRESSIVE_WORST_QUALITY 10 // Not doing auto automatic layered encoding below this quality
+#define PROGRESSIVE_START_QUALITY 2  // First layer use this quality
+
+static avifBool avifEncodeUpdateEncoderSettings(avifEncoder * encoder, const avifInputFileSettings * settings)
+{
+    if (!settings) {
+        return AVIF_TRUE;
+    }
+
+    if (settings->quality.set) {
+        encoder->quality = settings->quality.value;
+    }
+    if (settings->qualityAlpha.set) {
+        encoder->qualityAlpha = settings->qualityAlpha.value;
+    }
+    if (settings->minQuantizer.set) {
+        encoder->minQuantizer = settings->minQuantizer.value;
+    }
+    if (settings->maxQuantizer.set) {
+        encoder->maxQuantizer = settings->maxQuantizer.value;
+    }
+    if (settings->minQuantizerAlpha.set) {
+        encoder->minQuantizerAlpha = settings->minQuantizerAlpha.value;
+    }
+    if (settings->maxQuantizerAlpha.set) {
+        encoder->maxQuantizerAlpha = settings->maxQuantizerAlpha.value;
+    }
+    if (settings->tileRowsLog2.set) {
+        encoder->tileRowsLog2 = settings->tileRowsLog2.value;
+    }
+    if (settings->tileColsLog2.set) {
+        encoder->tileColsLog2 = settings->tileColsLog2.value;
+    }
+    if (settings->autoTiling.set) {
+        encoder->autoTiling = settings->autoTiling.value;
+    }
+    if (settings->scalingMode.set) {
+        encoder->scalingMode = settings->scalingMode.value;
+    }
+    for (int i = 0; i < settings->codecSpecificOptions.count; ++i) {
+        if (avifEncoderSetCodecSpecificOption(encoder, settings->codecSpecificOptions.keys[i], settings->codecSpecificOptions.values[i]) !=
+            AVIF_RESULT_OK) {
+            fprintf(stderr,
+                    "ERROR: Failed to set codec specific option: %s = %s\n",
+                    settings->codecSpecificOptions.keys[i],
+                    settings->codecSpecificOptions.values[i]);
+            return AVIF_FALSE;
+        }
+    }
+
+    return AVIF_TRUE;
+}
+
+static avifBool avifEncoderVerifyImageCompatibility(const avifImage * refImage,
+                                                    const avifImage * testImage,
+                                                    const char * seriesType,
+                                                    const char * filename)
+{
+    // Verify that this frame's properties matches the first frame's properties
+    if ((refImage->width != testImage->width) || (refImage->height != testImage->height)) {
+        fprintf(stderr,
+                "ERROR: Image %s dimensions mismatch, [%ux%u] vs [%ux%u]: %s\n",
+                seriesType,
+                refImage->width,
+                refImage->height,
+                testImage->width,
+                testImage->height,
+                filename);
+        return AVIF_FALSE;
+    }
+    if (refImage->depth != testImage->depth) {
+        fprintf(stderr, "ERROR: Image %s depth mismatch, [%u] vs [%u]: %s\n", seriesType, refImage->depth, testImage->depth, filename);
+        return AVIF_FALSE;
+    }
+    if ((refImage->colorPrimaries != testImage->colorPrimaries) ||
+        (refImage->transferCharacteristics != testImage->transferCharacteristics) ||
+        (refImage->matrixCoefficients != testImage->matrixCoefficients)) {
+        fprintf(stderr,
+                "ERROR: Image %s CICP mismatch, [%u/%u/%u] vs [%u/%u/%u]: %s\n",
+                seriesType,
+                refImage->colorPrimaries,
+                refImage->matrixCoefficients,
+                refImage->transferCharacteristics,
+                testImage->colorPrimaries,
+                testImage->transferCharacteristics,
+                testImage->matrixCoefficients,
+                filename);
+        return AVIF_FALSE;
+    }
+    if (refImage->yuvRange != testImage->yuvRange) {
+        fprintf(stderr,
+                "ERROR: Image %s range mismatch, [%s] vs [%s]: %s\n",
+                seriesType,
+                (refImage->yuvRange == AVIF_RANGE_FULL) ? "Full" : "Limited",
+                (testImage->yuvRange == AVIF_RANGE_FULL) ? "Full" : "Limited",
+                filename);
+        return AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
+
+static avifBool avifEncodeRestOfImageSequence(avifEncoder * encoder,
+                                              const avifSettings * settings,
+                                              avifInput * input,
+                                              int imageIndex,
+                                              const avifImage * firstImage)
+{
+    avifBool success = AVIF_FALSE;
+    avifImage * nextImage = NULL;
+    const avifInputFileSettings * nextSettings = NULL;
+
+    const avifInputFile * nextFile;
+    while ((nextFile = avifInputGetFile(input, imageIndex)) != NULL) {
+        uint64_t nextDurationInTimescales = nextFile->duration ? nextFile->duration : settings->outputTiming.duration;
+
+        printf(" * Encoding frame %d [%" PRIu64 "/%" PRIu64 " ts]: %s\n",
+               imageIndex,
+               nextDurationInTimescales,
+               settings->outputTiming.timescale,
+               nextFile->filename);
+
+        if (nextImage) {
+            avifImageDestroy(nextImage);
+        }
+        nextImage = avifImageCreateEmpty();
+        if (!nextImage) {
+            fprintf(stderr, "ERROR: Out of memory\n");
+            goto cleanup;
+        }
+        nextImage->colorPrimaries = firstImage->colorPrimaries;
+        nextImage->transferCharacteristics = firstImage->transferCharacteristics;
+        nextImage->matrixCoefficients = firstImage->matrixCoefficients;
+        nextImage->yuvRange = firstImage->yuvRange;
+        nextImage->alphaPremultiplied = firstImage->alphaPremultiplied;
+
+        // Ignore ICC, Exif and XMP because only the metadata of the first frame is taken into
+        // account by the libavif API.
+        // Ignore gain map as it's not supported for sequences.
+        if (!avifInputReadImage(input,
+                                imageIndex,
+                                /*ignoreColorProfile=*/AVIF_TRUE,
+                                /*ignoreExif=*/AVIF_TRUE,
+                                /*ignoreXMP=*/AVIF_TRUE,
+                                /*allowChangingCicp=*/AVIF_FALSE,
+                                /*ignoreGainMap=*/AVIF_TRUE,
+                                nextImage,
+                                &nextSettings,
+                                /*outDepth=*/NULL,
+                                /*sourceIsRGB=*/NULL,
+                                /*sourceTiming=*/NULL,
+                                settings->chromaDownsampling)) {
+            goto cleanup;
+        }
+        if (!avifEncoderVerifyImageCompatibility(firstImage, nextImage, "sequence", nextFile->filename)) {
+            goto cleanup;
+        }
+        if (!avifEncodeUpdateEncoderSettings(encoder, nextSettings)) {
+            goto cleanup;
+        }
+        const avifResult nextImageResult = avifEncoderAddImage(encoder, nextImage, nextDurationInTimescales, AVIF_ADD_IMAGE_FLAG_NONE);
+        if (nextImageResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "ERROR: Failed to encode image: %s\n", avifResultToString(nextImageResult));
+            goto cleanup;
+        }
+        ++imageIndex;
+    }
+    success = AVIF_TRUE;
+
+cleanup:
+    if (nextImage) {
+        avifImageDestroy(nextImage);
+    }
+    return success;
+}
+
+static avifBool avifEncodeRestOfLayeredImage(avifEncoder * encoder,
+                                             const avifSettings * settings,
+                                             avifInput * input,
+                                             int layerIndex,
+                                             const avifImage * firstImage)
+{
+    avifBool success = AVIF_FALSE;
+    int layers = encoder->extraLayerCount + 1;
+    // --progressive only allows one input, so directly read from it.
+    int targetQuality = (settings->overrideQuality != INVALID_QUALITY) ? settings->overrideQuality
+                                                                       : input->files[0].settings.quality.value;
+
+    avifImage * nextImage = NULL;
+    const avifImage * encodingImage = firstImage;
+    const avifInputFileSettings * nextSettings = NULL;
+
+    if (settings->progressive && avifInputHasRemainingData(input, layerIndex)) {
+        fprintf(stderr, "ERROR: Automatic layered encoding can only have one input image.\n");
+        goto cleanup;
+    }
+
+    while (layerIndex < layers) {
+        if (settings->progressive) {
+            // reversed lerp, so that last layer reaches exact targetQuality
+            encoder->quality = targetQuality - (targetQuality - PROGRESSIVE_START_QUALITY) *
+                                                   (encoder->extraLayerCount - layerIndex) / encoder->extraLayerCount;
+        } else {
+            const avifInputFile * nextFile = avifInputGetFile(input, layerIndex);
+            // main() function should set number of layers to number of input,
+            // so nextFile should not be NULL.
+            assert(nextFile);
+
+            if (nextImage) {
+                avifImageDestroy(nextImage);
+            }
+            nextImage = avifImageCreateEmpty();
+            if (!nextImage) {
+                fprintf(stderr, "ERROR: Out of memory\n");
+                goto cleanup;
+            }
+            nextImage->colorPrimaries = firstImage->colorPrimaries;
+            nextImage->transferCharacteristics = firstImage->transferCharacteristics;
+            nextImage->matrixCoefficients = firstImage->matrixCoefficients;
+            nextImage->yuvRange = firstImage->yuvRange;
+            nextImage->alphaPremultiplied = firstImage->alphaPremultiplied;
+
+            // Ignore ICC, Exif and XMP because only the metadata of the first frame is taken into
+            // account by the libavif API.
+            // Ignore gain map because the two features are currently incompatible.
+            if (!avifInputReadImage(input,
+                                    layerIndex,
+                                    /*ignoreColorProfile=*/AVIF_TRUE,
+                                    /*ignoreExif=*/AVIF_TRUE,
+                                    /*ignoreXMP=*/AVIF_TRUE,
+                                    !settings->cicpExplicitlySet,
+                                    /*ignoreGainMap=*/AVIF_TRUE,
+                                    nextImage,
+                                    &nextSettings,
+                                    /*outDepth=*/NULL,
+                                    /*sourceIsRGB=*/NULL,
+                                    /*sourceTiming=*/NULL,
+                                    settings->chromaDownsampling)) {
+                goto cleanup;
+            }
+            // frameIter is NULL if y4m reached end, so single frame y4m is still supported.
+            if (input->frameIter) {
+                fprintf(stderr, "ERROR: Layered encoding does not support input with multiple frames: %s.\n", nextFile->filename);
+                goto cleanup;
+            }
+            if (!avifEncoderVerifyImageCompatibility(firstImage, nextImage, "layer", nextFile->filename)) {
+                goto cleanup;
+            }
+            if (!avifEncodeUpdateEncoderSettings(encoder, nextSettings)) {
+                goto cleanup;
+            }
+            encodingImage = nextImage;
+        }
+
+        printf(" * Encoding layer %d: color quality [%d (%s)], alpha quality [%d (%s)]\n",
+               layerIndex,
+               encoder->quality,
+               qualityString(encoder->quality),
+               encoder->qualityAlpha,
+               qualityString(encoder->qualityAlpha));
+
+        const avifResult result = avifEncoderAddImage(encoder, encodingImage, settings->outputTiming.duration, AVIF_ADD_IMAGE_FLAG_NONE);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "ERROR: Failed to encode image: %s\n", avifResultToString(result));
+            goto cleanup;
+        }
+        ++layerIndex;
+    }
+
+    // main() function should set number of layers to number of input,
+    // so there should be no input left.
+    assert(!avifInputHasRemainingData(input, layerIndex));
+    success = AVIF_TRUE;
+cleanup:
+    if (nextImage) {
+        avifImageDestroy(nextImage);
+    }
+    return success;
+}
+
+static avifBool avifEncodeImagesFixedQuality(const avifSettings * settings,
+                                             avifInput * input,
+                                             const avifInputFile * firstFile,
+                                             const avifImage * firstImage,
+                                             const avifImage * const * gridCells,
+                                             avifRWData * encoded,
+                                             avifEncodedByteSizes * byteSizes)
+{
+    avifBool success = AVIF_FALSE;
+    avifRWDataFree(encoded);
+    avifEncoder * encoder = avifEncoderCreate();
+    if (!encoder) {
+        fprintf(stderr, "ERROR: Out of memory\n");
+        goto cleanup;
+    }
+
+    char manualTilingStr[128];
+    snprintf(manualTilingStr,
+             sizeof(manualTilingStr),
+             "tileRowsLog2 [%d], tileColsLog2 [%d]",
+             firstFile->settings.tileRowsLog2.value,
+             firstFile->settings.tileColsLog2.value);
+
+    encoder->maxThreads = settings->jobs;
+    encoder->codecChoice = settings->codecChoice;
+    encoder->speed = settings->speed;
+    encoder->timescale = settings->outputTiming.timescale;
+    encoder->keyframeInterval = settings->keyframeInterval;
+    encoder->repetitionCount = settings->repetitionCount;
+    encoder->headerFormat = settings->headerFormat;
+    encoder->extraLayerCount = settings->layers - 1;
+    if (!avifEncodeUpdateEncoderSettings(encoder, &firstFile->settings)) {
+        goto cleanup;
+    }
+
+    if (settings->overrideQuality != INVALID_QUALITY) {
+        encoder->quality = settings->overrideQuality;
+    }
+    if (settings->overrideQualityAlpha != INVALID_QUALITY) {
+        encoder->qualityAlpha = settings->overrideQualityAlpha;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    if (settings->qualityGainMap != INVALID_QUALITY) {
+        encoder->qualityGainMap = settings->qualityGainMap;
+    }
+#endif
+
+    const char * const codecName = avifCodecName(settings->codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE);
+    char speedStr[16];
+    if (settings->speed == AVIF_SPEED_DEFAULT) {
+        strcpy(speedStr, "default");
+    } else {
+        snprintf(speedStr, sizeof(speedStr), "%d", settings->speed);
+    }
+    char gainMapStr[100] = { 0 };
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    if (firstImage->gainMap && firstImage->gainMap->image) {
+        snprintf(gainMapStr, sizeof(gainMapStr), ", gain map quality [%d (%s)]", encoder->qualityGainMap, qualityString(encoder->qualityGainMap));
+    }
+#endif
+
+    printf("Encoding with codec '%s' speed [%s], color quality [%d (%s)], alpha quality [%d (%s)]%s, %s, %d worker thread(s), please wait...\n",
+           codecName ? codecName : "none",
+           speedStr,
+           encoder->quality,
+           qualityString(encoder->quality),
+           encoder->qualityAlpha,
+           qualityString(encoder->qualityAlpha),
+           gainMapStr,
+           encoder->autoTiling ? "automatic tiling" : manualTilingStr,
+           settings->jobs);
+    if (settings->progressive) {
+        // If the color quality is less than 10, the main() function overrides
+        // --progressive and sets settings->autoProgressive to false.
+        assert(encoder->quality >= PROGRESSIVE_WORST_QUALITY);
+        // Encode the base layer with a very low quality to ensure a small encoded size.
+        encoder->quality = 2;
+        // Low alpha quality resulted in weird artifact, so we don't do it.
+    }
+
+    if (settings->layers > 1) {
+        printf(" * Encoding layer %d: color quality [%d (%s)], alpha quality [%d (%s)]\n",
+               0,
+               encoder->quality,
+               qualityString(encoder->quality),
+               encoder->qualityAlpha,
+               qualityString(encoder->qualityAlpha));
+    }
+
+    if (settings->gridDimsPresent) {
+        const avifResult addImageResult =
+            avifEncoderAddImageGrid(encoder, settings->gridDims[0], settings->gridDims[1], gridCells, AVIF_ADD_IMAGE_FLAG_SINGLE);
+        if (addImageResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "ERROR: Failed to encode image grid: %s\n", avifResultToString(addImageResult));
+            goto cleanup;
+        }
+    } else {
+        int imageIndex = 1; // firstImage with imageIndex 0 is already available.
+
+        avifAddImageFlags addImageFlags = AVIF_ADD_IMAGE_FLAG_NONE;
+        if (!avifInputHasRemainingData(input, imageIndex) && (settings->layers == 1)) {
+            addImageFlags |= AVIF_ADD_IMAGE_FLAG_SINGLE;
+        }
+
+        uint64_t firstDurationInTimescales = firstFile->duration ? firstFile->duration : settings->outputTiming.duration;
+        if (input->useStdin || (settings->layers == 1 && input->filesCount > 1)) {
+            printf(" * Encoding frame %d [%" PRIu64 "/%" PRIu64 " ts]: %s\n",
+                   0,
+                   firstDurationInTimescales,
+                   settings->outputTiming.timescale,
+                   firstFile->filename);
+        }
+        const avifResult addImageResult = avifEncoderAddImage(encoder, firstImage, firstDurationInTimescales, addImageFlags);
+        if (addImageResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "ERROR: Failed to encode image: %s\n", avifResultToString(addImageResult));
+            goto cleanup;
+        }
+
+        if (settings->layers > 1) {
+            if (!avifEncodeRestOfLayeredImage(encoder, settings, input, imageIndex, firstImage)) {
+                goto cleanup;
+            }
+        } else {
+            // Not generating a single-image grid: Use all remaining input files as subsequent
+            // frames.
+            if (!avifEncodeRestOfImageSequence(encoder, settings, input, imageIndex, firstImage)) {
+                goto cleanup;
+            }
+        }
+    }
+
+    const avifResult finishResult = avifEncoderFinish(encoder, encoded);
+    if (finishResult != AVIF_RESULT_OK) {
+        fprintf(stderr, "ERROR: Failed to finish encoding: %s\n", avifResultToString(finishResult));
+        goto cleanup;
+    }
+    success = AVIF_TRUE;
+    byteSizes->colorSizeBytes = encoder->ioStats.colorOBUSize;
+    byteSizes->alphaSizeBytes = encoder->ioStats.alphaOBUSize;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    byteSizes->gainMapSizeBytes = avifEncoderGetGainMapSizeBytes(encoder);
+#endif
+
+cleanup:
+    if (encoder) {
+        if (!success) {
+            avifDumpDiagnostics(&encoder->diag);
+        }
+        avifEncoderDestroy(encoder);
+    }
+    return success;
+}
+
+static avifBool avifEncodeImages(avifSettings * settings,
+                                 avifInput * input,
+                                 const avifInputFile * firstFile,
+                                 const avifImage * firstImage,
+                                 const avifImage * const * gridCells,
+                                 avifRWData * encoded,
+                                 avifEncodedByteSizes * byteSizes)
+{
+    if (settings->targetSize == -1) {
+        return avifEncodeImagesFixedQuality(settings, input, firstFile, firstImage, gridCells, encoded, byteSizes);
+    }
+
+    avifBool hasGainMap = AVIF_FALSE;
+    avifBool allQualitiesConstrained = settings->qualityIsConstrained && settings->qualityAlphaIsConstrained;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    hasGainMap = (firstImage->gainMap && firstImage->gainMap->image);
+    if (hasGainMap) {
+        allQualitiesConstrained = allQualitiesConstrained && settings->qualityGainMapIsConstrained;
+    }
+#endif
+
+    if (allQualitiesConstrained) {
+        fprintf(stderr, "ERROR: --target-size is used with constrained --qcolor and --qalpha %s\n", (hasGainMap ? "and --qgain-map" : ""));
+        return AVIF_FALSE;
+    }
+
+    printf("Starting a binary search to find the %s%s generating the encoded image size closest to %d bytes, please wait...\n",
+           settings->qualityAlphaIsConstrained ? "color quality"
+                                               : (settings->qualityIsConstrained ? "alpha quality" : "color and alpha qualities"),
+           (hasGainMap && !settings->qualityGainMapIsConstrained) ? " and gain map quality" : "",
+           settings->targetSize);
+    const size_t targetSize = (size_t)settings->targetSize;
+
+    // TODO(yguyon): Use quantizer instead of quality because quantizer range is smaller (faster binary search).
+    int closestQuality = INVALID_QUALITY;
+    avifRWData closestEncoded = { NULL, 0 };
+    size_t closestSizeDiff = 0;
+    avifEncodedByteSizes closestByteSizes = { 0, 0, 0 };
+
+    int minQuality = settings->progressive ? PROGRESSIVE_WORST_QUALITY : AVIF_QUALITY_WORST; // inclusive
+    int maxQuality = AVIF_QUALITY_BEST;                                                      // inclusive
+    while (minQuality <= maxQuality) {
+        const int quality = (minQuality + maxQuality) / 2;
+        if (!settings->qualityIsConstrained) {
+            settings->overrideQuality = quality;
+        }
+        if (!settings->qualityAlphaIsConstrained) {
+            settings->overrideQualityAlpha = quality;
+        }
+        if (!settings->qualityGainMapIsConstrained) {
+            settings->qualityGainMap = quality;
+        }
+
+        if (!avifEncodeImagesFixedQuality(settings, input, firstFile, firstImage, gridCells, encoded, byteSizes)) {
+            avifRWDataFree(&closestEncoded);
+            return AVIF_FALSE;
+        }
+        printf("Encoded image of size %" AVIF_FMT_ZU " bytes.\n", encoded->size);
+
+        if (encoded->size == targetSize) {
+            return AVIF_TRUE;
+        }
+
+        size_t sizeDiff;
+        if (encoded->size > targetSize) {
+            sizeDiff = encoded->size - targetSize;
+            maxQuality = quality - 1;
+        } else {
+            sizeDiff = targetSize - encoded->size;
+            minQuality = quality + 1;
+        }
+
+        if ((closestQuality == INVALID_QUALITY) || (sizeDiff < closestSizeDiff)) {
+            closestQuality = quality;
+            avifRWDataFree(&closestEncoded);
+            closestEncoded = *encoded;
+            encoded->size = 0;
+            encoded->data = NULL;
+            closestSizeDiff = sizeDiff;
+            closestByteSizes = *byteSizes;
+        }
+    }
+
+    if (!settings->qualityIsConstrained) {
+        settings->overrideQuality = closestQuality;
+    }
+    if (!settings->qualityAlphaIsConstrained) {
+        settings->overrideQualityAlpha = closestQuality;
+    }
+    avifRWDataFree(encoded);
+    *encoded = closestEncoded;
+    *byteSizes = closestByteSizes;
+    printf("Kept the encoded image of size %" AVIF_FMT_ZU " bytes generated with ", encoded->size);
+    if (!settings->qualityIsConstrained) {
+        printf("color quality %d", settings->overrideQuality);
+    }
+    if (!settings->qualityAlphaIsConstrained) {
+        if (!settings->qualityIsConstrained) {
+            printf(" and ");
+        }
+        printf("alpha quality %d", settings->overrideQualityAlpha);
+    }
+    printf(".\n");
+    return AVIF_TRUE;
+}
+
+int main(int argc, char * argv[])
+{
+    if (argc < 2) {
+        syntaxShort();
+        return 1;
+    }
+
+    const char * outputFilename = NULL;
+
+    avifInput input;
+    memset(&input, 0, sizeof(input));
+    input.files = malloc(sizeof(avifInputFile) * argc);
+    if (input.files == NULL) {
+        fprintf(stderr, "ERROR: memory allocation failure\n");
+        return 1;
+    }
+    input.requestedFormat = AVIF_PIXEL_FORMAT_NONE; // AVIF_PIXEL_FORMAT_NONE is used as a sentinel for "auto"
+
+    // See here for the discussion on the semi-arbitrary defaults for speed:
+    //     https://github.com/AOMediaCodec/libavif/issues/440
+
+    int returnCode = 1;
+    avifBool noOverwrite = AVIF_FALSE;
+    avifSettings settings;
+    memset(&settings, 0, sizeof(settings));
+    settings.codecChoice = AVIF_CODEC_CHOICE_AUTO;
+    settings.jobs = -1;
+    settings.targetSize = -1;
+    settings.qualityIsConstrained = AVIF_FALSE;
+    settings.qualityAlphaIsConstrained = AVIF_FALSE;
+    settings.overrideQuality = INVALID_QUALITY;
+    settings.overrideQualityAlpha = INVALID_QUALITY;
+    settings.qualityGainMap = DEFAULT_QUALITY_GAIN_MAP;
+    settings.progressive = AVIF_FALSE;
+    settings.layered = AVIF_FALSE;
+    settings.layers = 0;
+    settings.speed = 6;
+    settings.headerFormat = AVIF_HEADER_FULL;
+    settings.repetitionCount = AVIF_REPETITION_COUNT_INFINITE;
+    settings.keyframeInterval = 0;
+    settings.ignoreExif = AVIF_FALSE;
+    settings.ignoreXMP = AVIF_FALSE;
+    settings.ignoreColorProfile = AVIF_FALSE;
+    settings.ignoreGainMap = AVIF_FALSE;
+    settings.cicpExplicitlySet = AVIF_FALSE;
+
+    avifInputFileSettings pendingSettings;
+    memset(&pendingSettings, 0, sizeof(pendingSettings));
+
+    avifBool cropConversionRequired = AVIF_FALSE;
+    uint8_t irotAngle = 0xff; // sentinel value indicating "unused"
+    uint8_t imirAxis = 0xff;  // sentinel value indicating "unused"
+    avifRange requestedRange = AVIF_RANGE_FULL;
+    avifBool lossless = AVIF_FALSE;
+    avifImage * image = NULL;
+    avifRWData raw = AVIF_DATA_EMPTY;
+    avifRWData exifOverride = AVIF_DATA_EMPTY;
+    avifRWData xmpOverride = AVIF_DATA_EMPTY;
+    avifRWData iccOverride = AVIF_DATA_EMPTY;
+    avifBool premultiplyAlpha = AVIF_FALSE;
+    uint32_t gridCellCount = 0;
+    avifImage ** gridCells = NULL;
+    avifImage * gridSplitImage = NULL; // used for cleanup tracking
+
+    // By default, the color profile itself is unspecified, so CP/TC are set (to 2) accordingly.
+    // However, if the end-user doesn't specify any CICP, we will convert to YUV using BT601
+    // coefficients anyway (as MC:2 falls back to MC:5/6), so we might as well signal it explicitly.
+    // See: ISO/IEC 23000-22:2019 Amendment 2, or the comment in avifCalcYUVCoefficients()
+    settings.colorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;
+    settings.transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED;
+    settings.matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;
+    settings.chromaDownsampling = AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC;
+
+    int argIndex = 1;
+    while (argIndex < argc) {
+        const char * arg = argv[argIndex];
+
+        if (!strcmp(arg, "--")) {
+            // Stop parsing flags, everything after this is positional arguments
+            ++argIndex;
+            // Parse additional positional arguments if any
+            while (argIndex < argc) {
+                arg = argv[argIndex];
+                input.files[input.filesCount].filename = arg;
+                input.files[input.filesCount].duration = settings.outputTiming.duration;
+                input.files[input.filesCount].settings = pendingSettings;
+                memset(&pendingSettings, 0, sizeof(pendingSettings));
+                ++input.filesCount;
+                ++argIndex;
+            }
+            break;
+        } else if (!strcmp(arg, "-h") || !strcmp(arg, "--help")) {
+            syntaxLong();
+            returnCode = 0;
+            goto cleanup;
+        } else if (!strcmp(arg, "-V") || !strcmp(arg, "--version")) {
+            avifPrintVersions();
+            returnCode = 0;
+            goto cleanup;
+        } else if (!strcmp(arg, "--no-overwrite")) {
+            noOverwrite = AVIF_TRUE;
+        } else if (!strcmp(arg, "-j") || !strcmp(arg, "--jobs")) {
+            NEXTARG();
+            if (!strcmp(arg, "all")) {
+                settings.jobs = avifQueryCPUCount();
+            } else {
+                settings.jobs = atoi(arg);
+                if (settings.jobs < 1) {
+                    settings.jobs = 1;
+                }
+            }
+        } else if (!strcmp(arg, "--stdin")) {
+            input.useStdin = AVIF_TRUE;
+        } else if (!strcmp(arg, "-o") || !strcmp(arg, "--output")) {
+            NEXTARG();
+            outputFilename = arg;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+        } else if (!strcmp(arg, "--mini")) {
+            settings.headerFormat = AVIF_HEADER_REDUCED;
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+        } else if (!strcmp(arg, "-d") || !strcmp(arg, "--depth")) {
+            NEXTARG();
+            input.requestedDepth = atoi(arg);
+            if ((input.requestedDepth != 8) && (input.requestedDepth != 10) && (input.requestedDepth != 12)) {
+                fprintf(stderr, "ERROR: invalid depth: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "-y") || !strcmp(arg, "--yuv")) {
+            NEXTARG();
+            if (!strcmp(arg, "444")) {
+                input.requestedFormat = AVIF_PIXEL_FORMAT_YUV444;
+            } else if (!strcmp(arg, "422")) {
+                input.requestedFormat = AVIF_PIXEL_FORMAT_YUV422;
+            } else if (!strcmp(arg, "420")) {
+                input.requestedFormat = AVIF_PIXEL_FORMAT_YUV420;
+            } else if (!strcmp(arg, "400")) {
+                input.requestedFormat = AVIF_PIXEL_FORMAT_YUV400;
+            } else {
+                fprintf(stderr, "ERROR: invalid format: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "-k") || !strcmp(arg, "--keyframe")) {
+            NEXTARG();
+            settings.keyframeInterval = atoi(arg);
+        } else if (!strcmp(arg, "-q") || !strcmp(arg, "--qcolor") || strpre(arg, "-q:") || strpre(arg, "--qcolor:")) {
+            // For compatibility reason unsuffixed flags always apply to all input (as if they appear before first input).
+            // Print a warning if unsuffixed flag appears after input file.
+            avifOptionSuffixType type = parseOptionSuffix(arg, /*warnNoSuffix=*/input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int quality = atoi(arg);
+            if (quality < AVIF_QUALITY_WORST) {
+                quality = AVIF_QUALITY_WORST;
+            }
+            if (quality > AVIF_QUALITY_BEST) {
+                quality = AVIF_QUALITY_BEST;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.quality = intSettingsEntryOf(quality);
+            } else {
+                input.files[0].settings.quality = intSettingsEntryOf(quality);
+            }
+        } else if (!strcmp(arg, "--qalpha") || strpre(arg, "--qalpha:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int qualityAlpha = atoi(arg);
+            if (qualityAlpha < AVIF_QUALITY_WORST) {
+                qualityAlpha = AVIF_QUALITY_WORST;
+            }
+            if (qualityAlpha > AVIF_QUALITY_BEST) {
+                qualityAlpha = AVIF_QUALITY_BEST;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.qualityAlpha = intSettingsEntryOf(qualityAlpha);
+            } else {
+                input.files[0].settings.qualityAlpha = intSettingsEntryOf(qualityAlpha);
+            }
+        } else if (!strcmp(arg, "--min") || strpre(arg, "--min:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int minQuantizer = atoi(arg);
+            if (minQuantizer < AVIF_QUANTIZER_BEST_QUALITY) {
+                minQuantizer = AVIF_QUANTIZER_BEST_QUALITY;
+            }
+            if (minQuantizer > AVIF_QUANTIZER_WORST_QUALITY) {
+                minQuantizer = AVIF_QUANTIZER_WORST_QUALITY;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.minQuantizer = intSettingsEntryOf(minQuantizer);
+            } else {
+                input.files[0].settings.minQuantizer = intSettingsEntryOf(minQuantizer);
+            }
+        } else if (!strcmp(arg, "--max") || strpre(arg, "--max:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int maxQuantizer = atoi(arg);
+            if (maxQuantizer < AVIF_QUANTIZER_BEST_QUALITY) {
+                maxQuantizer = AVIF_QUANTIZER_BEST_QUALITY;
+            }
+            if (maxQuantizer > AVIF_QUANTIZER_WORST_QUALITY) {
+                maxQuantizer = AVIF_QUANTIZER_WORST_QUALITY;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.maxQuantizer = intSettingsEntryOf(maxQuantizer);
+            } else {
+                input.files[0].settings.maxQuantizer = intSettingsEntryOf(maxQuantizer);
+            }
+        } else if (!strcmp(arg, "--minalpha") || strpre(arg, "--minalpha:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int minQuantizerAlpha = atoi(arg);
+            if (minQuantizerAlpha < AVIF_QUANTIZER_BEST_QUALITY) {
+                minQuantizerAlpha = AVIF_QUANTIZER_BEST_QUALITY;
+            }
+            if (minQuantizerAlpha > AVIF_QUANTIZER_WORST_QUALITY) {
+                minQuantizerAlpha = AVIF_QUANTIZER_WORST_QUALITY;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.minQuantizerAlpha = intSettingsEntryOf(minQuantizerAlpha);
+            } else {
+                input.files[0].settings.minQuantizerAlpha = intSettingsEntryOf(minQuantizerAlpha);
+            }
+        } else if (!strcmp(arg, "--maxalpha") || strpre(arg, "--maxalpha:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int maxQuantizerAlpha = atoi(arg);
+            if (maxQuantizerAlpha < AVIF_QUANTIZER_BEST_QUALITY) {
+                maxQuantizerAlpha = AVIF_QUANTIZER_BEST_QUALITY;
+            }
+            if (maxQuantizerAlpha > AVIF_QUANTIZER_WORST_QUALITY) {
+                maxQuantizerAlpha = AVIF_QUANTIZER_WORST_QUALITY;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.maxQuantizerAlpha = intSettingsEntryOf(maxQuantizerAlpha);
+            } else {
+                input.files[0].settings.maxQuantizerAlpha = intSettingsEntryOf(maxQuantizerAlpha);
+            }
+        } else if (!strcmp(arg, "--target-size")) {
+            NEXTARG();
+            settings.targetSize = atoi(arg);
+            if (settings.targetSize < 0) {
+                settings.targetSize = -1;
+            }
+        } else if (!strcmp(arg, "--tilerowslog2") || strpre(arg, "--tilerowslog2:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int tileRowsLog2 = atoi(arg);
+            if (tileRowsLog2 < 0) {
+                tileRowsLog2 = 0;
+            }
+            if (tileRowsLog2 > 6) {
+                tileRowsLog2 = 6;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.tileRowsLog2 = intSettingsEntryOf(tileRowsLog2);
+            } else {
+                input.files[0].settings.tileRowsLog2 = intSettingsEntryOf(tileRowsLog2);
+            }
+        } else if (!strcmp(arg, "--tilecolslog2") || strpre(arg, "--tilecolslog2:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int tileColsLog2 = atoi(arg);
+            if (tileColsLog2 < 0) {
+                tileColsLog2 = 0;
+            }
+            if (tileColsLog2 > 6) {
+                tileColsLog2 = 6;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.tileColsLog2 = intSettingsEntryOf(tileColsLog2);
+            } else {
+                input.files[0].settings.tileColsLog2 = intSettingsEntryOf(tileColsLog2);
+            }
+        } else if (!strcmp(arg, "--autotiling") || strpre(arg, "--autotiling:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.autoTiling = boolSettingsEntryOf(AVIF_TRUE);
+            } else {
+                input.files[0].settings.autoTiling = boolSettingsEntryOf(AVIF_TRUE);
+            }
+        } else if (!strcmp(arg, "--progressive")) {
+            if (settings.layered) {
+                fprintf(stderr, "ERROR: Can not use both --progressive and --layered\n");
+                goto cleanup;
+            }
+            settings.progressive = AVIF_TRUE;
+        } else if (!strcmp(arg, "--layered")) {
+            if (settings.progressive) {
+                fprintf(stderr, "ERROR: Can not use both --progressive and --layered\n");
+                goto cleanup;
+            }
+            settings.layered = AVIF_TRUE;
+        } else if (!strcmp(arg, "--scaling-mode") || strpre(arg, "--scaling-mode:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            uint32_t frac[2] = { 0, 1 };
+            if (!(parseU32List(frac, 1, arg, '/') || parseU32List(frac, 2, arg, '/')) || frac[0] > INT32_MAX || frac[1] > INT32_MAX) {
+                fprintf(stderr, "ERROR: Invalid scaling mode: %s\n", arg);
+                goto cleanup;
+            }
+            if (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) {
+                pendingSettings.scalingMode = scalingModeSettingsEntryOf(frac[0], frac[1]);
+            } else {
+                input.files[0].settings.scalingMode = scalingModeSettingsEntryOf(frac[0], frac[1]);
+            }
+        } else if (!strcmp(arg, "-g") || !strcmp(arg, "--grid")) {
+            NEXTARG();
+            if (!parseU32List(settings.gridDims, 2, arg, 'x')) {
+                fprintf(stderr, "ERROR: Invalid grid dims: %s\n", arg);
+                goto cleanup;
+            }
+            settings.gridDimsPresent = AVIF_TRUE;
+            if ((settings.gridDims[0] == 0) || (settings.gridDims[0] > 256) || (settings.gridDims[1] == 0) ||
+                (settings.gridDims[1] > 256)) {
+                fprintf(stderr, "ERROR: Invalid grid dims (valid dim range [1-256]): %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "--cicp") || !strcmp(arg, "--nclx")) {
+            NEXTARG();
+            uint32_t cicp[3];
+            if (!parseU32List(cicp, 3, arg, '/')) {
+                fprintf(stderr, "ERROR: Invalid CICP value: %s\n", arg);
+                goto cleanup;
+            }
+            settings.colorPrimaries = (avifColorPrimaries)cicp[0];
+            settings.transferCharacteristics = (avifTransferCharacteristics)cicp[1];
+            settings.matrixCoefficients = (avifMatrixCoefficients)cicp[2];
+            settings.cicpExplicitlySet = AVIF_TRUE;
+        } else if (!strcmp(arg, "-r") || !strcmp(arg, "--range")) {
+            NEXTARG();
+            if (!strcmp(arg, "limited") || !strcmp(arg, "l")) {
+                requestedRange = AVIF_RANGE_LIMITED;
+            } else if (!strcmp(arg, "full") || !strcmp(arg, "f")) {
+                requestedRange = AVIF_RANGE_FULL;
+            } else {
+                fprintf(stderr, "ERROR: Unknown range: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "-s") || !strcmp(arg, "--speed")) {
+            NEXTARG();
+            if (!strcmp(arg, "default") || !strcmp(arg, "d")) {
+                settings.speed = AVIF_SPEED_DEFAULT;
+            } else {
+                settings.speed = atoi(arg);
+                if (settings.speed > AVIF_SPEED_FASTEST) {
+                    settings.speed = AVIF_SPEED_FASTEST;
+                }
+                if (settings.speed < AVIF_SPEED_SLOWEST) {
+                    settings.speed = AVIF_SPEED_SLOWEST;
+                }
+            }
+        } else if (!strcmp(arg, "--exif")) {
+            NEXTARG();
+            if (!avifReadEntireFile(arg, &exifOverride)) {
+                fprintf(stderr, "ERROR: Unable to read Exif metadata: %s\n", arg);
+                goto cleanup;
+            }
+            settings.ignoreExif = AVIF_TRUE;
+        } else if (!strcmp(arg, "--xmp")) {
+            NEXTARG();
+            if (!avifReadEntireFile(arg, &xmpOverride)) {
+                fprintf(stderr, "ERROR: Unable to read XMP metadata: %s\n", arg);
+                goto cleanup;
+            }
+            settings.ignoreXMP = AVIF_TRUE;
+        } else if (!strcmp(arg, "--icc")) {
+            NEXTARG();
+            if (!avifReadEntireFile(arg, &iccOverride)) {
+                fprintf(stderr, "ERROR: Unable to read ICC profile: %s\n", arg);
+                goto cleanup;
+            }
+            settings.ignoreColorProfile = AVIF_TRUE;
+        } else if (!strcmp(arg, "--duration") || strpre(arg, "--duration:")) {
+            // --duration is special, we always treat it as suffixed with :u, so don't print warning for it.
+            avifOptionSuffixType type = parseOptionSuffix(arg, /*warnNoSuffix=*/AVIF_FALSE);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            int durationInt = atoi(arg);
+            if (durationInt < 1) {
+                fprintf(stderr, "ERROR: Invalid duration: %d\n", durationInt);
+                goto cleanup;
+            }
+            settings.outputTiming.duration = (uint64_t)durationInt;
+        } else if (!strcmp(arg, "--timescale") || !strcmp(arg, "--fps")) {
+            NEXTARG();
+            int timescaleInt = atoi(arg);
+            if (timescaleInt < 1) {
+                fprintf(stderr, "ERROR: Invalid timescale: %d\n", timescaleInt);
+                goto cleanup;
+            }
+            settings.outputTiming.timescale = (uint64_t)timescaleInt;
+        } else if (!strcmp(arg, "-c") || !strcmp(arg, "--codec")) {
+            NEXTARG();
+            settings.codecChoice = avifCodecChoiceFromName(arg);
+            if (settings.codecChoice == AVIF_CODEC_CHOICE_AUTO) {
+                fprintf(stderr, "ERROR: Unrecognized codec: %s\n", arg);
+                goto cleanup;
+            } else {
+                const char * codecName = avifCodecName(settings.codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE);
+                if (codecName == NULL) {
+                    fprintf(stderr, "ERROR: Codec cannot encode: %s\n", arg);
+                    goto cleanup;
+                }
+            }
+        } else if (!strcmp(arg, "-a") || !strcmp(arg, "--advanced") || strpre(arg, "-a:") || strpre(arg, "--advanced:")) {
+            avifOptionSuffixType type = parseOptionSuffix(arg, input.filesCount != 0);
+            if (type == AVIF_OPTION_SUFFIX_INVALID) {
+                goto cleanup;
+            }
+            NEXTARG();
+            avifInputFileSettings * targetSettings =
+                (type == AVIF_OPTION_SUFFIX_UPDATE || input.filesCount == 0) ? &pendingSettings : &input.files[0].settings;
+            if (!avifCodecSpecificOptionsAdd(&targetSettings->codecSpecificOptions, arg)) {
+                fprintf(stderr, "ERROR: Out of memory when setting codec specific option: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "--ignore-exif")) {
+            settings.ignoreExif = AVIF_TRUE;
+        } else if (!strcmp(arg, "--ignore-xmp")) {
+            settings.ignoreXMP = AVIF_TRUE;
+        } else if (!strcmp(arg, "--ignore-profile") || !strcmp(arg, "--ignore-icc")) {
+            settings.ignoreColorProfile = AVIF_TRUE;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+        } else if (!strcmp(arg, "--ignore-gain-map")) {
+            settings.ignoreGainMap = AVIF_TRUE;
+        } else if (!strcmp(arg, "--qgain-map")) {
+            NEXTARG();
+            int qualityGainMap = atoi(arg);
+            if (qualityGainMap < AVIF_QUALITY_WORST) {
+                qualityGainMap = AVIF_QUALITY_WORST;
+            }
+            if (qualityGainMap > AVIF_QUALITY_BEST) {
+                qualityGainMap = AVIF_QUALITY_BEST;
+            }
+            settings.qualityGainMap = qualityGainMap;
+            settings.qualityGainMapIsConstrained = AVIF_TRUE;
+#endif
+        } else if (!strcmp(arg, "--pasp")) {
+            NEXTARG();
+            if (!parseU32List(settings.paspValues, 2, arg, ',')) {
+                fprintf(stderr, "ERROR: Invalid pasp values: %s\n", arg);
+                goto cleanup;
+            }
+            settings.paspPresent = AVIF_TRUE;
+        } else if (!strcmp(arg, "--crop")) {
+            NEXTARG();
+            if (!parseU32List(settings.clapValues, 4, arg, ',')) {
+                fprintf(stderr, "ERROR: Invalid crop values: %s\n", arg);
+                goto cleanup;
+            }
+            cropConversionRequired = AVIF_TRUE;
+        } else if (!strcmp(arg, "--clap")) {
+            NEXTARG();
+            if (!parseU32List(settings.clapValues, 8, arg, ',')) {
+                fprintf(stderr, "ERROR: Invalid clap values: %s\n", arg);
+                goto cleanup;
+            }
+            settings.clapValid = AVIF_TRUE;
+        } else if (!strcmp(arg, "--irot")) {
+            NEXTARG();
+            irotAngle = (uint8_t)atoi(arg);
+            if (irotAngle > 3) {
+                fprintf(stderr, "ERROR: Invalid irot angle: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "--imir")) {
+            NEXTARG();
+            imirAxis = (uint8_t)atoi(arg);
+            if (imirAxis > 1) {
+                fprintf(stderr, "ERROR: Invalid imir axis: %s\n", arg);
+                goto cleanup;
+            }
+        } else if (!strcmp(arg, "--clli")) {
+            NEXTARG();
+            if (!parseU32List(settings.clliValues, 2, arg, ',') || settings.clliValues[0] >= (1u << 16) ||
+                settings.clliValues[1] >= (1u << 16)) {
+                fprintf(stderr, "ERROR: Invalid clli values: %s\n", arg);
+                goto cleanup;
+            }
+            settings.clliPresent = AVIF_TRUE;
+        } else if (!strcmp(arg, "--repetition-count")) {
+            NEXTARG();
+            if (!strcmp(arg, "infinite")) {
+                settings.repetitionCount = AVIF_REPETITION_COUNT_INFINITE;
+            } else {
+                settings.repetitionCount = atoi(arg);
+                if (settings.repetitionCount < 0) {
+                    fprintf(stderr, "ERROR: Invalid repetition count: %s\n", arg);
+                    goto cleanup;
+                }
+            }
+        } else if (!strcmp(arg, "-l") || !strcmp(arg, "--lossless")) {
+            lossless = AVIF_TRUE;
+        } else if (!strcmp(arg, "-p") || !strcmp(arg, "--premultiply")) {
+            premultiplyAlpha = AVIF_TRUE;
+        } else if (!strcmp(arg, "--sharpyuv")) {
+            settings.chromaDownsampling = AVIF_CHROMA_DOWNSAMPLING_SHARP_YUV;
+        } else if (arg[0] == '-') {
+            fprintf(stderr, "ERROR: unrecognized option %s\n\n", arg);
+            syntaxLong();
+            goto cleanup;
+        } else {
+            // Positional argument
+            input.files[input.filesCount].filename = arg;
+            input.files[input.filesCount].duration = settings.outputTiming.duration;
+            input.files[input.filesCount].settings = pendingSettings;
+            memset(&pendingSettings, 0, sizeof(pendingSettings));
+            ++input.filesCount;
+        }
+
+        ++argIndex;
+    }
+
+    if (settings.jobs == -1) {
+        settings.jobs = avifQueryCPUCount();
+    }
+
+    // Check global lossless parameters and set to default if needed.
+    if (lossless) {
+        // Pixel format.
+        if (input.requestedFormat != AVIF_PIXEL_FORMAT_NONE && input.requestedFormat != AVIF_PIXEL_FORMAT_YUV444 &&
+            input.requestedFormat != AVIF_PIXEL_FORMAT_YUV400) {
+            fprintf(stderr,
+                    "When set, the pixel format can only be 444 in lossless "
+                    "mode. 400 also works if the input is grayscale.\n");
+            goto cleanup;
+        }
+        // Codec.
+        const char * codecName = avifCodecName(settings.codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE);
+        if (codecName && !strcmp(codecName, "rav1e")) {
+            fprintf(stderr, "rav1e doesn't support lossless encoding yet: https://github.com/xiph/rav1e/issues/151\n");
+            goto cleanup;
+        } else if (codecName && !strcmp(codecName, "svt")) {
+            fprintf(stderr, "SVT-AV1 doesn't support lossless encoding yet: https://gitlab.com/AOMediaCodec/SVT-AV1/-/issues/1636\n");
+            goto cleanup;
+        }
+        // Range.
+        if (requestedRange != AVIF_RANGE_FULL) {
+            fprintf(stderr, "Range has to be full in lossless mode.\n");
+            goto cleanup;
+        }
+        // Matrix coefficients.
+        if (settings.cicpExplicitlySet) {
+            avifBool incompatibleMC = (settings.matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_IDENTITY);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+            incompatibleMC &= (settings.matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_YCGCO_RE &&
+                               settings.matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_YCGCO_RO);
+#endif
+            if (incompatibleMC) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                fprintf(stderr, "Matrix coefficients have to be identity, YCgCo-Re, or YCgCo-Ro in lossless mode.\n");
+#else
+                fprintf(stderr, "Matrix coefficients have to be identity in lossless mode.\n");
+#endif
+                goto cleanup;
+            }
+        } else {
+            settings.matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_IDENTITY;
+        }
+        if (settings.progressive) {
+            fprintf(stderr, "Automatic layered encoding is unsupported in lossless mode.\n");
+        }
+    }
+
+    stdinFile.filename = "(stdin)";
+    stdinFile.duration = settings.outputTiming.duration;
+
+    avifInputFileSettings emptySettingsReference;
+    memset(&emptySettingsReference, 0, sizeof(emptySettingsReference));
+
+    if (!outputFilename) {
+        if (((input.useStdin && (input.filesCount == 1)) || (!input.useStdin && (input.filesCount > 1)))) {
+            --input.filesCount;
+            outputFilename = input.files[input.filesCount].filename;
+            if (memcmp(&input.files[input.filesCount].settings, &emptySettingsReference, sizeof(avifInputFileSettings)) != 0) {
+                fprintf(stderr, "WARNING: Trailing options with update suffix has no effect. Place them before the input you intend to apply to.\n");
+            }
+        }
+    }
+
+    if (!outputFilename || (input.useStdin && (input.filesCount > 0)) || (!input.useStdin && (input.filesCount < 1))) {
+        syntaxShort();
+        goto cleanup;
+    }
+
+    if (noOverwrite && fileExists(outputFilename)) {
+        fprintf(stderr, "ERROR: output file %s already exists and --no-overwrite was specified\n", outputFilename);
+        goto cleanup;
+    }
+
+#if defined(_WIN32)
+    if (input.useStdin) {
+        setmode(fileno(stdin), O_BINARY);
+    }
+#endif
+
+    if (memcmp(&pendingSettings, &emptySettingsReference, sizeof(avifInputFileSettings)) != 0) {
+        fprintf(stderr, "WARNING: Trailing options with update suffix has no effect. Place them before the input you intend to apply to.\n");
+    }
+
+    // Check layer config
+    if (settings.progressive) {
+        assert(!settings.layered);
+        if (input.filesCount > 1) {
+            fprintf(stderr, "ERROR: --progressive only supports one input.\n");
+            goto cleanup;
+        }
+        // for automatic layered encoding, make a 2 layer AVIF.
+        settings.layers = 2;
+    } else if (settings.layered) {
+        // For manual layered encoding, infer number of layers from input count.
+        // For multi-frame input (Y4Ms) layered encoding only use the first frame,
+        // so that we can assume number of inputs is number of layers.
+        // We don't support changing config halfway encoding on input,
+        // therefore encoding layered AVIF with single multi-frame input is not very meaningful.
+        if (input.filesCount < 2 || input.filesCount > AVIF_MAX_AV1_LAYER_COUNT) {
+            fprintf(stderr, "Encoding layered AVIF required 2 to %d inputs, but got %d.\n", AVIF_MAX_AV1_LAYER_COUNT, input.filesCount);
+            goto cleanup;
+        }
+        settings.layers = input.filesCount;
+    } else {
+        settings.layers = 1;
+    }
+    if (settings.layers > 1 && settings.gridDimsPresent) {
+        fprintf(stderr, "Layered grid image unimplemented in avifenc.\n");
+        goto cleanup;
+    }
+
+    for (int i = 0; i < input.filesCount; ++i) {
+        avifInputFile * file = &input.files[i];
+        avifInputFileSettings * fileSettings = &file->settings;
+
+        // Check tiling parameters.
+        // Auto tiling (autoTiling) and manual tiling (tileRowsLog2, tileColsLog2) are mutually exclusive, which means:
+        // - At each input, only one of the two shall be set.
+        // - At some input, specify one disables the other.
+        if (fileSettings->autoTiling.set) {
+            if (fileSettings->tileRowsLog2.set || fileSettings->tileColsLog2.set) {
+                fprintf(stderr, "ERROR: --autotiling is specified but --tilerowslog2 or --tilecolslog2 is also specified for current input.\n");
+                goto cleanup;
+            }
+            // At this point, autoTiling of this input file can only be set by command line.
+            // (auto generation of setting entries happens below)
+            // Since it's a boolean flag, its value must be AVIF_TRUE.
+            assert(fileSettings->autoTiling.value);
+            // Therefore disables manual tiling at this input (in case it was enabled at previous input).
+            fileSettings->tileRowsLog2 = intSettingsEntryOf(0);
+            fileSettings->tileColsLog2 = intSettingsEntryOf(0);
+        } else if (fileSettings->tileColsLog2.set || fileSettings->tileRowsLog2.set) {
+            // If this file has manual tile config set, disable autotiling, for the same reason as above.
+            fileSettings->autoTiling = boolSettingsEntryOf(AVIF_FALSE);
+        }
+
+        // Check per-input lossy/lossless parameters.
+        if (lossless) {
+            // Quality.
+            if ((fileSettings->quality.set && fileSettings->quality.value != AVIF_QUALITY_LOSSLESS) ||
+                (fileSettings->qualityAlpha.set && fileSettings->qualityAlpha.value != AVIF_QUALITY_LOSSLESS)) {
+                fprintf(stderr, "ERROR: Quality cannot be set in lossless mode, except to %d.\n", AVIF_QUALITY_LOSSLESS);
+                goto cleanup;
+            }
+            // Quantizers.
+            if ((fileSettings->minQuantizer.set && fileSettings->minQuantizer.value != AVIF_QUANTIZER_LOSSLESS) ||
+                (fileSettings->maxQuantizer.set && fileSettings->maxQuantizer.value != AVIF_QUANTIZER_LOSSLESS) ||
+                (fileSettings->minQuantizerAlpha.set && fileSettings->minQuantizerAlpha.value != AVIF_QUANTIZER_LOSSLESS) ||
+                (fileSettings->maxQuantizerAlpha.set && fileSettings->maxQuantizerAlpha.value != AVIF_QUANTIZER_LOSSLESS)) {
+                fprintf(stderr, "ERROR: Quantizers cannot be set in lossless mode, except to %d.\n", AVIF_QUANTIZER_LOSSLESS);
+                goto cleanup;
+            }
+        } else {
+            if (settings.progressive) {
+                assert(DEFAULT_QUALITY >= PROGRESSIVE_WORST_QUALITY);
+                if (fileSettings->quality.set && fileSettings->quality.value < PROGRESSIVE_WORST_QUALITY) {
+                    fprintf(stderr, "ERROR: --qcolor must be at least %d when using --progressive.\n", PROGRESSIVE_WORST_QUALITY);
+                    goto cleanup;
+                }
+                // --progressive only adjust color quality
+            }
+        }
+
+        // Set defaults for first input file.
+        if (i == 0) {
+            // This check only applies to the first input.
+            // Following inputs can change only one and leave the other unchanged.
+            if (fileSettings->minQuantizer.set != fileSettings->maxQuantizer.set) {
+                fprintf(stderr, "ERROR: --min and --max must be either both specified or both unspecified for input %s.\n", file->filename);
+                goto cleanup;
+            }
+            if (fileSettings->minQuantizerAlpha.set != fileSettings->maxQuantizerAlpha.set) {
+                fprintf(stderr,
+                        "ERROR: --minalpha and --maxalpha must be either both specified or both unspecified for input %s.\n",
+                        file->filename);
+                goto cleanup;
+            }
+
+            if (!fileSettings->autoTiling.set) {
+                fileSettings->autoTiling = boolSettingsEntryOf(AVIF_FALSE);
+            }
+            if (!fileSettings->tileRowsLog2.set) {
+                fileSettings->tileRowsLog2 = intSettingsEntryOf(0);
+            }
+            if (!fileSettings->tileColsLog2.set) {
+                fileSettings->tileColsLog2 = intSettingsEntryOf(0);
+            }
+
+            // Set lossy/lossless parameters to default if needed.
+            if (lossless) {
+                // Add lossless settings.
+                // Settings on first input will be inherited by all inputs, so this is sufficient.
+                fileSettings->quality = intSettingsEntryOf(AVIF_QUALITY_LOSSLESS);
+                fileSettings->qualityAlpha = intSettingsEntryOf(AVIF_QUALITY_LOSSLESS);
+                fileSettings->minQuantizer = intSettingsEntryOf(AVIF_QUANTIZER_LOSSLESS);
+                fileSettings->maxQuantizer = intSettingsEntryOf(AVIF_QUANTIZER_LOSSLESS);
+                fileSettings->minQuantizerAlpha = intSettingsEntryOf(AVIF_QUANTIZER_LOSSLESS);
+                fileSettings->maxQuantizerAlpha = intSettingsEntryOf(AVIF_QUANTIZER_LOSSLESS);
+            } else {
+                settings.qualityIsConstrained = fileSettings->quality.set;
+                settings.qualityAlphaIsConstrained = fileSettings->qualityAlpha.set;
+
+                if (fileSettings->minQuantizer.set) {
+                    assert(fileSettings->maxQuantizer.set);
+                    if (!fileSettings->quality.set) {
+                        const int quantizer = (fileSettings->minQuantizer.value + fileSettings->maxQuantizer.value) / 2;
+                        const int quality = ((63 - quantizer) * 100 + 31) / 63;
+                        fileSettings->quality = intSettingsEntryOf(quality);
+                    }
+                } else {
+                    assert(!fileSettings->maxQuantizer.set);
+                    if (!fileSettings->quality.set) {
+                        fileSettings->quality = intSettingsEntryOf(DEFAULT_QUALITY);
+                    }
+                    fileSettings->minQuantizer = intSettingsEntryOf(AVIF_QUANTIZER_BEST_QUALITY);
+                    fileSettings->maxQuantizer = intSettingsEntryOf(AVIF_QUANTIZER_WORST_QUALITY);
+                }
+
+                if (fileSettings->minQuantizerAlpha.set) {
+                    assert(fileSettings->maxQuantizerAlpha.set);
+                    if (!fileSettings->qualityAlpha.set) {
+                        const int quantizerAlpha = (fileSettings->minQuantizerAlpha.value + fileSettings->maxQuantizerAlpha.value) / 2;
+                        const int qualityAlpha = ((63 - quantizerAlpha) * 100 + 31) / 63;
+                        fileSettings->qualityAlpha = intSettingsEntryOf(qualityAlpha);
+                    }
+                } else {
+                    assert(!fileSettings->maxQuantizerAlpha.set);
+                    if (!fileSettings->qualityAlpha.set) {
+                        fileSettings->qualityAlpha = intSettingsEntryOf(DEFAULT_QUALITY_ALPHA);
+                    }
+                    fileSettings->minQuantizerAlpha = intSettingsEntryOf(AVIF_QUANTIZER_BEST_QUALITY);
+                    fileSettings->maxQuantizerAlpha = intSettingsEntryOf(AVIF_QUANTIZER_WORST_QUALITY);
+                }
+            }
+
+            if (!fileSettings->scalingMode.set) {
+                fileSettings->scalingMode = scalingModeSettingsEntryOf(1, 1);
+            }
+        }
+    }
+
+    image = avifImageCreateEmpty();
+    if (!image) {
+        fprintf(stderr, "ERROR: Out of memory\n");
+        goto cleanup;
+    }
+
+    // Set these in advance so any upcoming RGB -> YUV use the proper coefficients
+    image->colorPrimaries = settings.colorPrimaries;
+    image->transferCharacteristics = settings.transferCharacteristics;
+    image->matrixCoefficients = settings.matrixCoefficients;
+    image->yuvRange = requestedRange;
+    image->alphaPremultiplied = premultiplyAlpha;
+
+    if ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) && (input.requestedFormat != AVIF_PIXEL_FORMAT_NONE) &&
+        (input.requestedFormat != AVIF_PIXEL_FORMAT_YUV444)) {
+        // User explicitly asked for non YUV444 yuvFormat, while matrixCoefficients was likely
+        // set to AVIF_MATRIX_COEFFICIENTS_IDENTITY as a side effect of --lossless,
+        // and Identity is only valid with YUV444. Set matrixCoefficients back to the default.
+        image->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;
+
+        if (settings.cicpExplicitlySet) {
+            // Only warn if someone explicitly asked for identity.
+            printf("WARNING: matrixCoefficients may not be set to identity (0) when %s. Resetting MC to defaults (%d).\n",
+                   (input.requestedFormat == AVIF_PIXEL_FORMAT_YUV400) ? "encoding 4:0:0" : "subsampling",
+                   image->matrixCoefficients);
+        }
+    }
+
+    // --target-size requires multiple encodings of the same files. Cache the input images.
+    input.cacheEnabled = (settings.targetSize != -1);
+
+    const avifInputFile * firstFile = avifInputGetFile(&input, /*imageIndex=*/0);
+    uint32_t sourceDepth = 0;
+    avifBool sourceWasRGB = AVIF_FALSE;
+    avifAppSourceTiming firstSourceTiming;
+    const avifBool isImageSequence = (!settings.gridDimsPresent) && (settings.layers == 1) && (input.filesCount > 1);
+    // Gain maps are not supported for animations or layered images.
+    const avifBool ignoreGainMap = settings.ignoreGainMap || isImageSequence || settings.progressive;
+    if (!avifInputReadImage(&input,
+                            /*imageIndex=*/0,
+                            settings.ignoreColorProfile,
+                            settings.ignoreExif,
+                            settings.ignoreXMP,
+                            /*allowChangingCicp=*/!settings.cicpExplicitlySet,
+                            ignoreGainMap,
+                            image,
+                            /*settings=*/NULL, // Must use the setting for first input
+                            &sourceDepth,
+                            &sourceWasRGB,
+                            &firstSourceTiming,
+                            settings.chromaDownsampling)) {
+        goto cleanup;
+    }
+
+    // Check again for -y auto or for y4m input (y4m input ignores input.requestedFormat and
+    // retains the format in file).
+    if ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) && (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400)) {
+        image->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;
+
+        if (settings.cicpExplicitlySet) {
+            // Only warn if someone explicitly asked for identity.
+            printf("WARNING: matrixCoefficients may not be set to identity (0) when encoding 4:0:0. Resetting MC to defaults (%d).\n",
+                   image->matrixCoefficients);
+        }
+    }
+    if ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) && (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV444)) {
+        fprintf(stderr, "matrixCoefficients may not be set to identity (0) when subsampling.\n");
+        goto cleanup;
+    }
+
+    printf("Successfully loaded: %s\n", firstFile->filename);
+
+    // Prepare image timings
+    if ((settings.outputTiming.duration == 0) && (settings.outputTiming.timescale == 0) && (firstSourceTiming.duration > 0) &&
+        (firstSourceTiming.timescale > 0)) {
+        // Set the default duration and timescale to the first image's timing.
+        settings.outputTiming = firstSourceTiming;
+    } else {
+        // Set output timing defaults to 30 fps
+        if (settings.outputTiming.duration == 0) {
+            settings.outputTiming.duration = 1;
+        }
+        if (settings.outputTiming.timescale == 0) {
+            settings.outputTiming.timescale = 30;
+        }
+    }
+
+    if ((iccOverride.size && (avifImageSetProfileICC(image, iccOverride.data, iccOverride.size) != AVIF_RESULT_OK)) ||
+        (exifOverride.size && (avifImageSetMetadataExif(image, exifOverride.data, exifOverride.size) != AVIF_RESULT_OK)) ||
+        (xmpOverride.size && (avifImageSetMetadataXMP(image, xmpOverride.data, xmpOverride.size) != AVIF_RESULT_OK))) {
+        fprintf(stderr, "Error when setting overridden metadata: out of memory.\n");
+        goto cleanup;
+    }
+
+    if (!image->icc.size && !settings.cicpExplicitlySet && (image->colorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED) &&
+        (image->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED)) {
+        // The final image has no ICC profile, the user didn't specify any CICP, and the source
+        // image didn't provide any CICP. Explicitly signal SRGB CP/TC here, as 2/2/x will be
+        // interpreted as SRGB anyway.
+        image->colorPrimaries = AVIF_COLOR_PRIMARIES_SRGB;
+        image->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_SRGB;
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    if (image->gainMap && !image->gainMap->altICC.size) {
+        if (image->gainMap->altColorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+            // Assume the alternate image has the same primaries as the base image.
+            image->gainMap->altColorPrimaries = image->colorPrimaries;
+        }
+        if (image->gainMap->altTransferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+            // Assume the alternate image is PQ HDR.
+            image->gainMap->altTransferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_PQ;
+        }
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION
+
+    if (settings.paspPresent) {
+        image->transformFlags |= AVIF_TRANSFORM_PASP;
+        image->pasp.hSpacing = settings.paspValues[0];
+        image->pasp.vSpacing = settings.paspValues[1];
+    }
+    if (cropConversionRequired) {
+        if (!convertCropToClap(image->width, image->height, image->yuvFormat, settings.clapValues)) {
+            goto cleanup;
+        }
+        settings.clapValid = AVIF_TRUE;
+    }
+    if (settings.clapValid) {
+        image->transformFlags |= AVIF_TRANSFORM_CLAP;
+        image->clap.widthN = settings.clapValues[0];
+        image->clap.widthD = settings.clapValues[1];
+        image->clap.heightN = settings.clapValues[2];
+        image->clap.heightD = settings.clapValues[3];
+        image->clap.horizOffN = settings.clapValues[4];
+        image->clap.horizOffD = settings.clapValues[5];
+        image->clap.vertOffN = settings.clapValues[6];
+        image->clap.vertOffD = settings.clapValues[7];
+
+        // Validate clap
+        avifCropRect cropRect;
+        avifDiagnostics diag;
+        avifDiagnosticsClearError(&diag);
+        if (!avifCropRectConvertCleanApertureBox(&cropRect, &image->clap, image->width, image->height, image->yuvFormat, &diag)) {
+            fprintf(stderr,
+                    "ERROR: Invalid clap: width:[%d / %d], height:[%d / %d], horizOff:[%d / %d], vertOff:[%d / %d] - %s\n",
+                    (int32_t)image->clap.widthN,
+                    (int32_t)image->clap.widthD,
+                    (int32_t)image->clap.heightN,
+                    (int32_t)image->clap.heightD,
+                    (int32_t)image->clap.horizOffN,
+                    (int32_t)image->clap.horizOffD,
+                    (int32_t)image->clap.vertOffN,
+                    (int32_t)image->clap.vertOffD,
+                    diag.error);
+            goto cleanup;
+        }
+    }
+    if (irotAngle != 0xff) {
+        image->transformFlags |= AVIF_TRANSFORM_IROT;
+        image->irot.angle = irotAngle;
+    }
+    if (imirAxis != 0xff) {
+        image->transformFlags |= AVIF_TRANSFORM_IMIR;
+        image->imir.axis = imirAxis;
+    }
+    if (settings.clliPresent) {
+        image->clli.maxCLL = (uint16_t)settings.clliValues[0];
+        image->clli.maxPALL = (uint16_t)settings.clliValues[1];
+    }
+
+    avifBool hasAlpha = (image->alphaPlane && image->alphaRowBytes);
+    avifBool usingLosslessColor = (firstFile->settings.quality.value == AVIF_QUALITY_LOSSLESS);
+    avifBool usingLosslessAlpha = (firstFile->settings.qualityAlpha.value == AVIF_QUALITY_LOSSLESS);
+    avifBool using400 = (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400);
+    avifBool using444 = (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444);
+    avifBool usingFullRange = (image->yuvRange == AVIF_RANGE_FULL);
+    avifBool usingIdentityMatrix = (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY);
+
+    // Guess if the enduser is asking for lossless and enable it so that warnings can be emitted
+    if (!lossless && usingLosslessColor && (!hasAlpha || usingLosslessAlpha)) {
+        // The enduser is probably expecting lossless. Turn it on and emit warnings
+        printf("Quality set to %d, assuming --lossless to enable warnings on potential lossless issues.\n", AVIF_QUALITY_LOSSLESS);
+        lossless = AVIF_TRUE;
+    }
+
+    // Check for any reasons lossless will fail, and complain loudly
+    if (lossless) {
+        if (!usingLosslessColor) {
+            fprintf(stderr,
+                    "WARNING: [--lossless] Color quality (-q or --qcolor) not set to %d. Color output might not be lossless.\n",
+                    AVIF_QUALITY_LOSSLESS);
+            lossless = AVIF_FALSE;
+        }
+
+        if (hasAlpha && !usingLosslessAlpha) {
+            fprintf(stderr,
+                    "WARNING: [--lossless] Alpha present and alpha quality (--qalpha) not set to %d. Alpha output might not be lossless.\n",
+                    AVIF_QUALITY_LOSSLESS);
+            lossless = AVIF_FALSE;
+        }
+
+        if (usingIdentityMatrix && (sourceDepth != image->depth)) {
+            fprintf(stderr,
+                    "WARNING: [--lossless] Identity matrix is used but input depth (%d) does not match output depth (%d). Output might not be lossless.\n",
+                    sourceDepth,
+                    image->depth);
+            lossless = AVIF_FALSE;
+        }
+
+        if (sourceWasRGB) {
+            if (!using444 && !using400) {
+                fprintf(stderr,
+                        "WARNING: [--lossless] Input data was RGB and YUV "
+                        "subsampling (-y) isn't YUV444 or YUV400. Output might "
+                        "not be lossless.\n");
+                lossless = AVIF_FALSE;
+            }
+
+            if (!usingFullRange) {
+                fprintf(stderr, "WARNING: [--lossless] Input data was RGB and output range (-r) isn't full. Output might not be lossless.\n");
+                lossless = AVIF_FALSE;
+            }
+
+            avifBool matrixCoefficientsAreLosslessCompatible = usingIdentityMatrix;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+            matrixCoefficientsAreLosslessCompatible |= (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE ||
+                                                        image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO);
+#endif
+            if (!matrixCoefficientsAreLosslessCompatible && !using400) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                fprintf(stderr, "WARNING: [--lossless] Input data was RGB and matrixCoefficients isn't set to identity (--cicp x/x/0) or YCgCo-Re/Ro (--cicp x/x/15 or x/x/16); Output might not be lossless.\n");
+#else
+                fprintf(stderr, "WARNING: [--lossless] Input data was RGB and matrixCoefficients isn't set to identity (--cicp x/x/0); Output might not be lossless.\n");
+#endif
+                lossless = AVIF_FALSE;
+            }
+        }
+    }
+
+    if (settings.gridDimsPresent) {
+        // Grid image!
+
+        gridCellCount = settings.gridDims[0] * settings.gridDims[1];
+        printf("Preparing to encode a %ux%u grid (%u cells)...\n", settings.gridDims[0], settings.gridDims[1], gridCellCount);
+
+        gridCells = calloc(gridCellCount, sizeof(avifImage *));
+        if (gridCells == NULL) {
+            fprintf(stderr, "ERROR: memory allocation failure\n");
+            goto cleanup;
+        }
+        gridCells[0] = image; // take ownership of image
+
+        int imageIndex = 1; // The first grid cell was loaded into image (imageIndex 0).
+        const avifInputFile * nextFile;
+        while ((nextFile = avifInputGetFile(&input, imageIndex)) != NULL) {
+            if (imageIndex == 1) {
+                printf("Loading additional cells for grid image (%u cells)...\n", gridCellCount);
+            }
+            if (imageIndex >= (int)gridCellCount) {
+                // We have enough, warn and continue
+                fprintf(stderr,
+                        "WARNING: [--grid] More than %u images were supplied for this %ux%u grid. The rest will be ignored.\n",
+                        gridCellCount,
+                        settings.gridDims[0],
+                        settings.gridDims[1]);
+                break;
+            }
+
+            // Ensure no settings is set for other cells
+            if (memcmp(&nextFile->settings, &emptySettingsReference, sizeof(avifInputFileSettings)) != 0) {
+                fprintf(stderr, "ERROR: Grid image cannot use different settings for each cell.\n");
+                goto cleanup;
+            }
+
+            avifImage * cellImage = avifImageCreateEmpty();
+            if (!cellImage) {
+                fprintf(stderr, "ERROR: Out of memory\n");
+                goto cleanup;
+            }
+            cellImage->colorPrimaries = image->colorPrimaries;
+            cellImage->transferCharacteristics = image->transferCharacteristics;
+            cellImage->matrixCoefficients = image->matrixCoefficients;
+            cellImage->yuvRange = image->yuvRange;
+            cellImage->alphaPremultiplied = image->alphaPremultiplied;
+            gridCells[imageIndex] = cellImage;
+
+            // Ignore ICC, Exif and XMP because only the metadata of the first frame is taken into
+            // account by the libavif API.
+            if (!avifInputReadImage(&input,
+                                    imageIndex,
+                                    /*ignoreColorProfile=*/AVIF_TRUE,
+                                    /*ignoreExif=*/AVIF_TRUE,
+                                    /*ignoreXMP=*/AVIF_TRUE,
+                                    /*allowChangingCicp=*/AVIF_FALSE,
+                                    settings.ignoreGainMap,
+                                    cellImage,
+                                    /*settings=*/NULL,
+                                    /*outDepth=*/NULL,
+                                    /*sourceIsRGB=*/NULL,
+                                    /*sourceTiming=*/NULL,
+                                    settings.chromaDownsampling)) {
+                goto cleanup;
+            }
+            // Let avifEncoderAddImageGrid() verify the grid integrity (valid cell sizes, depths etc.).
+
+            ++imageIndex;
+        }
+
+        if (imageIndex == 1) {
+            printf("Single image input for a grid image. Attempting to split into %u cells...\n", gridCellCount);
+            gridSplitImage = image;
+            gridCells[0] = NULL;
+
+            if (!avifImageSplitGrid(gridSplitImage, settings.gridDims[0], settings.gridDims[1], gridCells)) {
+                goto cleanup;
+            }
+        } else if (imageIndex != (int)gridCellCount) {
+            fprintf(stderr, "ERROR: Not enough input files for grid image! (expecting %u, or a single image to be split)\n", gridCellCount);
+            goto cleanup;
+        }
+        // TODO(yguyon): Check if it is possible to use frames from a single input file as grid cells. Maybe forbid it.
+    }
+
+    const char * lossyHint = " (Lossy)";
+    if (lossless) {
+        lossyHint = " (Lossless)";
+    }
+    printf("AVIF to be written:%s\n", lossyHint);
+    const avifImage * avif = gridCells ? gridCells[0] : image;
+    avifImageDump(avif,
+                  settings.gridDims[0],
+                  settings.gridDims[1],
+                  settings.layers > 1 ? AVIF_PROGRESSIVE_STATE_AVAILABLE : AVIF_PROGRESSIVE_STATE_UNAVAILABLE);
+
+    avifEncodedByteSizes byteSizes = { 0, 0, 0 };
+    if (!avifEncodeImages(&settings, &input, firstFile, image, (const avifImage * const *)gridCells, &raw, &byteSizes)) {
+        goto cleanup;
+    }
+
+    printf("Encoded successfully.\n");
+    printf(" * Color total size: %" AVIF_FMT_ZU " bytes\n", byteSizes.colorSizeBytes);
+    printf(" * Alpha total size: %" AVIF_FMT_ZU " bytes\n", byteSizes.alphaSizeBytes);
+    if (byteSizes.gainMapSizeBytes > 0) {
+        printf(" * Gain Map AV1 total size: %" AVIF_FMT_ZU " bytes\n", byteSizes.gainMapSizeBytes);
+    }
+    if (isImageSequence) {
+        if (settings.repetitionCount == AVIF_REPETITION_COUNT_INFINITE) {
+            printf(" * Repetition Count: Infinite\n");
+        } else {
+            printf(" * Repetition Count: %d\n", settings.repetitionCount);
+        }
+    }
+    if (noOverwrite && fileExists(outputFilename)) {
+        // check again before write
+        fprintf(stderr, "ERROR: output file %s already exists and --no-overwrite was specified\n", outputFilename);
+        goto cleanup;
+    }
+    FILE * f = fopen(outputFilename, "wb");
+    if (!f) {
+        fprintf(stderr, "ERROR: Failed to open file for write: %s\n", outputFilename);
+        goto cleanup;
+    }
+    if (fwrite(raw.data, 1, raw.size, f) != raw.size) {
+        fprintf(stderr, "Failed to write %" AVIF_FMT_ZU " bytes: %s\n", raw.size, outputFilename);
+        goto cleanup;
+    } else {
+        printf("Wrote AVIF: %s\n", outputFilename);
+    }
+    fclose(f);
+    returnCode = 0;
+
+cleanup:
+    if (gridCells) {
+        for (uint32_t i = 0; i < gridCellCount; ++i) {
+            if (gridCells[i]) {
+                avifImageDestroy(gridCells[i]);
+            }
+        }
+        free(gridCells);
+    } else if (image) { // image is owned/cleaned up by gridCells if it exists
+        avifImageDestroy(image);
+    }
+    if (gridSplitImage) {
+        avifImageDestroy(gridSplitImage);
+    }
+    avifRWDataFree(&raw);
+    avifRWDataFree(&exifOverride);
+    avifRWDataFree(&xmpOverride);
+    avifRWDataFree(&iccOverride);
+    avifCodecSpecificOptionsFree(&pendingSettings.codecSpecificOptions);
+    while (input.cacheCount) {
+        --input.cacheCount;
+        if (input.cache[input.cacheCount].image) {
+            avifImageDestroy(input.cache[input.cacheCount].image);
+        }
+    }
+    free(input.cache);
+    while (input.filesCount) {
+        --input.filesCount;
+        avifInputFile * file = &input.files[input.filesCount];
+        avifCodecSpecificOptionsFree(&file->settings.codecSpecificOptions);
+    }
+    free(input.files);
+
+    return returnCode;
+}
diff --git a/third_party/libavif/src/apps/avifgainmaputil/.clang-format b/third_party/libavif/src/apps/avifgainmaputil/.clang-format
new file mode 100644
index 0000000000..dd860a0f86
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/.clang-format
@@ -0,0 +1,6 @@
+---
+Language: Cpp
+BasedOnStyle: Google
+DerivePointerAlignment: false
+PointerAlignment: Left
+...
diff --git a/third_party/libavif/src/apps/avifgainmaputil/avifgainmaputil.cc b/third_party/libavif/src/apps/avifgainmaputil/avifgainmaputil.cc
new file mode 100644
index 0000000000..08d2d08554
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/avifgainmaputil.cc
@@ -0,0 +1,111 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include <iomanip>
+#include <string>
+#include <vector>
+
+#include "argparse.hpp"
+#include "avif/avif.h"
+#include "avifutil.h"
+#include "combine_command.h"
+#include "convert_command.h"
+#include "extractgainmap_command.h"
+#include "printmetadata_command.h"
+#include "program_command.h"
+#include "swapbase_command.h"
+#include "tonemap_command.h"
+
+namespace avif {
+namespace {
+
+class HelpCommand : public ProgramCommand {
+ public:
+  HelpCommand() : ProgramCommand("help", "Prints a command's usage") {}
+  avifResult Run() override {
+    // Actual implementation is in the main function because it needs access
+    // to the list of commands.
+    return AVIF_RESULT_OK;
+  }
+};
+
+void PrintUsage(const std::vector<std::unique_ptr<ProgramCommand>>& commands) {
+  std::cout << "\nExperimental tool to manipulate avif images with HDR gain "
+               "maps.\n\n";
+  std::cout << "usage: avifgainmaputil <command> [options] [arguments...]\n\n";
+  std::cout << "Available commands:\n";
+  int longest_command_size = 0;
+  for (const std::unique_ptr<ProgramCommand>& command : commands) {
+    longest_command_size = std::max(longest_command_size,
+                                    static_cast<int>(command->name().size()));
+  }
+  for (const std::unique_ptr<ProgramCommand>& command : commands) {
+    std::cout << "  " << std::left << std::setw(longest_command_size)
+              << command->name() << "  " << command->description() << "\n";
+  }
+  std::cout << "\n";
+  avifPrintVersions();
+}
+
+}  // namespace
+}  // namespace avif
+
+int main(int argc, char** argv) {
+  std::vector<std::unique_ptr<avif::ProgramCommand>> commands;
+  commands.emplace_back(std::make_unique<avif::HelpCommand>());
+  commands.emplace_back(std::make_unique<avif::CombineCommand>());
+  commands.emplace_back(std::make_unique<avif::ConvertCommand>());
+  commands.emplace_back(std::make_unique<avif::TonemapCommand>());
+  commands.emplace_back(std::make_unique<avif::SwapBaseCommand>());
+  commands.emplace_back(std::make_unique<avif::ExtractGainMapCommand>());
+  commands.emplace_back(std::make_unique<avif::PrintMetadataCommand>());
+
+  if (argc < 2) {
+    std::cerr << "Command name missing\n";
+    avif::PrintUsage(commands);
+    return 1;
+  }
+
+  const std::string command_name(argv[1]);
+  if (command_name == "help") {
+    if (argc >= 3) {
+      const std::string sub_command_name(argv[2]);
+      for (const auto& command : commands) {
+        if (command->name() == sub_command_name) {
+          command->PrintUsage();
+          return 0;
+        }
+      }
+      std::cerr << "Unknown command " << sub_command_name << "\n";
+      avif::PrintUsage(commands);
+      return 1;
+    } else {
+      avif::PrintUsage(commands);
+      return 0;
+    }
+  }
+
+  for (const auto& command : commands) {
+    if (command->name() == command_name) {
+      try {
+        avifResult result = command->ParseArgs(argc - 1, argv + 1);
+        if (result == AVIF_RESULT_OK) {
+          result = command->Run();
+        }
+
+        if (result == AVIF_RESULT_INVALID_ARGUMENT) {
+          command->PrintUsage();
+        }
+        return (result == AVIF_RESULT_OK) ? 0 : 1;
+      } catch (const std::invalid_argument& e) {
+        std::cerr << e.what() << "\n\n";
+        command->PrintUsage();
+        return 1;
+      }
+    }
+  }
+
+  std::cerr << "Unknown command " << command_name << "\n";
+  avif::PrintUsage(commands);
+  return 1;
+}
diff --git a/third_party/libavif/src/apps/avifgainmaputil/combine_command.cc b/third_party/libavif/src/apps/avifgainmaputil/combine_command.cc
new file mode 100644
index 0000000000..8b4c705c59
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/combine_command.cc
@@ -0,0 +1,143 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "combine_command.h"
+
+#include <cmath>
+
+#include "avif/avif_cxx.h"
+#include "imageio.h"
+
+namespace avif {
+
+CombineCommand::CombineCommand()
+    : ProgramCommand("combine",
+                     "Creates an avif image with a gain map from a base image "
+                     "and an alternate image.") {
+  argparse_.add_argument(arg_base_filename_, "base_image")
+      .help(
+          "The base image, that will be shown by viewers that don't support "
+          "gain maps");
+  argparse_.add_argument(arg_alternate_filename_, "alternate_image")
+      .help("The alternate image, the result of fully applying the gain map");
+  argparse_.add_argument(arg_output_filename_, "output_image.avif");
+  argparse_.add_argument(arg_downscaling_, "--downscaling")
+      .help("Downscaling factor for the gain map")
+      .default_value("1");
+  argparse_.add_argument(arg_gain_map_quality_, "--qgain-map")
+      .help("Quality for the gain map (0-100, where 100 is lossless)")
+      .default_value("60");
+  argparse_.add_argument(arg_gain_map_depth_, "--depth-gain-map")
+      .choices({"8", "10", "12"})
+      .help("Output depth for the gain map")
+      .default_value("8");
+  argparse_
+      .add_argument<int, PixelFormatConverter>(arg_gain_map_pixel_format_,
+                                               "--yuv-gain-map")
+      .choices({"444", "422", "420", "400"})
+      .help("Output format for the gain map")
+      .default_value("444");
+  argparse_
+      .add_argument<CicpValues, CicpConverter>(arg_base_cicp_, "--cicp-base")
+      .help(
+          "Set or override the cicp values for the base image, expressed as "
+          "P/T/M where P = color primaries, T = transfer characteristics, "
+          "M = matrix coefficients.");
+  argparse_
+      .add_argument<CicpValues, CicpConverter>(arg_alternate_cicp_,
+                                               "--cicp-alternate")
+      .help(
+          "Set or override the cicp values for the alternate image, expressed "
+          "as P/T/M  where P = color primaries, T = transfer characteristics, "
+          "M = matrix coefficients.");
+  arg_image_encode_.Init(argparse_, /*can_have_alpha=*/true);
+  arg_image_read_.Init(argparse_);
+}
+
+avifResult CombineCommand::Run() {
+  const avifPixelFormat pixel_format =
+      static_cast<avifPixelFormat>(arg_image_read_.pixel_format.value());
+  const avifPixelFormat gain_map_pixel_format =
+      static_cast<avifPixelFormat>(arg_gain_map_pixel_format_.value());
+
+  ImagePtr base_image(avifImageCreateEmpty());
+  ImagePtr alternate_image(avifImageCreateEmpty());
+  if (base_image == nullptr || alternate_image == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  avifResult result =
+      ReadImage(base_image.get(), arg_base_filename_, pixel_format,
+                arg_image_read_.depth, arg_image_read_.ignore_profile);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to read base image: " << avifResultToString(result)
+              << "\n";
+    return result;
+  }
+  if (arg_base_cicp_.provenance() == argparse::Provenance::SPECIFIED) {
+    base_image->colorPrimaries = arg_base_cicp_.value().color_primaries;
+    base_image->transferCharacteristics =
+        arg_base_cicp_.value().transfer_characteristics;
+    base_image->matrixCoefficients = arg_base_cicp_.value().matrix_coefficients;
+  }
+
+  result =
+      ReadImage(alternate_image.get(), arg_alternate_filename_, pixel_format,
+                arg_image_read_.depth, arg_image_read_.ignore_profile);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to read alternate image: "
+              << avifResultToString(result) << "\n";
+    return result;
+  }
+  if (arg_alternate_cicp_.provenance() == argparse::Provenance::SPECIFIED) {
+    alternate_image->colorPrimaries =
+        arg_alternate_cicp_.value().color_primaries;
+    alternate_image->transferCharacteristics =
+        arg_alternate_cicp_.value().transfer_characteristics;
+    alternate_image->matrixCoefficients =
+        arg_alternate_cicp_.value().matrix_coefficients;
+  }
+
+  const uint32_t downscaling = std::max<int>(1, arg_downscaling_);
+  const uint32_t rounding = downscaling / 2;
+  const uint32_t gain_map_width =
+      std::max((base_image->width + rounding) / downscaling, 1u);
+  const uint32_t gain_map_height =
+      std::max((base_image->height + rounding) / downscaling, 1u);
+  std::cout << "Creating a gain map of size " << gain_map_width << " x "
+            << gain_map_height << "\n";
+
+  base_image->gainMap = avifGainMapCreate();
+  base_image->gainMap->image =
+      avifImageCreate(gain_map_width, gain_map_height, arg_gain_map_depth_,
+                      gain_map_pixel_format);
+  if (base_image->gainMap->image == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  avifDiagnostics diag;
+  result = avifImageComputeGainMap(base_image.get(), alternate_image.get(),
+                                   base_image->gainMap, &diag);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to compute gain map: " << avifResultToString(result)
+              << " (" << diag.error << ")\n";
+    return result;
+  }
+
+  EncoderPtr encoder(avifEncoderCreate());
+  if (encoder == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  encoder->quality = arg_image_encode_.quality;
+  encoder->qualityAlpha = arg_image_encode_.quality_alpha;
+  encoder->qualityGainMap = arg_gain_map_quality_;
+  encoder->speed = arg_image_encode_.speed;
+  result = WriteAvif(base_image.get(), encoder.get(), arg_output_filename_);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to encode image: " << avifResultToString(result)
+              << " (" << encoder->diag.error << ")\n";
+    return result;
+  }
+
+  return AVIF_RESULT_OK;
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/combine_command.h b/third_party/libavif/src/apps/avifgainmaputil/combine_command.h
new file mode 100644
index 0000000000..6bbfe7dca1
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/combine_command.h
@@ -0,0 +1,33 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_COMBINE_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_COMBINE_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+class CombineCommand : public ProgramCommand {
+ public:
+  CombineCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_base_filename_;
+  argparse::ArgValue<std::string> arg_alternate_filename_;
+  argparse::ArgValue<std::string> arg_output_filename_;
+  argparse::ArgValue<CicpValues> arg_base_cicp_;
+  argparse::ArgValue<CicpValues> arg_alternate_cicp_;
+  argparse::ArgValue<int> arg_downscaling_;
+  argparse::ArgValue<int> arg_gain_map_quality_;
+  argparse::ArgValue<int> arg_gain_map_depth_;
+  argparse::ArgValue<int> arg_gain_map_pixel_format_;
+  BasicImageEncodeArgs arg_image_encode_;
+  ImageReadArgs arg_image_read_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_COMBINE_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/convert_command.cc b/third_party/libavif/src/apps/avifgainmaputil/convert_command.cc
new file mode 100644
index 0000000000..47f149c75b
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/convert_command.cc
@@ -0,0 +1,124 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "convert_command.h"
+
+#include "avif/avif_cxx.h"
+#include "avifutil.h"
+#include "imageio.h"
+#include "swapbase_command.h"
+
+namespace avif {
+
+ConvertCommand::ConvertCommand()
+    : ProgramCommand("convert", "Convert a jpeg with a gain map to avif.") {
+  argparse_.add_argument(arg_input_filename_, "input_filename.jpg");
+  argparse_.add_argument(arg_output_filename_, "output_image.avif");
+  argparse_.add_argument(arg_swap_base_, "--swap-base")
+      .help("Make the HDR image the base image")
+      .action(argparse::Action::STORE_TRUE)
+      .default_value("false");
+  argparse_.add_argument(arg_gain_map_quality_, "--qgain-map")
+      .help("Quality for the gain map (0-100, where 100 is lossless)")
+      .default_value("60");
+  argparse_.add_argument<CicpValues, CicpConverter>(arg_cicp_, "--cicp")
+      .help(
+          "Set the cicp values for the input image, expressed as "
+          "P/T/M where P = color primaries, T = transfer characteristics, "
+          "M = matrix coefficients.");
+  arg_image_encode_.Init(argparse_, /*can_have_alpha=*/false);
+  arg_image_read_.Init(argparse_);
+}
+
+avifResult ConvertCommand::Run() {
+  const avifPixelFormat pixel_format =
+      static_cast<avifPixelFormat>(arg_image_read_.pixel_format.value());
+
+  ImagePtr image(avifImageCreateEmpty());
+  if (image == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+
+  const avifAppFileFormat file_format = avifReadImage(
+      arg_input_filename_.value().c_str(), pixel_format, arg_image_read_.depth,
+      AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC, arg_image_read_.ignore_profile,
+      /*ignoreExif=*/false,
+      /*ignoreXMP=*/false,
+      /*allowChangingCicp=*/true,
+      /*ignoreGainMap=*/false, AVIF_DEFAULT_IMAGE_SIZE_LIMIT, image.get(),
+      /*outDepth=*/nullptr,
+      /*sourceTiming=*/nullptr,
+      /*frameIter=*/nullptr);
+  if (file_format == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+    std::cout << "Failed to decode image: " << arg_input_filename_;
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+  if (arg_cicp_.provenance() == argparse::Provenance::SPECIFIED) {
+    image->colorPrimaries = arg_cicp_.value().color_primaries;
+    image->transferCharacteristics = arg_cicp_.value().transfer_characteristics;
+    image->matrixCoefficients = arg_cicp_.value().matrix_coefficients;
+  } else if (image->icc.size == 0 &&
+             image->colorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED &&
+             image->transferCharacteristics ==
+                 AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+    // If there is no ICC and no CICP, assume sRGB by default.
+    image->colorPrimaries = AVIF_COLOR_PRIMARIES_SRGB;
+    image->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_SRGB;
+  }
+
+  if (image->gainMap && image->gainMap->altICC.size == 0) {
+    if (image->gainMap->altColorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+      // Assume the alternate image has the same primaries as the base image.
+      image->gainMap->altColorPrimaries = image->colorPrimaries;
+    }
+    if (image->gainMap->altTransferCharacteristics ==
+        AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+      // Assume the alternate image is PQ HDR.
+      image->gainMap->altTransferCharacteristics =
+          AVIF_TRANSFER_CHARACTERISTICS_PQ;
+    }
+  }
+
+  if (image->gainMap == nullptr || image->gainMap->image == nullptr) {
+    std::cerr << "Input image " << arg_input_filename_
+              << " does not contain a gain map\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+
+  if (arg_swap_base_) {
+    int depth = arg_image_read_.depth;
+    if (depth == 0) {
+      depth = image->gainMap->alternateHdrHeadroom.n == 0 ? 8 : 10;
+    }
+    ImagePtr new_base(avifImageCreateEmpty());
+    if (new_base == nullptr) {
+      return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    const avifResult result =
+        ChangeBase(*image, depth, image->yuvFormat, new_base.get());
+    if (result != AVIF_RESULT_OK) {
+      return result;
+    }
+    std::swap(image, new_base);
+  }
+
+  EncoderPtr encoder(avifEncoderCreate());
+  if (encoder == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  encoder->quality = arg_image_encode_.quality;
+  encoder->qualityAlpha = arg_image_encode_.quality_alpha;
+  encoder->qualityGainMap = arg_gain_map_quality_;
+  encoder->speed = arg_image_encode_.speed;
+  const avifResult result =
+      WriteAvif(image.get(), encoder.get(), arg_output_filename_);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to encode image: " << avifResultToString(result)
+              << " (" << encoder->diag.error << ")\n";
+    return result;
+  }
+
+  return AVIF_RESULT_OK;
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/convert_command.h b/third_party/libavif/src/apps/avifgainmaputil/convert_command.h
new file mode 100644
index 0000000000..c5eb195cee
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/convert_command.h
@@ -0,0 +1,32 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_CONVERT_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_CONVERT_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+class ConvertCommand : public ProgramCommand {
+ public:
+  ConvertCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_input_filename_;
+  argparse::ArgValue<std::string> arg_output_filename_;
+  argparse::ArgValue<bool> arg_swap_base_;
+  argparse::ArgValue<CicpValues> arg_cicp_;
+  argparse::ArgValue<int> arg_downscaling_;
+  argparse::ArgValue<int> arg_gain_map_quality_;
+  argparse::ArgValue<int> arg_gain_map_depth_;
+  argparse::ArgValue<int> arg_gain_map_pixel_format_;
+  BasicImageEncodeArgs arg_image_encode_;
+  ImageReadArgs arg_image_read_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_CONVERT_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.cc b/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.cc
new file mode 100644
index 0000000000..63212f1f99
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.cc
@@ -0,0 +1,43 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "extractgainmap_command.h"
+
+#include "avif/avif_cxx.h"
+#include "imageio.h"
+
+namespace avif {
+
+ExtractGainMapCommand::ExtractGainMapCommand()
+    : ProgramCommand("extractgainmap",
+                     "Saves the gain map of an avif file as an image") {
+  argparse_.add_argument(arg_input_filename_, "input_filename");
+  argparse_.add_argument(arg_output_filename_, "output_filename");
+  arg_image_encode_.Init(argparse_, /*can_have_alpha=*/false);
+}
+
+avifResult ExtractGainMapCommand::Run() {
+  DecoderPtr decoder(avifDecoderCreate());
+  if (decoder == NULL) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  decoder->imageContentToDecode = AVIF_IMAGE_CONTENT_GAIN_MAP;
+
+  avifResult result =
+      ReadAvif(decoder.get(), arg_input_filename_, /*ignore_profile=*/true);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+
+  if (decoder->image->gainMap == nullptr ||
+      decoder->image->gainMap->image == nullptr) {
+    std::cerr << "Input image " << arg_input_filename_
+              << " does not contain a gain map\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+
+  return WriteImage(decoder->image->gainMap->image, arg_output_filename_,
+                    arg_image_encode_.quality, arg_image_encode_.speed);
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.h b/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.h
new file mode 100644
index 0000000000..9872a18fc8
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/extractgainmap_command.h
@@ -0,0 +1,25 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_EXTRACTGAINMAP_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_EXTRACTGAINMAP_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+class ExtractGainMapCommand : public ProgramCommand {
+ public:
+  ExtractGainMapCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_input_filename_;
+  argparse::ArgValue<std::string> arg_output_filename_;
+  BasicImageEncodeArgs arg_image_encode_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_EXTRACTGAINMAP_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/imageio.cc b/third_party/libavif/src/apps/avifgainmaputil/imageio.cc
new file mode 100644
index 0000000000..d52ddeddad
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/imageio.cc
@@ -0,0 +1,171 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "imageio.h"
+
+#include <cstring>
+#include <fstream>
+#include <iostream>
+#include <memory>
+
+#include "avif/avif_cxx.h"
+#include "avifjpeg.h"
+#include "avifpng.h"
+#include "avifutil.h"
+#include "y4m.h"
+
+namespace avif {
+
+template <typename T>
+inline T Clamp(T x, T low, T high) {  // Only exists in C++17.
+  return (x < low) ? low : (high < x) ? high : x;
+}
+
+avifResult WriteImage(const avifImage* image,
+                      const std::string& output_filename, int quality,
+                      int speed) {
+  quality = Clamp(quality, 0, 100);
+  speed = Clamp(speed, 0, 10);
+  const avifAppFileFormat output_format =
+      avifGuessFileFormat(output_filename.c_str());
+  if (output_format == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+    std::cerr << "Cannot determine output file extension: " << output_filename
+              << "\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  } else if (output_format == AVIF_APP_FILE_FORMAT_Y4M) {
+    if (!y4mWrite(output_filename.c_str(), image)) {
+      return AVIF_RESULT_UNKNOWN_ERROR;
+    }
+  } else if (output_format == AVIF_APP_FILE_FORMAT_JPEG) {
+    if (!avifJPEGWrite(output_filename.c_str(), image, quality,
+                       AVIF_CHROMA_UPSAMPLING_AUTOMATIC)) {
+      return AVIF_RESULT_UNKNOWN_ERROR;
+    }
+  } else if (output_format == AVIF_APP_FILE_FORMAT_PNG) {
+    const int compression_level = Clamp(10 - speed, 0, 9);
+    if (!avifPNGWrite(output_filename.c_str(), image, /*requestedDepth=*/0,
+                      AVIF_CHROMA_UPSAMPLING_AUTOMATIC, compression_level)) {
+      return AVIF_RESULT_UNKNOWN_ERROR;
+    }
+  } else if (output_format == AVIF_APP_FILE_FORMAT_AVIF) {
+    EncoderPtr encoder(avifEncoderCreate());
+    if (encoder == nullptr) {
+      return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    encoder->quality = quality;
+    encoder->speed = speed;
+    return WriteAvif(image, encoder.get(), output_filename);
+  } else {
+    std::cerr << "Unsupported output file extension: " << output_filename
+              << "\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+  return AVIF_RESULT_OK;
+}
+
+avifResult WriteAvif(const avifImage* image, avifEncoder* encoder,
+                     const std::string& output_filename) {
+  avifRWData encoded = AVIF_DATA_EMPTY;
+  std::cout << "AVIF to be written:\n";
+  avifImageDump(image,
+                /*gridCols=*/1,
+                /*gridRows=*/1, AVIF_PROGRESSIVE_STATE_UNAVAILABLE);
+  std::cout << "Encoding AVIF at quality " << encoder->quality << " speed "
+            << encoder->speed << ", please wait...\n";
+  avifResult result = avifEncoderWrite(encoder, image, &encoded);
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to encode image: " << avifResultToString(result)
+              << " (" << encoder->diag.error << ")\n";
+    return result;
+  }
+  std::ofstream f(output_filename, std::ios::binary);
+  f.write(reinterpret_cast<char*>(encoded.data), encoded.size);
+  if (f.fail()) {
+    std::cerr << "Failed to write image " << output_filename << ": "
+              << std::strerror(errno) << "\n";
+    return AVIF_RESULT_IO_ERROR;
+  }
+  std::cout << "Wrote AVIF: " << output_filename << "\n";
+  return AVIF_RESULT_OK;
+}
+
+avifResult ReadImage(avifImage* image, const std::string& input_filename,
+                     avifPixelFormat requested_format, uint32_t requested_depth,
+                     bool ignore_profile) {
+  avifAppFileFormat input_format = avifGuessFileFormat(input_filename.c_str());
+  if (input_format == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+    std::cerr << "Cannot determine input format: " << input_filename;
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  } else if (input_format == AVIF_APP_FILE_FORMAT_AVIF) {
+    DecoderPtr decoder(avifDecoderCreate());
+    if (decoder == NULL) {
+      return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    avifResult result = ReadAvif(decoder.get(), input_filename, ignore_profile);
+    if (result != AVIF_RESULT_OK) {
+      return result;
+    }
+    if (decoder->image->imageOwnsYUVPlanes &&
+        (decoder->image->alphaPlane == NULL ||
+         decoder->image->imageOwnsAlphaPlane)) {
+      std::swap(*image, *decoder->image);
+    } else {
+      result = avifImageCopy(image, decoder->image, AVIF_PLANES_ALL);
+      if (result != AVIF_RESULT_OK) {
+        return result;
+      }
+    }
+  } else {
+    const avifAppFileFormat file_format = avifReadImage(
+        input_filename.c_str(), requested_format,
+        static_cast<int>(requested_depth), AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC,
+        ignore_profile, /*ignoreExif=*/false, /*ignoreXMP=*/false,
+        /*allowChangingCicp=*/true, /*ignoreGainMap=*/true,
+        AVIF_DEFAULT_IMAGE_SIZE_LIMIT, image, /*outDepth=*/nullptr,
+        /*sourceTiming=*/nullptr, /*frameIter=*/nullptr);
+    if (file_format == AVIF_APP_FILE_FORMAT_UNKNOWN) {
+      std::cout << "Failed to decode image: " << input_filename;
+      return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (image->icc.size == 0) {
+      // Assume sRGB by default.
+      if (image->colorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED &&
+          image->transferCharacteristics == AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+        image->colorPrimaries = AVIF_COLOR_PRIMARIES_SRGB;
+        image->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_SRGB;
+      }
+    }
+  }
+  return AVIF_RESULT_OK;
+}
+
+avifResult ReadAvif(avifDecoder* decoder, const std::string& input_filename,
+                    bool ignore_profile) {
+  avifResult result = avifDecoderSetIOFile(decoder, input_filename.c_str());
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Cannot open file for read: " << input_filename << "\n";
+    return result;
+  }
+  result = avifDecoderParse(decoder);
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to parse image: " << avifResultToString(result) << " ("
+              << decoder->diag.error << ")\n";
+    return result;
+  }
+  result = avifDecoderNextImage(decoder);
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to decode image: " << avifResultToString(result)
+              << " (" << decoder->diag.error << ")\n";
+    return result;
+  }
+  if (ignore_profile) {
+    avifRWDataFree(&decoder->image->icc);
+    if (decoder->image->gainMap) {
+      avifRWDataFree(&decoder->image->gainMap->altICC);
+    }
+  }
+
+  return AVIF_RESULT_OK;
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/imageio.h b/third_party/libavif/src/apps/avifgainmaputil/imageio.h
new file mode 100644
index 0000000000..31dd5e0db3
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/imageio.h
@@ -0,0 +1,33 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_IMAGEIO_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_IMAGEIO_H_
+
+#include <string>
+
+#include "avif/avif.h"
+
+namespace avif {
+
+// Writes an image in any of the supported formats based on the file extension.
+avifResult WriteImage(const avifImage* image,
+                      const std::string& output_filename, int quality,
+                      int speed);
+// Reads an image in any of the supported formats. Ignores any gain map.
+avifResult ReadImage(avifImage* image, const std::string& input_filename,
+                     avifPixelFormat requested_format, uint32_t requested_depth,
+                     bool ignore_profile);
+
+// Reads an image in avif format given a pre-configured encoder.
+avifResult WriteAvif(const avifImage* image, avifEncoder* encoder,
+                     const std::string& output_filename);
+
+// Reads an image in avif format given a pre-configured decoder.
+// The image can be accessed at decoder->image.
+avifResult ReadAvif(avifDecoder* decoder, const std::string& input_filename,
+                    bool ignore_profile);
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_IMAGEIO_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.cc b/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.cc
new file mode 100644
index 0000000000..30b4a409d3
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.cc
@@ -0,0 +1,89 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "printmetadata_command.h"
+
+#include <cassert>
+#include <iomanip>
+
+#include "avif/avif_cxx.h"
+
+namespace avif {
+
+namespace {
+template <typename T>
+std::string FormatFraction(T fraction) {
+  std::stringstream stream;
+  stream << (fraction->d != 0 ? (double)fraction->n / fraction->d : 0)
+         << " (as fraction: " << fraction->n << "/" << fraction->d << ")";
+  return stream.str();
+}
+
+template <typename T>
+std::string FormatFractions(const T fractions[3]) {
+  std::stringstream stream;
+  const int w = 40;
+  stream << "R " << std::left << std::setw(w) << FormatFraction(fractions)
+         << " G " << std::left << std::setw(w) << FormatFraction(fractions)
+         << " B " << std::left << std::setw(w) << FormatFraction(fractions);
+  return stream.str();
+}
+}  // namespace
+
+PrintMetadataCommand::PrintMetadataCommand()
+    : ProgramCommand("printmetadata",
+                     "Prints the metadata of the gain map of an avif file") {
+  argparse_.add_argument(arg_input_filename_, "input_filename");
+}
+
+avifResult PrintMetadataCommand::Run() {
+  DecoderPtr decoder(avifDecoderCreate());
+  if (decoder == NULL) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+
+  avifResult result =
+      avifDecoderSetIOFile(decoder.get(), arg_input_filename_.value().c_str());
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Cannot open file for read: " << arg_input_filename_ << "\n";
+    return result;
+  }
+  result = avifDecoderParse(decoder.get());
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to parse image: " << avifResultToString(result) << " ("
+              << decoder->diag.error << ")\n";
+    return result;
+  }
+  if (decoder->image->gainMap == nullptr) {
+    std::cerr << "Input image " << arg_input_filename_
+              << " does not contain a gain map\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+  assert(decoder->image->gainMap);
+
+  const avifGainMap& gainMap = *decoder->image->gainMap;
+  const int w = 20;
+  std::cout << " * " << std::left << std::setw(w)
+            << "Base headroom: " << FormatFraction(&gainMap.baseHdrHeadroom)
+            << "\n";
+  std::cout << " * " << std::left << std::setw(w) << "Alternate headroom: "
+            << FormatFraction(&gainMap.alternateHdrHeadroom) << "\n";
+  std::cout << " * " << std::left << std::setw(w)
+            << "Gain Map Min: " << FormatFractions(gainMap.gainMapMin) << "\n";
+  std::cout << " * " << std::left << std::setw(w)
+            << "Gain Map Max: " << FormatFractions(gainMap.gainMapMax) << "\n";
+  std::cout << " * " << std::left << std::setw(w)
+            << "Base Offset: " << FormatFractions(gainMap.baseOffset) << "\n";
+  std::cout << " * " << std::left << std::setw(w)
+            << "Alternate Offset: " << FormatFractions(gainMap.alternateOffset)
+            << "\n";
+  std::cout << " * " << std::left << std::setw(w)
+            << "Gain Map Gamma: " << FormatFractions(gainMap.gainMapGamma)
+            << "\n";
+  std::cout << " * " << std::left << std::setw(w) << "Use Base Color Space: "
+            << (gainMap.useBaseColorSpace ? "True" : "False") << "\n";
+
+  return AVIF_RESULT_OK;
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.h b/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.h
new file mode 100644
index 0000000000..41d3e8e2f1
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/printmetadata_command.h
@@ -0,0 +1,23 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_PRINTMETADATA_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_PRINTMETADATA_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+class PrintMetadataCommand : public ProgramCommand {
+ public:
+  PrintMetadataCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_input_filename_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_PRINTMETADATA_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/program_command.cc b/third_party/libavif/src/apps/avifgainmaputil/program_command.cc
new file mode 100644
index 0000000000..d0f0f0b97e
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/program_command.cc
@@ -0,0 +1,66 @@
+#include "program_command.h"
+
+namespace avif {
+
+ProgramCommand::ProgramCommand(const std::string& name,
+                               const std::string& description)
+    : argparse_(
+          argparse::ArgumentParser("avifgainmaputil " + name, description)),
+      name_(name),
+      description_(description) {}
+
+// Parses command line arguments. Should be called before Run().
+avifResult ProgramCommand::ParseArgs(int argc, const char* const argv[]) {
+  argparse_.parse_args(argc, argv);
+  return AVIF_RESULT_OK;
+}
+
+// Prints this command's help on stdout.
+void ProgramCommand::PrintUsage() { argparse_.print_help(); }
+
+argparse::ConvertedValue<int> PixelFormatConverter::from_str(
+    const std::string& str) {
+  argparse::ConvertedValue<int> converted_value;
+
+  if (str == "444") {
+    converted_value.set_value(AVIF_PIXEL_FORMAT_YUV444);
+  } else if (str == "422") {
+    converted_value.set_value(AVIF_PIXEL_FORMAT_YUV422);
+  } else if (str == "420") {
+    converted_value.set_value(AVIF_PIXEL_FORMAT_YUV420);
+  } else if (str == "400") {
+    converted_value.set_value(AVIF_PIXEL_FORMAT_YUV400);
+  } else {
+    converted_value.set_error("Invalid argument value");
+  }
+  return converted_value;
+}
+
+std::vector<std::string> PixelFormatConverter::default_choices() {
+  return {"444", "422", "420", "400"};
+}
+
+argparse::ConvertedValue<CicpValues> CicpConverter::from_str(
+    const std::string& str) {
+  argparse::ConvertedValue<CicpValues> converted_value;
+
+  std::vector<uint32_t> cicp_values;
+  if (!ParseList(str, '/', 3, &cicp_values)) {
+    converted_value.set_error(
+        "Invalid cicp values, expected format: P/T/M where each "
+        "value is a positive integer, got: " +
+        str);
+  }
+
+  CicpValues cicp = {};
+  cicp.color_primaries = (avifColorPrimaries)cicp_values[0];
+  cicp.transfer_characteristics = (avifTransferCharacteristics)cicp_values[1];
+  cicp.matrix_coefficients = (avifMatrixCoefficients)cicp_values[2];
+  converted_value.set_value(cicp);
+
+  return converted_value;
+}
+
+std::vector<std::string> CicpConverter::default_choices() { return {}; }
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/program_command.h b/third_party/libavif/src/apps/avifgainmaputil/program_command.h
new file mode 100644
index 0000000000..d02eb49028
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/program_command.h
@@ -0,0 +1,142 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_PROGRAM_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_PROGRAM_COMMAND_H_
+
+#include <string>
+
+#include "argparse.hpp"
+#include "avif/avif.h"
+
+namespace avif {
+
+// A command that can be invoked by name (similar to how 'git' has commands like
+// 'commit', 'checkout', etc.)
+// NOTE: "avifgainmaputil" is currently hardcoded in the implementation (for
+// help messages).
+class ProgramCommand {
+ public:
+  // 'name' is the command that should be used to invoke the command on the
+  // command line.
+  // 'description' should be a one line description of what the command does.
+  ProgramCommand(const std::string& name, const std::string& description);
+
+  virtual ~ProgramCommand() = default;
+
+  // Parses command line arguments. Should be called before Run().
+  avifResult ParseArgs(int argc, const char* const argv[]);
+
+  // Runs the command.
+  virtual avifResult Run() = 0;
+
+  std::string name() const { return name_; }
+  std::string description() const { return description_; }
+
+  // Prints this command's help on stdout.
+  void PrintUsage();
+
+ protected:
+  argparse::ArgumentParser argparse_;
+
+ private:
+  std::string name_;
+  std::string description_;
+};
+
+//------------------------------------------------------------------------------
+// Utilities for flag parsing.
+
+// avifPixelFormat converter for use with argparse.
+// Actually converts to int, converting to avifPixelFormat didn't seem to
+// compile.
+struct PixelFormatConverter {
+  // Methods expected by argparse.
+  argparse::ConvertedValue<int> from_str(const std::string& str);
+  std::vector<std::string> default_choices();
+};
+
+struct CicpValues {
+  avifColorPrimaries color_primaries;
+  avifTransferCharacteristics transfer_characteristics;
+  avifMatrixCoefficients matrix_coefficients;
+};
+
+// CicpValues converter for use with argparse.
+struct CicpConverter {
+  // Methods expected by argparse.
+  argparse::ConvertedValue<CicpValues> from_str(const std::string& str);
+  std::vector<std::string> default_choices();
+};
+
+// Basic flags for image writing.
+struct BasicImageEncodeArgs {
+  argparse::ArgValue<int> speed;
+  argparse::ArgValue<int> quality;
+  argparse::ArgValue<int> quality_alpha;
+
+  // can_have_alpha should be true if the image can have alpha and the
+  // output format can be avif.
+  void Init(argparse::ArgumentParser& argparse, bool can_have_alpha) {
+    argparse.add_argument(speed, "--speed", "-s")
+        .help("Encoder speed (0-10, slowest-fastest)")
+        .default_value("6");
+    argparse.add_argument(quality, "--qcolor", "-q")
+        .help((can_have_alpha
+                   ? "Quality for color (0-100, where 100 is lossless)"
+                   : "Quality (0-100, where 100 is lossless)"))
+        .default_value("60");
+    if (can_have_alpha) {
+      argparse.add_argument(quality_alpha, "--qalpha")
+          .help("Quality for alpha (0-100, where 100 is lossless)")
+          .default_value("100");
+    }
+  }
+};
+
+// Flags relevant when reading jpeg/png.
+struct ImageReadArgs {
+  argparse::ArgValue<int> depth;
+  argparse::ArgValue<int> pixel_format;
+  argparse::ArgValue<bool> ignore_profile;
+
+  void Init(argparse::ArgumentParser& argparse) {
+    argparse
+        .add_argument<int, PixelFormatConverter>(pixel_format, "--yuv", "-y")
+        .help("Output YUV format for avif (default = automatic)");
+    argparse.add_argument(depth, "--depth", "-d")
+        .choices({"0", "8", "10", "12"})
+        .help("Output depth (0 = automatic)");
+    argparse.add_argument(ignore_profile, "--ignore-profile")
+        .help(
+            "If the input file contains an embedded color profile, ignore it "
+            "(no-op if absent)")
+        .action(argparse::Action::STORE_TRUE)
+        .default_value("false");
+  }
+};
+
+// Helper to parse flags that contain several delimited values.
+template <typename T>
+bool ParseList(std::string to_parse, char delim, int expected_num,
+               std::vector<T>* out) {
+  std::stringstream ss(to_parse);
+  std::string part;
+  T parsed;
+  while (std::getline(ss, part, delim)) {
+    std::istringstream is(part);
+    is >> parsed;
+    if (is.bad()) {
+      return false;
+    }
+    out->push_back(parsed);
+  }
+  if (expected_num > 0 && (int)out->size() != expected_num) {
+    return false;
+  }
+  return true;
+}
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_PROGRAM_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.cc b/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.cc
new file mode 100644
index 0000000000..90869af42f
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.cc
@@ -0,0 +1,192 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "swapbase_command.h"
+
+#include "avif/avif_cxx.h"
+#include "imageio.h"
+
+namespace avif {
+
+avifResult ChangeBase(const avifImage& image, int depth,
+                      avifPixelFormat yuvFormat, avifImage* swapped) {
+  if (image.gainMap == nullptr || image.gainMap->image == nullptr) {
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+
+  // Copy all metadata (no planes).
+  avifResult result = avifImageCopy(swapped, &image, /*planes=*/0);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+  swapped->depth = depth;
+  swapped->yuvFormat = yuvFormat;
+
+  if (image.gainMap->alternateHdrHeadroom.d == 0) {
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+  const float headroom =
+      static_cast<float>(image.gainMap->alternateHdrHeadroom.n) /
+      image.gainMap->alternateHdrHeadroom.d;
+  const bool tone_mapping_to_sdr = (headroom == 0.0f);
+
+  swapped->colorPrimaries = image.gainMap->altColorPrimaries;
+  if (swapped->colorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+    // Default to the same primaries as the base image if unspecified.
+    swapped->colorPrimaries = image.colorPrimaries;
+  }
+
+  swapped->transferCharacteristics = image.gainMap->altTransferCharacteristics;
+  if (swapped->transferCharacteristics ==
+      AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+    // Default to PQ for HDR and sRGB for SDR if unspecified.
+    const avifTransferCharacteristics transfer_characteristics =
+        static_cast<avifTransferCharacteristics>(
+            tone_mapping_to_sdr ? AVIF_TRANSFER_CHARACTERISTICS_SRGB
+                                : AVIF_TRANSFER_CHARACTERISTICS_PQ);
+    swapped->transferCharacteristics = transfer_characteristics;
+  }
+
+  swapped->matrixCoefficients = image.gainMap->altMatrixCoefficients;
+  if (swapped->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED) {
+    // Default to the same matrix as the base image if unspecified.
+    swapped->matrixCoefficients = image.matrixCoefficients;
+  }
+
+  avifRGBImage swapped_rgb;
+  avifRGBImageSetDefaults(&swapped_rgb, swapped);
+
+  avifContentLightLevelInformationBox clli = image.gainMap->image->clli;
+  const bool compute_clli =
+      !tone_mapping_to_sdr && clli.maxCLL == 0 && clli.maxPALL == 0;
+
+  avifDiagnostics diag;
+  result = avifImageApplyGainMap(&image, image.gainMap, headroom,
+                                 swapped->colorPrimaries,
+                                 swapped->transferCharacteristics, &swapped_rgb,
+                                 (compute_clli ? &clli : nullptr), &diag);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to tone map image: " << avifResultToString(result)
+              << " (" << diag.error << ")\n";
+    return result;
+  }
+  result = avifImageRGBToYUV(swapped, &swapped_rgb);
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to convert to YUV: " << avifResultToString(result)
+              << "\n";
+    return result;
+  }
+
+  swapped->clli = clli;
+  // Copy the gain map's planes.
+  result = avifImageCopy(swapped->gainMap->image, image.gainMap->image,
+                         AVIF_PLANES_YUV);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+
+  // Fill in the information on the alternate image
+  result =
+      avifRWDataSet(&swapped->gainMap->altICC, image.icc.data, image.icc.size);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+  swapped->gainMap->altColorPrimaries = image.colorPrimaries;
+  swapped->gainMap->altTransferCharacteristics = image.transferCharacteristics;
+  swapped->gainMap->altMatrixCoefficients = image.matrixCoefficients;
+  swapped->gainMap->altYUVRange = image.yuvRange;
+  swapped->gainMap->altDepth = image.depth;
+  swapped->gainMap->altPlaneCount =
+      (image.yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+  swapped->gainMap->altCLLI = image.clli;
+
+  // Swap base and alternate in the gain map
+  avifGainMap* gainMap = swapped->gainMap;
+  gainMap->useBaseColorSpace = !gainMap->useBaseColorSpace;
+  std::swap(gainMap->baseHdrHeadroom, gainMap->alternateHdrHeadroom);
+  for (int c = 0; c < 3; ++c) {
+    std::swap(gainMap->baseOffset, gainMap->alternateOffset);
+  }
+
+  return AVIF_RESULT_OK;
+}
+
+SwapBaseCommand::SwapBaseCommand()
+    : ProgramCommand(
+          "swapbase",
+          "Swaps the base and alternate images (e.g. if the base image is SDR "
+          "and the alternate is HDR, makes the base HDR). The alternate image "
+          "is the result ot fully applying the gain map.") {
+  argparse_.add_argument(arg_input_filename_, "input_filename");
+  argparse_.add_argument(arg_output_filename_, "output_filename");
+  arg_image_read_.Init(argparse_);
+  arg_image_encode_.Init(argparse_, /*can_have_alpha=*/true);
+  argparse_.add_argument(arg_gain_map_quality_, "--qgain-map")
+      .help("Quality for the gain map (0-100, where 100 is lossless)")
+      .default_value("60");
+}
+
+avifResult SwapBaseCommand::Run() {
+  DecoderPtr decoder(avifDecoderCreate());
+  if (decoder == NULL) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  decoder->imageContentToDecode |= AVIF_IMAGE_CONTENT_GAIN_MAP;
+  avifResult result = ReadAvif(decoder.get(), arg_input_filename_,
+                               arg_image_read_.ignore_profile);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+
+  const avifImage* image = decoder->image;
+  if (image->gainMap == nullptr || image->gainMap->image == nullptr) {
+    std::cerr << "Input image " << arg_input_filename_
+              << " does not contain a gain map\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+
+  int depth = arg_image_read_.depth;
+  if (depth == 0) {
+    depth = image->gainMap->altDepth;
+  }
+  if (depth == 0) {
+    // Default to the max depth between the base image and the gain map/
+    depth = std::max(image->depth, image->gainMap->image->depth);
+  }
+
+  avifPixelFormat pixel_format =
+      (avifPixelFormat)arg_image_read_.pixel_format.value();
+  if (pixel_format == AVIF_PIXEL_FORMAT_NONE) {
+    pixel_format = (image->gainMap->altPlaneCount == 1)
+                       ? AVIF_PIXEL_FORMAT_YUV420
+                       : AVIF_PIXEL_FORMAT_YUV444;
+  }
+
+  ImagePtr new_base(avifImageCreateEmpty());
+  if (new_base == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  result = ChangeBase(*image, depth, pixel_format, new_base.get());
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+
+  EncoderPtr encoder(avifEncoderCreate());
+  if (encoder == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  encoder->quality = arg_image_encode_.quality;
+  encoder->qualityAlpha = arg_image_encode_.quality_alpha;
+  encoder->qualityGainMap = arg_gain_map_quality_;
+  encoder->speed = arg_image_encode_.speed;
+  result = WriteAvif(new_base.get(), encoder.get(), arg_output_filename_);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to encode image: " << avifResultToString(result)
+              << " (" << encoder->diag.error << ")\n";
+    return result;
+  }
+
+  return AVIF_RESULT_OK;
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.h b/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.h
new file mode 100644
index 0000000000..fdf6cabb50
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/swapbase_command.h
@@ -0,0 +1,32 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_SWAPBASE_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_SWAPBASE_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+// Given an 'image' with a gain map, tone maps it to get the "alternate" image,
+// and saves it to 'output'.
+avifResult ChangeBase(const avifImage& image, int depth,
+                      avifPixelFormat yuvFormat, avifImage* output);
+
+class SwapBaseCommand : public ProgramCommand {
+ public:
+  SwapBaseCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_input_filename_;
+  argparse::ArgValue<std::string> arg_output_filename_;
+  ImageReadArgs arg_image_read_;
+  BasicImageEncodeArgs arg_image_encode_;
+  argparse::ArgValue<int> arg_gain_map_quality_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_SWAPBASE_COMMAND_H_
diff --git a/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.cc b/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.cc
new file mode 100644
index 0000000000..6c72f46c49
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.cc
@@ -0,0 +1,220 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "tonemap_command.h"
+
+#include <cmath>
+
+#include "avif/avif_cxx.h"
+#include "imageio.h"
+
+namespace avif {
+
+TonemapCommand::TonemapCommand()
+    : ProgramCommand("tonemap",
+                     "Tone maps an avif image that has a gain map to a "
+                     "given HDR headroom (how much brighter the display can go "
+                     "compared to an SDR display)") {
+  argparse_.add_argument(arg_input_filename_, "input_image");
+  argparse_.add_argument(arg_output_filename_, "output_image");
+  argparse_.add_argument(arg_headroom_, "--headroom")
+      .help(
+          "HDR headroom to tone map to. This is log2 of the ratio of HDR to "
+          "SDR luminance. 0 means SDR.")
+      .default_value("0");
+  argparse_
+      .add_argument<CicpValues, CicpConverter>(arg_input_cicp_, "--cicp-input")
+      .help(
+          "Override input CICP values, expressed as P/T/M "
+          "where P = color primaries, T = transfer characteristics, "
+          "M = matrix coefficients.");
+  argparse_
+      .add_argument<CicpValues, CicpConverter>(arg_output_cicp_,
+                                               "--cicp-output")
+      .help(
+          "CICP values for the output, expressed as P/T/M "
+          "where P = color primaries, T = transfer characteristics, "
+          "M = matrix coefficients. P and M are only relevant when saving to "
+          "AVIF. "
+          "If not specified, 'color primaries' defaults to the base image's "
+          "primaries, 'transfer characteristics' defaults to 16 (PQ) if "
+          "headroom > 0, or 13 (sRGB) otherwise, 'matrix coefficients' "
+          "defaults to 6 (BT601).");
+  argparse_.add_argument(arg_clli_str_, "--clli")
+      .help(
+          "Override content light level information expressed as: "
+          "MaxCLL,MaxPALL. Only relevant when saving to AVIF.");
+  arg_image_read_.Init(argparse_);
+  arg_image_encode_.Init(argparse_, /*can_have_alpha=*/true);
+}
+
+avifResult TonemapCommand::Run() {
+  avifContentLightLevelInformationBox clli_box = {};
+  bool clli_set = false;
+  if (!arg_clli_str_.value().empty()) {
+    std::vector<uint16_t> clli;
+    if (!ParseList(arg_clli_str_, ',', 2, &clli)) {
+      std::cerr << "Invalid clli values, expected format: maxCLL,maxPALL where "
+                   "both maxCLL and maxPALL are positive integers, got: "
+                << arg_clli_str_ << "\n";
+      return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    clli_box.maxCLL = clli[0];
+    clli_box.maxPALL = clli[1];
+    clli_set = true;
+  }
+
+  const float headroom = arg_headroom_;
+  const bool tone_mapping_to_hdr = (headroom > 0.0f);
+
+  DecoderPtr decoder(avifDecoderCreate());
+  if (decoder == NULL) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  decoder->imageContentToDecode |= AVIF_IMAGE_CONTENT_GAIN_MAP;
+  avifResult result = ReadAvif(decoder.get(), arg_input_filename_,
+                               arg_image_read_.ignore_profile);
+  if (result != AVIF_RESULT_OK) {
+    return result;
+  }
+
+  avifImage* image = decoder->image;
+  if (image->gainMap == nullptr || image->gainMap->image == nullptr) {
+    std::cerr << "Input image " << arg_input_filename_
+              << " does not contain a gain map\n";
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+  if (image->gainMap->baseHdrHeadroom.d == 0 ||
+      image->gainMap->alternateHdrHeadroom.d == 0) {
+    return AVIF_RESULT_INVALID_ARGUMENT;
+  }
+
+  const float base_hdr_hreadroom =
+      static_cast<float>(image->gainMap->baseHdrHeadroom.n) /
+      image->gainMap->baseHdrHeadroom.d;
+  const float alternate_hdr_hreadroom =
+      static_cast<float>(image->gainMap->alternateHdrHeadroom.n) /
+      image->gainMap->alternateHdrHeadroom.d;
+  // We are either tone mapping to the base image (i.e. leaving it as is),
+  // or tone mapping to the alternate image (i.e. fully applying the gain map),
+  // or tone mapping in between (partially applying the gain map).
+  const bool tone_mapping_to_base =
+      (headroom <= base_hdr_hreadroom &&
+       base_hdr_hreadroom <= alternate_hdr_hreadroom) ||
+      (headroom >= base_hdr_hreadroom &&
+       base_hdr_hreadroom >= alternate_hdr_hreadroom);
+  const bool tone_mapping_to_alternate =
+      (headroom <= alternate_hdr_hreadroom &&
+       alternate_hdr_hreadroom <= base_hdr_hreadroom) ||
+      (headroom >= alternate_hdr_hreadroom &&
+       alternate_hdr_hreadroom >= base_hdr_hreadroom);
+  const bool base_is_hdr = (base_hdr_hreadroom != 0.0f);
+
+  // Determine output CICP.
+  CicpValues cicp;
+  if (arg_output_cicp_.provenance() == argparse::Provenance::SPECIFIED) {
+    cicp = arg_output_cicp_;  // User provided values.
+  } else if (tone_mapping_to_base || (tone_mapping_to_hdr && base_is_hdr)) {
+    cicp = {image->colorPrimaries, image->transferCharacteristics,
+            image->matrixCoefficients};
+  } else {
+    cicp = {image->gainMap->altColorPrimaries,
+            image->gainMap->altTransferCharacteristics,
+            image->gainMap->altMatrixCoefficients};
+  }
+  if (cicp.color_primaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+    // TODO(maryla): for now avifImageApplyGainMap always uses the primaries of
+    // the base image, but it should take into account the metadata's
+    // useBaseColorSpace property.
+    cicp.color_primaries = image->colorPrimaries;
+  }
+  if (cicp.transfer_characteristics ==
+      AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+    cicp.transfer_characteristics = static_cast<avifTransferCharacteristics>(
+        tone_mapping_to_hdr ? AVIF_TRANSFER_CHARACTERISTICS_PQ
+                            : AVIF_TRANSFER_CHARACTERISTICS_SRGB);
+  }
+
+  // Determine output depth.
+  int depth = arg_image_read_.depth;
+  if (depth == 0) {
+    if (tone_mapping_to_base) {
+      depth = image->depth;
+    } else if (tone_mapping_to_alternate) {
+      depth = image->gainMap->altDepth;
+    }
+    if (depth == 0) {
+      // Default to the max depth between the base image, the gain map and
+      // the specified 'altDepth'.
+      depth = std::max(std::max(image->depth, image->gainMap->image->depth),
+                       image->gainMap->altDepth);
+    }
+  }
+
+  // Determine output pixel format.
+  avifPixelFormat pixel_format =
+      (avifPixelFormat)arg_image_read_.pixel_format.value();
+  const avifPixelFormat alt_yuv_format =
+      (image->gainMap->altPlaneCount == 1)
+          ? AVIF_PIXEL_FORMAT_YUV400
+          // Favor the least chroma subsampled format.
+          : std::min(image->yuvFormat, image->gainMap->image->yuvFormat);
+  if (pixel_format == AVIF_PIXEL_FORMAT_NONE) {
+    if (tone_mapping_to_base) {
+      pixel_format = image->yuvFormat;
+    } else if (tone_mapping_to_alternate) {
+      pixel_format = alt_yuv_format;
+    }
+    if (pixel_format == AVIF_PIXEL_FORMAT_NONE) {
+      // Default to the least chroma subsampled format provided.
+      pixel_format =
+          std::min(std::min(image->yuvFormat, image->gainMap->image->yuvFormat),
+                   alt_yuv_format);
+    }
+  }
+
+  // Use the clli from the base image or the alternate image if the headroom
+  // is outside of the (baseHdrHeadroom, alternateHdrHeadroom) range.
+  if (!clli_set) {
+    if (tone_mapping_to_base) {
+      clli_box = image->clli;
+    } else if (tone_mapping_to_alternate) {
+      clli_box = image->gainMap->image->clli;
+    }
+  }
+  clli_set = (clli_box.maxCLL != 0) || (clli_box.maxPALL != 0);
+
+  ImagePtr tone_mapped(
+      avifImageCreate(image->width, image->height, depth, pixel_format));
+  if (tone_mapped == nullptr) {
+    return AVIF_RESULT_OUT_OF_MEMORY;
+  }
+  avifRGBImage tone_mapped_rgb;
+  avifRGBImageSetDefaults(&tone_mapped_rgb, tone_mapped.get());
+  avifDiagnostics diag;
+  result = avifImageApplyGainMap(
+      decoder->image, image->gainMap, arg_headroom_, cicp.color_primaries,
+      cicp.transfer_characteristics, &tone_mapped_rgb,
+      clli_set ? nullptr : &clli_box, &diag);
+  if (result != AVIF_RESULT_OK) {
+    std::cout << "Failed to tone map image: " << avifResultToString(result)
+              << " (" << diag.error << ")\n";
+    return result;
+  }
+  result = avifImageRGBToYUV(tone_mapped.get(), &tone_mapped_rgb);
+  if (result != AVIF_RESULT_OK) {
+    std::cerr << "Failed to convert to YUV: " << avifResultToString(result)
+              << "\n";
+    return result;
+  }
+
+  tone_mapped->clli = clli_box;
+  tone_mapped->transferCharacteristics = cicp.transfer_characteristics;
+  tone_mapped->colorPrimaries = cicp.color_primaries;
+  tone_mapped->matrixCoefficients = cicp.matrix_coefficients;
+
+  return WriteImage(tone_mapped.get(), arg_output_filename_,
+                    arg_image_encode_.quality, arg_image_encode_.speed);
+}
+
+}  // namespace avif
diff --git a/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.h b/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.h
new file mode 100644
index 0000000000..2a7ea26dd9
--- /dev/null
+++ b/third_party/libavif/src/apps/avifgainmaputil/tonemap_command.h
@@ -0,0 +1,30 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_AVIFGAINMAPUTIL_TONEMAP_COMMAND_H_
+#define LIBAVIF_APPS_AVIFGAINMAPUTIL_TONEMAP_COMMAND_H_
+
+#include "avif/avif.h"
+#include "program_command.h"
+
+namespace avif {
+
+class TonemapCommand : public ProgramCommand {
+ public:
+  TonemapCommand();
+  avifResult Run() override;
+
+ private:
+  argparse::ArgValue<std::string> arg_input_filename_;
+  argparse::ArgValue<std::string> arg_output_filename_;
+  argparse::ArgValue<float> arg_headroom_;
+  argparse::ArgValue<std::string> arg_clli_str_;
+  argparse::ArgValue<CicpValues> arg_input_cicp_;
+  argparse::ArgValue<CicpValues> arg_output_cicp_;
+  ImageReadArgs arg_image_read_;
+  BasicImageEncodeArgs arg_image_encode_;
+};
+
+}  // namespace avif
+
+#endif  // LIBAVIF_APPS_AVIFGAINMAPUTIL_TONEMAP_COMMAND_H_
diff --git a/third_party/libavif/src/apps/shared/avifexif.c b/third_party/libavif/src/apps/shared/avifexif.c
new file mode 100644
index 0000000000..13fe8bfc73
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifexif.c
@@ -0,0 +1,63 @@
+// Copyright 2022 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avifexif.h"
+#include "avif/avif.h"
+
+uint8_t avifImageGetExifOrientationFromIrotImir(const avifImage * image)
+{
+    if ((image->transformFlags & AVIF_TRANSFORM_IROT) && (image->irot.angle == 1)) {
+        if (image->transformFlags & AVIF_TRANSFORM_IMIR) {
+            if (image->imir.axis) {
+                return 7; // 90 degrees anti-clockwise then swap left and right.
+            }
+            return 5; // 90 degrees anti-clockwise then swap top and bottom.
+        }
+        return 6; // 90 degrees anti-clockwise.
+    }
+    if ((image->transformFlags & AVIF_TRANSFORM_IROT) && (image->irot.angle == 2)) {
+        if (image->transformFlags & AVIF_TRANSFORM_IMIR) {
+            if (image->imir.axis) {
+                return 4; // 180 degrees anti-clockwise then swap left and right.
+            }
+            return 2; // 180 degrees anti-clockwise then swap top and bottom.
+        }
+        return 3; // 180 degrees anti-clockwise.
+    }
+    if ((image->transformFlags & AVIF_TRANSFORM_IROT) && (image->irot.angle == 3)) {
+        if (image->transformFlags & AVIF_TRANSFORM_IMIR) {
+            if (image->imir.axis) {
+                return 5; // 270 degrees anti-clockwise then swap left and right.
+            }
+            return 7; // 270 degrees anti-clockwise then swap top and bottom.
+        }
+        return 8; // 270 degrees anti-clockwise.
+    }
+    if (image->transformFlags & AVIF_TRANSFORM_IMIR) {
+        if (image->imir.axis) {
+            return 2; // Swap left and right.
+        }
+        return 4; // Swap top and bottom.
+    }
+    return 1; // Default orientation ("top-left", no-op).
+}
+
+avifResult avifSetExifOrientation(avifRWData * exif, uint8_t orientation)
+{
+    size_t offset;
+    const avifResult result = avifGetExifOrientationOffset(exif->data, exif->size, &offset);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    if (offset < exif->size) {
+        exif->data[offset] = orientation;
+        return AVIF_RESULT_OK;
+    }
+    // No Exif orientation was found.
+    if (orientation == 1) {
+        // The default orientation is 1, so if the given orientation is 1 too, do nothing.
+        return AVIF_RESULT_OK;
+    }
+    // Adding an orientation tag to an Exif payload is involved.
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
diff --git a/third_party/libavif/src/apps/shared/avifexif.h b/third_party/libavif/src/apps/shared/avifexif.h
new file mode 100644
index 0000000000..0c99a618a1
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifexif.h
@@ -0,0 +1,23 @@
+// Copyright 2022 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_AVIFEXIF_H
+#define LIBAVIF_APPS_SHARED_AVIFEXIF_H
+
+#include "avif/avif.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Converts image->transformFlags, image->irot and image->imir to the equivalent Exif orientation value in [1:8].
+uint8_t avifImageGetExifOrientationFromIrotImir(const avifImage * image);
+
+// Attempts to parse the Exif payload until the orientation is found, then sets it to the given value.
+avifResult avifSetExifOrientation(avifRWData * exif, uint8_t orientation);
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef LIBAVIF_APPS_SHARED_AVIFEXIF_H
diff --git a/third_party/libavif/src/apps/shared/avifjpeg.c b/third_party/libavif/src/apps/shared/avifjpeg.c
new file mode 100644
index 0000000000..43b008cc12
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifjpeg.c
@@ -0,0 +1,1384 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avifjpeg.h"
+#include "avifexif.h"
+#include "avifutil.h"
+
+#include <assert.h>
+#include <ctype.h>
+#include <math.h>
+#include <setjmp.h>
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "jpeglib.h"
+
+#include "iccjpeg.h"
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+#include <libxml/parser.h>
+#endif
+
+#define AVIF_MIN(a, b) (((a) < (b)) ? (a) : (b))
+#define AVIF_MAX(a, b) (((a) > (b)) ? (a) : (b))
+
+struct my_error_mgr
+{
+    struct jpeg_error_mgr pub;
+    jmp_buf setjmp_buffer;
+};
+typedef struct my_error_mgr * my_error_ptr;
+static void my_error_exit(j_common_ptr cinfo)
+{
+    my_error_ptr myerr = (my_error_ptr)cinfo->err;
+    (*cinfo->err->output_message)(cinfo);
+    longjmp(myerr->setjmp_buffer, 1);
+}
+
+#if JPEG_LIB_VERSION >= 70
+#define AVIF_LIBJPEG_DCT_v_scaled_size DCT_v_scaled_size
+#define AVIF_LIBJPEG_DCT_h_scaled_size DCT_h_scaled_size
+#else
+#define AVIF_LIBJPEG_DCT_h_scaled_size DCT_scaled_size
+#define AVIF_LIBJPEG_DCT_v_scaled_size DCT_scaled_size
+#endif
+
+// An internal function used by avifJPEGReadCopy(), this is the shared libjpeg decompression code
+// for all paths avifJPEGReadCopy() takes.
+static avifBool avifJPEGCopyPixels(avifImage * avif, uint32_t sizeLimit, struct jpeg_decompress_struct * cinfo)
+{
+    cinfo->raw_data_out = TRUE;
+    jpeg_start_decompress(cinfo);
+
+    avif->width = cinfo->image_width;
+    avif->height = cinfo->image_height;
+    if (avif->width > sizeLimit / avif->height) {
+        return AVIF_FALSE;
+    }
+
+    JSAMPIMAGE buffer = (*cinfo->mem->alloc_small)((j_common_ptr)cinfo, JPOOL_IMAGE, sizeof(JSAMPARRAY) * cinfo->num_components);
+
+    // lines of output image to be read per jpeg_read_raw_data call
+    int readLines = 0;
+    // lines of samples to be read per call (for each channel)
+    int linesPerCall[3] = { 0, 0, 0 };
+    // expected count of sample lines (for each channel)
+    int targetRead[3] = { 0, 0, 0 };
+    for (int i = 0; i < cinfo->num_components; ++i) {
+        jpeg_component_info * comp = &cinfo->comp_info[i];
+
+        linesPerCall[i] = comp->v_samp_factor * comp->AVIF_LIBJPEG_DCT_v_scaled_size;
+        targetRead[i] = comp->downsampled_height;
+        buffer[i] = (*cinfo->mem->alloc_sarray)((j_common_ptr)cinfo,
+                                                JPOOL_IMAGE,
+                                                comp->width_in_blocks * comp->AVIF_LIBJPEG_DCT_h_scaled_size,
+                                                linesPerCall[i]);
+        readLines = AVIF_MAX(readLines, linesPerCall[i]);
+    }
+
+    avifImageFreePlanes(avif, AVIF_PLANES_ALL); // Free planes in case they were already allocated.
+    if (avifImageAllocatePlanes(avif, AVIF_PLANES_YUV) != AVIF_RESULT_OK) {
+        return AVIF_FALSE;
+    }
+
+    // destination avif channel for each jpeg channel
+    avifChannelIndex targetChannel[3] = { AVIF_CHAN_Y, AVIF_CHAN_Y, AVIF_CHAN_Y };
+    if (cinfo->jpeg_color_space == JCS_YCbCr) {
+        targetChannel[0] = AVIF_CHAN_Y;
+        targetChannel[1] = AVIF_CHAN_U;
+        targetChannel[2] = AVIF_CHAN_V;
+    } else if (cinfo->jpeg_color_space == JCS_GRAYSCALE) {
+        targetChannel[0] = AVIF_CHAN_Y;
+    } else {
+        // cinfo->jpeg_color_space == JCS_RGB
+        targetChannel[0] = AVIF_CHAN_V;
+        targetChannel[1] = AVIF_CHAN_Y;
+        targetChannel[2] = AVIF_CHAN_U;
+    }
+
+    int workComponents = avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400 ? 1 : cinfo->num_components;
+
+    // count of already-read lines (for each channel)
+    int alreadyRead[3] = { 0, 0, 0 };
+    while (cinfo->output_scanline < cinfo->output_height) {
+        jpeg_read_raw_data(cinfo, buffer, readLines);
+
+        for (int i = 0; i < workComponents; ++i) {
+            int linesRead = AVIF_MIN(targetRead[i] - alreadyRead[i], linesPerCall[i]);
+            for (int j = 0; j < linesRead; ++j) {
+                memcpy(&avif->yuvPlanes[targetChannel[i]][avif->yuvRowBytes[targetChannel[i]] * (alreadyRead[i] + j)],
+                       buffer[i][j],
+                       avif->yuvRowBytes[targetChannel[i]]);
+            }
+            alreadyRead[i] += linesPerCall[i];
+        }
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifJPEGHasCompatibleMatrixCoefficients(avifMatrixCoefficients matrixCoefficients)
+{
+    switch (matrixCoefficients) {
+        case AVIF_MATRIX_COEFFICIENTS_BT470BG:
+        case AVIF_MATRIX_COEFFICIENTS_BT601:
+            // JPEG always uses [Kr:0.299, Kb:0.114], which matches these MCs.
+            return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+// This attempts to copy the internal representation of the JPEG directly into avifImage without
+// YUV->RGB conversion. If it returns AVIF_FALSE, a typical RGB->YUV conversion is required.
+static avifBool avifJPEGReadCopy(avifImage * avif, uint32_t sizeLimit, struct jpeg_decompress_struct * cinfo)
+{
+    if ((avif->depth != 8) || (avif->yuvRange != AVIF_RANGE_FULL)) {
+        return AVIF_FALSE;
+    }
+
+    if (cinfo->jpeg_color_space == JCS_YCbCr) {
+        // Import from YUV: must use compatible matrixCoefficients.
+        if (avifJPEGHasCompatibleMatrixCoefficients(avif->matrixCoefficients)) {
+            // YUV->YUV: require precise match for pixel format.
+            avifPixelFormat jpegFormat = AVIF_PIXEL_FORMAT_NONE;
+            if (cinfo->comp_info[0].h_samp_factor == 1 && cinfo->comp_info[0].v_samp_factor == 1 &&
+                cinfo->comp_info[1].h_samp_factor == 1 && cinfo->comp_info[1].v_samp_factor == 1 &&
+                cinfo->comp_info[2].h_samp_factor == 1 && cinfo->comp_info[2].v_samp_factor == 1) {
+                jpegFormat = AVIF_PIXEL_FORMAT_YUV444;
+            } else if (cinfo->comp_info[0].h_samp_factor == 2 && cinfo->comp_info[0].v_samp_factor == 1 &&
+                       cinfo->comp_info[1].h_samp_factor == 1 && cinfo->comp_info[1].v_samp_factor == 1 &&
+                       cinfo->comp_info[2].h_samp_factor == 1 && cinfo->comp_info[2].v_samp_factor == 1) {
+                jpegFormat = AVIF_PIXEL_FORMAT_YUV422;
+            } else if (cinfo->comp_info[0].h_samp_factor == 2 && cinfo->comp_info[0].v_samp_factor == 2 &&
+                       cinfo->comp_info[1].h_samp_factor == 1 && cinfo->comp_info[1].v_samp_factor == 1 &&
+                       cinfo->comp_info[2].h_samp_factor == 1 && cinfo->comp_info[2].v_samp_factor == 1) {
+                jpegFormat = AVIF_PIXEL_FORMAT_YUV420;
+            }
+            if (jpegFormat != AVIF_PIXEL_FORMAT_NONE) {
+                if (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE) {
+                    // The requested format is "auto": Adopt JPEG's internal format.
+                    avif->yuvFormat = jpegFormat;
+                }
+                if (avif->yuvFormat == jpegFormat) {
+                    cinfo->out_color_space = JCS_YCbCr;
+                    return avifJPEGCopyPixels(avif, sizeLimit, cinfo);
+                }
+            }
+
+            // YUV->Grayscale: subsample Y plane not allowed.
+            if ((avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) && (cinfo->comp_info[0].h_samp_factor == cinfo->max_h_samp_factor &&
+                                                                  cinfo->comp_info[0].v_samp_factor == cinfo->max_v_samp_factor)) {
+                cinfo->out_color_space = JCS_YCbCr;
+                return avifJPEGCopyPixels(avif, sizeLimit, cinfo);
+            }
+        }
+    } else if (cinfo->jpeg_color_space == JCS_GRAYSCALE) {
+        // Import from Grayscale: subsample not allowed.
+        if ((cinfo->comp_info[0].h_samp_factor == cinfo->max_h_samp_factor &&
+             cinfo->comp_info[0].v_samp_factor == cinfo->max_v_samp_factor)) {
+            // Import to YUV/Grayscale: must use compatible matrixCoefficients.
+            if (avifJPEGHasCompatibleMatrixCoefficients(avif->matrixCoefficients)) {
+                // Grayscale->Grayscale: direct copy.
+                if ((avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) || (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE)) {
+                    avif->yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+                    cinfo->out_color_space = JCS_GRAYSCALE;
+                    return avifJPEGCopyPixels(avif, sizeLimit, cinfo);
+                }
+
+                // Grayscale->YUV: copy Y, fill UV with monochrome value.
+                if ((avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) || (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV422) ||
+                    (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV420)) {
+                    cinfo->out_color_space = JCS_GRAYSCALE;
+                    if (!avifJPEGCopyPixels(avif, sizeLimit, cinfo)) {
+                        return AVIF_FALSE;
+                    }
+
+                    uint32_t uvHeight = avifImagePlaneHeight(avif, AVIF_CHAN_U);
+                    memset(avif->yuvPlanes[AVIF_CHAN_U], 128, (size_t)avif->yuvRowBytes[AVIF_CHAN_U] * uvHeight);
+                    memset(avif->yuvPlanes[AVIF_CHAN_V], 128, (size_t)avif->yuvRowBytes[AVIF_CHAN_V] * uvHeight);
+
+                    return AVIF_TRUE;
+                }
+            }
+
+            // Grayscale->RGB: copy Y to G, duplicate to B and R.
+            if ((avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) &&
+                ((avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) || (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE))) {
+                avif->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                cinfo->out_color_space = JCS_GRAYSCALE;
+                if (!avifJPEGCopyPixels(avif, sizeLimit, cinfo)) {
+                    return AVIF_FALSE;
+                }
+
+                memcpy(avif->yuvPlanes[AVIF_CHAN_U], avif->yuvPlanes[AVIF_CHAN_Y], (size_t)avif->yuvRowBytes[AVIF_CHAN_U] * avif->height);
+                memcpy(avif->yuvPlanes[AVIF_CHAN_V], avif->yuvPlanes[AVIF_CHAN_Y], (size_t)avif->yuvRowBytes[AVIF_CHAN_V] * avif->height);
+
+                return AVIF_TRUE;
+            }
+        }
+    } else if (cinfo->jpeg_color_space == JCS_RGB) {
+        // RGB->RGB: subsample not allowed.
+        if ((avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) &&
+            ((avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) || (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE)) &&
+            (cinfo->comp_info[0].h_samp_factor == 1 && cinfo->comp_info[0].v_samp_factor == 1 &&
+             cinfo->comp_info[1].h_samp_factor == 1 && cinfo->comp_info[1].v_samp_factor == 1 &&
+             cinfo->comp_info[2].h_samp_factor == 1 && cinfo->comp_info[2].v_samp_factor == 1)) {
+            avif->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+            cinfo->out_color_space = JCS_RGB;
+            return avifJPEGCopyPixels(avif, sizeLimit, cinfo);
+        }
+    }
+
+    // A typical RGB->YUV conversion is required.
+    return AVIF_FALSE;
+}
+
+// Reads a 4-byte unsigned integer in big-endian format from the raw bitstream src.
+static uint32_t avifJPEGReadUint32BigEndian(const uint8_t * src)
+{
+    return ((uint32_t)src[0] << 24) | ((uint32_t)src[1] << 16) | ((uint32_t)src[2] << 8) | ((uint32_t)src[3] << 0);
+}
+
+// Returns the pointer in str to the first occurrence of substr. Returns NULL if substr cannot be found in str.
+static const uint8_t * avifJPEGFindSubstr(const uint8_t * str, size_t strLength, const uint8_t * substr, size_t substrLength)
+{
+    for (size_t index = 0; index + substrLength <= strLength; ++index) {
+        if (!memcmp(&str[index], substr, substrLength)) {
+            return &str[index];
+        }
+    }
+    return NULL;
+}
+
+#define AVIF_JPEG_MAX_MARKER_DATA_LENGTH 65533
+
+// Exif tag
+#define AVIF_JPEG_EXIF_HEADER "Exif\0\0"
+#define AVIF_JPEG_EXIF_HEADER_LENGTH 6
+
+// XMP tags
+#define AVIF_JPEG_STANDARD_XMP_TAG "http://ns.adobe.com/xap/1.0/\0"
+#define AVIF_JPEG_STANDARD_XMP_TAG_LENGTH 29
+#define AVIF_JPEG_EXTENDED_XMP_TAG "http://ns.adobe.com/xmp/extension/\0"
+#define AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH 35
+
+// MPF tag (Multi-Picture Format)
+#define AVIF_JPEG_MPF_HEADER "MPF\0"
+#define AVIF_JPEG_MPF_HEADER_LENGTH 4
+
+// One way of storing the Extended XMP GUID (generated by a camera for example).
+#define AVIF_JPEG_XMP_NOTE_TAG "xmpNote:HasExtendedXMP=\""
+#define AVIF_JPEG_XMP_NOTE_TAG_LENGTH 24
+// Another way of storing the Extended XMP GUID (generated by exiftool for example).
+#define AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG "<xmpNote:HasExtendedXMP>"
+#define AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG_LENGTH 24
+
+#define AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH 32
+
+// Offset in APP1 segment (skip tag + guid + size + offset).
+#define AVIF_JPEG_OFFSET_TILL_EXTENDED_XMP (AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH + AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH + 4 + 4)
+
+#define AVIF_CHECK(A)          \
+    do {                       \
+        if (!(A))              \
+            return AVIF_FALSE; \
+    } while (0)
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+
+// Reads a 4-byte unsigned integer in little-endian format from the raw bitstream src.
+static uint32_t avifJPEGReadUint32LittleEndian(const uint8_t * src)
+{
+    return ((uint32_t)src[0] << 0) | ((uint32_t)src[1] << 8) | ((uint32_t)src[2] << 16) | ((uint32_t)src[3] << 24);
+}
+
+// Reads a 2-byte unsigned integer in big-endian format from the raw bitstream src.
+static uint16_t avifJPEGReadUint16BigEndian(const uint8_t * src)
+{
+    return (uint16_t)((src[0] << 8) | (src[1] << 0));
+}
+
+// Reads a 2-byte unsigned integer in little-endian format from the raw bitstream src.
+static uint16_t avifJPEGReadUint16LittleEndian(const uint8_t * src)
+{
+    return (uint16_t)((src[0] << 0) | (src[1] << 8));
+}
+
+// Reads 'numBytes' at 'offset', stores them in 'bytes' and increases 'offset'.
+static avifBool avifJPEGReadBytes(const avifROData * data, uint8_t * bytes, uint32_t * offset, uint32_t numBytes)
+{
+    if (data->size < (*offset + numBytes)) {
+        return AVIF_FALSE;
+    }
+    memcpy(bytes, &data->data[*offset], numBytes);
+    *offset += numBytes;
+    return AVIF_TRUE;
+}
+
+static avifBool avifJPEGReadU32(const avifROData * data, uint32_t * v, uint32_t * offset, avifBool isBigEndian)
+{
+    uint8_t bytes[4];
+    AVIF_CHECK(avifJPEGReadBytes(data, bytes, offset, 4));
+    *v = isBigEndian ? avifJPEGReadUint32BigEndian(bytes) : avifJPEGReadUint32LittleEndian(bytes);
+    return AVIF_TRUE;
+}
+
+static avifBool avifJPEGReadU16(const avifROData * data, uint16_t * v, uint32_t * offset, avifBool isBigEndian)
+{
+    uint8_t bytes[2];
+    AVIF_CHECK(avifJPEGReadBytes(data, bytes, offset, 2));
+    *v = isBigEndian ? avifJPEGReadUint16BigEndian(bytes) : avifJPEGReadUint16LittleEndian(bytes);
+    return AVIF_TRUE;
+}
+
+static avifBool avifJPEGReadInternal(FILE * f,
+                                     const char * inputFilename,
+                                     avifImage * avif,
+                                     avifPixelFormat requestedFormat,
+                                     uint32_t requestedDepth,
+                                     avifChromaDownsampling chromaDownsampling,
+                                     avifBool ignoreColorProfile,
+                                     avifBool ignoreExif,
+                                     avifBool ignoreXMP,
+                                     avifBool ignoreGainMap,
+                                     uint32_t sizeLimit);
+
+// Arbitrary max number of jpeg segments to parse before giving up.
+#define MAX_JPEG_SEGMENTS 100
+
+// Finds the offset of the first MPF segment. Returns AVIF_TRUE if it was found.
+static avifBool avifJPEGFindMpfSegmentOffset(FILE * f, uint32_t * mpfOffset)
+{
+    const long oldOffset = ftell(f);
+
+    uint32_t offset = 2; // Skip the 2 byte SOI (Start Of Image) marker.
+    if (fseek(f, offset, SEEK_SET) != 0) {
+        return AVIF_FALSE;
+    }
+
+    uint8_t buffer[4];
+    int numSegments = 0;
+    while (numSegments < MAX_JPEG_SEGMENTS) {
+        ++numSegments;
+        // Read the APP<n> segment marker (2 bytes) and the segment size (2 bytes).
+        if (fread(buffer, 1, 4, f) != 4) {
+            fseek(f, oldOffset, SEEK_SET);
+            return AVIF_FALSE; // End of the file reached.
+        }
+        offset += 4;
+
+        // Total APP<n> segment byte count, including the byte count value (2 bytes), but excluding the 2 byte APP<n> marker itself.
+        const uint16_t segmentLength = avifJPEGReadUint16BigEndian(&buffer[2]);
+        if (segmentLength < 2) {
+            fseek(f, oldOffset, SEEK_SET);
+            return AVIF_FALSE; // Invalid length.
+        } else if (segmentLength < 2 + AVIF_JPEG_MPF_HEADER_LENGTH) {
+            // Cannot be an MPF segment, skip to the next segment.
+            offset += segmentLength - 2;
+            if (fseek(f, offset, SEEK_SET) != 0) {
+                fseek(f, oldOffset, SEEK_SET);
+                return AVIF_FALSE;
+            }
+            continue;
+        }
+
+        uint8_t identifier[AVIF_JPEG_MPF_HEADER_LENGTH];
+        if (fread(identifier, 1, AVIF_JPEG_MPF_HEADER_LENGTH, f) != AVIF_JPEG_MPF_HEADER_LENGTH) {
+            fseek(f, oldOffset, SEEK_SET);
+            return AVIF_FALSE; // End of the file reached.
+        }
+        offset += AVIF_JPEG_MPF_HEADER_LENGTH;
+
+        if (buffer[1] == (JPEG_APP0 + 2) && !memcmp(identifier, AVIF_JPEG_MPF_HEADER, AVIF_JPEG_MPF_HEADER_LENGTH)) {
+            // MPF segment found.
+            *mpfOffset = offset;
+            fseek(f, oldOffset, SEEK_SET);
+            return AVIF_TRUE;
+        }
+
+        // Skip to the next segment.
+        offset += segmentLength - 2 - AVIF_JPEG_MPF_HEADER_LENGTH;
+        if (fseek(f, offset, SEEK_SET) != 0) {
+            fseek(f, oldOffset, SEEK_SET);
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_FALSE;
+}
+
+// Searches for a node called 'nameSpace:nodeName' in the children (or descendants if 'recursive' is set) of 'parentNode'.
+// Returns the first such node found (in depth first search). Returns NULL if no such node is found.
+static const xmlNode * avifJPEGFindXMLNodeByName(const xmlNode * parentNode, const char * nameSpace, const char * nodeName, avifBool recursive)
+{
+    if (parentNode == NULL) {
+        return NULL;
+    }
+    for (const xmlNode * node = parentNode->children; node != NULL; node = node->next) {
+        if (node->ns != NULL && !xmlStrcmp(node->ns->href, (const xmlChar *)nameSpace) &&
+            !xmlStrcmp(node->name, (const xmlChar *)nodeName)) {
+            return node;
+        } else if (recursive) {
+            const xmlNode * descendantNode = avifJPEGFindXMLNodeByName(node, nameSpace, nodeName, recursive);
+            if (descendantNode != NULL) {
+                return descendantNode;
+            }
+        }
+    }
+    return NULL;
+}
+
+#define XML_NAME_SPACE_GAIN_MAP "http://ns.adobe.com/hdr-gain-map/1.0/"
+#define XML_NAME_SPACE_RDF "http://www.w3.org/1999/02/22-rdf-syntax-ns#"
+
+// Finds an 'rdf:Description' node containing a gain map version attribute (hdrgm:Version="1.0").
+// Returns NULL if not found.
+static const xmlNode * avifJPEGFindGainMapXMPNode(const xmlNode * rootNode)
+{
+    // See XMP specification https://github.com/adobe/XMP-Toolkit-SDK/blob/main/docs/XMPSpecificationPart1.pdf
+    // ISO 16684-1:2011 7.1 "For this serialization, a single XMP packet shall be serialized using a single rdf:RDF XML element."
+    // 7.3 "Other XML elements may appear around the rdf:RDF element."
+    const xmlNode * rdfNode = avifJPEGFindXMLNodeByName(rootNode, XML_NAME_SPACE_RDF, "RDF", /*recursive=*/AVIF_TRUE);
+    if (rdfNode == NULL) {
+        return NULL;
+    }
+    for (const xmlNode * node = rdfNode->children; node != NULL; node = node->next) {
+        // Loop through rdf:Description children.
+        // 7.4 "A single XMP packet shall be serialized using a single rdf:RDF XML element. The rdf:RDF element content
+        // shall consist of only zero or more rdf:Description elements."
+        if (node->ns && !xmlStrcmp(node->ns->href, (const xmlChar *)XML_NAME_SPACE_RDF) &&
+            !xmlStrcmp(node->name, (const xmlChar *)"Description")) {
+            // Look for the gain map version attribute: hdrgm:Version="1.0"
+            for (xmlAttr * prop = node->properties; prop != NULL; prop = prop->next) {
+                if (prop->ns && !xmlStrcmp(prop->ns->href, (const xmlChar *)XML_NAME_SPACE_GAIN_MAP) &&
+                    !xmlStrcmp(prop->name, (const xmlChar *)"Version") && prop->children != NULL &&
+                    !xmlStrcmp(prop->children->content, (const xmlChar *)"1.0")) {
+                    return node;
+                }
+            }
+        }
+    }
+    return NULL;
+}
+
+// Use XML_PARSE_RECOVER and XML_PARSE_NOERROR to avoid failing/printing errors for invalid XML.
+// In particular, if the jpeg files contains extended XMP, avifJPEGReadInternal simply concatenates it to
+// standard XMP, which is not a valid XML tree.
+// TODO(maryla): better handle extended XMP. If the gain map metadata is in the extended part,
+// the current code won't detect it.
+#define LIBXML2_XML_PARSING_FLAGS (XML_PARSE_RECOVER | XML_PARSE_NOERROR)
+
+// Returns true if there is an 'rdf:Description' node containing a gain map version attribute (hdrgm:Version="1.0").
+// On the main image, this signals that the file also contains a gain map.
+// On a subsequent image, this signals that it is a gain map.
+static avifBool avifJPEGHasGainMapXMPNode(const uint8_t * xmpData, size_t xmpSize)
+{
+    xmlDoc * document = xmlReadMemory((const char *)xmpData, (int)xmpSize, NULL, NULL, LIBXML2_XML_PARSING_FLAGS);
+    if (document == NULL) {
+        return AVIF_FALSE; // Probably and out of memory error.
+    }
+    const xmlNode * rootNode = xmlDocGetRootElement(document);
+    const xmlNode * node = avifJPEGFindGainMapXMPNode(rootNode);
+    const avifBool found = (node != NULL);
+    xmlFreeDoc(document);
+    return found;
+}
+
+// Finds the value of a gain map metadata property, that can be either stored as an attribute of 'descriptionNode'
+// (which should point to a <rdf:Description> node) or as a child node.
+// 'maxValues' is the maximum number of expected values, and the size of the 'values' array. 'numValues' is set to the number
+// of values actually found (which may be smaller or larger, but only up to 'maxValues' are stored in 'values').
+// Returns AVIF_TRUE if the property was found.
+static avifBool avifJPEGFindGainMapProperty(const xmlNode * descriptionNode,
+                                            const char * propertyName,
+                                            uint32_t maxValues,
+                                            const char * values[],
+                                            uint32_t * numValues)
+{
+    *numValues = 0;
+
+    // Search attributes.
+    for (xmlAttr * prop = descriptionNode->properties; prop != NULL; prop = prop->next) {
+        if (prop->ns && !xmlStrcmp(prop->ns->href, (const xmlChar *)XML_NAME_SPACE_GAIN_MAP) &&
+            !xmlStrcmp(prop->name, (const xmlChar *)propertyName) && prop->children != NULL && prop->children->content != NULL) {
+            // Properties should have just one child containing the property's value
+            // (in fact the 'children' field is documented as "the value of the property").
+            values[0] = (const char *)prop->children->content;
+            *numValues = 1;
+            return AVIF_TRUE;
+        }
+    }
+
+    // Search child nodes.
+    for (const xmlNode * node = descriptionNode->children; node != NULL; node = node->next) {
+        if (node->ns && !xmlStrcmp(node->ns->href, (const xmlChar *)XML_NAME_SPACE_GAIN_MAP) &&
+            !xmlStrcmp(node->name, (const xmlChar *)propertyName) && node->children) {
+            // Multiple values can be specified with a Seq tag: <rdf:Seq><rdf:li>value1</rdf:li><rdf:li>value2</rdf:li>...</rdf:Seq>
+            const xmlNode * seq = avifJPEGFindXMLNodeByName(node, XML_NAME_SPACE_RDF, "Seq", /*recursive=*/AVIF_FALSE);
+            if (seq) {
+                for (xmlNode * seqChild = seq->children; seqChild; seqChild = seqChild->next) {
+                    if (!xmlStrcmp(seqChild->name, (const xmlChar *)"li") && seqChild->children != NULL &&
+                        seqChild->children->content != NULL) {
+                        if (*numValues < maxValues) {
+                            values[*numValues] = (const char *)seqChild->children->content;
+                        }
+                        ++(*numValues);
+                    }
+                }
+                return *numValues > 0 ? AVIF_TRUE : AVIF_FALSE;
+            } else if (node->children->next == NULL && node->children->type == XML_TEXT_NODE) { // Only one child and it's text.
+                values[0] = (const char *)node->children->content;
+                *numValues = 1;
+                return AVIF_TRUE;
+            }
+            // We found a tag for this property but no valid content.
+            return AVIF_FALSE;
+        }
+    }
+
+    return AVIF_FALSE; // Property not found.
+}
+
+// Up to 3 values per property (one for each RGB channel).
+#define GAIN_MAP_PROPERTY_MAX_VALUES 3
+
+// Looks for a given gain map property's double value(s), and if found, stores them in 'values'.
+// The 'values' array should have size at least 'numDoubles', and should be initialized with default
+// values for this property, since the array will be left untouched if the property is not found.
+// Returns AVIF_TRUE if the property was successfully parsed, or if it was not found, since all properties
+// are optional. Returns AVIF_FALSE in case of error (invalid metadata XMP).
+static avifBool avifJPEGFindGainMapPropertyDoubles(const xmlNode * descriptionNode, const char * propertyName, double * values, uint32_t numDoubles)
+{
+    assert(numDoubles <= GAIN_MAP_PROPERTY_MAX_VALUES);
+    const char * textValues[GAIN_MAP_PROPERTY_MAX_VALUES];
+    uint32_t numValues;
+    if (!avifJPEGFindGainMapProperty(descriptionNode, propertyName, /*maxValues=*/numDoubles, &textValues[0], &numValues)) {
+        return AVIF_TRUE; // Property was not found, but it's not an error since they're optional.
+    }
+    if (numValues != 1 && numValues != numDoubles) {
+        return AVIF_FALSE; // Invalid, we expect either 1 or exactly numDoubles values.
+    }
+    for (uint32_t i = 0; i < numDoubles; ++i) {
+        if (i >= numValues) {
+            // If there is only 1 value, it's copied into the rest of the array.
+            values[i] = values[i - 1];
+        } else {
+            int charsRead;
+            if (sscanf(textValues[i], "%lf%n", &values[i], &charsRead) < 1) {
+                return AVIF_FALSE; // Was not able to parse the full string value as a double.
+            }
+            // Make sure that remaining characters (if any) are only whitespace.
+            const int len = (int)strlen(textValues[i]);
+            while (charsRead < len) {
+                if (!isspace(textValues[i][charsRead])) {
+                    return AVIF_FALSE; // Invalid character.
+                }
+                ++charsRead;
+            }
+        }
+    }
+
+    return AVIF_TRUE;
+}
+
+static inline void SwapDoubles(double * x, double * y)
+{
+    double tmp = *x;
+    *x = *y;
+    *y = tmp;
+}
+
+// Parses gain map metadata from XMP.
+// See https://helpx.adobe.com/camera-raw/using/gain-map.html
+// Returns AVIF_TRUE if the gain map metadata was successfully read.
+static avifBool avifJPEGParseGainMapXMPProperties(const xmlNode * rootNode, avifGainMap * gainMap)
+{
+    const xmlNode * descNode = avifJPEGFindGainMapXMPNode(rootNode);
+    if (descNode == NULL) {
+        return AVIF_FALSE;
+    }
+
+    // Set default values from Adobe's spec.
+    double baseHdrHeadroom = 0.0;
+    double alternateHdrHeadroom = 1.0;
+    double gainMapMin[3] = { 0.0, 0.0, 0.0 };
+    double gainMapMax[3] = { 1.0, 1.0, 1.0 };
+    double gainMapGamma[3] = { 1.0, 1.0, 1.0 };
+    double baseOffset[3] = { 1.0 / 64.0, 1.0 / 64.0, 1.0 / 64.0 };
+    double alternateOffset[3] = { 1.0 / 64.0, 1.0 / 64.0, 1.0 / 64.0 };
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "HDRCapacityMin", &baseHdrHeadroom, /*numDoubles=*/1));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "HDRCapacityMax", &alternateHdrHeadroom, /*numDoubles=*/1));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "OffsetSDR", baseOffset, /*numDoubles=*/3));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "OffsetHDR", alternateOffset, /*numDoubles=*/3));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "GainMapMin", gainMapMin, /*numDoubles=*/3));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "GainMapMax", gainMapMax, /*numDoubles=*/3));
+    AVIF_CHECK(avifJPEGFindGainMapPropertyDoubles(descNode, "Gamma", gainMapGamma, /*numDoubles=*/3));
+
+    // See inequality requirements in section 'XMP Representation of Gain Map Metadata' of Adobe's gain map specification
+    // https://helpx.adobe.com/camera-raw/using/gain-map.html
+    AVIF_CHECK(alternateHdrHeadroom > baseHdrHeadroom);
+    AVIF_CHECK(baseHdrHeadroom >= 0);
+    for (int i = 0; i < 3; ++i) {
+        AVIF_CHECK(gainMapMax[i] >= gainMapMin[i]);
+        AVIF_CHECK(baseOffset[i] >= 0.0);
+        AVIF_CHECK(alternateOffset[i] >= 0.0);
+        AVIF_CHECK(gainMapGamma[i] > 0.0);
+    }
+
+    uint32_t numValues;
+    const char * baseRenditionIsHDR;
+    if (avifJPEGFindGainMapProperty(descNode, "BaseRenditionIsHDR", /*maxValues=*/1, &baseRenditionIsHDR, &numValues)) {
+        if (!strcmp(baseRenditionIsHDR, "True")) {
+            SwapDoubles(&baseHdrHeadroom, &alternateHdrHeadroom);
+            for (int c = 0; c < 3; ++c) {
+                SwapDoubles(&baseOffset[c], &alternateOffset[c]);
+            }
+        } else if (!strcmp(baseRenditionIsHDR, "False")) {
+        } else {
+            return AVIF_FALSE; // Unexpected value.
+        }
+    }
+
+    for (int i = 0; i < 3; ++i) {
+        AVIF_CHECK(avifDoubleToSignedFraction(gainMapMin[i], &gainMap->gainMapMin[i]));
+        AVIF_CHECK(avifDoubleToSignedFraction(gainMapMax[i], &gainMap->gainMapMax[i]));
+        AVIF_CHECK(avifDoubleToUnsignedFraction(gainMapGamma[i], &gainMap->gainMapGamma[i]));
+        AVIF_CHECK(avifDoubleToSignedFraction(baseOffset[i], &gainMap->baseOffset[i]));
+        AVIF_CHECK(avifDoubleToSignedFraction(alternateOffset[i], &gainMap->alternateOffset[i]));
+    }
+    AVIF_CHECK(avifDoubleToUnsignedFraction(baseHdrHeadroom, &gainMap->baseHdrHeadroom));
+    AVIF_CHECK(avifDoubleToUnsignedFraction(alternateHdrHeadroom, &gainMap->alternateHdrHeadroom));
+    // Not in Adobe's spec but both color spaces should be the same so this value doesn't matter.
+    gainMap->useBaseColorSpace = AVIF_TRUE;
+
+    return AVIF_TRUE;
+}
+
+// Parses gain map metadata from an XMP payload.
+// Returns AVIF_TRUE if the gain map metadata was successfully read.
+avifBool avifJPEGParseGainMapXMP(const uint8_t * xmpData, size_t xmpSize, avifGainMap * gainMap)
+{
+    xmlDoc * document = xmlReadMemory((const char *)xmpData, (int)xmpSize, NULL, NULL, LIBXML2_XML_PARSING_FLAGS);
+    if (document == NULL) {
+        return AVIF_FALSE; // Probably an out of memory error.
+    }
+    xmlNode * rootNode = xmlDocGetRootElement(document);
+    const avifBool res = avifJPEGParseGainMapXMPProperties(rootNode, gainMap);
+    xmlFreeDoc(document);
+    return res;
+}
+
+// Parses an MPF (Multi-Picture File) JPEG metadata segment to find the location of other
+// images, and decodes the gain map image (as determined by having gain map XMP metadata) into 'avif'.
+// See CIPA DC-007-Translation-2021 Multi-Picture Format at https://www.cipa.jp/e/std/std-sec.html
+// and https://helpx.adobe.com/camera-raw/using/gain-map.html in particular Figures 1 to 6.
+// Returns AVIF_FALSE if no gain map was found.
+static avifBool avifJPEGExtractGainMapImageFromMpf(FILE * f,
+                                                   uint32_t sizeLimit,
+                                                   const avifROData * segmentData,
+                                                   avifImage * avif,
+                                                   avifChromaDownsampling chromaDownsampling)
+{
+    uint32_t offset = 0;
+
+    const uint8_t littleEndian[4] = { 0x49, 0x49, 0x2A, 0x00 }; // "II*\0"
+    const uint8_t bigEndian[4] = { 0x4D, 0x4D, 0x00, 0x2A };    // "MM\0*"
+
+    uint8_t endiannessTag[4];
+    AVIF_CHECK(avifJPEGReadBytes(segmentData, endiannessTag, &offset, 4));
+
+    avifBool isBigEndian;
+    if (!memcmp(endiannessTag, bigEndian, 4)) {
+        isBigEndian = AVIF_TRUE;
+    } else if (!memcmp(endiannessTag, littleEndian, 4)) {
+        isBigEndian = AVIF_FALSE;
+    } else {
+        return AVIF_FALSE; // Invalid endianness tag.
+    }
+
+    uint32_t offsetToFirstIfd;
+    AVIF_CHECK(avifJPEGReadU32(segmentData, &offsetToFirstIfd, &offset, isBigEndian));
+    if (offsetToFirstIfd < offset) {
+        return AVIF_FALSE;
+    }
+    offset = offsetToFirstIfd;
+
+    // Read MP (Multi-Picture) tags.
+    uint16_t mpTagCount;
+    AVIF_CHECK(avifJPEGReadU16(segmentData, &mpTagCount, &offset, isBigEndian));
+
+    // See also https://www.media.mit.edu/pia/Research/deepview/exif.html
+    uint32_t numImages = 0;
+    uint32_t mpEntryOffset = 0;
+    for (int mpTagIdx = 0; mpTagIdx < mpTagCount; ++mpTagIdx) {
+        uint16_t tagId;
+        AVIF_CHECK(avifJPEGReadU16(segmentData, &tagId, &offset, isBigEndian));
+        offset += 2; // Skip data format.
+        offset += 4; // Skip num components.
+        uint8_t valueBytes[4];
+        AVIF_CHECK(avifJPEGReadBytes(segmentData, valueBytes, &offset, 4));
+        const uint32_t value = isBigEndian ? avifJPEGReadUint32BigEndian(valueBytes) : avifJPEGReadUint32LittleEndian(valueBytes);
+
+        switch (tagId) { // MPFVersion
+            case 45056:  // MPFVersion
+                if (memcmp(valueBytes, "0100", 4)) {
+                    // Unexpected version.
+                    return AVIF_FALSE;
+                }
+                break;
+            case 45057: // NumberOfImages
+                numImages = value;
+                break;
+            case 45058: // MPEntry
+                mpEntryOffset = value;
+                break;
+            case 45059: // ImageUIDList, unused
+            case 45060: // TotalFrames, unused
+            default:
+                break;
+        }
+    }
+    if (numImages < 2 || mpEntryOffset < offset) {
+        return AVIF_FALSE;
+    }
+    offset = mpEntryOffset;
+
+    uint32_t mpfSegmentOffset;
+    AVIF_CHECK(avifJPEGFindMpfSegmentOffset(f, &mpfSegmentOffset));
+
+    for (uint32_t imageIdx = 0; imageIdx < numImages; ++imageIdx) {
+        offset += 4; // Skip "Individual Image Attribute"
+        uint32_t imageSize;
+        AVIF_CHECK(avifJPEGReadU32(segmentData, &imageSize, &offset, isBigEndian));
+        uint32_t imageDataOffset;
+        AVIF_CHECK(avifJPEGReadU32(segmentData, &imageDataOffset, &offset, isBigEndian));
+
+        offset += 4; // Skip "Dependent image Entry Number" (2 + 2 bytes)
+        if (imageDataOffset == 0) {
+            // 0 is a special value which indicates the first image.
+            // Assume the first image cannot be the gain map and skip it.
+            continue;
+        }
+
+        // Offsets are relative to the start of the MPF segment. Make them absolute.
+        imageDataOffset += mpfSegmentOffset;
+        if (fseek(f, imageDataOffset, SEEK_SET) != 0) {
+            return AVIF_FALSE;
+        }
+        // Read the image and check its XMP to see if it's a gain map.
+        // NOTE we decode all additional images until a gain map is found, even if some might not
+        // be gain maps. This could be fixed by having a helper function to get just the XMP without
+        // decoding the whole image.
+        if (!avifJPEGReadInternal(f,
+                                  "gain map",
+                                  avif,
+                                  /*requestedFormat=*/AVIF_PIXEL_FORMAT_NONE, // automatic
+                                  /*requestedDepth=*/0,                       // automatic
+                                  chromaDownsampling,
+                                  /*ignoreColorProfile=*/AVIF_TRUE,
+                                  /*ignoreExif=*/AVIF_TRUE,
+                                  /*ignoreXMP=*/AVIF_FALSE,
+                                  /*ignoreGainMap=*/AVIF_TRUE,
+                                  sizeLimit)) {
+            continue;
+        }
+        if (avifJPEGHasGainMapXMPNode(avif->xmp.data, avif->xmp.size)) {
+            return AVIF_TRUE;
+        }
+    }
+
+    return AVIF_FALSE;
+}
+
+// Tries to find and decode a gain map image and its metadata.
+// Looks for an MPF (Multi-Picture Format) segment then loops through the linked images to see
+// if one of them has gain map XMP metadata.
+// See CIPA DC-007-Translation-2021 Multi-Picture Format at https://www.cipa.jp/e/std/std-sec.html
+// and https://helpx.adobe.com/camera-raw/using/gain-map.html
+// Returns AVIF_TRUE if a gain map was found.
+static avifBool avifJPEGExtractGainMapImage(FILE * f,
+                                            uint32_t sizeLimit,
+                                            struct jpeg_decompress_struct * cinfo,
+                                            avifGainMap * gainMap,
+                                            avifChromaDownsampling chromaDownsampling)
+{
+    const avifROData tagMpf = { (const uint8_t *)AVIF_JPEG_MPF_HEADER, AVIF_JPEG_MPF_HEADER_LENGTH };
+    for (jpeg_saved_marker_ptr marker = cinfo->marker_list; marker != NULL; marker = marker->next) {
+        // Note we assume there is only one MPF segment and only look at the first one.
+        // Otherwise avifJPEGFindMpfSegmentOffset() would have to be modified to take the index of the
+        // MPF segment whose offset to return.
+        if ((marker->marker == (JPEG_APP0 + 2)) && (marker->data_length > tagMpf.size) &&
+            !memcmp(marker->data, tagMpf.data, tagMpf.size)) {
+            avifImage * image = avifImageCreateEmpty();
+            // Set jpeg native matrix coefficients to allow copying YUV values directly.
+            image->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;
+            assert(avifJPEGHasCompatibleMatrixCoefficients(image->matrixCoefficients));
+
+            const avifROData mpfData = { (const uint8_t *)marker->data + tagMpf.size, marker->data_length - tagMpf.size };
+            if (!avifJPEGExtractGainMapImageFromMpf(f, sizeLimit, &mpfData, image, chromaDownsampling)) {
+                fprintf(stderr, "Note: XMP metadata indicated the presence of a gain map, but it could not be found or decoded\n");
+                avifImageDestroy(image);
+                return AVIF_FALSE;
+            }
+            if (!avifJPEGParseGainMapXMP(image->xmp.data, image->xmp.size, gainMap)) {
+                fprintf(stderr, "Warning: failed to parse gain map metadata\n");
+                avifImageDestroy(image);
+                return AVIF_FALSE;
+            }
+
+            gainMap->image = image;
+            return AVIF_TRUE;
+        }
+    }
+    return AVIF_FALSE;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION
+
+// Note on setjmp() and volatile variables:
+//
+// K & R, The C Programming Language 2nd Ed, p. 254 says:
+//   ... Accessible objects have the values they had when longjmp was called,
+//   except that non-volatile automatic variables in the function calling setjmp
+//   become undefined if they were changed after the setjmp call.
+//
+// Therefore, 'iccData' is declared as volatile. 'rgb' should be declared as
+// volatile, but doing so would be inconvenient (try it) and since it is a
+// struct, the compiler is unlikely to put it in a register. 'ret' does not need
+// to be declared as volatile because it is not modified between setjmp and
+// longjmp. But GCC's -Wclobbered warning may have trouble figuring that out, so
+// we preemptively declare it as volatile.
+
+static avifBool avifJPEGReadInternal(FILE * f,
+                                     const char * inputFilename,
+                                     avifImage * avif,
+                                     avifPixelFormat requestedFormat,
+                                     uint32_t requestedDepth,
+                                     avifChromaDownsampling chromaDownsampling,
+                                     avifBool ignoreColorProfile,
+                                     avifBool ignoreExif,
+                                     avifBool ignoreXMP,
+                                     avifBool ignoreGainMap,
+                                     uint32_t sizeLimit)
+{
+    volatile avifBool ret = AVIF_FALSE;
+    uint8_t * volatile iccData = NULL;
+
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(avifRGBImage));
+
+    // Standard XMP segment followed by all extended XMP segments.
+    avifRWData totalXMP = { NULL, 0 };
+    // Each byte set to 0 is a missing byte. Each byte set to 1 was read and copied to totalXMP.
+    avifRWData extendedXMPReadBytes = { NULL, 0 };
+
+    struct my_error_mgr jerr;
+    struct jpeg_decompress_struct cinfo;
+    cinfo.err = jpeg_std_error(&jerr.pub);
+    jerr.pub.error_exit = my_error_exit;
+    if (setjmp(jerr.setjmp_buffer)) {
+        goto cleanup;
+    }
+
+    jpeg_create_decompress(&cinfo);
+
+    // See also https://exiftool.org/TagNames/JPEG.html for the meaning of various APP<n> segments.
+    if (!ignoreExif || !ignoreXMP || !ignoreGainMap) {
+        // Keep APP1 blocks, for Exif and XMP.
+        jpeg_save_markers(&cinfo, JPEG_APP0 + 1, /*length_limit=*/0xFFFF);
+    }
+    if (!ignoreGainMap) {
+        // Keep APP2 blocks, for obtaining ICC and MPF data.
+        jpeg_save_markers(&cinfo, JPEG_APP0 + 2, /*length_limit=*/0xFFFF);
+    }
+
+    if (!ignoreColorProfile) {
+        setup_read_icc_profile(&cinfo);
+    }
+    jpeg_stdio_src(&cinfo, f);
+    jpeg_read_header(&cinfo, TRUE);
+
+    jpeg_calc_output_dimensions(&cinfo);
+    if (cinfo.output_width > sizeLimit / cinfo.output_height) {
+        fprintf(stderr, "Too big JPEG dimensions (%u x %u > %u px): %s\n", cinfo.output_width, cinfo.output_height, sizeLimit, inputFilename);
+        goto cleanup;
+    }
+
+    if (!ignoreColorProfile) {
+        uint8_t * iccDataTmp;
+        unsigned int iccDataLen;
+        if (read_icc_profile(&cinfo, &iccDataTmp, &iccDataLen)) {
+            iccData = iccDataTmp;
+            if (avifImageSetProfileICC(avif, iccDataTmp, (size_t)iccDataLen) != AVIF_RESULT_OK) {
+                fprintf(stderr, "Setting ICC profile failed: %s (out of memory)\n", inputFilename);
+                goto cleanup;
+            }
+        }
+    }
+
+    avif->yuvFormat = requestedFormat; // This may be AVIF_PIXEL_FORMAT_NONE, which is "auto" to avifJPEGReadCopy()
+    avif->depth = requestedDepth ? requestedDepth : 8;
+    // JPEG doesn't have alpha. Prevent confusion.
+    avif->alphaPremultiplied = AVIF_FALSE;
+
+    if (avifJPEGReadCopy(avif, sizeLimit, &cinfo)) {
+        // JPEG pixels were successfully copied without conversion. Notify the enduser.
+
+        assert(inputFilename); // JPEG read doesn't support stdin
+        printf("Directly copied JPEG pixel data (no YUV conversion): %s\n", inputFilename);
+    } else {
+        // JPEG pixels could not be copied without conversion. Request (converted) RGB pixels from
+        // libjpeg and convert to YUV with libavif instead.
+
+        cinfo.out_color_space = JCS_RGB;
+        jpeg_start_decompress(&cinfo);
+
+        int row_stride = cinfo.output_width * cinfo.output_components;
+        JSAMPARRAY buffer = (*cinfo.mem->alloc_sarray)((j_common_ptr)&cinfo, JPOOL_IMAGE, row_stride, 1);
+
+        avif->width = cinfo.output_width;
+        avif->height = cinfo.output_height;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+        const avifBool useYCgCoR = (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE ||
+                                    avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO);
+#endif
+        if (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE) {
+            // Identity and YCgCo-R are only valid with YUV444.
+            avif->yuvFormat = (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                               || useYCgCoR
+#endif
+                               )
+                                  ? AVIF_PIXEL_FORMAT_YUV444
+                                  : AVIF_APP_DEFAULT_PIXEL_FORMAT;
+        }
+        avif->depth = requestedDepth ? requestedDepth : 8;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+        if (useYCgCoR) {
+            if (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO) {
+                fprintf(stderr, "AVIF_MATRIX_COEFFICIENTS_YCGCO_RO cannot be used with JPEG because it has an even bit depth.\n");
+                goto cleanup;
+            }
+            if (requestedDepth && requestedDepth != 10) {
+                fprintf(stderr, "Cannot request %u bits for YCgCo-Re as it uses 2 extra bits.\n", requestedDepth);
+                goto cleanup;
+            }
+            avif->depth = 10;
+        }
+#endif
+        avifRGBImageSetDefaults(&rgb, avif);
+        rgb.format = AVIF_RGB_FORMAT_RGB;
+        rgb.chromaDownsampling = chromaDownsampling;
+        rgb.depth = 8;
+        if (avifRGBImageAllocatePixels(&rgb) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion to YUV failed: %s (out of memory)\n", inputFilename);
+            goto cleanup;
+        }
+
+        int row = 0;
+        while (cinfo.output_scanline < cinfo.output_height) {
+            jpeg_read_scanlines(&cinfo, buffer, 1);
+            uint8_t * pixelRow = &rgb.pixels[row * rgb.rowBytes];
+            memcpy(pixelRow, buffer[0], rgb.rowBytes);
+            ++row;
+        }
+        if (avifImageRGBToYUV(avif, &rgb) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion to YUV failed: %s\n", inputFilename);
+            goto cleanup;
+        }
+    }
+
+    if (!ignoreExif) {
+        avifBool found = AVIF_FALSE;
+        for (jpeg_saved_marker_ptr marker = cinfo.marker_list; marker != NULL; marker = marker->next) {
+            if ((marker->marker == (JPEG_APP0 + 1)) && (marker->data_length > AVIF_JPEG_EXIF_HEADER_LENGTH) &&
+                !memcmp(marker->data, AVIF_JPEG_EXIF_HEADER, AVIF_JPEG_EXIF_HEADER_LENGTH)) {
+                if (found) {
+                    // TODO(yguyon): Implement instead of outputting an error.
+                    fprintf(stderr, "Exif extraction failed: unsupported Exif split into multiple segments or invalid multiple Exif segments\n");
+                    goto cleanup;
+                }
+
+                if (marker->data_length - AVIF_JPEG_EXIF_HEADER_LENGTH > sizeLimit) {
+                    fprintf(stderr,
+                            "Setting Exif metadata failed: Exif size is too large (%u > %u bytes): %s\n",
+                            marker->data_length - AVIF_JPEG_EXIF_HEADER_LENGTH,
+                            sizeLimit,
+                            inputFilename);
+                    goto cleanup;
+                }
+
+                // Exif orientation, if any, is imported to avif->irot/imir and kept in avif->exif.
+                // libheif has the same behavior, see
+                // https://github.com/strukturag/libheif/blob/ea78603d8e47096606813d221725621306789ff2/examples/heif_enc.cc#L403
+                if (avifImageSetMetadataExif(avif,
+                                             marker->data + AVIF_JPEG_EXIF_HEADER_LENGTH,
+                                             marker->data_length - AVIF_JPEG_EXIF_HEADER_LENGTH) != AVIF_RESULT_OK) {
+                    fprintf(stderr, "Setting Exif metadata failed: %s (out of memory)\n", inputFilename);
+                    goto cleanup;
+                }
+                found = AVIF_TRUE;
+            }
+        }
+    }
+
+    avifBool readXMP = !ignoreXMP;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    readXMP = readXMP || !ignoreGainMap; // Gain map metadata is in XMP.
+#endif
+    if (readXMP) {
+        const uint8_t * standardXMPData = NULL;
+        uint32_t standardXMPSize = 0; // At most 64kB as defined by Adobe XMP Specification Part 3.
+        for (jpeg_saved_marker_ptr marker = cinfo.marker_list; marker != NULL; marker = marker->next) {
+            if ((marker->marker == (JPEG_APP0 + 1)) && (marker->data_length > AVIF_JPEG_STANDARD_XMP_TAG_LENGTH) &&
+                !memcmp(marker->data, AVIF_JPEG_STANDARD_XMP_TAG, AVIF_JPEG_STANDARD_XMP_TAG_LENGTH)) {
+                if (standardXMPData) {
+                    fprintf(stderr, "XMP extraction failed: invalid multiple standard XMP segments\n");
+                    goto cleanup;
+                }
+                standardXMPData = marker->data + AVIF_JPEG_STANDARD_XMP_TAG_LENGTH;
+                standardXMPSize = (uint32_t)(marker->data_length - AVIF_JPEG_STANDARD_XMP_TAG_LENGTH);
+            }
+        }
+
+        avifBool foundExtendedXMP = AVIF_FALSE;
+        uint8_t extendedXMPGUID[AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH]; // The value is common to all extended XMP segments.
+        for (jpeg_saved_marker_ptr marker = cinfo.marker_list; marker != NULL; marker = marker->next) {
+            if ((marker->marker == (JPEG_APP0 + 1)) && (marker->data_length > AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH) &&
+                !memcmp(marker->data, AVIF_JPEG_EXTENDED_XMP_TAG, AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH)) {
+                if (!standardXMPData) {
+                    fprintf(stderr, "XMP extraction failed: extended XMP segment found, missing standard XMP segment\n");
+                    goto cleanup;
+                }
+
+                if (marker->data_length < AVIF_JPEG_OFFSET_TILL_EXTENDED_XMP) {
+                    fprintf(stderr, "XMP extraction failed: truncated extended XMP segment\n");
+                    goto cleanup;
+                }
+                const uint8_t * guid = &marker->data[AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH];
+                for (size_t c = 0; c < AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH; ++c) {
+                    // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+                    //   "128-bit GUID stored as a 32-byte ASCII hex string, capital A-F, no null termination"
+                    if (((guid[c] < '0') || (guid[c] > '9')) && ((guid[c] < 'A') || (guid[c] > 'F'))) {
+                        fprintf(stderr, "XMP extraction failed: invalid XMP segment GUID\n");
+                        goto cleanup;
+                    }
+                }
+                // Size of the current extended segment.
+                const size_t extendedXMPSize = marker->data_length - AVIF_JPEG_OFFSET_TILL_EXTENDED_XMP;
+                // Expected size of the sum of all extended segments.
+                // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+                //   "full length of the ExtendedXMP serialization as a 32-bit unsigned integer"
+                const uint32_t totalExtendedXMPSize =
+                    avifJPEGReadUint32BigEndian(&marker->data[AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH + AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH]);
+                // Offset in totalXMP after standardXMP.
+                // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+                //   "offset of this portion as a 32-bit unsigned integer"
+                const uint32_t extendedXMPOffset = avifJPEGReadUint32BigEndian(
+                    &marker->data[AVIF_JPEG_EXTENDED_XMP_TAG_LENGTH + AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH + 4]);
+                if (((uint64_t)standardXMPSize + totalExtendedXMPSize) > SIZE_MAX ||
+                    ((uint64_t)standardXMPSize + totalExtendedXMPSize) > sizeLimit) {
+                    fprintf(stderr,
+                            "XMP extraction failed: total XMP size is too large (%u + %u > %u bytes): %s\n",
+                            standardXMPSize,
+                            totalExtendedXMPSize,
+                            sizeLimit,
+                            inputFilename);
+                    goto cleanup;
+                }
+                if ((extendedXMPSize == 0) || (((uint64_t)extendedXMPOffset + extendedXMPSize) > totalExtendedXMPSize)) {
+                    fprintf(stderr, "XMP extraction failed: invalid extended XMP segment size or offset\n");
+                    goto cleanup;
+                }
+                if (foundExtendedXMP) {
+                    if (memcmp(guid, extendedXMPGUID, AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH)) {
+                        fprintf(stderr, "XMP extraction failed: extended XMP segment GUID mismatch\n");
+                        goto cleanup;
+                    }
+                    if (totalExtendedXMPSize != (totalXMP.size - standardXMPSize)) {
+                        fprintf(stderr, "XMP extraction failed: extended XMP total size mismatch\n");
+                        goto cleanup;
+                    }
+                } else {
+                    memcpy(extendedXMPGUID, guid, AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH);
+
+                    if (avifRWDataRealloc(&totalXMP, (size_t)standardXMPSize + totalExtendedXMPSize) != AVIF_RESULT_OK) {
+                        fprintf(stderr, "XMP extraction failed: out of memory\n");
+                        goto cleanup;
+                    }
+                    memcpy(totalXMP.data, standardXMPData, standardXMPSize);
+
+                    // Keep track of the bytes that were set.
+                    if (avifRWDataRealloc(&extendedXMPReadBytes, totalExtendedXMPSize) != AVIF_RESULT_OK) {
+                        fprintf(stderr, "XMP extraction failed: out of memory\n");
+                        goto cleanup;
+                    }
+                    memset(extendedXMPReadBytes.data, 0, extendedXMPReadBytes.size);
+
+                    foundExtendedXMP = AVIF_TRUE;
+                }
+                // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+                //   "A robust JPEG reader should tolerate the marker segments in any order."
+                memcpy(&totalXMP.data[standardXMPSize + extendedXMPOffset], &marker->data[AVIF_JPEG_OFFSET_TILL_EXTENDED_XMP], extendedXMPSize);
+
+                // Make sure no previously read data was overwritten by the current segment.
+                if (memchr(&extendedXMPReadBytes.data[extendedXMPOffset], 1, extendedXMPSize)) {
+                    fprintf(stderr, "XMP extraction failed: overlapping extended XMP segments\n");
+                    goto cleanup;
+                }
+                // Keep track of the bytes that were set.
+                memset(&extendedXMPReadBytes.data[extendedXMPOffset], 1, extendedXMPSize);
+            }
+        }
+
+        if (foundExtendedXMP) {
+            // Make sure there is no missing byte.
+            if (memchr(extendedXMPReadBytes.data, 0, extendedXMPReadBytes.size)) {
+                fprintf(stderr, "XMP extraction failed: missing extended XMP segments\n");
+                goto cleanup;
+            }
+
+            // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+            //   "A reader must incorporate only ExtendedXMP blocks whose GUID matches the value of xmpNote:HasExtendedXMP."
+            uint8_t xmpNote[AVIF_JPEG_XMP_NOTE_TAG_LENGTH + AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH];
+            memcpy(xmpNote, AVIF_JPEG_XMP_NOTE_TAG, AVIF_JPEG_XMP_NOTE_TAG_LENGTH);
+            memcpy(xmpNote + AVIF_JPEG_XMP_NOTE_TAG_LENGTH, extendedXMPGUID, AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH);
+            if (!avifJPEGFindSubstr(standardXMPData, standardXMPSize, xmpNote, sizeof(xmpNote))) {
+                // Try the alternative before returning an error.
+                uint8_t alternativeXmpNote[AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG_LENGTH + AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH];
+                memcpy(alternativeXmpNote, AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG, AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG_LENGTH);
+                memcpy(alternativeXmpNote + AVIF_JPEG_ALTERNATIVE_XMP_NOTE_TAG_LENGTH, extendedXMPGUID, AVIF_JPEG_EXTENDED_XMP_GUID_LENGTH);
+                if (!avifJPEGFindSubstr(standardXMPData, standardXMPSize, alternativeXmpNote, sizeof(alternativeXmpNote))) {
+                    fprintf(stderr, "XMP extraction failed: standard and extended XMP GUID mismatch\n");
+                    goto cleanup;
+                }
+            }
+
+            // According to Adobe XMP Specification Part 3 section 1.1.3.1:
+            //   "A JPEG reader must [...] remove the xmpNote:HasExtendedXMP property."
+            // This constraint is ignored here because leaving the xmpNote:HasExtendedXMP property is rather harmless
+            // and editing XMP metadata is quite involved.
+
+            avifRWDataFree(&avif->xmp);
+            avif->xmp = totalXMP;
+            totalXMP.data = NULL;
+            totalXMP.size = 0;
+        } else if (standardXMPData) {
+            if (avifImageSetMetadataXMP(avif, standardXMPData, standardXMPSize) != AVIF_RESULT_OK) {
+                fprintf(stderr, "XMP extraction failed: out of memory\n");
+                goto cleanup;
+            }
+        }
+        avifImageFixXMP(avif); // Remove one trailing null character if any.
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+    // The primary XMP block (for the main image) must contain a node with an hdrgm:Version field if and only if a gain map is present.
+    if (!ignoreGainMap && avifJPEGHasGainMapXMPNode(avif->xmp.data, avif->xmp.size)) {
+        avifGainMap * gainMap = avifGainMapCreate();
+        if (gainMap == NULL) {
+            fprintf(stderr, "Creating gain map failed: out of memory\n");
+            goto cleanup;
+        }
+        // Ignore the return value: continue even if we fail to find/parse/decode the gain map.
+        if (avifJPEGExtractGainMapImage(f, sizeLimit, &cinfo, gainMap, chromaDownsampling)) {
+            // Since jpeg doesn't provide this metadata, assume the values are the same as the base image
+            // with a PQ transfer curve.
+            gainMap->altColorPrimaries = avif->colorPrimaries;
+            gainMap->altTransferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_PQ;
+            gainMap->altMatrixCoefficients = avif->matrixCoefficients;
+            gainMap->altDepth = 8;
+            gainMap->altPlaneCount =
+                (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400 && gainMap->image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+            if (avif->icc.size > 0) {
+                // The base image's ICC should also apply to the alternage image.
+                if (avifRWDataSet(&gainMap->altICC, avif->icc.data, avif->icc.size) != AVIF_RESULT_OK) {
+                    fprintf(stderr, "Setting gain map ICC profile failed: out of memory\n");
+                    goto cleanup;
+                }
+            }
+            avif->gainMap = gainMap;
+        } else {
+            avifGainMapDestroy(gainMap);
+        }
+    }
+
+    if (avif->xmp.size > 0 && ignoreXMP) {
+        // Clear XMP in case we read it for something else (like gain map).
+        if (avifImageSetMetadataXMP(avif, NULL, 0) != AVIF_RESULT_OK) {
+            assert(AVIF_FALSE);
+        }
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION
+    jpeg_finish_decompress(&cinfo);
+    ret = AVIF_TRUE;
+cleanup:
+    jpeg_destroy_decompress(&cinfo);
+    free(iccData);
+    avifRGBImageFreePixels(&rgb);
+    avifRWDataFree(&totalXMP);
+    avifRWDataFree(&extendedXMPReadBytes);
+    return ret;
+}
+
+avifBool avifJPEGRead(const char * inputFilename,
+                      avifImage * avif,
+                      avifPixelFormat requestedFormat,
+                      uint32_t requestedDepth,
+                      avifChromaDownsampling chromaDownsampling,
+                      avifBool ignoreColorProfile,
+                      avifBool ignoreExif,
+                      avifBool ignoreXMP,
+                      avifBool ignoreGainMap,
+                      uint32_t sizeLimit)
+{
+    FILE * f = fopen(inputFilename, "rb");
+    if (!f) {
+        fprintf(stderr, "Can't open JPEG file for read: %s\n", inputFilename);
+        return AVIF_FALSE;
+    }
+    const avifBool res = avifJPEGReadInternal(f,
+                                              inputFilename,
+                                              avif,
+                                              requestedFormat,
+                                              requestedDepth,
+                                              chromaDownsampling,
+                                              ignoreColorProfile,
+                                              ignoreExif,
+                                              ignoreXMP,
+                                              ignoreGainMap,
+                                              sizeLimit);
+    fclose(f);
+    return res;
+}
+
+avifBool avifJPEGWrite(const char * outputFilename, const avifImage * avif, int jpegQuality, avifChromaUpsampling chromaUpsampling)
+{
+    avifBool ret = AVIF_FALSE;
+    FILE * f = NULL;
+
+    struct jpeg_compress_struct cinfo;
+    struct jpeg_error_mgr jerr;
+    JSAMPROW row_pointer[1];
+    cinfo.err = jpeg_std_error(&jerr);
+    jpeg_create_compress(&cinfo);
+
+    avifRGBImage rgb;
+    avifRGBImageSetDefaults(&rgb, avif);
+    rgb.format = AVIF_RGB_FORMAT_RGB;
+    rgb.chromaUpsampling = chromaUpsampling;
+    rgb.depth = 8;
+    if (avifRGBImageAllocatePixels(&rgb) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Conversion to RGB failed: %s (out of memory)\n", outputFilename);
+        goto cleanup;
+    }
+    if (avifImageYUVToRGB(avif, &rgb) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Conversion to RGB failed: %s\n", outputFilename);
+        goto cleanup;
+    }
+
+    f = fopen(outputFilename, "wb");
+    if (!f) {
+        fprintf(stderr, "Can't open JPEG file for write: %s\n", outputFilename);
+        goto cleanup;
+    }
+
+    jpeg_stdio_dest(&cinfo, f);
+    cinfo.image_width = avif->width;
+    cinfo.image_height = avif->height;
+    cinfo.input_components = 3;
+    cinfo.in_color_space = JCS_RGB;
+    jpeg_set_defaults(&cinfo);
+    jpeg_set_quality(&cinfo, jpegQuality, TRUE);
+    jpeg_start_compress(&cinfo, TRUE);
+
+    if (avif->icc.data && (avif->icc.size > 0)) {
+        // TODO(yguyon): Use jpeg_write_icc_profile() instead?
+        write_icc_profile(&cinfo, avif->icc.data, (unsigned int)avif->icc.size);
+    }
+
+    if (avif->exif.data && (avif->exif.size > 0)) {
+        size_t exifTiffHeaderOffset;
+        avifResult result = avifGetExifTiffHeaderOffset(avif->exif.data, avif->exif.size, &exifTiffHeaderOffset);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Error writing JPEG metadata: %s\n", avifResultToString(result));
+            goto cleanup;
+        }
+
+        avifRWData exif = { NULL, 0 };
+        if (avifRWDataRealloc(&exif, AVIF_JPEG_EXIF_HEADER_LENGTH + avif->exif.size - exifTiffHeaderOffset) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Error writing JPEG metadata: out of memory\n");
+            goto cleanup;
+        }
+        memcpy(exif.data, AVIF_JPEG_EXIF_HEADER, AVIF_JPEG_EXIF_HEADER_LENGTH);
+        memcpy(exif.data + AVIF_JPEG_EXIF_HEADER_LENGTH, avif->exif.data + exifTiffHeaderOffset, avif->exif.size - exifTiffHeaderOffset);
+        // Make sure the Exif orientation matches the irot/imir values.
+        // libheif does not have the same behavior. The orientation is applied to samples and orientation data is discarded there,
+        // see https://github.com/strukturag/libheif/blob/ea78603d8e47096606813d221725621306789ff2/examples/encoder_jpeg.cc#L187
+        const uint8_t orientation = avifImageGetExifOrientationFromIrotImir(avif);
+        result = avifSetExifOrientation(&exif, orientation);
+        if (result != AVIF_RESULT_OK) {
+            // Ignore errors if the orientation is the default one because not being able to set Exif orientation now
+            // means a reader will not be able to parse it later either.
+            if (orientation != 1) {
+                fprintf(stderr, "Error writing JPEG metadata: %s\n", avifResultToString(result));
+                avifRWDataFree(&exif);
+                goto cleanup;
+            }
+        }
+
+        avifROData remainingExif = { exif.data, exif.size };
+        while (remainingExif.size > AVIF_JPEG_MAX_MARKER_DATA_LENGTH) {
+            jpeg_write_marker(&cinfo, JPEG_APP0 + 1, remainingExif.data, AVIF_JPEG_MAX_MARKER_DATA_LENGTH);
+            remainingExif.data += AVIF_JPEG_MAX_MARKER_DATA_LENGTH;
+            remainingExif.size -= AVIF_JPEG_MAX_MARKER_DATA_LENGTH;
+        }
+        jpeg_write_marker(&cinfo, JPEG_APP0 + 1, remainingExif.data, (unsigned int)remainingExif.size);
+        avifRWDataFree(&exif);
+    } else if (avifImageGetExifOrientationFromIrotImir(avif) != 1) {
+        // There is no Exif yet, but we need to store the orientation.
+        // TODO(yguyon): Add a valid Exif payload or rotate the samples.
+    }
+
+    if (avif->xmp.data && (avif->xmp.size > 0)) {
+        // See XMP specification part 3.
+        if (avif->xmp.size > 65502) {
+            // libheif just refuses to export JPEG with long XMP, see
+            // https://github.com/strukturag/libheif/blob/18291ddebc23c924440a8a3c9a7267fe3beb5901/examples/encoder_jpeg.cc#L227
+            // But libheif also ignores extended XMP at reading, so converting a JPEG with extended XMP to HEIC and back to JPEG
+            // works, with the extended XMP part dropped, even if it had fit into a single JPEG marker.
+
+            // In libavif the whole XMP payload is dropped if it exceeds a single JPEG marker size limit, with a warning.
+            // The advantage is that it keeps the whole XMP payload, including the extended part, if it fits into a single JPEG
+            // marker. This is acceptable because section 1.1.3.1 of XMP specification part 3 says
+            //   "It is unusual for XMP to exceed 65502 bytes; typically, it is around 2 KB."
+            fprintf(stderr, "Warning writing JPEG metadata: XMP payload is too big and was dropped\n");
+        } else {
+            avifRWData xmp = { NULL, 0 };
+            if (avifRWDataRealloc(&xmp, AVIF_JPEG_STANDARD_XMP_TAG_LENGTH + avif->xmp.size) != AVIF_RESULT_OK) {
+                fprintf(stderr, "Error writing JPEG metadata: out of memory\n");
+                goto cleanup;
+            }
+            memcpy(xmp.data, AVIF_JPEG_STANDARD_XMP_TAG, AVIF_JPEG_STANDARD_XMP_TAG_LENGTH);
+            memcpy(xmp.data + AVIF_JPEG_STANDARD_XMP_TAG_LENGTH, avif->xmp.data, avif->xmp.size);
+            jpeg_write_marker(&cinfo, JPEG_APP0 + 1, xmp.data, (unsigned int)xmp.size);
+            avifRWDataFree(&xmp);
+        }
+    }
+
+    while (cinfo.next_scanline < cinfo.image_height) {
+        row_pointer[0] = &rgb.pixels[cinfo.next_scanline * rgb.rowBytes];
+        (void)jpeg_write_scanlines(&cinfo, row_pointer, 1);
+    }
+
+    jpeg_finish_compress(&cinfo);
+    ret = AVIF_TRUE;
+    printf("Wrote JPEG: %s\n", outputFilename);
+cleanup:
+    if (f) {
+        fclose(f);
+    }
+    jpeg_destroy_compress(&cinfo);
+    avifRGBImageFreePixels(&rgb);
+    return ret;
+}
diff --git a/third_party/libavif/src/apps/shared/avifjpeg.h b/third_party/libavif/src/apps/shared/avifjpeg.h
new file mode 100644
index 0000000000..ad2a3f0c97
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifjpeg.h
@@ -0,0 +1,41 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_AVIFJPEG_H
+#define LIBAVIF_APPS_SHARED_AVIFJPEG_H
+
+#include "avif/avif.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Decodes the jpeg file at path 'inputFilename' into 'avif'.
+// At most sizeLimit pixels will be read or an error returned. At most sizeLimit
+// bytes of Exif or XMP metadata will be read or an error returned.
+// 'ignoreGainMap' is only relevant for jpeg files that have a gain map
+// and only if AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION is ON
+// (requires AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP and libxml2). Otherwise
+// it has no effect.
+avifBool avifJPEGRead(const char * inputFilename,
+                      avifImage * avif,
+                      avifPixelFormat requestedFormat,
+                      uint32_t requestedDepth,
+                      avifChromaDownsampling chromaDownsampling,
+                      avifBool ignoreColorProfile,
+                      avifBool ignoreExif,
+                      avifBool ignoreXMP,
+                      avifBool ignoreGainMap,
+                      uint32_t sizeLimit);
+avifBool avifJPEGWrite(const char * outputFilename, const avifImage * avif, int jpegQuality, avifChromaUpsampling chromaUpsampling);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION)
+// Parses XMP gain map metadata. Visible for testing.
+avifBool avifJPEGParseGainMapXMP(const uint8_t * xmpData, size_t xmpSize, avifGainMap * gainMap);
+#endif
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef LIBAVIF_APPS_SHARED_AVIFJPEG_H
diff --git a/third_party/libavif/src/apps/shared/avifpng.c b/third_party/libavif/src/apps/shared/avifpng.c
new file mode 100644
index 0000000000..c2f8a478d6
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifpng.c
@@ -0,0 +1,756 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avifpng.h"
+#include "avifexif.h"
+#include "avifutil.h"
+#include "iccmaker.h"
+
+#include "png.h"
+
+#include <ctype.h>
+#include <limits.h>
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#if !defined(PNG_eXIf_SUPPORTED) || !defined(PNG_iTXt_SUPPORTED)
+#error "libpng 1.6.32 or above with PNG_eXIf_SUPPORTED and PNG_iTXt_SUPPORTED is required."
+#endif
+
+//------------------------------------------------------------------------------
+// Reading
+
+// Converts a hexadecimal string which contains 2-byte character representations of hexadecimal values to raw data (bytes).
+// hexString may contain values consisting of [A-F][a-f][0-9] in pairs, e.g., 7af2..., separated by any number of newlines.
+// On success the bytes are filled and AVIF_TRUE is returned.
+// AVIF_FALSE is returned if fewer than numExpectedBytes hexadecimal pairs are converted.
+static avifBool avifHexStringToBytes(const char * hexString, size_t hexStringLength, size_t numExpectedBytes, avifRWData * bytes)
+{
+    if (avifRWDataRealloc(bytes, numExpectedBytes) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Metadata extraction failed: out of memory\n");
+        return AVIF_FALSE;
+    }
+    size_t numBytes = 0;
+    for (size_t i = 0; (i + 1 < hexStringLength) && (numBytes < numExpectedBytes);) {
+        if (hexString[i] == '\n') {
+            ++i;
+            continue;
+        }
+        if (!isxdigit(hexString[i]) || !isxdigit(hexString[i + 1])) {
+            avifRWDataFree(bytes);
+            fprintf(stderr, "Metadata extraction failed: invalid character at %" AVIF_FMT_ZU "\n", i);
+            return AVIF_FALSE;
+        }
+        const char twoHexDigits[] = { hexString[i], hexString[i + 1], '\0' };
+        bytes->data[numBytes] = (uint8_t)strtol(twoHexDigits, NULL, 16);
+        ++numBytes;
+        i += 2;
+    }
+
+    if (numBytes != numExpectedBytes) {
+        avifRWDataFree(bytes);
+        fprintf(stderr, "Metadata extraction failed: expected %" AVIF_FMT_ZU " tokens but got %" AVIF_FMT_ZU "\n", numExpectedBytes, numBytes);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+// Parses the raw profile string of profileLength characters and extracts the payload.
+static avifBool avifCopyRawProfile(const char * profile, size_t profileLength, avifRWData * payload)
+{
+    // ImageMagick formats 'raw profiles' as "\n<name>\n<length>(%8lu)\n<hex payload>\n".
+    if (!profile || (profileLength == 0) || (profile[0] != '\n')) {
+        fprintf(stderr, "Metadata extraction failed: truncated or malformed raw profile\n");
+        return AVIF_FALSE;
+    }
+
+    const char * lengthStart = NULL;
+    for (size_t i = 1; i < profileLength; ++i) { // i starts at 1 because the first '\n' was already checked above.
+        if (profile[i] == '\0') {
+            // This should not happen as libpng provides this guarantee but extra safety does not hurt.
+            fprintf(stderr, "Metadata extraction failed: malformed raw profile, unexpected null character at %" AVIF_FMT_ZU "\n", i);
+            return AVIF_FALSE;
+        }
+        if (profile[i] == '\n') {
+            if (!lengthStart) {
+                // Skip the name and store the beginning of the string containing the length of the payload.
+                lengthStart = &profile[i + 1];
+            } else {
+                const char * hexPayloadStart = &profile[i + 1];
+                const size_t hexPayloadMaxLength = profileLength - (i + 1);
+                // Parse the length, now that we are sure that it is surrounded by '\n' within the profileLength characters.
+                char * lengthEnd;
+                const long expectedLength = strtol(lengthStart, &lengthEnd, 10);
+                if (lengthEnd != &profile[i]) {
+                    fprintf(stderr, "Metadata extraction failed: malformed raw profile, expected '\\n' but got '\\x%.2X'\n", *lengthEnd);
+                    return AVIF_FALSE;
+                }
+                // No need to check for errno. Just make sure expectedLength is not LONG_MIN and not LONG_MAX.
+                if ((expectedLength <= 0) || (expectedLength == LONG_MAX) ||
+                    ((unsigned long)expectedLength > (hexPayloadMaxLength / 2))) {
+                    fprintf(stderr, "Metadata extraction failed: invalid length %ld\n", expectedLength);
+                    return AVIF_FALSE;
+                }
+                // Note: The profile may be malformed by containing more data than the extracted expectedLength bytes.
+                //       Be lenient about it and consider it as a valid payload.
+                return avifHexStringToBytes(hexPayloadStart, hexPayloadMaxLength, (size_t)expectedLength, payload);
+            }
+        }
+    }
+    fprintf(stderr, "Metadata extraction failed: malformed or truncated raw profile\n");
+    return AVIF_FALSE;
+}
+
+static avifBool avifRemoveHeader(const avifROData * header, avifRWData * payload)
+{
+    if (payload->size > header->size && !memcmp(payload->data, header->data, header->size)) {
+        memmove(payload->data, payload->data + header->size, payload->size - header->size);
+        payload->size -= header->size;
+        return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+// Extracts metadata to avif->exif and avif->xmp unless the corresponding *ignoreExif or *ignoreXMP is set to AVIF_TRUE.
+// *ignoreExif and *ignoreXMP may be set to AVIF_TRUE if the corresponding Exif or XMP metadata was extracted.
+// Returns AVIF_FALSE in case of a parsing error.
+static avifBool avifExtractExifAndXMP(png_structp png, png_infop info, avifBool * ignoreExif, avifBool * ignoreXMP, avifImage * avif)
+{
+    if (!*ignoreExif) {
+        png_uint_32 exifSize = 0;
+        png_bytep exif = NULL;
+        if (png_get_eXIf_1(png, info, &exifSize, &exif) == PNG_INFO_eXIf) {
+            if ((exifSize == 0) || !exif) {
+                fprintf(stderr, "Exif extraction failed: empty eXIf chunk\n");
+                return AVIF_FALSE;
+            }
+            // Avoid avifImageSetMetadataExif() that sets irot/imir.
+            if (avifRWDataSet(&avif->exif, exif, exifSize) != AVIF_RESULT_OK) {
+                fprintf(stderr, "Exif extraction failed: out of memory\n");
+                return AVIF_FALSE;
+            }
+            // According to the Extensions to the PNG 1.2 Specification, Version 1.5.0, section 3.7:
+            //   "It is recommended that unless a decoder has independent knowledge of the validity of the Exif data,
+            //    the data should be considered to be of historical value only."
+            // Try to remove any Exif orientation data to be safe.
+            // It is easier to set it to 1 (the default top-left) than actually removing the tag.
+            // libheif has the same behavior, see
+            // https://github.com/strukturag/libheif/blob/18291ddebc23c924440a8a3c9a7267fe3beb5901/examples/heif_enc.cc#L703
+            // Ignore errors because not being able to set Exif orientation now means it cannot be parsed later either.
+            (void)avifSetExifOrientation(&avif->exif, 1);
+            *ignoreExif = AVIF_TRUE; // Ignore any other Exif chunk.
+        }
+    }
+
+    // HEIF specification ISO-23008 section A.2.1 allows including and excluding the Exif\0\0 header from AVIF files.
+    // The PNG 1.5 extension mentions the omission of this header for the modern standard eXIf chunk.
+    const avifROData exifApp1Header = { (const uint8_t *)"Exif\0\0", 6 };
+    const avifROData xmpApp1Header = { (const uint8_t *)"http://ns.adobe.com/xap/1.0/\0", 29 };
+
+    // tXMP could be retrieved using the png_get_unknown_chunks() API but tXMP is deprecated
+    // and there is no PNG file example with a tXMP chunk lying around, so it is not worth the hassle.
+
+    png_textp text = NULL;
+    const png_uint_32 numTextChunks = png_get_text(png, info, &text, NULL);
+    for (png_uint_32 i = 0; (!*ignoreExif || !*ignoreXMP) && (i < numTextChunks); ++i, ++text) {
+        png_size_t textLength = text->text_length;
+        if ((text->compression == PNG_ITXT_COMPRESSION_NONE) || (text->compression == PNG_ITXT_COMPRESSION_zTXt)) {
+            textLength = text->itxt_length;
+        }
+
+        if (!*ignoreExif && !strcmp(text->key, "Raw profile type exif")) {
+            if (!avifCopyRawProfile(text->text, textLength, &avif->exif)) {
+                return AVIF_FALSE;
+            }
+            avifRemoveHeader(&exifApp1Header, &avif->exif); // Ignore the return value because the header is optional.
+            (void)avifSetExifOrientation(&avif->exif, 1);   // See above.
+            *ignoreExif = AVIF_TRUE;                        // Ignore any other Exif chunk.
+        } else if (!*ignoreXMP && !strcmp(text->key, "Raw profile type xmp")) {
+            if (!avifCopyRawProfile(text->text, textLength, &avif->xmp)) {
+                return AVIF_FALSE;
+            }
+            avifRemoveHeader(&xmpApp1Header, &avif->xmp); // Ignore the return value because the header is optional.
+            *ignoreXMP = AVIF_TRUE;                       // Ignore any other XMP chunk.
+        } else if (!strcmp(text->key, "Raw profile type APP1")) {
+            // This can be either Exif, XMP or something else.
+            avifRWData metadata = { NULL, 0 };
+            if (!avifCopyRawProfile(text->text, textLength, &metadata)) {
+                return AVIF_FALSE;
+            }
+            if (!*ignoreExif && avifRemoveHeader(&exifApp1Header, &metadata)) {
+                avifRWDataFree(&avif->exif);
+                avif->exif = metadata;
+                (void)avifSetExifOrientation(&avif->exif, 1); // See above.
+                *ignoreExif = AVIF_TRUE;                      // Ignore any other Exif chunk.
+            } else if (!*ignoreXMP && avifRemoveHeader(&xmpApp1Header, &metadata)) {
+                avifRWDataFree(&avif->xmp);
+                avif->xmp = metadata;
+                *ignoreXMP = AVIF_TRUE; // Ignore any other XMP chunk.
+            } else {
+                avifRWDataFree(&metadata); // Discard chunk.
+            }
+        } else if (!*ignoreXMP && !strcmp(text->key, "XML:com.adobe.xmp")) {
+            if (textLength == 0) {
+                fprintf(stderr, "XMP extraction failed: empty XML:com.adobe.xmp payload\n");
+                return AVIF_FALSE;
+            }
+            if (avifImageSetMetadataXMP(avif, (const uint8_t *)text->text, textLength) != AVIF_RESULT_OK) {
+                fprintf(stderr, "XMP extraction failed: out of memory\n");
+                return AVIF_FALSE;
+            }
+            *ignoreXMP = AVIF_TRUE; // Ignore any other XMP chunk.
+        }
+    }
+    // The iTXt XMP payload may not contain a zero byte according to section 4.2.3.3 of
+    // the PNG specification, version 1.2. Still remove one trailing null character if any,
+    // in case libpng does not strictly enforce that at decoding.
+    avifImageFixXMP(avif);
+    return AVIF_TRUE;
+}
+
+// Note on setjmp() and volatile variables:
+//
+// K & R, The C Programming Language 2nd Ed, p. 254 says:
+//   ... Accessible objects have the values they had when longjmp was called,
+//   except that non-volatile automatic variables in the function calling setjmp
+//   become undefined if they were changed after the setjmp call.
+//
+// Therefore, 'rowPointers' is declared as volatile. 'rgb' should be declared as
+// volatile, but doing so would be inconvenient (try it) and since it is a
+// struct, the compiler is unlikely to put it in a register. 'readResult' and
+// 'writeResult' do not need to be declared as volatile because they are not
+// modified between setjmp and longjmp. But GCC's -Wclobbered warning may have
+// trouble figuring that out, so we preemptively declare them as volatile.
+
+avifBool avifPNGRead(const char * inputFilename,
+                     avifImage * avif,
+                     avifPixelFormat requestedFormat,
+                     uint32_t requestedDepth,
+                     avifChromaDownsampling chromaDownsampling,
+                     avifBool ignoreColorProfile,
+                     avifBool ignoreExif,
+                     avifBool ignoreXMP,
+                     avifBool allowChangingCicp,
+                     uint32_t imageSizeLimit,
+                     uint32_t * outPNGDepth)
+{
+    volatile avifBool readResult = AVIF_FALSE;
+    png_structp png = NULL;
+    png_infop info = NULL;
+    png_bytep * volatile rowPointers = NULL;
+
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(avifRGBImage));
+
+    FILE * f = fopen(inputFilename, "rb");
+    if (!f) {
+        fprintf(stderr, "Can't open PNG file for read: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    uint8_t header[8];
+    size_t bytesRead = fread(header, 1, 8, f);
+    if (bytesRead != 8) {
+        fprintf(stderr, "Can't read PNG header: %s\n", inputFilename);
+        goto cleanup;
+    }
+    if (png_sig_cmp(header, 0, 8)) {
+        fprintf(stderr, "Not a PNG: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    png = png_create_read_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);
+    if (!png) {
+        fprintf(stderr, "Cannot init libpng (png): %s\n", inputFilename);
+        goto cleanup;
+    }
+    info = png_create_info_struct(png);
+    if (!info) {
+        fprintf(stderr, "Cannot init libpng (info): %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    if (setjmp(png_jmpbuf(png))) {
+        fprintf(stderr, "Error reading PNG: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    png_init_io(png, f);
+    png_set_sig_bytes(png, 8);
+    png_read_info(png, info);
+
+    int rawWidth = png_get_image_width(png, info);
+    int rawHeight = png_get_image_height(png, info);
+    png_byte rawColorType = png_get_color_type(png, info);
+    png_byte rawBitDepth = png_get_bit_depth(png, info);
+
+    if (rawColorType == PNG_COLOR_TYPE_PALETTE) {
+        png_set_palette_to_rgb(png);
+    }
+
+    if ((rawColorType == PNG_COLOR_TYPE_GRAY) && (rawBitDepth < 8)) {
+        png_set_expand_gray_1_2_4_to_8(png);
+    }
+
+    if (png_get_valid(png, info, PNG_INFO_tRNS)) {
+        png_set_tRNS_to_alpha(png);
+    }
+
+    if ((rawColorType == PNG_COLOR_TYPE_GRAY) || (rawColorType == PNG_COLOR_TYPE_GRAY_ALPHA)) {
+        png_set_gray_to_rgb(png);
+    }
+
+    int imgBitDepth = 8;
+    if (rawBitDepth == 16) {
+        png_set_swap(png);
+        imgBitDepth = 16;
+    }
+
+    if (outPNGDepth) {
+        *outPNGDepth = imgBitDepth;
+    }
+
+    png_read_update_info(png, info);
+
+    avif->width = rawWidth;
+    avif->height = rawHeight;
+    avif->yuvFormat = requestedFormat;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    if (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO) {
+        fprintf(stderr, "AVIF_MATRIX_COEFFICIENTS_YCGCO_RO cannot be used with PNG because it has an even bit depth.\n");
+        goto cleanup;
+    }
+    const avifBool useYCgCoR = (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE);
+#endif
+    if (avif->yuvFormat == AVIF_PIXEL_FORMAT_NONE) {
+        if ((rawColorType == PNG_COLOR_TYPE_GRAY) || (rawColorType == PNG_COLOR_TYPE_GRAY_ALPHA)) {
+            avif->yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+        } else if (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                   || useYCgCoR
+#endif
+        ) {
+            // Identity and YCgCo-R are only valid with YUV444.
+            avif->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+        } else {
+            avif->yuvFormat = AVIF_APP_DEFAULT_PIXEL_FORMAT;
+        }
+    }
+    avif->depth = requestedDepth;
+    if (avif->depth == 0) {
+        if (imgBitDepth == 8) {
+            avif->depth = 8;
+        } else {
+            avif->depth = 12;
+        }
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    if (useYCgCoR) {
+        if (imgBitDepth != 8) {
+            fprintf(stderr, "AVIF_MATRIX_COEFFICIENTS_YCGCO_RE cannot be used on 16 bit input because it adds two bits.\n");
+            goto cleanup;
+        }
+        if (requestedDepth && requestedDepth != 10) {
+            fprintf(stderr, "Cannot request %u bits for YCgCo-Re as it uses 2 extra bits.\n", requestedDepth);
+            goto cleanup;
+        }
+        avif->depth = 10;
+    }
+#endif
+
+    if (!ignoreColorProfile) {
+        char * iccpProfileName = NULL;
+        int iccpCompression = 0;
+        unsigned char * iccpData = NULL;
+        png_uint_32 iccpDataLen = 0;
+        int srgbIntent;
+
+        // PNG specification 1.2 Section 4.2.2:
+        // The sRGB and iCCP chunks should not both appear.
+        //
+        // When the sRGB / iCCP chunk is present, applications that recognize it and are capable of color management
+        // must ignore the gAMA and cHRM chunks and use the sRGB / iCCP chunk instead.
+        if (png_get_iCCP(png, info, &iccpProfileName, &iccpCompression, &iccpData, &iccpDataLen) == PNG_INFO_iCCP) {
+            if (avifImageSetProfileICC(avif, iccpData, iccpDataLen) != AVIF_RESULT_OK) {
+                fprintf(stderr, "Setting ICC profile failed: out of memory.\n");
+                goto cleanup;
+            }
+        } else if (allowChangingCicp) {
+            if (png_get_sRGB(png, info, &srgbIntent) == PNG_INFO_sRGB) {
+                // srgbIntent ignored
+                avif->colorPrimaries = AVIF_COLOR_PRIMARIES_SRGB;
+                avif->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_SRGB;
+            } else {
+                avifBool needToGenerateICC = AVIF_FALSE;
+                double gamma;
+                double wX, wY, rX, rY, gX, gY, bX, bY;
+                float primaries[8];
+                if (png_get_gAMA(png, info, &gamma) == PNG_INFO_gAMA) {
+                    gamma = 1.0 / gamma;
+                    avif->transferCharacteristics = avifTransferCharacteristicsFindByGamma((float)gamma);
+                    if (avif->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_UNKNOWN) {
+                        needToGenerateICC = AVIF_TRUE;
+                    }
+                } else {
+                    // No gamma information in file. Assume the default value.
+                    // PNG specification 1.2 Section 10.5:
+                    // Assume a CRT exponent of 2.2 unless detailed calibration measurements
+                    // of this particular CRT are available.
+                    gamma = 2.2;
+                }
+
+                if (png_get_cHRM(png, info, &wX, &wY, &rX, &rY, &gX, &gY, &bX, &bY) == PNG_INFO_cHRM) {
+                    primaries[0] = (float)rX;
+                    primaries[1] = (float)rY;
+                    primaries[2] = (float)gX;
+                    primaries[3] = (float)gY;
+                    primaries[4] = (float)bX;
+                    primaries[5] = (float)bY;
+                    primaries[6] = (float)wX;
+                    primaries[7] = (float)wY;
+                    avif->colorPrimaries = avifColorPrimariesFind(primaries, NULL);
+                    if (avif->colorPrimaries == AVIF_COLOR_PRIMARIES_UNKNOWN) {
+                        needToGenerateICC = AVIF_TRUE;
+                    }
+                } else {
+                    // No chromaticity information in file. Assume the default value.
+                    // PNG specification 1.2 Section 10.6:
+                    // Decoders may wish to do this for PNG files with no cHRM chunk.
+                    // In that case, a reasonable default would be the CCIR 709 primaries [ITU-R-BT709].
+                    avifColorPrimariesGetValues(AVIF_COLOR_PRIMARIES_BT709, primaries);
+                }
+
+                if (needToGenerateICC) {
+                    avif->colorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;
+                    avif->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED;
+                    fprintf(stderr,
+                            "INFO: legacy PNG color space information found in file %s not matching any CICP value. libavif is generating an ICC profile for it."
+                            " Use --ignore-profile to ignore color space information instead (may affect the colors of the encoded AVIF image).\n",
+                            inputFilename);
+
+                    avifBool generateICCResult = AVIF_FALSE;
+                    if (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+                        generateICCResult = avifGenerateGrayICC(&avif->icc, (float)gamma, &primaries[6]);
+                    } else {
+                        generateICCResult = avifGenerateRGBICC(&avif->icc, (float)gamma, primaries);
+                    }
+
+                    if (!generateICCResult) {
+                        fprintf(stderr,
+                                "WARNING: libavif could not generate an ICC profile for file %s. "
+                                "It may be caused by invalid values in the color space information. "
+                                "The encoded AVIF image's colors may be affected.\n",
+                                inputFilename);
+                    }
+                }
+            }
+        }
+        // Note: There is no support for the rare "Raw profile type icc" or "Raw profile type icm" text chunks.
+        // TODO(yguyon): Also check if there is a cICp chunk (https://github.com/AOMediaCodec/libavif/pull/1065#discussion_r958534232)
+    }
+
+    const int numChannels = png_get_channels(png, info);
+    if ((numChannels != 3) && (numChannels != 4)) {
+        fprintf(stderr, "png_get_channels() should return 3 or 4 but returns %d.\n", numChannels);
+        goto cleanup;
+    }
+    if (avif->width > imageSizeLimit / avif->height) {
+        fprintf(stderr, "Too big PNG dimensions (%u x %u > %u px): %s\n", avif->width, avif->height, imageSizeLimit, inputFilename);
+        goto cleanup;
+    }
+
+    avifRGBImageSetDefaults(&rgb, avif);
+    rgb.chromaDownsampling = chromaDownsampling;
+    rgb.depth = imgBitDepth;
+    if (numChannels == 3) {
+        rgb.format = AVIF_RGB_FORMAT_RGB;
+    }
+    if (avifRGBImageAllocatePixels(&rgb) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Conversion to YUV failed: %s (out of memory)\n", inputFilename);
+        goto cleanup;
+    }
+    // png_read_image() receives the row pointers but not the row buffer size. Verify the row
+    // buffer size is exactly what libpng expects. If they are different, we have a bug and should
+    // not proceed.
+    const size_t rowBytes = png_get_rowbytes(png, info);
+    if (rgb.rowBytes != rowBytes) {
+        fprintf(stderr, "avifPNGRead internal error: rowBytes mismatch libavif %u vs libpng %" AVIF_FMT_ZU "\n", rgb.rowBytes, rowBytes);
+        goto cleanup;
+    }
+    rowPointers = (png_bytep *)malloc(sizeof(png_bytep) * rgb.height);
+    if (rowPointers == NULL) {
+        fprintf(stderr, "avifPNGRead internal error: memory allocation failure");
+        goto cleanup;
+    }
+    uint8_t * rgbRow = rgb.pixels;
+    for (uint32_t y = 0; y < rgb.height; ++y) {
+        rowPointers[y] = rgbRow;
+        rgbRow += rgb.rowBytes;
+    }
+    png_read_image(png, rowPointers);
+    if (avifImageRGBToYUV(avif, &rgb) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Conversion to YUV failed: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    // Read Exif metadata at the beginning of the file.
+    if (!avifExtractExifAndXMP(png, info, &ignoreExif, &ignoreXMP, avif)) {
+        goto cleanup;
+    }
+    // Read Exif or XMP metadata at the end of the file if there was none at the beginning.
+    if (!ignoreExif || !ignoreXMP) {
+        png_read_end(png, info);
+        if (!avifExtractExifAndXMP(png, info, &ignoreExif, &ignoreXMP, avif)) {
+            goto cleanup;
+        }
+    }
+    readResult = AVIF_TRUE;
+
+cleanup:
+    if (f) {
+        fclose(f);
+    }
+    if (png) {
+        png_destroy_read_struct(&png, &info, NULL);
+    }
+    if (rowPointers) {
+        free(rowPointers);
+    }
+    avifRGBImageFreePixels(&rgb);
+    return readResult;
+}
+
+//------------------------------------------------------------------------------
+// Writing
+
+avifBool avifPNGWrite(const char * outputFilename, const avifImage * avif, uint32_t requestedDepth, avifChromaUpsampling chromaUpsampling, int compressionLevel)
+{
+    volatile avifBool writeResult = AVIF_FALSE;
+    png_structp png = NULL;
+    png_infop info = NULL;
+    avifRWData xmp = { NULL, 0 };
+    png_bytep * volatile rowPointers = NULL;
+    FILE * volatile f = NULL;
+
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(avifRGBImage));
+
+    volatile int rgbDepth = requestedDepth;
+    if (rgbDepth == 0) {
+        rgbDepth = (avif->depth > 8) ? 16 : 8;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    if (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO) {
+        fprintf(stderr, "AVIF_MATRIX_COEFFICIENTS_YCGCO_RO cannot be used with PNG because it has an even bit depth.\n");
+        goto cleanup;
+    }
+    if (avif->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE) {
+        if (avif->depth != 10) {
+            fprintf(stderr, "avif->depth must be 10 bits and not %u.\n", avif->depth);
+            goto cleanup;
+        }
+        if (requestedDepth && requestedDepth != 8) {
+            fprintf(stderr, "Cannot request %u bits for YCgCo-Re as it only works for 8 bits.\n", requestedDepth);
+            goto cleanup;
+        }
+
+        rgbDepth = 8;
+    }
+#endif
+
+    volatile avifBool monochrome8bit = (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) && !avif->alphaPlane && (avif->depth == 8) &&
+                                       (rgbDepth == 8);
+
+    volatile int colorType;
+    if (monochrome8bit) {
+        colorType = PNG_COLOR_TYPE_GRAY;
+    } else {
+        avifRGBImageSetDefaults(&rgb, avif);
+        rgb.chromaUpsampling = chromaUpsampling;
+        rgb.depth = rgbDepth;
+        colorType = PNG_COLOR_TYPE_RGBA;
+        if (avifImageIsOpaque(avif)) {
+            colorType = PNG_COLOR_TYPE_RGB;
+            rgb.format = AVIF_RGB_FORMAT_RGB;
+        }
+        if (avifRGBImageAllocatePixels(&rgb) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion to RGB failed: %s (out of memory)\n", outputFilename);
+            goto cleanup;
+        }
+        if (avifImageYUVToRGB(avif, &rgb) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion to RGB failed: %s\n", outputFilename);
+            goto cleanup;
+        }
+    }
+
+    f = fopen(outputFilename, "wb");
+    if (!f) {
+        fprintf(stderr, "Can't open PNG file for write: %s\n", outputFilename);
+        goto cleanup;
+    }
+
+    png = png_create_write_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);
+    if (!png) {
+        fprintf(stderr, "Cannot init libpng (png): %s\n", outputFilename);
+        goto cleanup;
+    }
+    info = png_create_info_struct(png);
+    if (!info) {
+        fprintf(stderr, "Cannot init libpng (info): %s\n", outputFilename);
+        goto cleanup;
+    }
+
+    if (setjmp(png_jmpbuf(png))) {
+        fprintf(stderr, "Error writing PNG: %s\n", outputFilename);
+        goto cleanup;
+    }
+
+    png_init_io(png, f);
+
+    // Don't bother complaining about ICC profile's contents when transferring from AVIF to PNG.
+    // It is up to the enduser to decide if they want to keep their ICC profiles or not.
+#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED) // See libpng-manual.txt, section XII.
+    png_set_option(png, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);
+#endif
+
+    if (compressionLevel >= 0) {
+        png_set_compression_level(png, compressionLevel);
+    }
+
+    png_set_IHDR(png, info, avif->width, avif->height, rgbDepth, colorType, PNG_INTERLACE_NONE, PNG_COMPRESSION_TYPE_DEFAULT, PNG_FILTER_TYPE_DEFAULT);
+
+    const avifBool hasIcc = avif->icc.data && (avif->icc.size > 0);
+    if (hasIcc) {
+        // If there is an ICC profile, the CICP values are irrelevant and only the ICC profile
+        // is written. If we could extract the primaries/transfer curve from the ICC profile,
+        // then they could be written in cHRM/gAMA chunks.
+        png_set_iCCP(png, info, "libavif", 0, avif->icc.data, (png_uint_32)avif->icc.size);
+    } else {
+        const avifBool isSrgb = (avif->colorPrimaries == AVIF_COLOR_PRIMARIES_SRGB) &&
+                                (avif->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_SRGB);
+        if (isSrgb) {
+            png_set_sRGB_gAMA_and_cHRM(png, info, PNG_sRGB_INTENT_PERCEPTUAL);
+        } else {
+            if (avif->colorPrimaries != AVIF_COLOR_PRIMARIES_UNKNOWN && avif->colorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+                float primariesCoords[8];
+                avifColorPrimariesGetValues(avif->colorPrimaries, primariesCoords);
+                png_set_cHRM(png,
+                             info,
+                             primariesCoords[6],
+                             primariesCoords[7],
+                             primariesCoords[0],
+                             primariesCoords[1],
+                             primariesCoords[2],
+                             primariesCoords[3],
+                             primariesCoords[4],
+                             primariesCoords[5]);
+            }
+            float gamma;
+            // Write the transfer characteristics IF it can be represented as a
+            // simple gamma value. Most transfer characteristics cannot be
+            // represented this way. Viewers that support the cICP chunk can use
+            // that instead, but older viewers might show incorrect colors.
+            if (avifTransferCharacteristicsGetGamma(avif->transferCharacteristics, &gamma) == AVIF_RESULT_OK) {
+                png_set_gAMA(png, info, 1.0f / gamma);
+            }
+        }
+    }
+
+    png_text texts[2];
+    int numTextMetadataChunks = 0;
+    if (avif->exif.data && (avif->exif.size > 0)) {
+        if (avif->exif.size > UINT32_MAX) {
+            fprintf(stderr, "Error writing PNG: Exif metadata is too big\n");
+            goto cleanup;
+        }
+        png_set_eXIf_1(png, info, (png_uint_32)avif->exif.size, avif->exif.data);
+    }
+    if (avif->xmp.data && (avif->xmp.size > 0)) {
+        // The iTXt XMP payload may not contain a zero byte according to section 4.2.3.3 of
+        // the PNG specification, version 1.2.
+        // The chunk is given to libpng as is. Bytes after a zero byte may be stripped.
+
+        // Providing the length through png_text.itxt_length does not work.
+        // The given png_text.text string must end with a zero byte.
+        if (avif->xmp.size >= SIZE_MAX) {
+            fprintf(stderr, "Error writing PNG: XMP metadata is too big\n");
+            goto cleanup;
+        }
+        if (avifRWDataRealloc(&xmp, avif->xmp.size + 1) != AVIF_RESULT_OK) {
+            fprintf(stderr, "Error writing PNG: out of memory\n");
+            goto cleanup;
+        }
+        memcpy(xmp.data, avif->xmp.data, avif->xmp.size);
+        xmp.data[avif->xmp.size] = '\0';
+        png_text * text = &texts[numTextMetadataChunks++];
+        memset(text, 0, sizeof(*text));
+        text->compression = PNG_ITXT_COMPRESSION_NONE;
+        text->key = "XML:com.adobe.xmp";
+        text->text = (char *)xmp.data;
+        text->itxt_length = xmp.size;
+    }
+    if (numTextMetadataChunks != 0) {
+        png_set_text(png, info, texts, numTextMetadataChunks);
+    }
+
+    png_write_info(png, info);
+
+    // Custom chunk writing, must appear after png_write_info.
+    // With AVIF, an ICC profile takes priority over CICP, but with PNG files, CICP takes priority over ICC.
+    // Therefore CICP should only be written if there is no ICC profile.
+    if (!hasIcc) {
+        const png_byte cicp[5] = "cICP";
+        const png_byte cicpData[4] = { (png_byte)avif->colorPrimaries,
+                                       (png_byte)avif->transferCharacteristics,
+                                       AVIF_MATRIX_COEFFICIENTS_IDENTITY,
+                                       1 /*full range*/ };
+        png_write_chunk(png, cicp, cicpData, 4);
+    }
+
+    rowPointers = (png_bytep *)malloc(sizeof(png_bytep) * avif->height);
+    if (rowPointers == NULL) {
+        fprintf(stderr, "Error writing PNG: memory allocation failure");
+        goto cleanup;
+    }
+    uint8_t * row;
+    uint32_t rowBytes;
+    if (monochrome8bit) {
+        row = avif->yuvPlanes[AVIF_CHAN_Y];
+        rowBytes = avif->yuvRowBytes[AVIF_CHAN_Y];
+    } else {
+        row = rgb.pixels;
+        rowBytes = rgb.rowBytes;
+    }
+    for (uint32_t y = 0; y < avif->height; ++y) {
+        rowPointers[y] = row;
+        row += rowBytes;
+    }
+    if (avifImageGetExifOrientationFromIrotImir(avif) != 1) {
+        // TODO(yguyon): Rotate the samples.
+    }
+
+    if (rgbDepth > 8) {
+        png_set_swap(png);
+    }
+
+    png_write_image(png, rowPointers);
+    png_write_end(png, NULL);
+
+    writeResult = AVIF_TRUE;
+    printf("Wrote PNG: %s\n", outputFilename);
+cleanup:
+    if (f) {
+        fclose(f);
+    }
+    if (png) {
+        png_destroy_write_struct(&png, &info);
+    }
+    avifRWDataFree(&xmp);
+    if (rowPointers) {
+        free(rowPointers);
+    }
+    avifRGBImageFreePixels(&rgb);
+    return writeResult;
+}
diff --git a/third_party/libavif/src/apps/shared/avifpng.h b/third_party/libavif/src/apps/shared/avifpng.h
new file mode 100644
index 0000000000..16d5a2f5be
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifpng.h
@@ -0,0 +1,35 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_AVIFPNG_H
+#define LIBAVIF_APPS_SHARED_AVIFPNG_H
+
+#include "avif/avif.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// if (requestedDepth == 0), do best-fit
+avifBool avifPNGRead(const char * inputFilename,
+                     avifImage * avif,
+                     avifPixelFormat requestedFormat,
+                     uint32_t requestedDepth,
+                     avifChromaDownsampling chromaDownsampling,
+                     avifBool ignoreColorProfile,
+                     avifBool ignoreExif,
+                     avifBool ignoreXMP,
+                     avifBool allowChangingCicp,
+                     uint32_t imageSizeLimit,
+                     uint32_t * outPNGDepth);
+avifBool avifPNGWrite(const char * outputFilename,
+                      const avifImage * avif,
+                      uint32_t requestedDepth,
+                      avifChromaUpsampling chromaUpsampling,
+                      int compressionLevel);
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef LIBAVIF_APPS_SHARED_AVIFPNG_H
diff --git a/third_party/libavif/src/apps/shared/avifutil.c b/third_party/libavif/src/apps/shared/avifutil.c
new file mode 100644
index 0000000000..fc36349e66
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifutil.c
@@ -0,0 +1,464 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avifutil.h"
+
+#include <ctype.h>
+#include <stdio.h>
+#include <string.h>
+
+#include "avifjpeg.h"
+#include "avifpng.h"
+#include "y4m.h"
+
+// |a| and |b| hold int32_t values. The int64_t type is used so that we can negate INT32_MIN without
+// overflowing int32_t.
+static int64_t calcGCD(int64_t a, int64_t b)
+{
+    if (a < 0) {
+        a *= -1;
+    }
+    if (b < 0) {
+        b *= -1;
+    }
+    while (b != 0) {
+        int64_t r = a % b;
+        a = b;
+        b = r;
+    }
+    return a;
+}
+
+static void printClapFraction(const char * name, int32_t n, int32_t d)
+{
+    printf("%s: %d/%d", name, n, d);
+    if (d != 0) {
+        int64_t gcd = calcGCD(n, d);
+        if (gcd > 1) {
+            int32_t rn = (int32_t)(n / gcd);
+            int32_t rd = (int32_t)(d / gcd);
+            printf(" (%d/%d)", rn, rd);
+        }
+    }
+}
+
+static void avifImageDumpInternal(const avifImage * avif, uint32_t gridCols, uint32_t gridRows, avifBool alphaPresent, avifProgressiveState progressiveState)
+{
+    uint32_t width = avif->width;
+    uint32_t height = avif->height;
+    if (gridCols && gridRows) {
+        width *= gridCols;
+        height *= gridRows;
+    }
+    printf(" * Resolution     : %ux%u\n", width, height);
+    printf(" * Bit Depth      : %u\n", avif->depth);
+    printf(" * Format         : %s\n", avifPixelFormatToString(avif->yuvFormat));
+    if (avif->yuvFormat == AVIF_PIXEL_FORMAT_YUV420) {
+        printf(" * Chroma Sam. Pos: %u\n", avif->yuvChromaSamplePosition);
+    }
+    printf(" * Alpha          : %s\n", alphaPresent ? (avif->alphaPremultiplied ? "Premultiplied" : "Not premultiplied") : "Absent");
+    printf(" * Range          : %s\n", (avif->yuvRange == AVIF_RANGE_FULL) ? "Full" : "Limited");
+
+    printf(" * Color Primaries: %u\n", avif->colorPrimaries);
+    printf(" * Transfer Char. : %u\n", avif->transferCharacteristics);
+    printf(" * Matrix Coeffs. : %u\n", avif->matrixCoefficients);
+
+    if (avif->icc.size != 0) {
+        printf(" * ICC Profile    : Present (%" AVIF_FMT_ZU " bytes)\n", avif->icc.size);
+    } else {
+        printf(" * ICC Profile    : Absent\n");
+    }
+    if (avif->xmp.size != 0) {
+        printf(" * XMP Metadata   : Present (%" AVIF_FMT_ZU " bytes)\n", avif->xmp.size);
+    } else {
+        printf(" * XMP Metadata   : Absent\n");
+    }
+    if (avif->exif.size != 0) {
+        printf(" * Exif Metadata  : Present (%" AVIF_FMT_ZU " bytes)\n", avif->exif.size);
+    } else {
+        printf(" * Exif Metadata  : Absent\n");
+    }
+
+    if (avif->transformFlags == AVIF_TRANSFORM_NONE) {
+        printf(" * Transformations: None\n");
+    } else {
+        printf(" * Transformations:\n");
+
+        if (avif->transformFlags & AVIF_TRANSFORM_PASP) {
+            printf("    * pasp (Aspect Ratio)  : %d/%d\n", (int)avif->pasp.hSpacing, (int)avif->pasp.vSpacing);
+        }
+        if (avif->transformFlags & AVIF_TRANSFORM_CLAP) {
+            printf("    * clap (Clean Aperture): ");
+            printClapFraction("W", (int32_t)avif->clap.widthN, (int32_t)avif->clap.widthD);
+            printf(", ");
+            printClapFraction("H", (int32_t)avif->clap.heightN, (int32_t)avif->clap.heightD);
+            printf(", ");
+            printClapFraction("hOff", (int32_t)avif->clap.horizOffN, (int32_t)avif->clap.horizOffD);
+            printf(", ");
+            printClapFraction("vOff", (int32_t)avif->clap.vertOffN, (int32_t)avif->clap.vertOffD);
+            printf("\n");
+
+            avifCropRect cropRect;
+            avifDiagnostics diag;
+            avifDiagnosticsClearError(&diag);
+            avifBool validClap =
+                avifCropRectConvertCleanApertureBox(&cropRect, &avif->clap, avif->width, avif->height, avif->yuvFormat, &diag);
+            if (validClap) {
+                printf("      * Valid, derived crop rect: X: %d, Y: %d, W: %d, H: %d\n",
+                       cropRect.x,
+                       cropRect.y,
+                       cropRect.width,
+                       cropRect.height);
+            } else {
+                printf("      * Invalid: %s\n", diag.error);
+            }
+        }
+        if (avif->transformFlags & AVIF_TRANSFORM_IROT) {
+            printf("    * irot (Rotation)      : %u\n", avif->irot.angle);
+        }
+        if (avif->transformFlags & AVIF_TRANSFORM_IMIR) {
+            printf("    * imir (Mirror)        : %u (%s)\n", avif->imir.axis, (avif->imir.axis == 0) ? "top-to-bottom" : "left-to-right");
+        }
+    }
+    printf(" * Progressive    : %s\n", avifProgressiveStateToString(progressiveState));
+    if (avif->clli.maxCLL > 0 || avif->clli.maxPALL > 0) {
+        printf(" * CLLI           : %hu, %hu\n", avif->clli.maxCLL, avif->clli.maxPALL);
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    printf(" * Gain map       : ");
+    avifImage * gainMapImage = avif->gainMap ? avif->gainMap->image : NULL;
+    if (gainMapImage != NULL) {
+        printf("%ux%u pixels, %u bit, %s, %s Range, Matrix Coeffs. %u, Base Image is %s\n",
+               gainMapImage->width,
+               gainMapImage->height,
+               gainMapImage->depth,
+               avifPixelFormatToString(gainMapImage->yuvFormat),
+               (gainMapImage->yuvRange == AVIF_RANGE_FULL) ? "Full" : "Limited",
+               gainMapImage->matrixCoefficients,
+               (avif->gainMap->baseHdrHeadroom.n == 0) ? "SDR" : "HDR");
+        printf(" * Alternate image:\n");
+        printf("    * Color Primaries: %u\n", avif->gainMap->altColorPrimaries);
+        printf("    * Transfer Char. : %u\n", avif->gainMap->altTransferCharacteristics);
+        printf("    * Matrix Coeffs. : %u\n", avif->gainMap->altMatrixCoefficients);
+        if (avif->gainMap->altICC.size != 0) {
+            printf("    * ICC Profile    : Present (%" AVIF_FMT_ZU " bytes)\n", avif->gainMap->altICC.size);
+        } else {
+            printf("    * ICC Profile    : Absent\n");
+        }
+        if (avif->gainMap->altDepth) {
+            printf("    * Bit Depth      : %u\n", avif->gainMap->altDepth);
+        }
+        if (avif->gainMap->altPlaneCount) {
+            printf("    * Planes         : %u\n", avif->gainMap->altPlaneCount);
+        }
+        if (gainMapImage->clli.maxCLL > 0 || gainMapImage->clli.maxPALL > 0) {
+            printf("    * CLLI           : %hu, %hu\n", gainMapImage->clli.maxCLL, gainMapImage->clli.maxPALL);
+        }
+        printf("\n");
+    } else if (avif->gainMap != NULL) {
+        printf("Present (but ignored)\n");
+    } else {
+        printf("Absent\n");
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+}
+
+void avifImageDump(const avifImage * avif, uint32_t gridCols, uint32_t gridRows, avifProgressiveState progressiveState)
+{
+    const avifBool alphaPresent = avif->alphaPlane && (avif->alphaRowBytes > 0);
+    avifImageDumpInternal(avif, gridCols, gridRows, alphaPresent, progressiveState);
+}
+
+void avifContainerDump(const avifDecoder * decoder)
+{
+    avifImageDumpInternal(decoder->image, 0, 0, decoder->alphaPresent, decoder->progressiveState);
+    if (decoder->imageSequenceTrackPresent) {
+        if (decoder->repetitionCount == AVIF_REPETITION_COUNT_INFINITE) {
+            printf(" * Repeat Count   : Infinite\n");
+        } else if (decoder->repetitionCount == AVIF_REPETITION_COUNT_UNKNOWN) {
+            printf(" * Repeat Count   : Unknown\n");
+        } else {
+            printf(" * Repeat Count   : %d\n", decoder->repetitionCount);
+        }
+    }
+}
+
+void avifPrintVersions(void)
+{
+    char codecVersions[256];
+    avifCodecVersions(codecVersions);
+    printf("Version: %s (%s)\n", avifVersion(), codecVersions);
+
+    unsigned int libyuvVersion = avifLibYUVVersion();
+    if (libyuvVersion == 0) {
+        printf("libyuv : unavailable\n");
+    } else {
+        printf("libyuv : available (%u)\n", libyuvVersion);
+    }
+
+    printf("\n");
+}
+
+avifAppFileFormat avifGuessFileFormat(const char * filename)
+{
+    // Guess from the file header
+    FILE * f = fopen(filename, "rb");
+    if (f) {
+        uint8_t headerBuffer[144];
+        size_t bytesRead = fread(headerBuffer, 1, sizeof(headerBuffer), f);
+        fclose(f);
+
+        if (bytesRead > 0) {
+            // If the file could be read, use the first bytes to guess the file format.
+            return avifGuessBufferFileFormat(headerBuffer, bytesRead);
+        }
+    }
+
+    // If we get here, the file header couldn't be read for some reason. Guess from the extension.
+
+    const char * fileExt = strrchr(filename, '.');
+    if (!fileExt) {
+        return AVIF_APP_FILE_FORMAT_UNKNOWN;
+    }
+    ++fileExt; // skip past the dot
+
+    char lowercaseExt[8]; // This only needs to fit up to "jpeg", so this is plenty
+    const size_t fileExtLen = strlen(fileExt);
+    if (fileExtLen >= sizeof(lowercaseExt)) { // >= accounts for NULL terminator
+        return AVIF_APP_FILE_FORMAT_UNKNOWN;
+    }
+
+    for (size_t i = 0; i < fileExtLen; ++i) {
+        lowercaseExt[i] = (char)tolower((unsigned char)fileExt[i]);
+    }
+    lowercaseExt[fileExtLen] = 0;
+
+    if (!strcmp(lowercaseExt, "avif")) {
+        return AVIF_APP_FILE_FORMAT_AVIF;
+    } else if (!strcmp(lowercaseExt, "y4m")) {
+        return AVIF_APP_FILE_FORMAT_Y4M;
+    } else if (!strcmp(lowercaseExt, "jpg") || !strcmp(lowercaseExt, "jpeg")) {
+        return AVIF_APP_FILE_FORMAT_JPEG;
+    } else if (!strcmp(lowercaseExt, "png")) {
+        return AVIF_APP_FILE_FORMAT_PNG;
+    }
+    return AVIF_APP_FILE_FORMAT_UNKNOWN;
+}
+
+avifAppFileFormat avifGuessBufferFileFormat(const uint8_t * data, size_t size)
+{
+    if (size == 0) {
+        return AVIF_APP_FILE_FORMAT_UNKNOWN;
+    }
+
+    avifROData header;
+    header.data = data;
+    header.size = size;
+
+    if (avifPeekCompatibleFileType(&header)) {
+        return AVIF_APP_FILE_FORMAT_AVIF;
+    }
+
+    static const uint8_t signatureJPEG[2] = { 0xFF, 0xD8 };
+    static const uint8_t signaturePNG[8] = { 0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A };
+    static const uint8_t signatureY4M[9] = { 0x59, 0x55, 0x56, 0x34, 0x4D, 0x50, 0x45, 0x47, 0x32 }; // "YUV4MPEG2"
+    struct avifHeaderSignature
+    {
+        avifAppFileFormat format;
+        const uint8_t * magic;
+        size_t magicSize;
+    } signatures[] = { { AVIF_APP_FILE_FORMAT_JPEG, signatureJPEG, sizeof(signatureJPEG) },
+                       { AVIF_APP_FILE_FORMAT_PNG, signaturePNG, sizeof(signaturePNG) },
+                       { AVIF_APP_FILE_FORMAT_Y4M, signatureY4M, sizeof(signatureY4M) } };
+    const size_t signaturesCount = sizeof(signatures) / sizeof(signatures[0]);
+
+    for (size_t signatureIndex = 0; signatureIndex < signaturesCount; ++signatureIndex) {
+        const struct avifHeaderSignature * const signature = &signatures[signatureIndex];
+        if (header.size < signature->magicSize) {
+            continue;
+        }
+        if (!memcmp(header.data, signature->magic, signature->magicSize)) {
+            return signature->format;
+        }
+    }
+
+    return AVIF_APP_FILE_FORMAT_UNKNOWN;
+}
+
+avifAppFileFormat avifReadImage(const char * filename,
+                                avifPixelFormat requestedFormat,
+                                int requestedDepth,
+                                avifChromaDownsampling chromaDownsampling,
+                                avifBool ignoreColorProfile,
+                                avifBool ignoreExif,
+                                avifBool ignoreXMP,
+                                avifBool allowChangingCicp,
+                                avifBool ignoreGainMap,
+                                uint32_t imageSizeLimit,
+                                avifImage * image,
+                                uint32_t * outDepth,
+                                avifAppSourceTiming * sourceTiming,
+                                struct y4mFrameIterator ** frameIter)
+{
+    const avifAppFileFormat format = avifGuessFileFormat(filename);
+    if (format == AVIF_APP_FILE_FORMAT_Y4M) {
+        if (!y4mRead(filename, imageSizeLimit, image, sourceTiming, frameIter)) {
+            return AVIF_APP_FILE_FORMAT_UNKNOWN;
+        }
+        if (outDepth) {
+            *outDepth = image->depth;
+        }
+    } else if (format == AVIF_APP_FILE_FORMAT_JPEG) {
+        // imageSizeLimit is also used to limit Exif and XMP metadata here.
+        if (!avifJPEGRead(filename, image, requestedFormat, requestedDepth, chromaDownsampling, ignoreColorProfile, ignoreExif, ignoreXMP, ignoreGainMap, imageSizeLimit)) {
+            return AVIF_APP_FILE_FORMAT_UNKNOWN;
+        }
+        if (outDepth) {
+            *outDepth = 8;
+        }
+    } else if (format == AVIF_APP_FILE_FORMAT_PNG) {
+        if (!avifPNGRead(filename,
+                         image,
+                         requestedFormat,
+                         requestedDepth,
+                         chromaDownsampling,
+                         ignoreColorProfile,
+                         ignoreExif,
+                         ignoreXMP,
+                         allowChangingCicp,
+                         imageSizeLimit,
+                         outDepth)) {
+            return AVIF_APP_FILE_FORMAT_UNKNOWN;
+        }
+    } else {
+        fprintf(stderr, "Unrecognized file format for input file: %s\n", filename);
+        return AVIF_APP_FILE_FORMAT_UNKNOWN;
+    }
+    return format;
+}
+
+avifBool avifReadEntireFile(const char * filename, avifRWData * raw)
+{
+    FILE * f = fopen(filename, "rb");
+    if (!f) {
+        return AVIF_FALSE;
+    }
+
+    fseek(f, 0, SEEK_END);
+    long pos = ftell(f);
+    if (pos <= 0) {
+        fclose(f);
+        return AVIF_FALSE;
+    }
+    size_t fileSize = (size_t)pos;
+    fseek(f, 0, SEEK_SET);
+
+    if (avifRWDataRealloc(raw, fileSize) != AVIF_RESULT_OK) {
+        fclose(f);
+        return AVIF_FALSE;
+    }
+    size_t bytesRead = fread(raw->data, 1, fileSize, f);
+    fclose(f);
+
+    if (bytesRead != fileSize) {
+        avifRWDataFree(raw);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+void avifImageFixXMP(avifImage * image)
+{
+    // Zero bytes are forbidden in UTF-8 XML: https://en.wikipedia.org/wiki/Valid_characters_in_XML
+    // Keeping zero bytes in XMP may lead to issues at encoding or decoding.
+    // For example, the PNG specification forbids null characters in XMP. See avifPNGWrite().
+    // The XMP Specification Part 3 says "When XMP is encoded as UTF-8,
+    // there are no zero bytes in the XMP packet" for GIF.
+
+    // Consider a single trailing null character following a non-null character
+    // as a programming error. Leave other null characters as is.
+    // See the discussion at https://github.com/AOMediaCodec/libavif/issues/1333.
+    if (image->xmp.size >= 2 && image->xmp.data[image->xmp.size - 1] == '\0' && image->xmp.data[image->xmp.size - 2] != '\0') {
+        --image->xmp.size;
+    }
+}
+
+void avifDumpDiagnostics(const avifDiagnostics * diag)
+{
+    if (!*diag->error) {
+        return;
+    }
+
+    printf("Diagnostics:\n");
+    printf(" * %s\n", diag->error);
+}
+
+// ---------------------------------------------------------------------------
+// avifQueryCPUCount (separated into OS implementations)
+
+#if defined(_WIN32)
+
+// Windows
+
+#include <windows.h>
+
+int avifQueryCPUCount(void)
+{
+    int numCPU;
+    SYSTEM_INFO sysinfo;
+    GetSystemInfo(&sysinfo);
+    numCPU = sysinfo.dwNumberOfProcessors;
+    return numCPU;
+}
+
+#elif defined(__APPLE__)
+
+// Apple
+
+#include <sys/sysctl.h>
+
+int avifQueryCPUCount()
+{
+    int mib[4];
+    int numCPU;
+    size_t len = sizeof(numCPU);
+
+    /* set the mib for hw.ncpu */
+    mib[0] = CTL_HW;
+    mib[1] = HW_AVAILCPU; // alternatively, try HW_NCPU;
+
+    /* get the number of CPUs from the system */
+    sysctl(mib, 2, &numCPU, &len, NULL, 0);
+
+    if (numCPU < 1) {
+        mib[1] = HW_NCPU;
+        sysctl(mib, 2, &numCPU, &len, NULL, 0);
+        if (numCPU < 1)
+            numCPU = 1;
+    }
+    return numCPU;
+}
+
+#elif defined(__EMSCRIPTEN__)
+
+// Emscripten
+
+int avifQueryCPUCount()
+{
+    return 1;
+}
+
+#else
+
+// POSIX
+
+#include <unistd.h>
+
+int avifQueryCPUCount()
+{
+    int numCPU = (int)sysconf(_SC_NPROCESSORS_ONLN);
+    return (numCPU > 0) ? numCPU : 1;
+}
+
+#endif
diff --git a/third_party/libavif/src/apps/shared/avifutil.h b/third_party/libavif/src/apps/shared/avifutil.h
new file mode 100644
index 0000000000..734ccf5f02
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/avifutil.h
@@ -0,0 +1,101 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_AVIFUTIL_H
+#define LIBAVIF_APPS_SHARED_AVIFUTIL_H
+
+#include "avif/avif.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// The %z format specifier is not available in the old Windows CRT msvcrt,
+// hence the %I format specifier must be used instead to print out `size_t`.
+// The new Windows CRT UCRT, which is used by Visual Studio 2015 or later,
+// supports the %z specifier properly.
+//
+// Additionally, with c99 set as the standard mingw-w64 toolchains built with
+// the commit mentioned can patch format functions to support the %z specifier,
+// even if it's using the old msvcrt, and this can be detected by
+// the `__USE_MINGW_ANSI_STDIO` macro.
+//
+// Related mingw-w64 commit: bfd33f6c0ec5e652cc9911857dd1492ece8d8383
+
+#if !defined(_UCRT) && (defined(__USE_MINGW_ANSI_STDIO) && __USE_MINGW_ANSI_STDIO == 0)
+#define AVIF_FMT_ZU "Iu"
+#else
+#define AVIF_FMT_ZU "zu"
+#endif
+
+void avifImageDump(const avifImage * avif, uint32_t gridCols, uint32_t gridRows, avifProgressiveState progressiveState);
+void avifContainerDump(const avifDecoder * decoder);
+void avifPrintVersions(void);
+void avifDumpDiagnostics(const avifDiagnostics * diag);
+int avifQueryCPUCount(void); // Returns 1 if it cannot query or fails to query
+
+typedef enum avifAppFileFormat
+{
+    AVIF_APP_FILE_FORMAT_UNKNOWN = 0,
+
+    AVIF_APP_FILE_FORMAT_AVIF,
+    AVIF_APP_FILE_FORMAT_JPEG,
+    AVIF_APP_FILE_FORMAT_PNG,
+    AVIF_APP_FILE_FORMAT_Y4M
+} avifAppFileFormat;
+
+// Guesses the format of a file by looking at the first bytes, or at the extension if the file
+// can't be read or is empty.
+avifAppFileFormat avifGuessFileFormat(const char * filename);
+// Guesses the format of a buffer by looking at the first bytes.
+avifAppFileFormat avifGuessBufferFileFormat(const uint8_t * data, size_t size);
+
+// This structure holds any timing data coming from source (typically non-AVIF) inputs being fed
+// into avifenc. If either or both values are 0, the timing is "invalid" / sentinel and the values
+// should be ignored. This structure is used to override the timing defaults in avifenc when the
+// enduser doesn't provide timing on the commandline and the source content provides a framerate.
+typedef struct avifAppSourceTiming
+{
+    uint64_t duration;  // duration in time units (based on the timescale below)
+    uint64_t timescale; // timescale of the media (Hz)
+} avifAppSourceTiming;
+
+struct y4mFrameIterator;
+// Reads an image from a file with the requested format and depth.
+// At most imageSizeLimit pixels will be read or an error returned.
+// In case of a y4m file, sourceTiming and frameIter can be set.
+// Returns AVIF_APP_FILE_FORMAT_UNKNOWN in case of error.
+// 'ignoreGainMap' is only relevant for jpeg files that have a gain map
+// and only if AVIF_ENABLE_EXPERIMENTAL_JPEG_GAIN_MAP_CONVERSION is ON
+// (requires AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP and libxml2). Otherwise
+// it has no effect.
+avifAppFileFormat avifReadImage(const char * filename,
+                                avifPixelFormat requestedFormat,
+                                int requestedDepth,
+                                avifChromaDownsampling chromaDownsampling,
+                                avifBool ignoreColorProfile,
+                                avifBool ignoreExif,
+                                avifBool ignoreXMP,
+                                avifBool allowChangingCicp,
+                                avifBool ignoreGainMap,
+                                uint32_t imageSizeLimit,
+                                avifImage * image,
+                                uint32_t * outDepth,
+                                avifAppSourceTiming * sourceTiming,
+                                struct y4mFrameIterator ** frameIter);
+
+// Copies all the bytes from the file at filename to a newly allocated memory chunk.
+avifBool avifReadEntireFile(const char * filename, avifRWData * raw);
+
+// Removes a single trailing null character from the image->xmp, if there is exactly one.
+void avifImageFixXMP(avifImage * image);
+
+// Used by image decoders when the user doesn't explicitly choose a format with --yuv
+// This must match the cited fallback for "--yuv auto" in avifenc.c's syntax() function.
+#define AVIF_APP_DEFAULT_PIXEL_FORMAT AVIF_PIXEL_FORMAT_YUV444
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef LIBAVIF_APPS_SHARED_AVIFUTIL_H
diff --git a/third_party/libavif/src/apps/shared/iccmaker.c b/third_party/libavif/src/apps/shared/iccmaker.c
new file mode 100644
index 0000000000..a4fcac083c
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/iccmaker.c
@@ -0,0 +1,480 @@
+// Copyright 2023 Yuan Tong. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "iccmaker.h"
+
+#include <math.h>
+#include <string.h>
+
+// ICCv2 profile specification: https://www.color.org/icc32.pdf
+
+/**
+ * Color Profile Structure
+ *
+ * Header:
+ *  size         = 376 bytes (*1)
+ *  CMM          = 'lcms' (*2)
+ *  Version      = 2.2.0
+ *  Device Class = Display
+ *  Color Space  = RGB
+ *  Conn. Space  = XYZ
+ *  Date, Time   = 1 Jan 2000, 0:00:00
+ *  Platform     = Microsoft
+ *  Flags        = Not Embedded Profile, Use anywhere
+ *  Dev. Mnfctr. = 0x0
+ *  Dev. Model   = 0x0
+ *  Dev. Attrbts = Reflective, Glossy, Positive, Color
+ *  Rndrng Intnt = Perceptual
+ *  Illuminant   = 0.96420288, 1.00000000, 0.82490540    [Lab 100.000000, 0.000000, 0.000000]
+ *  Creator      = 'avif'
+ *
+ * Profile Tags:
+ *                    Tag    ID      Offset         Size                 Value
+ *                   ----  ------    ------         ----                 -----
+ *  profileDescriptionTag  'desc'       240           95                  avif
+ *     mediaWhitePointTag  'wtpt'       268 (*3)      20        (to be filled)
+ *         redColorantTag  'rXYZ'       288           20        (to be filled)
+ *       greenColorantTag  'gXYZ'       308           20        (to be filled)
+ *        blueColorantTag  'bXYZ'       328           20        (to be filled)
+ *              redTRCTag  'rTRC'       348 (*4)      16        (to be filled)
+ *            greenTRCTag  'gTRC'       348           16        (to be filled)
+ *             blueTRCTag  'bTRC'       348           16        (to be filled)
+ *           copyrightTag  'cprt'       364           12                   CC0
+ *
+ * (*1): The template data is padded to 448 bytes according to MD5 specification, so that computation can be applied
+ *       directly on it. The actual ICC profile data is the first 376 bytes.
+ * (*2): 6.1.2 CMM Type: The signatures must be registered in order to avoid conflicts.
+ *       The registry can be found at https://www.color.org/signatures2.xalter (Private and ICC tag and CMM registry)
+ *       Therefore we are using the signature of Little CMS.
+ * (*3): The profileDescriptionTag requires 95 bytes of data, but with some trick, the content of the last 67 bytes
+ *       can be anything. Therefore we are placing the following tags in this region to reduce profile size.
+ * (*4): The transfer characteristic (gamma) of the 3 channels are the same, so the data can be shared.
+ */
+
+static const uint8_t iccColorTemplate[448] = {
+    0x00, 0x00, 0x01, 0x78, 0x6c, 0x63, 0x6d, 0x73, 0x02, 0x20, 0x00, 0x00, 0x6d, 0x6e, 0x74, 0x72, 0x52, 0x47, 0x42, 0x20, 0x58,
+    0x59, 0x5a, 0x20, 0x07, 0xd0, 0x00, 0x01, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x61, 0x63, 0x73, 0x70, 0x4d, 0x53,
+    0x46, 0x54, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf6, 0xd6, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0xd3, 0x2d, 0x61, 0x76, 0x69, 0x66,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x09, 0x64, 0x65, 0x73, 0x63, 0x00, 0x00, 0x00, 0xf0, 0x00, 0x00, 0x00, 0x5f, 0x77, 0x74, 0x70,
+    0x74, 0x00, 0x00, 0x01, 0x0c, 0x00, 0x00, 0x00, 0x14, 0x72, 0x58, 0x59, 0x5a, 0x00, 0x00, 0x01, 0x20, 0x00, 0x00, 0x00, 0x14,
+    0x67, 0x58, 0x59, 0x5a, 0x00, 0x00, 0x01, 0x34, 0x00, 0x00, 0x00, 0x14, 0x62, 0x58, 0x59, 0x5a, 0x00, 0x00, 0x01, 0x48, 0x00,
+    0x00, 0x00, 0x14, 0x72, 0x54, 0x52, 0x43, 0x00, 0x00, 0x01, 0x5c, 0x00, 0x00, 0x00, 0x10, 0x67, 0x54, 0x52, 0x43, 0x00, 0x00,
+    0x01, 0x5c, 0x00, 0x00, 0x00, 0x10, 0x62, 0x54, 0x52, 0x43, 0x00, 0x00, 0x01, 0x5c, 0x00, 0x00, 0x00, 0x10, 0x63, 0x70, 0x72,
+    0x74, 0x00, 0x00, 0x01, 0x6c, 0x00, 0x00, 0x00, 0x0c, 0x64, 0x65, 0x73, 0x63, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05,
+    0x61, 0x76, 0x69, 0x66, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x58, 0x59, 0x5a, 0x20, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0xf3, 0x54, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x16, 0xc9, 0x58, 0x59, 0x5a, 0x20, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x6f, 0xa0, 0x00, 0x00, 0x38, 0xf2, 0x00, 0x00, 0x03, 0x8f, 0x58, 0x59, 0x5a, 0x20, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x62, 0x96, 0x00, 0x00, 0xb7, 0x89, 0x00, 0x00, 0x18, 0xda, 0x58, 0x59, 0x5a, 0x20, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x24, 0xa0, 0x00, 0x00, 0x0f, 0x85, 0x00, 0x00, 0xb6, 0xc4, 0x63, 0x75, 0x72, 0x76, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00, 0x74, 0x65, 0x78, 0x74, 0x00, 0x00, 0x00, 0x00, 0x43, 0x43, 0x30, 0x00, 0x80, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc0,
+    0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+};
+
+static const size_t iccColorLength = 376;
+
+static const ptrdiff_t colorWhiteOffset = 0x114;
+static const ptrdiff_t colorRedOffset = 0x128;
+static const ptrdiff_t colorGreenOffset = 0x13c;
+static const ptrdiff_t colorBlueOffset = 0x150;
+static const ptrdiff_t colorGammaOffset = 0x168;
+
+/**
+ * Gray Profile Structure
+ *
+ * Header:
+ *  size         = 275 bytes
+ *  CMM          = 'lcms'
+ *  Version      = 2.2.0
+ *  Device Class = Display
+ *  Color Space  = Gray
+ *  Conn. Space  = XYZ
+ *  Date, Time   = 1 Jan 2000, 0:00:00
+ *  Platform     = Microsoft
+ *  Flags        = Not Embedded Profile, Use anywhere
+ *  Dev. Mnfctr. = 0x0
+ *  Dev. Model   = 0x0
+ *  Dev. Attrbts = Reflective, Glossy, Positive, Color
+ *  Rndrng Intnt = Perceptual
+ *  Illuminant   = 0.96420288, 1.00000000, 0.82490540    [Lab 100.000000, 0.000000, 0.000000]
+ *  Creator      = 'avif'
+ *
+ * Profile Tags:
+ *                    Tag    ID      Offset         Size                 Value
+ *                   ----  ------    ------         ----                 -----
+ *  profileDescriptionTag  'desc'       180           95                  avif
+ *     mediaWhitePointTag  'wtpt'       208           20        (to be filled)
+ *             grayTRCTag  'kTRC'       228           16        (to be filled)
+ *           copyrightTag  'cprt'       244           12                   CC0
+ */
+
+static const uint8_t iccGrayTemplate[320] = {
+    0x00, 0x00, 0x01, 0x13, 0x6c, 0x63, 0x6d, 0x73, 0x02, 0x20, 0x00, 0x00, 0x6d, 0x6e, 0x74, 0x72, 0x47, 0x52, 0x41, 0x59,
+    0x58, 0x59, 0x5a, 0x20, 0x07, 0xd0, 0x00, 0x01, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x61, 0x63, 0x73, 0x70,
+    0x4d, 0x53, 0x46, 0x54, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf6, 0xd6, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0xd3, 0x2d,
+    0x61, 0x76, 0x69, 0x66, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x64, 0x65, 0x73, 0x63, 0x00, 0x00, 0x00, 0xb4,
+    0x00, 0x00, 0x00, 0x5f, 0x77, 0x74, 0x70, 0x74, 0x00, 0x00, 0x00, 0xd0, 0x00, 0x00, 0x00, 0x14, 0x6b, 0x54, 0x52, 0x43,
+    0x00, 0x00, 0x00, 0xe4, 0x00, 0x00, 0x00, 0x10, 0x63, 0x70, 0x72, 0x74, 0x00, 0x00, 0x00, 0xf4, 0x00, 0x00, 0x00, 0x0c,
+    0x64, 0x65, 0x73, 0x63, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x05, 0x61, 0x76, 0x69, 0x66, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x58, 0x59, 0x5a, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xf3, 0x54,
+    0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x16, 0xc9, 0x63, 0x75, 0x72, 0x76, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+    0x01, 0x00, 0x00, 0x00, 0x74, 0x65, 0x78, 0x74, 0x00, 0x00, 0x00, 0x00, 0x43, 0x43, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x98, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+};
+
+static const size_t iccGrayLength = 275;
+
+static const ptrdiff_t grayWhiteOffset = 0xd8;
+static const ptrdiff_t grayGammaOffset = 0xf0;
+
+static const ptrdiff_t checksumOffset = 0x54;
+
+static const double small = 1e-12;
+
+static uint32_t readLittleEndianU32(const uint8_t * data)
+{
+    return ((uint32_t)data[0] << 0) | ((uint32_t)data[1] << 8) | ((uint32_t)data[2] << 16) | ((uint32_t)data[3] << 24);
+}
+
+static void writeLittleEndianU32(uint8_t * data, uint32_t value)
+{
+    data[0] = (value >> 0) & 0xff;
+    data[1] = (value >> 8) & 0xff;
+    data[2] = (value >> 16) & 0xff;
+    data[3] = (value >> 24) & 0xff;
+}
+
+static void writeBigEndianU16(uint8_t * data, uint16_t value)
+{
+    data[0] = (value >> 8) & 0xff;
+    data[1] = (value >> 0) & 0xff;
+}
+
+static void writeBigEndianU32(uint8_t * data, uint32_t value)
+{
+    data[0] = (value >> 24) & 0xff;
+    data[1] = (value >> 16) & 0xff;
+    data[2] = (value >> 8) & 0xff;
+    data[3] = (value >> 0) & 0xff;
+}
+
+static avifBool putS15Fixed16(uint8_t * data, double value)
+{
+    value = round(value * 65536);
+    if (value > INT32_MAX || value < INT32_MIN) {
+        return AVIF_FALSE;
+    }
+
+    int32_t fixed = (int32_t)value;
+    // reinterpret into uint32_t to ensure the exact bits are written.
+    writeBigEndianU32(data, *(uint32_t *)&fixed);
+
+    return AVIF_TRUE;
+}
+
+static avifBool putU8Fixed8(uint8_t * data, float value)
+{
+    value = roundf(value * 256);
+    if (value > UINT16_MAX || value < 1) {
+        return AVIF_FALSE;
+    }
+
+    uint16_t fixed = (uint16_t)value;
+    writeBigEndianU16(data, fixed);
+    return AVIF_TRUE;
+}
+
+static avifBool putColorant(uint8_t * data, const double XYZ[3])
+{
+    if (!putS15Fixed16(data, XYZ[0])) {
+        return AVIF_FALSE;
+    }
+
+    if (!putS15Fixed16(data + 4, XYZ[1])) {
+        return AVIF_FALSE;
+    }
+
+    if (!putS15Fixed16(data + 8, XYZ[2])) {
+        return AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
+
+static avifBool xyToXYZ(const float xy[2], double XYZ[3])
+{
+    if (fabsf(xy[1]) < small) {
+        return AVIF_FALSE;
+    }
+
+    const double factor = 1.0 / xy[1];
+    XYZ[0] = xy[0] * factor;
+    XYZ[1] = 1;
+    XYZ[2] = (1 - xy[0] - xy[1]) * factor;
+
+    return AVIF_TRUE;
+}
+
+// Computes I = M^-1. Returns false if M seems to be singular.
+static avifBool matInv(const double M[3][3], double I[3][3])
+{
+    double det = M[0][0] * (M[1][1] * M[2][2] - M[2][1] * M[1][2]) - M[0][1] * (M[1][0] * M[2][2] - M[1][2] * M[2][0]) +
+                 M[0][2] * (M[1][0] * M[2][1] - M[1][1] * M[2][0]);
+    if (fabs(det) < small) {
+        return AVIF_FALSE;
+    }
+    det = 1 / det;
+
+    I[0][0] = (M[1][1] * M[2][2] - M[2][1] * M[1][2]) * det;
+    I[0][1] = (M[0][2] * M[2][1] - M[0][1] * M[2][2]) * det;
+    I[0][2] = (M[0][1] * M[1][2] - M[0][2] * M[1][1]) * det;
+    I[1][0] = (M[1][2] * M[2][0] - M[1][0] * M[2][2]) * det;
+    I[1][1] = (M[0][0] * M[2][2] - M[0][2] * M[2][0]) * det;
+    I[1][2] = (M[1][0] * M[0][2] - M[0][0] * M[1][2]) * det;
+    I[2][0] = (M[1][0] * M[2][1] - M[2][0] * M[1][1]) * det;
+    I[2][1] = (M[2][0] * M[0][1] - M[0][0] * M[2][1]) * det;
+    I[2][2] = (M[0][0] * M[1][1] - M[1][0] * M[0][1]) * det;
+
+    return AVIF_TRUE;
+}
+
+// Computes C = A*B
+static void matMul(const double A[3][3], const double B[3][3], double C[3][3])
+{
+    C[0][0] = A[0][0] * B[0][0] + A[0][1] * B[1][0] + A[0][2] * B[2][0];
+    C[0][1] = A[0][0] * B[0][1] + A[0][1] * B[1][1] + A[0][2] * B[2][1];
+    C[0][2] = A[0][0] * B[0][2] + A[0][1] * B[1][2] + A[0][2] * B[2][2];
+    C[1][0] = A[1][0] * B[0][0] + A[1][1] * B[1][0] + A[1][2] * B[2][0];
+    C[1][1] = A[1][0] * B[0][1] + A[1][1] * B[1][1] + A[1][2] * B[2][1];
+    C[1][2] = A[1][0] * B[0][2] + A[1][1] * B[1][2] + A[1][2] * B[2][2];
+    C[2][0] = A[2][0] * B[0][0] + A[2][1] * B[1][0] + A[2][2] * B[2][0];
+    C[2][1] = A[2][0] * B[0][1] + A[2][1] * B[1][1] + A[2][2] * B[2][1];
+    C[2][2] = A[2][0] * B[0][2] + A[2][1] * B[1][2] + A[2][2] * B[2][2];
+}
+
+// Set M to have values of d on the leading diagonal, and zero elsewhere.
+static void matDiag(const double d[3], double M[3][3])
+{
+    M[0][0] = d[0];
+    M[0][1] = 0;
+    M[0][2] = 0;
+    M[1][0] = 0;
+    M[1][1] = d[1];
+    M[1][2] = 0;
+    M[2][0] = 0;
+    M[2][1] = 0;
+    M[2][2] = d[2];
+}
+
+static void swap(double * a, double * b)
+{
+    double tmp = *a;
+    *a = *b;
+    *b = tmp;
+}
+
+// Transpose M
+static void matTrans(double M[3][3])
+{
+    swap(&M[0][1], &M[1][0]);
+    swap(&M[0][2], &M[2][0]);
+    swap(&M[1][2], &M[2][1]);
+}
+
+// Computes y = M.x
+static void vecMul(const double M[3][3], const double x[3], double y[3])
+{
+    y[0] = M[0][0] * x[0] + M[0][1] * x[1] + M[0][2] * x[2];
+    y[1] = M[1][0] * x[0] + M[1][1] * x[1] + M[1][2] * x[2];
+    y[2] = M[2][0] * x[0] + M[2][1] * x[1] + M[2][2] * x[2];
+}
+
+// MD5 algorithm. See https://www.ietf.org/rfc/rfc1321.html#appendix-A.3
+// This function writes the MD5 checksum in place at offset `checksumOffset` of `data`.
+// This function shall only be called with a copy of iccColorTemplate or iccGrayTemplate, and sizeof(icc*Template).
+static void computeMD5(uint8_t * data, size_t length)
+{
+    static const uint32_t sineparts[64] = {
+        0xd76aa478, 0xe8c7b756, 0x242070db, 0xc1bdceee, 0xf57c0faf, 0x4787c62a, 0xa8304613, 0xfd469501, 0x698098d8, 0x8b44f7af,
+        0xffff5bb1, 0x895cd7be, 0x6b901122, 0xfd987193, 0xa679438e, 0x49b40821, 0xf61e2562, 0xc040b340, 0x265e5a51, 0xe9b6c7aa,
+        0xd62f105d, 0x02441453, 0xd8a1e681, 0xe7d3fbc8, 0x21e1cde6, 0xc33707d6, 0xf4d50d87, 0x455a14ed, 0xa9e3e905, 0xfcefa3f8,
+        0x676f02d9, 0x8d2a4c8a, 0xfffa3942, 0x8771f681, 0x6d9d6122, 0xfde5380c, 0xa4beea44, 0x4bdecfa9, 0xf6bb4b60, 0xbebfbc70,
+        0x289b7ec6, 0xeaa127fa, 0xd4ef3085, 0x04881d05, 0xd9d4d039, 0xe6db99e5, 0x1fa27cf8, 0xc4ac5665, 0xf4292244, 0x432aff97,
+        0xab9423a7, 0xfc93a039, 0x655b59c3, 0x8f0ccc92, 0xffeff47d, 0x85845dd1, 0x6fa87e4f, 0xfe2ce6e0, 0xa3014314, 0x4e0811a1,
+        0xf7537e82, 0xbd3af235, 0x2ad7d2bb, 0xeb86d391,
+    };
+    static const uint8_t shift[64] = {
+        7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 5, 9,  14, 20, 5, 9,  14, 20, 5, 9,  14, 20, 5, 9,  14, 20,
+        4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21,
+    };
+
+    uint32_t a0 = 0x67452301, b0 = 0xefcdab89, c0 = 0x98badcfe, d0 = 0x10325476;
+
+    for (uint32_t i = 0; i < length; i += 64) {
+        uint32_t a = a0, b = b0, c = c0, d = d0, f, g;
+        for (uint32_t j = 0; j < 64; j++) {
+            if (j < 16) {
+                f = (b & c) | ((~b) & d);
+                g = j;
+            } else if (j < 32) {
+                f = (d & b) | ((~d) & c);
+                g = (5 * j + 1) & 0xf;
+            } else if (j < 48) {
+                f = b ^ c ^ d;
+                g = (3 * j + 5) & 0xf;
+            } else {
+                f = c ^ (b | (~d));
+                g = (7 * j) & 0xf;
+            }
+            uint32_t u = readLittleEndianU32(data + i + g * 4);
+            f += a + sineparts[j] + u;
+            a = d;
+            d = c;
+            c = b;
+            b += (f << shift[j]) | (f >> (32u - shift[j]));
+        }
+        a0 += a;
+        b0 += b;
+        c0 += c;
+        d0 += d;
+    }
+
+    uint8_t * output = data + checksumOffset;
+    writeLittleEndianU32(output, a0);
+    writeLittleEndianU32(output + 4, b0);
+    writeLittleEndianU32(output + 8, c0);
+    writeLittleEndianU32(output + 12, d0);
+}
+
+// Bradford chromatic adaptation matrix
+// from https://www.researchgate.net/publication/253799640_A_uniform_colour_space_based_upon_CIECAM97s
+static const double bradford[3][3] = {
+    { 0.8951, 0.2664, -0.1614 },
+    { -0.7502, 1.7135, 0.0367 },
+    { 0.0389, -0.0685, 1.0296 },
+};
+
+// LMS values for D50 whitepoint
+static const double lmsD50[3] = { 0.996284, 1.02043, 0.818644 };
+
+avifBool avifGenerateRGBICC(avifRWData * icc, float gamma, const float primaries[8])
+{
+    uint8_t buffer[sizeof(iccColorTemplate)];
+    memcpy(buffer, iccColorTemplate, sizeof(iccColorTemplate));
+
+    double whitePointXYZ[3];
+    if (!xyToXYZ(&primaries[6], whitePointXYZ)) {
+        return AVIF_FALSE;
+    }
+
+    if (!putColorant(buffer + colorWhiteOffset, whitePointXYZ)) {
+        return AVIF_FALSE;
+    }
+
+    const double rgbPrimaries[3][3] = {
+        { primaries[0], primaries[2], primaries[4] },
+        { primaries[1], primaries[3], primaries[5] },
+        { 1.0 - primaries[0] - primaries[1], 1.0 - primaries[2] - primaries[3], 1.0 - primaries[4] - primaries[5] }
+    };
+
+    double rgbPrimariesInv[3][3];
+    if (!matInv(rgbPrimaries, rgbPrimariesInv)) {
+        return AVIF_FALSE;
+    }
+
+    double rgbCoefficients[3];
+    vecMul(rgbPrimariesInv, whitePointXYZ, rgbCoefficients);
+
+    double rgbCoefficientsMat[3][3];
+    matDiag(rgbCoefficients, rgbCoefficientsMat);
+
+    double rgbXYZ[3][3];
+    matMul(rgbPrimaries, rgbCoefficientsMat, rgbXYZ);
+
+    // ICC stores primaries XYZ under PCS.
+    // Adapt using linear bradford transform
+    // from https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119021780.app3
+    double lms[3];
+    vecMul(bradford, whitePointXYZ, lms);
+    for (int i = 0; i < 3; ++i) {
+        if (fabs(lms[i]) < small) {
+            return AVIF_FALSE;
+        }
+        lms[i] = lmsD50[i] / lms[i];
+    }
+
+    double adaptation[3][3];
+    matDiag(lms, adaptation);
+
+    double tmp[3][3];
+    matMul(adaptation, bradford, tmp);
+
+    double bradfordInv[3][3];
+    if (!matInv(bradford, bradfordInv)) {
+        return AVIF_FALSE;
+    }
+    matMul(bradfordInv, tmp, adaptation);
+
+    double rgbXYZD50[3][3];
+    matMul(adaptation, rgbXYZ, rgbXYZD50);
+    matTrans(rgbXYZD50);
+
+    if (!putColorant(buffer + colorRedOffset, rgbXYZD50[0])) {
+        return AVIF_FALSE;
+    }
+
+    if (!putColorant(buffer + colorGreenOffset, rgbXYZD50[1])) {
+        return AVIF_FALSE;
+    }
+
+    if (!putColorant(buffer + colorBlueOffset, rgbXYZD50[2])) {
+        return AVIF_FALSE;
+    }
+
+    if (!putU8Fixed8(buffer + colorGammaOffset, gamma)) {
+        return AVIF_FALSE;
+    }
+
+    computeMD5(buffer, sizeof(iccColorTemplate));
+    if (avifRWDataSet(icc, buffer, iccColorLength) != AVIF_RESULT_OK) {
+        return AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
+
+avifBool avifGenerateGrayICC(avifRWData * icc, float gamma, const float white[2])
+{
+    uint8_t buffer[sizeof(iccGrayTemplate)];
+    memcpy(buffer, iccGrayTemplate, sizeof(iccGrayTemplate));
+
+    double whitePointXYZ[3];
+    if (!xyToXYZ(white, whitePointXYZ)) {
+        return AVIF_FALSE;
+    }
+
+    if (!putColorant(buffer + grayWhiteOffset, whitePointXYZ)) {
+        return AVIF_FALSE;
+    }
+
+    if (!putU8Fixed8(buffer + grayGammaOffset, gamma)) {
+        return AVIF_FALSE;
+    }
+
+    computeMD5(buffer, sizeof(iccGrayTemplate));
+    if (avifRWDataSet(icc, buffer, iccGrayLength) != AVIF_RESULT_OK) {
+        return AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
diff --git a/third_party/libavif/src/apps/shared/iccmaker.h b/third_party/libavif/src/apps/shared/iccmaker.h
new file mode 100644
index 0000000000..7524c4a06d
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/iccmaker.h
@@ -0,0 +1,23 @@
+// Copyright 2023 Yuan Tong. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_ICCMAKER_H
+#define LIBAVIF_APPS_SHARED_ICCMAKER_H
+
+#include "avif/avif.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Note to libavif maintainers:
+// These ICC maker functions only serve to handle legacy color space
+// information in PNG files, and shall not be moved to libavif itself.
+avifBool avifGenerateRGBICC(avifRWData * icc, float gamma, const float primaries[8]);
+avifBool avifGenerateGrayICC(avifRWData * icc, float gamma, const float white[2]);
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif //LIBAVIF_APPS_SHARED_ICCMAKER_H
diff --git a/third_party/libavif/src/apps/shared/y4m.c b/third_party/libavif/src/apps/shared/y4m.c
new file mode 100644
index 0000000000..afdb59f1d7
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/y4m.c
@@ -0,0 +1,611 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+// This is a barebones y4m reader/writer for basic libavif testing. It is NOT comprehensive!
+
+#include "y4m.h"
+
+#include <assert.h>
+#include <inttypes.h>
+#include <limits.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+#include "avif/avif.h"
+#include "avifutil.h"
+
+#define Y4M_MAX_LINE_SIZE 2048 // Arbitrary limit. Y4M headers should be much smaller than this
+
+struct y4mFrameIterator
+{
+    int width;
+    int height;
+    int depth;
+    avifBool hasAlpha;
+    avifPixelFormat format;
+    avifRange range;
+    avifChromaSamplePosition chromaSamplePosition;
+    avifAppSourceTiming sourceTiming;
+
+    FILE * inputFile;
+    const char * displayFilename;
+};
+
+// Sets frame->format, frame->depth, frame->hasAlpha, and frame->chromaSamplePosition.
+static avifBool y4mColorSpaceParse(const char * formatString, struct y4mFrameIterator * frame)
+{
+    frame->hasAlpha = AVIF_FALSE;
+    frame->chromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+
+    if (!strcmp(formatString, "C420jpeg")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 8;
+        // Chroma sample position is center.
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C420mpeg2")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 8;
+        frame->chromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_VERTICAL;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C420paldv")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 8;
+        frame->chromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_COLOCATED;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C444p10")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV444;
+        frame->depth = 10;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C422p10")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV422;
+        frame->depth = 10;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C420p10")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 10;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C422p10")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV422;
+        frame->depth = 10;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C444p12")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV444;
+        frame->depth = 12;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C422p12")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV422;
+        frame->depth = 12;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C420p12")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 12;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C422p12")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV422;
+        frame->depth = 12;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C444")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV444;
+        frame->depth = 8;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C444alpha")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV444;
+        frame->depth = 8;
+        frame->hasAlpha = AVIF_TRUE;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C422")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV422;
+        frame->depth = 8;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "C420")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV420;
+        frame->depth = 8;
+        // Chroma sample position is center.
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "Cmono")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV400;
+        frame->depth = 8;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "Cmono10")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV400;
+        frame->depth = 10;
+        return AVIF_TRUE;
+    }
+    if (!strcmp(formatString, "Cmono12")) {
+        frame->format = AVIF_PIXEL_FORMAT_YUV400;
+        frame->depth = 12;
+        return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+// Returns an unsigned integer value parsed from [start:end[.
+// Returns -1 in case of failure.
+static int y4mReadUnsignedInt(const char * start, const char * end)
+{
+    const char * p = start;
+    int64_t value = 0;
+    while (p < end && *p >= '0' && *p <= '9') {
+        value = value * 10 + (*(p++) - '0');
+        if (value > INT_MAX) {
+            return -1;
+        }
+    }
+    return (p == start) ? -1 : (int)value;
+}
+
+// Note: this modifies framerateString
+static avifBool y4mFramerateParse(char * framerateString, avifAppSourceTiming * sourceTiming)
+{
+    if (framerateString[0] != 'F') {
+        return AVIF_FALSE;
+    }
+    ++framerateString; // skip past 'F'
+
+    char * colonLocation = strchr(framerateString, ':');
+    if (!colonLocation) {
+        return AVIF_FALSE;
+    }
+    *colonLocation = 0;
+    ++colonLocation;
+
+    int numerator = atoi(framerateString);
+    int denominator = atoi(colonLocation);
+    if ((numerator < 1) || (denominator < 1)) {
+        return AVIF_FALSE;
+    }
+
+    sourceTiming->timescale = (uint64_t)numerator;
+    sourceTiming->duration = (uint64_t)denominator;
+    return AVIF_TRUE;
+}
+
+static avifBool getHeaderString(uint8_t * p, uint8_t * end, char * out, size_t maxChars)
+{
+    uint8_t * headerEnd = p;
+    while ((*headerEnd != ' ') && (*headerEnd != '\n')) {
+        if (headerEnd >= end) {
+            return AVIF_FALSE;
+        }
+        ++headerEnd;
+    }
+    size_t formatLen = headerEnd - p;
+    if (formatLen > maxChars) {
+        return AVIF_FALSE;
+    }
+
+    strncpy(out, (const char *)p, formatLen);
+    out[formatLen] = 0;
+    return AVIF_TRUE;
+}
+
+static int y4mReadLine(FILE * inputFile, avifRWData * raw, const char * displayFilename)
+{
+    static const int maxBytes = Y4M_MAX_LINE_SIZE;
+    int bytesRead = 0;
+    uint8_t * front = raw->data;
+
+    for (;;) {
+        if (fread(front, 1, 1, inputFile) != 1) {
+            fprintf(stderr, "Failed to read line: %s\n", displayFilename);
+            break;
+        }
+
+        ++bytesRead;
+        if (bytesRead >= maxBytes) {
+            break;
+        }
+
+        if (*front == '\n') {
+            return bytesRead;
+        }
+        ++front;
+    }
+    return -1;
+}
+
+// Limits each sample value to fit into avif->depth bits.
+// Returns AVIF_TRUE if any sample was clamped this way.
+static avifBool y4mClampSamples(avifImage * avif)
+{
+    if (!avifImageUsesU16(avif)) {
+        assert(avif->depth == 8);
+        return AVIF_FALSE;
+    }
+    assert(avif->depth < 16); // Otherwise it could be skipped too.
+
+    // AV1 encoders and decoders do not care whether the samples are full range or limited range
+    // for the internal computation: it is only passed as an informative tag, so ignore avif->yuvRange.
+    const uint16_t maxSampleValue = (uint16_t)((1u << avif->depth) - 1u);
+
+    avifBool samplesWereClamped = AVIF_FALSE;
+    for (int plane = AVIF_CHAN_Y; plane <= AVIF_CHAN_A; ++plane) {
+        uint32_t planeHeight = avifImagePlaneHeight(avif, plane); // 0 for UV if 4:0:0.
+        uint32_t planeWidth = avifImagePlaneWidth(avif, plane);
+        uint8_t * row = avifImagePlane(avif, plane);
+        uint32_t rowBytes = avifImagePlaneRowBytes(avif, plane);
+        for (uint32_t y = 0; y < planeHeight; ++y) {
+            uint16_t * row16 = (uint16_t *)row;
+            for (uint32_t x = 0; x < planeWidth; ++x) {
+                if (row16[x] > maxSampleValue) {
+                    row16[x] = maxSampleValue;
+                    samplesWereClamped = AVIF_TRUE;
+                }
+            }
+            row += rowBytes;
+        }
+    }
+    return samplesWereClamped;
+}
+
+#define ADVANCE(BYTES)    \
+    do {                  \
+        p += BYTES;       \
+        if (p >= end)     \
+            goto cleanup; \
+    } while (0)
+
+avifBool y4mRead(const char * inputFilename,
+                 uint32_t imageSizeLimit,
+                 avifImage * avif,
+                 avifAppSourceTiming * sourceTiming,
+                 struct y4mFrameIterator ** iter)
+{
+    avifBool result = AVIF_FALSE;
+
+    struct y4mFrameIterator frame;
+    frame.width = -1;
+    frame.height = -1;
+    // Default to the color space "C420" to match the defaults of aomenc and ffmpeg.
+    frame.depth = 8;
+    frame.hasAlpha = AVIF_FALSE;
+    frame.format = AVIF_PIXEL_FORMAT_YUV420;
+    frame.range = AVIF_RANGE_LIMITED;
+    frame.chromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+    memset(&frame.sourceTiming, 0, sizeof(avifAppSourceTiming));
+    frame.inputFile = NULL;
+    frame.displayFilename = inputFilename;
+
+    avifRWData raw = AVIF_DATA_EMPTY;
+    if (avifRWDataRealloc(&raw, Y4M_MAX_LINE_SIZE) != AVIF_RESULT_OK) {
+        fprintf(stderr, "Out of memory\n");
+        goto cleanup;
+    }
+
+    if (iter && *iter) {
+        // Continue reading FRAMEs from this y4m stream
+        frame = **iter;
+    } else {
+        // Open a fresh y4m and read its header
+
+        if (inputFilename) {
+            frame.inputFile = fopen(inputFilename, "rb");
+            if (!frame.inputFile) {
+                fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+                goto cleanup;
+            }
+        } else {
+            frame.inputFile = stdin;
+            frame.displayFilename = "(stdin)";
+        }
+
+        int headerBytes = y4mReadLine(frame.inputFile, &raw, frame.displayFilename);
+        if (headerBytes < 0) {
+            fprintf(stderr, "Y4M header too large: %s\n", frame.displayFilename);
+            goto cleanup;
+        }
+        if (headerBytes < 10) {
+            fprintf(stderr, "Y4M header too small: %s\n", frame.displayFilename);
+            goto cleanup;
+        }
+
+        uint8_t * end = raw.data + headerBytes;
+        uint8_t * p = raw.data;
+
+        if (memcmp(p, "YUV4MPEG2 ", 10) != 0) {
+            fprintf(stderr, "Not a y4m file: %s\n", frame.displayFilename);
+            goto cleanup;
+        }
+        ADVANCE(10); // skip past header
+
+        char tmpBuffer[32];
+
+        while (p != end) {
+            switch (*p) {
+                case 'W': // width
+                    frame.width = y4mReadUnsignedInt((const char *)p + 1, (const char *)end);
+                    break;
+                case 'H': // height
+                    frame.height = y4mReadUnsignedInt((const char *)p + 1, (const char *)end);
+                    break;
+                case 'C': // color space
+                    if (!getHeaderString(p, end, tmpBuffer, 31)) {
+                        fprintf(stderr, "Bad y4m header: %s\n", frame.displayFilename);
+                        goto cleanup;
+                    }
+                    if (!y4mColorSpaceParse(tmpBuffer, &frame)) {
+                        fprintf(stderr, "Unsupported y4m pixel format: %s\n", frame.displayFilename);
+                        goto cleanup;
+                    }
+                    break;
+                case 'F': // framerate
+                    if (!getHeaderString(p, end, tmpBuffer, 31)) {
+                        fprintf(stderr, "Bad y4m header: %s\n", frame.displayFilename);
+                        goto cleanup;
+                    }
+                    if (!y4mFramerateParse(tmpBuffer, &frame.sourceTiming)) {
+                        fprintf(stderr, "Unsupported framerate: %s\n", frame.displayFilename);
+                        goto cleanup;
+                    }
+                    break;
+                case 'X':
+                    if (!getHeaderString(p, end, tmpBuffer, 31)) {
+                        fprintf(stderr, "Bad y4m header: %s\n", frame.displayFilename);
+                        goto cleanup;
+                    }
+                    if (!strcmp(tmpBuffer, "XCOLORRANGE=FULL")) {
+                        frame.range = AVIF_RANGE_FULL;
+                    }
+                    break;
+                default:
+                    break;
+            }
+
+            // Advance past header section
+            while ((*p != '\n') && (*p != ' ')) {
+                ADVANCE(1);
+            }
+            if (*p == '\n') {
+                // Done with y4m header
+                break;
+            }
+
+            ADVANCE(1);
+        }
+
+        if (*p != '\n') {
+            fprintf(stderr, "Truncated y4m header (no newline): %s\n", frame.displayFilename);
+            goto cleanup;
+        }
+    }
+
+    int frameHeaderBytes = y4mReadLine(frame.inputFile, &raw, frame.displayFilename);
+    if (frameHeaderBytes < 0) {
+        fprintf(stderr, "Y4M frame header too large: %s\n", frame.displayFilename);
+        goto cleanup;
+    }
+    if (frameHeaderBytes < 6) {
+        fprintf(stderr, "Y4M frame header too small: %s\n", frame.displayFilename);
+        goto cleanup;
+    }
+    if (memcmp(raw.data, "FRAME", 5) != 0) {
+        fprintf(stderr, "Truncated y4m (no frame): %s\n", frame.displayFilename);
+        goto cleanup;
+    }
+
+    if ((frame.width < 1) || (frame.height < 1) || ((frame.depth != 8) && (frame.depth != 10) && (frame.depth != 12))) {
+        fprintf(stderr, "Failed to parse y4m header (not enough information): %s\n", frame.displayFilename);
+        goto cleanup;
+    }
+    if ((uint32_t)frame.width > imageSizeLimit / (uint32_t)frame.height) {
+        fprintf(stderr, "Too big y4m dimensions (%d x %d > %u px): %s\n", frame.width, frame.height, imageSizeLimit, frame.displayFilename);
+        goto cleanup;
+    }
+
+    if (sourceTiming) {
+        *sourceTiming = frame.sourceTiming;
+    }
+
+    avifImageFreePlanes(avif, AVIF_PLANES_ALL);
+    avif->width = frame.width;
+    avif->height = frame.height;
+    avif->depth = frame.depth;
+    avif->yuvFormat = frame.format;
+    avif->yuvRange = frame.range;
+    avif->yuvChromaSamplePosition = frame.chromaSamplePosition;
+    avifResult allocationResult = avifImageAllocatePlanes(avif, frame.hasAlpha ? AVIF_PLANES_ALL : AVIF_PLANES_YUV);
+    if (allocationResult != AVIF_RESULT_OK) {
+        fprintf(stderr, "Failed to allocate the planes: %s\n", avifResultToString(allocationResult));
+        goto cleanup;
+    }
+
+    for (int plane = AVIF_CHAN_Y; plane <= AVIF_CHAN_A; ++plane) {
+        uint32_t planeHeight = avifImagePlaneHeight(avif, plane); // 0 for A if no alpha and 0 for UV if 4:0:0.
+        uint32_t planeWidthBytes = avifImagePlaneWidth(avif, plane) << (avif->depth > 8);
+        uint8_t * row = avifImagePlane(avif, plane);
+        uint32_t rowBytes = avifImagePlaneRowBytes(avif, plane);
+        for (uint32_t y = 0; y < planeHeight; ++y) {
+            uint32_t bytesRead = (uint32_t)fread(row, 1, planeWidthBytes, frame.inputFile);
+            if (bytesRead != planeWidthBytes) {
+                fprintf(stderr,
+                        "Failed to read y4m row (not enough data, wanted %" PRIu32 ", got %" PRIu32 "): %s\n",
+                        planeWidthBytes,
+                        bytesRead,
+                        frame.displayFilename);
+                goto cleanup;
+            }
+            row += rowBytes;
+        }
+    }
+
+    // libavif API does not guarantee the absence of undefined behavior if samples exceed the specified avif->depth.
+    // Avoid that by making sure input values are within the correct range.
+    if (y4mClampSamples(avif)) {
+        fprintf(stderr, "WARNING: some samples were clamped to fit into %u bits per sample\n", avif->depth);
+    }
+
+    result = AVIF_TRUE;
+cleanup:
+    if (iter) {
+        if (*iter) {
+            free(*iter);
+            *iter = NULL;
+        }
+
+        if (result && frame.inputFile) {
+            ungetc(fgetc(frame.inputFile), frame.inputFile); // Kick frame.inputFile to force EOF
+
+            if (!feof(frame.inputFile)) {
+                // Remember y4m state for next time
+                *iter = malloc(sizeof(struct y4mFrameIterator));
+                if (*iter == NULL) {
+                    fprintf(stderr, "Inter-frame state memory allocation failure\n");
+                    result = AVIF_FALSE;
+                } else {
+                    **iter = frame;
+                }
+            }
+        }
+    }
+
+    if (inputFilename && frame.inputFile && (!iter || !(*iter))) {
+        fclose(frame.inputFile);
+    }
+    avifRWDataFree(&raw);
+    return result;
+}
+
+avifBool y4mWrite(const char * outputFilename, const avifImage * avif)
+{
+    avifBool hasAlpha = (avif->alphaPlane != NULL) && (avif->alphaRowBytes > 0);
+    avifBool writeAlpha = AVIF_FALSE;
+    char * y4mHeaderFormat = NULL;
+
+    if (hasAlpha && ((avif->depth != 8) || (avif->yuvFormat != AVIF_PIXEL_FORMAT_YUV444))) {
+        fprintf(stderr, "WARNING: writing alpha is currently only supported in 8bpc YUV444, ignoring alpha channel: %s\n", outputFilename);
+    }
+
+    switch (avif->depth) {
+        case 8:
+            switch (avif->yuvFormat) {
+                case AVIF_PIXEL_FORMAT_YUV444:
+                    if (hasAlpha) {
+                        y4mHeaderFormat = "C444alpha XYSCSS=444";
+                        writeAlpha = AVIF_TRUE;
+                    } else {
+                        y4mHeaderFormat = "C444 XYSCSS=444";
+                    }
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV422:
+                    y4mHeaderFormat = "C422 XYSCSS=422";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV420:
+                    y4mHeaderFormat = "C420jpeg XYSCSS=420JPEG";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV400:
+                    y4mHeaderFormat = "Cmono XYSCSS=400";
+                    break;
+                case AVIF_PIXEL_FORMAT_NONE:
+                case AVIF_PIXEL_FORMAT_COUNT:
+                    // will error later; these cases are here for warning's sake
+                    break;
+            }
+            break;
+        case 10:
+            switch (avif->yuvFormat) {
+                case AVIF_PIXEL_FORMAT_YUV444:
+                    y4mHeaderFormat = "C444p10 XYSCSS=444P10";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV422:
+                    y4mHeaderFormat = "C422p10 XYSCSS=422P10";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV420:
+                    y4mHeaderFormat = "C420p10 XYSCSS=420P10";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV400:
+                    y4mHeaderFormat = "Cmono10 XYSCSS=400";
+                    break;
+                case AVIF_PIXEL_FORMAT_NONE:
+                case AVIF_PIXEL_FORMAT_COUNT:
+                    // will error later; these cases are here for warning's sake
+                    break;
+            }
+            break;
+        case 12:
+            switch (avif->yuvFormat) {
+                case AVIF_PIXEL_FORMAT_YUV444:
+                    y4mHeaderFormat = "C444p12 XYSCSS=444P12";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV422:
+                    y4mHeaderFormat = "C422p12 XYSCSS=422P12";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV420:
+                    y4mHeaderFormat = "C420p12 XYSCSS=420P12";
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV400:
+                    y4mHeaderFormat = "Cmono12 XYSCSS=400";
+                    break;
+                case AVIF_PIXEL_FORMAT_NONE:
+                case AVIF_PIXEL_FORMAT_COUNT:
+                    // will error later; these cases are here for warning's sake
+                    break;
+            }
+            break;
+        default:
+            fprintf(stderr, "ERROR: y4mWrite unsupported depth: %d\n", avif->depth);
+            return AVIF_FALSE;
+    }
+
+    if (y4mHeaderFormat == NULL) {
+        fprintf(stderr, "ERROR: unsupported format\n");
+        return AVIF_FALSE;
+    }
+
+    const char * rangeString = "XCOLORRANGE=FULL";
+    if (avif->yuvRange == AVIF_RANGE_LIMITED) {
+        rangeString = "XCOLORRANGE=LIMITED";
+    }
+
+    FILE * f = fopen(outputFilename, "wb");
+    if (!f) {
+        fprintf(stderr, "Cannot open file for write: %s\n", outputFilename);
+        return AVIF_FALSE;
+    }
+
+    avifBool success = AVIF_TRUE;
+    if (fprintf(f, "YUV4MPEG2 W%d H%d F25:1 Ip A0:0 %s %s\nFRAME\n", avif->width, avif->height, y4mHeaderFormat, rangeString) < 0) {
+        fprintf(stderr, "Cannot write to file: %s\n", outputFilename);
+        success = AVIF_FALSE;
+        goto cleanup;
+    }
+
+    const int lastPlane = writeAlpha ? AVIF_CHAN_A : AVIF_CHAN_V;
+    for (int plane = AVIF_CHAN_Y; plane <= lastPlane; ++plane) {
+        uint32_t planeHeight = avifImagePlaneHeight(avif, plane); // 0 for UV if 4:0:0.
+        uint32_t planeWidthBytes = avifImagePlaneWidth(avif, plane) << (avif->depth > 8);
+        const uint8_t * row = avifImagePlane(avif, plane);
+        uint32_t rowBytes = avifImagePlaneRowBytes(avif, plane);
+        for (uint32_t y = 0; y < planeHeight; ++y) {
+            if (fwrite(row, 1, planeWidthBytes, f) != planeWidthBytes) {
+                fprintf(stderr, "Failed to write %" PRIu32 " bytes: %s\n", planeWidthBytes, outputFilename);
+                success = AVIF_FALSE;
+                goto cleanup;
+            }
+            row += rowBytes;
+        }
+    }
+
+cleanup:
+    fclose(f);
+    if (success) {
+        printf("Wrote Y4M: %s\n", outputFilename);
+    }
+    return success;
+}
diff --git a/third_party/libavif/src/apps/shared/y4m.h b/third_party/libavif/src/apps/shared/y4m.h
new file mode 100644
index 0000000000..a4d837a774
--- /dev/null
+++ b/third_party/libavif/src/apps/shared/y4m.h
@@ -0,0 +1,32 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef LIBAVIF_APPS_SHARED_Y4M_H
+#define LIBAVIF_APPS_SHARED_Y4M_H
+
+#include "avif/avif.h"
+
+#include "avifutil.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// Optionally pass one of these pointers (set to NULL) on a fresh input. If it successfully reads in
+// a frame and sees that there is more data to be read, it will allocate an internal structure remembering
+// the y4m header and FILE position and return it. Pass in this pointer to continue reading frames.
+// The structure will always be freed upon failure or reaching EOF.
+struct y4mFrameIterator;
+
+avifBool y4mRead(const char * inputFilename,
+                 uint32_t imageSizeLimit,
+                 avifImage * avif,
+                 avifAppSourceTiming * sourceTiming,
+                 struct y4mFrameIterator ** iter);
+avifBool y4mWrite(const char * outputFilename, const avifImage * avif);
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef LIBAVIF_APPS_SHARED_Y4M_H
diff --git a/third_party/libavif/src/apps/utf8.manifest b/third_party/libavif/src/apps/utf8.manifest
new file mode 100755
index 0000000000..dab929e151
--- /dev/null
+++ b/third_party/libavif/src/apps/utf8.manifest
@@ -0,0 +1,8 @@
+<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
+<assembly manifestVersion="1.0" xmlns="urn:schemas-microsoft-com:asm.v1">
+  <application>
+    <windowsSettings>
+      <activeCodePage xmlns="http://schemas.microsoft.com/SMI/2019/WindowsSettings">UTF-8</activeCodePage>
+    </windowsSettings>
+  </application>
+</assembly>
diff --git a/third_party/libavif/src/apps/utf8.rc b/third_party/libavif/src/apps/utf8.rc
new file mode 100755
index 0000000000..62bdbdc362
--- /dev/null
+++ b/third_party/libavif/src/apps/utf8.rc
@@ -0,0 +1,3 @@
+#include <winuser.h>
+
+CREATEPROCESS_MANIFEST_RESOURCE_ID RT_MANIFEST "utf8.manifest"
diff --git a/third_party/libavif/src/cmake/Meson/crossfile-apple.meson.in b/third_party/libavif/src/cmake/Meson/crossfile-apple.meson.in
new file mode 100644
index 0000000000..800d35b684
--- /dev/null
+++ b/third_party/libavif/src/cmake/Meson/crossfile-apple.meson.in
@@ -0,0 +1,16 @@
+[binaries]
+c = ['clang']
+cpp = ['clang++']
+ar = ['ar']
+strip = ['strip']
+pkg-config = ['pkg-config']
+
+[host_machine]
+system = '@cross_system_name@'
+cpu_family = '@cross_system_processor@'
+cpu = '@cross_system_processor@'
+endian = '@cross_system_endian@'
+
+[built-in options]
+c_args = ['-arch', '@CMAKE_SYSTEM_PROCESSOR@', '-isysroot', '@CMAKE_OSX_SYSROOT@', '@cross_osx_deployment_target@' @cross_additional_cflags@]
+c_link_args = ['-arch', '@CMAKE_SYSTEM_PROCESSOR@', '-isysroot', '@CMAKE_OSX_SYSROOT@', '@cross_osx_deployment_target@' @cross_additional_cflags@]
diff --git a/third_party/libavif/src/cmake/Modules/AvifExternalProjectUtils.cmake b/third_party/libavif/src/cmake/Modules/AvifExternalProjectUtils.cmake
new file mode 100644
index 0000000000..8d19e53b48
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/AvifExternalProjectUtils.cmake
@@ -0,0 +1,13 @@
+macro(avif_fetchcontent_populate_cmake name)
+    if(NOT ${name}_POPULATED)
+        FetchContent_Populate(${name})
+
+        # Force static build
+        set(BUILD_SHARED_LIBS_ORIG ${BUILD_SHARED_LIBS})
+        set(BUILD_SHARED_LIBS OFF CACHE INTERNAL "")
+
+        add_subdirectory(${${name}_SOURCE_DIR} ${${name}_BINARY_DIR} EXCLUDE_FROM_ALL)
+
+        set(BUILD_SHARED_LIBS ${BUILD_SHARED_LIBS_ORIG} CACHE BOOL "" FORCE)
+    endif()
+endmacro()
diff --git a/third_party/libavif/src/cmake/Modules/Findaom.cmake b/third_party/libavif/src/cmake/Modules/Findaom.cmake
new file mode 100644
index 0000000000..95df9d7d86
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findaom.cmake
@@ -0,0 +1,56 @@
+# - Try to find aom
+# Once done this will define
+#
+#  AOM_FOUND - system has aom
+#  AOM_INCLUDE_DIR - the aom include directory
+#  AOM_LIBRARIES - Link these to use aom
+#
+#=============================================================================
+#  Copyright (c) 2020 Andreas Schneider <asn@cryptomilk.org>
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_AOM aom)
+endif(PKG_CONFIG_FOUND)
+
+find_path(AOM_INCLUDE_DIR NAMES aom/aom.h PATHS ${_AOM_INCLUDEDIR})
+
+find_library(AOM_LIBRARY NAMES aom PATHS ${_AOM_LIBDIR})
+
+set(AOM_LIBRARIES ${AOM_LIBRARIES} ${AOM_LIBRARY})
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(aom REQUIRED_VARS AOM_LIBRARY AOM_LIBRARIES AOM_INCLUDE_DIR VERSION_VAR _AOM_VERSION)
+
+# show the AOM_INCLUDE_DIR, AOM_LIBRARY and AOM_LIBRARIES variables only
+# in the advanced view
+mark_as_advanced(AOM_INCLUDE_DIR AOM_LIBRARY AOM_LIBRARIES)
+
+if(AOM_LIBRARY)
+    if("${AOM_LIBRARY}" MATCHES "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+        add_library(aom STATIC IMPORTED GLOBAL)
+
+        set(_AOM_PC_LIBRARIES "${_AOM_STATIC_LIBRARIES}")
+        # remove "aom" so we only have library dependencies
+        list(REMOVE_ITEM _AOM_PC_LIBRARIES "aom")
+
+        # Add absolute paths to libraries
+        foreach(_lib ${_AOM_PC_LIBRARIES})
+            find_library(_aom_dep_lib_${_lib} ${_lib} HINTS ${_AOM_STATIC_LIBRARY_DIRS})
+            target_link_libraries(aom INTERFACE ${_aom_dep_lib_${_lib}})
+        endforeach()
+    else()
+        add_library(aom SHARED IMPORTED GLOBAL)
+    endif()
+    set_target_properties(aom PROPERTIES IMPORTED_LOCATION "${AOM_LIBRARY}" IMPORTED_IMPLIB "${AOM_LIBRARY}")
+    target_include_directories(aom INTERFACE ${AOM_INCLUDE_DIR})
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Finddav1d.cmake b/third_party/libavif/src/cmake/Modules/Finddav1d.cmake
new file mode 100644
index 0000000000..7040a9cfe5
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Finddav1d.cmake
@@ -0,0 +1,50 @@
+# - Try to find dav1d
+# Once done this will define
+#
+#  DAV1D_FOUND - system has dav1d
+#  DAV1D_INCLUDE_DIR - the dav1d include directory
+#  DAV1D_LIBRARIES - Link these to use dav1d
+#
+#=============================================================================
+#  Copyright (c) 2020 Andreas Schneider <asn@cryptomilk.org>
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_DAV1D dav1d)
+endif(PKG_CONFIG_FOUND)
+
+find_path(DAV1D_INCLUDE_DIR NAMES dav1d/dav1d.h PATHS ${_DAV1D_INCLUDEDIR})
+
+find_library(DAV1D_LIBRARY NAMES dav1d PATHS ${_DAV1D_LIBDIR})
+
+if(DAV1D_LIBRARY)
+    set(DAV1D_LIBRARIES ${DAV1D_LIBRARIES} ${DAV1D_LIBRARY})
+endif(DAV1D_LIBRARY)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(dav1d REQUIRED_VARS DAV1D_LIBRARY DAV1D_LIBRARIES DAV1D_INCLUDE_DIR VERSION_VAR _DAV1D_VERSION)
+
+# show the DAV1D_INCLUDE_DIR, DAV1D_LIBRARY and DAV1D_LIBRARIES variables only
+# in the advanced view
+mark_as_advanced(DAV1D_INCLUDE_DIR DAV1D_LIBRARY DAV1D_LIBRARIES)
+
+if(DAV1D_LIBRARY)
+    if("${DAV1D_LIBRARY}" MATCHES "\\.a$")
+        add_library(dav1d::dav1d STATIC IMPORTED GLOBAL)
+    else()
+        add_library(dav1d::dav1d SHARED IMPORTED GLOBAL)
+    endif()
+    set_target_properties(
+        dav1d::dav1d PROPERTIES IMPORTED_LOCATION "${DAV1D_LIBRARY}" IMPORTED_IMPLIB "${DAV1D_LIBRARY}" IMPORTED_SONAME dav1d
+    )
+    target_include_directories(dav1d::dav1d INTERFACE ${DAV1D_INCLUDE_DIR})
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Findlibgav1.cmake b/third_party/libavif/src/cmake/Modules/Findlibgav1.cmake
new file mode 100644
index 0000000000..65d49984f5
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findlibgav1.cmake
@@ -0,0 +1,49 @@
+# - Try to find libgav1
+# Once done this will define
+#
+#  LIBGAV1_FOUND - system has libgav1
+#  LIBGAV1_INCLUDE_DIR - the libgav1 include directory
+#  LIBGAV1_LIBRARIES - Link these to use libgav1
+#
+#=============================================================================
+#  Copyright (c) 2020 Google LLC
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_LIBGAV1 libgav1)
+endif(PKG_CONFIG_FOUND)
+
+find_path(LIBGAV1_INCLUDE_DIR NAMES gav1/decoder.h PATHS ${_LIBGAV1_INCLUDEDIR})
+
+find_library(LIBGAV1_LIBRARY NAMES gav1 PATHS ${_LIBGAV1_LIBDIR})
+
+if(LIBGAV1_LIBRARY)
+    set(LIBGAV1_LIBRARIES ${LIBGAV1_LIBRARIES} ${LIBGAV1_LIBRARY})
+endif(LIBGAV1_LIBRARY)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(
+    libgav1 REQUIRED_VARS LIBGAV1_LIBRARY LIBGAV1_LIBRARIES LIBGAV1_INCLUDE_DIR VERSION_VAR _LIBGAV1_VERSION
+)
+
+# show the LIBGAV1_INCLUDE_DIR, LIBGAV1_LIBRARY and LIBGAV1_LIBRARIES variables
+# only in the advanced view
+mark_as_advanced(LIBGAV1_INCLUDE_DIR LIBGAV1_LIBRARY LIBGAV1_LIBRARIES)
+
+if(LIBGAV1_LIBRARY)
+    add_library(libgav1::libgav1 STATIC IMPORTED GLOBAL)
+    set_target_properties(
+        libgav1::libgav1 PROPERTIES IMPORTED_LOCATION "${LIBGAV1_LIBRARY}" IMPORTED_IMPLIB "${LIBGAV1_LIBRARY}" IMPORTED_SONAME
+                                                                                                                gav1
+    )
+    target_include_directories(libgav1::libgav1 INTERFACE ${LIBGAV1_INCLUDE_DIR})
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Findlibsharpyuv.cmake b/third_party/libavif/src/cmake/Modules/Findlibsharpyuv.cmake
new file mode 100644
index 0000000000..fe70f36526
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findlibsharpyuv.cmake
@@ -0,0 +1,53 @@
+# - Try to find libsharpyuv
+# Once done this will define
+#
+#  LIBSHARPYUV_FOUND - system has libsharpyuv
+#  LIBSHARPYUV_INCLUDE_DIR - the libsharpyuv include directory
+#  LIBSHARPYUV_LIBRARIES - Link these to use libsharpyuv
+#
+#=============================================================================
+#  Copyright (c) 2022 Google LLC
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_LIBSHARPYUV libsharpyuv)
+endif(PKG_CONFIG_FOUND)
+
+find_path(LIBSHARPYUV_INCLUDE_DIR NAMES sharpyuv/sharpyuv.h PATHS ${_LIBSHARPYUV_INCLUDEDIR})
+
+find_library(LIBSHARPYUV_LIBRARY NAMES sharpyuv PATHS ${_LIBSHARPYUV_LIBDIR})
+
+if(LIBSHARPYUV_LIBRARY)
+    set(LIBSHARPYUV_LIBRARIES ${LIBSHARPYUV_LIBRARIES} ${LIBSHARPYUV_LIBRARY})
+endif(LIBSHARPYUV_LIBRARY)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(
+    libsharpyuv REQUIRED_VARS LIBSHARPYUV_LIBRARY LIBSHARPYUV_LIBRARIES LIBSHARPYUV_INCLUDE_DIR VERSION_VAR _LIBSHARPYUV_VERSION
+)
+
+# show the LIBSHARPYUV_INCLUDE_DIR, LIBSHARPYUV_LIBRARY and LIBSHARPYUV_LIBRARIES variables
+# only in the advanced view
+mark_as_advanced(LIBSHARPYUV_INCLUDE_DIR LIBSHARPYUV_LIBRARY LIBSHARPYUV_LIBRARIES)
+
+if(LIBSHARPYUV_LIBRARY)
+    if("${LIBSHARPYUV_LIBRARY}" MATCHES "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+        add_library(sharpyuv::sharpyuv STATIC IMPORTED GLOBAL)
+    else()
+        add_library(sharpyuv::sharpyuv SHARED IMPORTED GLOBAL)
+    endif()
+    set_target_properties(
+        sharpyuv::sharpyuv PROPERTIES IMPORTED_LOCATION "${LIBSHARPYUV_LIBRARY}" IMPORTED_IMPLIB "${LIBSHARPYUV_LIBRARY}"
+                                      IMPORTED_SONAME sharpyuv
+    )
+    target_include_directories(sharpyuv::sharpyuv INTERFACE "${LIBSHARPYUV_INCLUDE_DIR}")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Findlibyuv.cmake b/third_party/libavif/src/cmake/Modules/Findlibyuv.cmake
new file mode 100644
index 0000000000..30e2e01bad
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findlibyuv.cmake
@@ -0,0 +1,71 @@
+# - Try to find libyuv
+# Once done this will define
+#
+#  LIBYUV_FOUND - system has libyuv
+#  LIBYUV_INCLUDE_DIR - the libyuv include directory
+#  LIBYUV_LIBRARIES - Link these to use libyuv
+#
+#=============================================================================
+#  Copyright (c) 2020 Andreas Schneider <asn@cryptomilk.org>
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_LIBYUV libyuv)
+endif(PKG_CONFIG_FOUND)
+
+if(NOT LIBYUV_INCLUDE_DIR)
+    find_path(LIBYUV_INCLUDE_DIR NAMES libyuv.h PATHS ${_LIBYUV_INCLUDEDIR})
+endif()
+
+if(LIBYUV_INCLUDE_DIR AND NOT LIBYUV_VERSION)
+    set(LIBYUV_VERSION_H "${LIBYUV_INCLUDE_DIR}/libyuv/version.h")
+    if(EXISTS ${LIBYUV_VERSION_H})
+        # message(STATUS "Reading: ${LIBYUV_VERSION_H}")
+        file(READ ${LIBYUV_VERSION_H} LIBYUV_VERSION_H_CONTENTS)
+        string(REGEX MATCH "#define LIBYUV_VERSION ([0-9]+)" _ ${LIBYUV_VERSION_H_CONTENTS})
+        set(LIBYUV_VERSION ${CMAKE_MATCH_1})
+        # message(STATUS "libyuv version detected: ${LIBYUV_VERSION}")
+    endif()
+    if(NOT LIBYUV_VERSION)
+        message(STATUS "libyuv version detection failed.")
+    endif()
+endif()
+
+if(NOT LIBYUV_LIBRARY)
+    find_library(LIBYUV_LIBRARY NAMES yuv PATHS ${_LIBYUV_LIBDIR})
+endif()
+
+if(LIBYUV_LIBRARY)
+    set(LIBYUV_LIBRARIES ${LIBYUV_LIBRARIES} ${LIBYUV_LIBRARY})
+endif(LIBYUV_LIBRARY)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(
+    libyuv REQUIRED_VARS LIBYUV_LIBRARY LIBYUV_LIBRARIES LIBYUV_INCLUDE_DIR VERSION_VAR _LIBYUV_VERSION
+)
+
+# show the LIBYUV_INCLUDE_DIR, LIBYUV_LIBRARY and LIBYUV_LIBRARIES variables only
+# in the advanced view
+mark_as_advanced(LIBYUV_INCLUDE_DIR LIBYUV_LIBRARY LIBYUV_LIBRARIES)
+
+if(LIBYUV_LIBRARY)
+    if("${LIBYUV_LIBRARY}" MATCHES "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+        add_library(yuv::yuv STATIC IMPORTED GLOBAL)
+    else()
+        add_library(yuv::yuv SHARED IMPORTED GLOBAL)
+    endif()
+    set_target_properties(
+        yuv::yuv PROPERTIES IMPORTED_LOCATION "${LIBYUV_LIBRARY}" IMPORTED_IMPLIB "${LIBYUV_LIBRARY}" IMPORTED_SONAME yuv
+    )
+    target_include_directories(yuv::yuv INTERFACE "${LIBYUV_INCLUDE_DIR}")
+    set(libyuv_FOUND ON)
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Findrav1e.cmake b/third_party/libavif/src/cmake/Modules/Findrav1e.cmake
new file mode 100644
index 0000000000..f844624a14
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findrav1e.cmake
@@ -0,0 +1,71 @@
+# - Try to find rav1e
+# Once done this will define
+#
+#  RAV1E_FOUND - system has rav1e
+#  RAV1E_INCLUDE_DIR - the rav1e include directory
+#  RAV1E_LIBRARIES - Link these to use rav1e
+#
+#=============================================================================
+#  Copyright (c) 2020 Andreas Schneider <asn@cryptomilk.org>
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_RAV1E rav1e)
+endif(PKG_CONFIG_FOUND)
+
+if(NOT RAV1E_INCLUDE_DIR)
+    find_path(
+        RAV1E_INCLUDE_DIR
+        NAMES rav1e.h
+        PATHS ${_RAV1E_INCLUDEDIR}
+        PATH_SUFFIXES rav1e
+    )
+endif()
+
+if(NOT RAV1E_LIBRARY)
+    # For Windows MSVC, cargo-c names the import library ravie.dll.lib
+    if(WIN32 AND NOT MINGW)
+        set(CMAKE_FIND_LIBRARY_SUFFIXES ".dll.lib" # import library from Rust toolchain for MSVC ABI
+                                        ".lib" # static or import library from MSVC tooling
+        )
+    endif()
+    find_library(RAV1E_LIBRARY NAMES rav1e PATHS ${_RAV1E_LIBDIR})
+endif()
+
+set(RAV1E_LIBRARIES ${RAV1E_LIBRARIES} ${RAV1E_LIBRARY} ${_RAV1E_LDFLAGS})
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(rav1e REQUIRED_VARS RAV1E_LIBRARY RAV1E_LIBRARIES RAV1E_INCLUDE_DIR VERSION_VAR _RAV1E_VERSION)
+
+# show the RAV1E_INCLUDE_DIR, RAV1E_LIBRARY and RAV1E_LIBRARIES variables only
+# in the advanced view
+mark_as_advanced(RAV1E_INCLUDE_DIR RAV1E_LIBRARY RAV1E_LIBRARIES)
+
+if(RAV1E_LIBRARY)
+    if(NOT TARGET rav1e::rav1e)
+        if("${RAV1E_LIBRARY}" MATCHES "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+            add_library(rav1e::rav1e STATIC IMPORTED GLOBAL)
+        else()
+            add_library(rav1e::rav1e SHARED IMPORTED GLOBAL)
+        endif()
+        set_target_properties(
+            rav1e::rav1e PROPERTIES IMPORTED_LOCATION "${RAV1E_LIBRARY}" IMPORTED_IMPLIB "${RAV1E_LIBRARY}" IMPORTED_SONAME rav1e
+        )
+        target_include_directories(rav1e::rav1e INTERFACE ${RAV1E_INCLUDE_DIR})
+        # The following is copied from the main CMakeLists.txt.
+        if(WIN32)
+            target_link_libraries(rav1e::rav1e INTERFACE ntdll.lib userenv.lib ws2_32.lib bcrypt.lib)
+        elseif(UNIX AND NOT APPLE)
+            target_link_libraries(rav1e::rav1e INTERFACE ${CMAKE_DL_LIBS}) # for backtrace
+        endif()
+    endif()
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/Findsvt.cmake b/third_party/libavif/src/cmake/Modules/Findsvt.cmake
new file mode 100644
index 0000000000..15484eb93a
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/Findsvt.cmake
@@ -0,0 +1,48 @@
+# - Try to find svt_av1
+# Once done this will define
+#
+#  SVT_FOUND - system has svt_av1
+#  SVT_INCLUDE_DIR - the svt_av1 include directory
+#  SVT_LIBRARIES - Link these to use svt_av1
+#
+#=============================================================================
+#  Copyright (c) 2020 Andreas Schneider <asn@cryptomilk.org>
+#
+#  Distributed under the OSI-approved BSD License (the "License");
+#  see accompanying file Copyright.txt for details.
+#
+#  This software is distributed WITHOUT ANY WARRANTY; without even the
+#  implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+#  See the License for more information.
+#=============================================================================
+#
+
+find_package(PkgConfig QUIET)
+if(PKG_CONFIG_FOUND)
+    pkg_check_modules(_SVT SvtAv1Enc)
+endif(PKG_CONFIG_FOUND)
+
+find_path(SVT_INCLUDE_DIR NAMES svt-av1/EbSvtAv1Enc.h PATHS ${_SVT_INCLUDEDIR})
+
+find_library(SVT_LIBRARY NAMES SvtAv1Enc PATHS ${_SVT_LIBDIR})
+
+if(SVT_LIBRARY)
+    set(SVT_LIBRARIES ${SVT_LIBRARIES} ${SVT_LIBRARY})
+endif(SVT_LIBRARY)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(svt REQUIRED_VARS SVT_LIBRARY SVT_LIBRARIES SVT_INCLUDE_DIR VERSION_VAR _SVT_VERSION)
+
+# show the SVT_INCLUDE_DIR, SVT_LIBRARY and SVT_LIBRARIES variables only
+# in the advanced view
+mark_as_advanced(SVT_INCLUDE_DIR SVT_LIBRARY SVT_LIBRARIES)
+
+if(SVT_LIBRARY)
+    if("${SVT_LIBRARY}" MATCHES "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+        add_library(SvtAv1Enc STATIC IMPORTED GLOBAL)
+    else()
+        add_library(SvtAv1Enc SHARED IMPORTED GLOBAL)
+    endif()
+    set_target_properties(SvtAv1Enc PROPERTIES IMPORTED_LOCATION "${SVT_LIBRARY}" IMPORTED_IMPLIB "${SVT_LIBRARY}")
+    target_include_directories(SvtAv1Enc INTERFACE ${SVT_INCLUDE_DIR})
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalAom.cmake b/third_party/libavif/src/cmake/Modules/LocalAom.cmake
new file mode 100644
index 0000000000..67cd440eae
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalAom.cmake
@@ -0,0 +1,177 @@
+set(AVIF_LOCAL_AOM_GIT_TAG v3.10.0)
+set(AVIF_LOCAL_AVM_GIT_TAG research-v8.0.0)
+
+if(AVIF_CODEC_AVM)
+    # Building the avm repository generates files such as "libaom.a" because it is a fork of aom,
+    # so its build can be treated the same as aom
+    set(AOM_PACKAGE_NAME avm)
+    set(AOM_MESSAGE_PREFIX "libavif(AVIF_CODEC_AVM=LOCAL)")
+else()
+    set(AOM_PACKAGE_NAME aom)
+    set(AOM_MESSAGE_PREFIX "libavif(AVIF_CODEC_AOM=LOCAL)")
+endif()
+
+set(AOM_EXT_SOURCE_DIR "${AVIF_SOURCE_DIR}/ext/${AOM_PACKAGE_NAME}")
+set(LIB_FILENAME "${AOM_EXT_SOURCE_DIR}/build.libavif/${CMAKE_STATIC_LIBRARY_PREFIX}aom${CMAKE_STATIC_LIBRARY_SUFFIX}")
+
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "${AOM_MESSAGE_PREFIX}: compiled library found at ${LIB_FILENAME}")
+    add_library(aom STATIC IMPORTED GLOBAL)
+    set_target_properties(aom PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON)
+    target_include_directories(aom INTERFACE "${AOM_EXT_SOURCE_DIR}")
+    if(AVIF_CODEC_AVM)
+        # ext/avm/aom/aom_encoder.h includes config/aom_config.h which is generated by the local build of avm.
+        target_include_directories(aom INTERFACE "${AOM_EXT_SOURCE_DIR}/build.libavif")
+    endif()
+
+    # Add link dependency flags from the aom.pc file in ext/aom or ext/avm
+    # by prepending the build directory to PKG_CONFIG_PATH and then calling
+    # pkg_check_modules
+    if(WIN32)
+        set(ENV{PKG_CONFIG_PATH} "${AOM_EXT_SOURCE_DIR}/build.libavif;$ENV{PKG_CONFIG_PATH}")
+    else()
+        set(ENV{PKG_CONFIG_PATH} "${AOM_EXT_SOURCE_DIR}/build.libavif:$ENV{PKG_CONFIG_PATH}")
+    endif()
+
+    pkg_check_modules(_AOM QUIET aom)
+
+    set(_AOM_PC_LIBRARIES "${_AOM_STATIC_LIBRARIES}")
+    # remove "aom" so we only have library dependencies
+    list(REMOVE_ITEM _AOM_PC_LIBRARIES "aom")
+    # Work around crbug.com/aomedia/356153293: aom.pc has -lm in the
+    # Libs.private field on all platforms, whether libm or m.lib exists or not.
+    if(WIN32 OR APPLE)
+        list(REMOVE_ITEM _AOM_PC_LIBRARIES "m")
+    endif()
+
+    # Add absolute paths to libraries
+    foreach(_lib ${_AOM_PC_LIBRARIES})
+        find_library(_aom_dep_lib_${_lib} ${_lib} HINTS ${_AOM_STATIC_LIBRARY_DIRS})
+        target_link_libraries(aom INTERFACE ${_aom_dep_lib_${_lib}})
+    endforeach()
+else()
+    message(STATUS "${AOM_MESSAGE_PREFIX}: compiled library not found at ${LIB_FILENAME}, using FetchContent")
+    if(EXISTS "${AOM_EXT_SOURCE_DIR}")
+        message(STATUS "${AOM_MESSAGE_PREFIX}: ext/${AOM_PACKAGE_NAME} found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_AOM "${AOM_EXT_SOURCE_DIR}")
+        message(CHECK_START "${AOM_MESSAGE_PREFIX}: configuring ${AOM_PACKAGE_NAME}")
+    else()
+        message(CHECK_START "${AOM_MESSAGE_PREFIX}: fetching and configuring ${AOM_PACKAGE_NAME}")
+    endif()
+
+    # aom sets its compile options by setting variables like CMAKE_C_FLAGS_RELEASE using
+    # CACHE FORCE, which effectively adds those flags to all targets. We stash and restore
+    # the original values and call avif_set_aom_compile_options to instead set the flags on all aom
+    # targets
+    function(avif_set_aom_compile_options target config)
+        string(REPLACE " " ";" AOM_C_FLAGS_LIST "${CMAKE_C_FLAGS_${config}}")
+        string(REPLACE " " ";" AOM_CXX_FLAGS_LIST "${CMAKE_CXX_FLAGS_${config}}")
+        foreach(flag ${AOM_C_FLAGS_LIST})
+            target_compile_options(${target} PRIVATE $<$<COMPILE_LANGUAGE:C>:${flag}>)
+        endforeach()
+        foreach(flag ${AOM_CXX_FLAGS_LIST})
+            target_compile_options(${target} PRIVATE $<$<COMPILE_LANGUAGE:CXX>:${flag}>)
+        endforeach()
+
+        get_target_property(sources ${target} SOURCES)
+        foreach(src ${sources})
+            if(src MATCHES "TARGET_OBJECTS:")
+                string(REGEX REPLACE "\\$<TARGET_OBJECTS:(.*)>" "\\1" source_target ${src})
+                avif_set_aom_compile_options(${source_target} ${config})
+            endif()
+        endforeach()
+    endfunction()
+
+    set(AOM_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/${AOM_PACKAGE_NAME}-build")
+
+    if(ANDROID_ABI)
+        set(AOM_BINARY_DIR "${AOM_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    if(AVIF_CODEC_AVM)
+        FetchContent_Declare(
+            libaom
+            GIT_REPOSITORY "https://gitlab.com/AOMediaCodec/avm.git"
+            BINARY_DIR "${AOM_BINARY_DIR}"
+            GIT_TAG ${AVIF_LOCAL_AVM_GIT_TAG}
+            GIT_PROGRESS ON
+            GIT_SHALLOW ON
+            UPDATE_COMMAND ""
+        )
+        # This will disable the tensorflow dependency.
+        set(CONFIG_ML_PART_SPLIT 0 CACHE INTERNAL "")
+    else()
+        FetchContent_Declare(
+            libaom URL "https://aomedia.googlesource.com/aom/+archive/${AVIF_LOCAL_AOM_GIT_TAG}.tar.gz" BINARY_DIR
+                       "${AOM_BINARY_DIR}" UPDATE_COMMAND ""
+        )
+    endif()
+
+    set(CONFIG_PIC 1 CACHE INTERNAL "")
+    if(libyuv_FOUND)
+        set(CONFIG_LIBYUV 0 CACHE INTERNAL "")
+    else()
+        set(CONFIG_LIBYUV 1 CACHE INTERNAL "")
+    endif()
+    set(CONFIG_WEBM_IO 0 CACHE INTERNAL "")
+    set(ENABLE_DOCS 0 CACHE INTERNAL "")
+    set(ENABLE_EXAMPLES 0 CACHE INTERNAL "")
+    set(ENABLE_TESTDATA 0 CACHE INTERNAL "")
+    set(ENABLE_TESTS 0 CACHE INTERNAL "")
+    set(ENABLE_TOOLS 0 CACHE INTERNAL "")
+    if(CMAKE_OSX_ARCHITECTURES STREQUAL "arm64")
+        set(AOM_TARGET_CPU "arm64")
+    endif()
+
+    if(NOT libaom_POPULATED)
+        # Guard against the project setting cmake variables that would affect the parent build
+        # See comment above for avif_set_aom_compile_options
+        foreach(_config_setting CMAKE_C_FLAGS CMAKE_CXX_FLAGS CMAKE_EXE_LINKER_FLAGS)
+            foreach(_config_type DEBUG RELEASE MINSIZEREL RELWITHDEBINFO)
+                set(${_config_setting}_${_config_type}_ORIG ${${_config_setting}_${_config_type}})
+            endforeach()
+        endforeach()
+
+        avif_fetchcontent_populate_cmake(libaom)
+
+        set(_aom_config RELEASE)
+        if(CMAKE_BUILD_TYPE)
+            string(TOUPPER ${CMAKE_BUILD_TYPE} _aom_config)
+        endif()
+        list(LENGTH CMAKE_CONFIGURATION_TYPES num_configs)
+        if(${num_configs} GREATER 0)
+            list(GET CMAKE_CONFIGURATION_TYPES 0 _aom_config_type)
+            string(TOUPPER ${_aom_config_type} _aom_config)
+        endif()
+        avif_set_aom_compile_options(aom ${_aom_config})
+
+        # Restore the variables.
+        foreach(_config_setting CMAKE_C_FLAGS CMAKE_CXX_FLAGS CMAKE_EXE_LINKER_FLAGS)
+            foreach(_config_type DEBUG RELEASE MINSIZEREL RELWITHDEBINFO)
+                unset(${_config_setting}_${_config_type} CACHE)
+                set(${_config_setting}_${_config_type} ${${_config_setting}_${_config_type}_ORIG})
+                unset(${_config_setting}_${_config_type}_ORIG)
+            endforeach()
+        endforeach()
+        unset(_config_type)
+        unset(_config_setting)
+    endif()
+
+    # If we have libyuv, we disable CONFIG_LIBYUV so that aom does not include the libyuv
+    # sources from its third-party vendor library. But we still want AOM to have libyuv, only
+    # linked against this project's target. Here we update the value in aom_config.h and add libyuv
+    # to AOM's link libraries
+    if(libyuv_FOUND)
+        file(READ ${AOM_BINARY_DIR}/config/aom_config.h AOM_CONFIG_H)
+        if("${AOM_CONFIG_H}" MATCHES "CONFIG_LIBYUV 0")
+            string(REPLACE "CONFIG_LIBYUV 0" "CONFIG_LIBYUV 1" AOM_CONFIG_H "${AOM_CONFIG_H}")
+            file(WRITE ${AOM_BINARY_DIR}/config/aom_config.h "${AOM_CONFIG_H}")
+        endif()
+        target_link_libraries(aom PRIVATE $<TARGET_FILE:yuv::yuv>)
+    endif()
+
+    set_property(TARGET aom PROPERTY AVIF_LOCAL ON)
+    target_include_directories(aom INTERFACE "${libaom_SOURCE_DIR}" ${AOM_BINARY_DIR})
+
+    message(CHECK_PASS "complete")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalAvm.cmake b/third_party/libavif/src/cmake/Modules/LocalAvm.cmake
new file mode 100644
index 0000000000..f641d7ffaa
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalAvm.cmake
@@ -0,0 +1 @@
+include(LocalAom)
diff --git a/third_party/libavif/src/cmake/Modules/LocalDav1d.cmake b/third_party/libavif/src/cmake/Modules/LocalDav1d.cmake
new file mode 100644
index 0000000000..c7304d4de9
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalDav1d.cmake
@@ -0,0 +1,132 @@
+set(AVIF_LOCAL_DAV1D_TAG "1.5.0")
+
+function(avif_build_local_dav1d)
+    set(download_step_args)
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/dav1d")
+        message(STATUS "libavif(AVIF_CODEC_DAV1D=LOCAL): ext/dav1d found, using as SOURCE_DIR")
+        set(source_dir "${AVIF_SOURCE_DIR}/ext/dav1d")
+    else()
+        message(STATUS "libavif(AVIF_CODEC_DAV1D=LOCAL): ext/dav1d not found, fetching")
+        set(source_dir "${FETCHCONTENT_BASE_DIR}/dav1d-src")
+        list(APPEND download_step_args GIT_REPOSITORY https://code.videolan.org/videolan/dav1d.git GIT_TAG
+             ${AVIF_LOCAL_DAV1D_TAG} GIT_SHALLOW ON
+        )
+    endif()
+
+    find_program(NINJA_EXECUTABLE NAMES ninja ninja-build REQUIRED)
+    find_program(MESON_EXECUTABLE meson REQUIRED)
+
+    set(PATH $ENV{PATH})
+    if(WIN32)
+        string(REPLACE ";" "\$<SEMICOLON>" PATH "${PATH}")
+    endif()
+    if(ANDROID_TOOLCHAIN_ROOT)
+        set(PATH "${ANDROID_TOOLCHAIN_ROOT}/bin$<IF:$<BOOL:${WIN32}>,$<SEMICOLON>,:>${PATH}")
+    endif()
+
+    if(ANDROID)
+        list(APPEND CMAKE_PROGRAM_PATH "${ANDROID_TOOLCHAIN_ROOT}/bin")
+
+        if(CMAKE_SYSTEM_PROCESSOR STREQUAL "armv7-a")
+            set(android_arch "arm")
+        elseif(CMAKE_SYSTEM_PROCESSOR STREQUAL "aarch64")
+            set(android_arch "aarch64")
+        elseif(CMAKE_SYSTEM_PROCESSOR STREQUAL "x86_64")
+            set(android_arch "x86_64")
+        else()
+            set(android_arch "x86")
+        endif()
+
+        set(CROSS_FILE "${source_dir}/package/crossfiles/${android_arch}-android.meson")
+    elseif(APPLE)
+        # If we are cross compiling generate the corresponding file to use with meson
+        if(NOT CMAKE_SYSTEM_PROCESSOR STREQUAL CMAKE_HOST_SYSTEM_PROCESSOR)
+            string(TOLOWER "${CMAKE_SYSTEM_NAME}" cross_system_name)
+            if(CMAKE_C_BYTE_ORDER STREQUAL "BIG_ENDIAN")
+                set(cross_system_endian "big")
+            else()
+                set(cross_system_endian "little")
+            endif()
+            if(CMAKE_SYSTEM_PROCESSOR STREQUAL "arm64")
+                set(cross_system_processor "aarch64")
+            else()
+                set(cross_system_processor "${CMAKE_SYSTEM_PROCESSOR}")
+            endif()
+            if(CMAKE_OSX_DEPLOYMENT_TARGET)
+                set(cross_osx_deployment_target "-mmacosx-version-min=${CMAKE_OSX_DEPLOYMENT_TARGET}")
+            endif()
+
+            set(CROSS_FILE "${PROJECT_BINARY_DIR}/crossfile-apple.meson")
+            configure_file("cmake/Meson/crossfile-apple.meson.in" "${CROSS_FILE}")
+        endif()
+    endif()
+
+    if(CROSS_FILE)
+        set(EXTRA_ARGS "--cross-file=${CROSS_FILE}")
+    endif()
+
+    set(build_dir "${FETCHCONTENT_BASE_DIR}/dav1d-build")
+    set(install_dir "${FETCHCONTENT_BASE_DIR}/dav1d-install")
+
+    if(ANDROID_ABI)
+        set(build_dir "${build_dir}/${ANDROID_ABI}")
+        set(install_dir "${install_dir}/${ANDROID_ABI}")
+    endif()
+    file(MAKE_DIRECTORY ${install_dir}/include)
+
+    ExternalProject_Add(
+        dav1d
+        ${download_step_args}
+        DOWNLOAD_DIR "${source_dir}"
+        LOG_DIR "${build_dir}"
+        STAMP_DIR "${build_dir}"
+        TMP_DIR "${build_dir}"
+        SOURCE_DIR "${source_dir}"
+        BINARY_DIR "${build_dir}"
+        INSTALL_DIR "${install_dir}"
+        LIST_SEPARATOR |
+        UPDATE_COMMAND ""
+        CONFIGURE_COMMAND
+            ${CMAKE_COMMAND} -E env "PATH=${PATH}" ${MESON_EXECUTABLE} setup --buildtype=release --default-library=static
+            --prefix=<INSTALL_DIR> --libdir=lib -Denable_asm=true -Denable_tools=false -Denable_examples=false
+            -Denable_tests=false ${EXTRA_ARGS} <SOURCE_DIR>
+        BUILD_COMMAND ${CMAKE_COMMAND} -E env "PATH=${PATH}" ${NINJA_EXECUTABLE} -C <BINARY_DIR>
+        INSTALL_COMMAND ${CMAKE_COMMAND} -E env "PATH=${PATH}" ${NINJA_EXECUTABLE} -C <BINARY_DIR> install
+        BUILD_BYPRODUCTS <INSTALL_DIR>/lib/libdav1d.a
+    )
+
+    add_library(dav1d::dav1d STATIC IMPORTED)
+    set_target_properties(dav1d::dav1d PROPERTIES IMPORTED_LOCATION ${install_dir}/lib/libdav1d.a AVIF_LOCAL ON)
+    target_include_directories(dav1d::dav1d INTERFACE "${install_dir}/include")
+    target_link_directories(dav1d::dav1d INTERFACE ${install_dir}/lib)
+    add_dependencies(dav1d::dav1d dav1d)
+endfunction()
+
+set(AVIF_DAV1D_BUILD_DIR "${AVIF_SOURCE_DIR}/ext/dav1d/build")
+# If ${ANDROID_ABI} is set, look for the library under that subdirectory.
+if(DEFINED ANDROID_ABI)
+    set(AVIF_DAV1D_BUILD_DIR "${AVIF_DAV1D_BUILD_DIR}/${ANDROID_ABI}")
+endif()
+set(LIB_FILENAME "${AVIF_DAV1D_BUILD_DIR}/src/libdav1d${CMAKE_STATIC_LIBRARY_SUFFIX}")
+if(NOT EXISTS "${LIB_FILENAME}" AND NOT "${CMAKE_STATIC_LIBRARY_SUFFIX}" STREQUAL ".a")
+    # On windows, meson will produce a libdav1d.a instead of the expected libdav1d.dll/.lib.
+    # See https://github.com/mesonbuild/meson/issues/8153.
+    set(LIB_FILENAME "${AVIF_DAV1D_BUILD_DIR}/src/libdav1d.a")
+endif()
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_CODEC_DAV1D=LOCAL): compiled library found at ${LIB_FILENAME}")
+    add_library(dav1d::dav1d STATIC IMPORTED)
+    set_target_properties(dav1d::dav1d PROPERTIES IMPORTED_LOCATION ${LIB_FILENAME} AVIF_LOCAL ON)
+    target_include_directories(
+        dav1d::dav1d INTERFACE "${AVIF_DAV1D_BUILD_DIR}" "${AVIF_DAV1D_BUILD_DIR}/include"
+                               "${AVIF_DAV1D_BUILD_DIR}/include/dav1d" "${AVIF_SOURCE_DIR}/ext/dav1d/include"
+    )
+else()
+    message(STATUS "libavif(AVIF_CODEC_DAV1D=LOCAL): compiled library not found at ${LIB_FILENAME}; using ExternalProject")
+
+    avif_build_local_dav1d()
+endif()
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/dav1d")
+    set_target_properties(dav1d::dav1d PROPERTIES FOLDER "ext/dav1d")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalGTest.cmake b/third_party/libavif/src/cmake/Modules/LocalGTest.cmake
new file mode 100644
index 0000000000..69581f513d
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalGTest.cmake
@@ -0,0 +1,52 @@
+set(AVIF_LOCAL_GTEST_GIT_TAG v1.14.0)
+
+set(GTest_FOUND ON CACHE BOOL "")
+set(GTEST_INCLUDE_DIRS ${AVIF_SOURCE_DIR}/ext/googletest/googletest/include)
+set(GTEST_LIB_FILENAME
+    ${AVIF_SOURCE_DIR}/ext/googletest/build/lib/${CMAKE_STATIC_LIBRARY_PREFIX}gtest${CMAKE_STATIC_LIBRARY_SUFFIX}
+)
+set(GTEST_MAIN_LIB_FILENAME
+    ${AVIF_SOURCE_DIR}/ext/googletest/build/lib/${CMAKE_STATIC_LIBRARY_PREFIX}gtest_main${CMAKE_STATIC_LIBRARY_SUFFIX}
+)
+if(EXISTS ${GTEST_INCLUDE_DIRS}/gtest/gtest.h AND EXISTS ${GTEST_LIB_FILENAME} AND EXISTS ${GTEST_MAIN_LIB_FILENAME})
+    message(STATUS "libavif(AVIF_GTEST=LOCAL): compiled library found in ext/googletest")
+
+    add_library(GTest::GTest STATIC IMPORTED)
+    set_target_properties(GTest::GTest PROPERTIES IMPORTED_LOCATION "${GTEST_LIB_FILENAME}" AVIF_LOCAL ON)
+
+    if(TARGET Threads::Threads)
+        target_link_libraries(GTest::GTest INTERFACE Threads::Threads)
+    endif()
+    target_include_directories(GTest::GTest INTERFACE "${GTEST_INCLUDE_DIRS}")
+
+    add_library(GTest::Main STATIC IMPORTED)
+    target_link_libraries(GTest::Main INTERFACE GTest::GTest)
+    set_target_properties(GTest::Main PROPERTIES IMPORTED_LOCATION "${GTEST_MAIN_LIB_FILENAME}" AVIF_LOCAL ON)
+else()
+    message(STATUS "libavif(AVIF_GTEST=LOCAL): compiled library not found in ext/googletest; using FetchContent")
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/googletest")
+        message(STATUS "libavif(AVIF_GTEST=LOCAL): ext/googletest found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_GOOGLETEST "${AVIF_SOURCE_DIR}/ext/googletest")
+        message(CHECK_START "libavif(AVIF_LOCAL_GTEST): configuring googletest")
+    else()
+        message(CHECK_START "libavif(AVIF_LOCAL_GTEST): fetching and configuring googletest")
+    endif()
+
+    FetchContent_Declare(
+        googletest
+        GIT_REPOSITORY https://github.com/google/googletest.git
+        GIT_TAG ${AVIF_LOCAL_GTEST_GIT_TAG}
+        GIT_SHALLOW ON
+    )
+    set(gtest_force_shared_crt ON CACHE BOOL "" FORCE)
+    set(BUILD_GMOCK OFF CACHE BOOL "" FORCE)
+
+    avif_fetchcontent_populate_cmake(googletest)
+
+    set_target_properties(gtest gtest_main PROPERTIES AVIF_LOCAL ON)
+
+    add_library(GTest::GTest ALIAS gtest)
+    add_library(GTest::Main ALIAS gtest_main)
+
+    message(CHECK_PASS "complete")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalJpeg.cmake b/third_party/libavif/src/cmake/Modules/LocalJpeg.cmake
new file mode 100644
index 0000000000..40a789c934
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalJpeg.cmake
@@ -0,0 +1,63 @@
+set(AVIF_LOCAL_JPEG_TAG "3.0.4")
+
+add_library(JPEG::JPEG STATIC IMPORTED GLOBAL)
+
+set(LIB_DIR "${AVIF_SOURCE_DIR}/ext/libjpeg-turbo/build.libavif")
+if(MSVC)
+    set(LIB_FILENAME "${LIB_DIR}/${CMAKE_STATIC_LIBRARY_PREFIX}jpeg-static${CMAKE_STATIC_LIBRARY_SUFFIX}")
+else()
+    set(LIB_FILENAME "${LIB_DIR}/${CMAKE_STATIC_LIBRARY_PREFIX}jpeg${CMAKE_STATIC_LIBRARY_SUFFIX}")
+endif()
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_JPEG=LOCAL): ${LIB_FILENAME} found, using for local JPEG")
+    set(JPEG_INCLUDE_DIR "${AVIF_SOURCE_DIR}/ext/libjpeg-turbo")
+else()
+    message(STATUS "libavif(AVIF_JPEG=LOCAL): ${LIB_FILENAME} not found, fetching")
+    set(LIB_DIR "${CMAKE_CURRENT_BINARY_DIR}/libjpeg/src/libjpeg-build")
+    if(MSVC)
+        set(LIB_FILENAME "${LIB_DIR}/${CMAKE_STATIC_LIBRARY_PREFIX}jpeg-static${CMAKE_STATIC_LIBRARY_SUFFIX}")
+    else()
+        set(LIB_FILENAME "${LIB_DIR}/${CMAKE_STATIC_LIBRARY_PREFIX}jpeg${CMAKE_STATIC_LIBRARY_SUFFIX}")
+    endif()
+
+    set(JPEG_INSTALL_DIR "${prefix}/libjpeg-install")
+
+    # Set WITH_CRT_DLL to ON to compile libjpeg-turbo with /MD (use the DLL
+    # version of the run-time library) instead of /MT (use the static version
+    # of the run-time library) on Windows. On non-Windows platform, this causes
+    # a CMake warning, which is safe to ignore:
+    #   Manually-specified variables were not used by the project:
+    #
+    #     WITH_CRT_DLL
+    ExternalProject_Add(
+        libjpeg
+        PREFIX ${CMAKE_CURRENT_BINARY_DIR}/libjpeg
+        GIT_REPOSITORY "https://github.com/libjpeg-turbo/libjpeg-turbo.git"
+        GIT_TAG "${AVIF_LOCAL_JPEG_TAG}"
+        LIST_SEPARATOR |
+        BUILD_COMMAND ${CMAKE_COMMAND} --build <BINARY_DIR> --config $<CONFIG> --target jpeg-static
+        CMAKE_ARGS -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}
+                   -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}
+                   -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}
+                   -DCMAKE_C_FLAGS_DEBUG=${CMAKE_C_FLAGS_DEBUG}
+                   -DCMAKE_C_FLAGS_RELEASE=${CMAKE_C_FLAGS_RELEASE}
+                   -DCMAKE_C_FLAGS_MINSIZEREL=${CMAKE_C_FLAGS_MINSIZEREL}
+                   -DCMAKE_C_FLAGS_RELWITHDEBINFO=${CMAKE_C_FLAGS_RELWITHDEBINFO}
+                   -DENABLE_SHARED=OFF
+                   -DENABLE_STATIC=ON
+                   -DCMAKE_BUILD_TYPE=Release
+                   -DWITH_TURBOJPEG=OFF
+                   -DWITH_CRT_DLL=ON
+        BUILD_BYPRODUCTS "${LIB_FILENAME}"
+        INSTALL_COMMAND ""
+    )
+    add_dependencies(JPEG::JPEG libjpeg)
+    set(JPEG_INCLUDE_DIR ${CMAKE_CURRENT_BINARY_DIR}/libjpeg/src/libjpeg)
+endif()
+
+set_target_properties(JPEG::JPEG PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON)
+target_include_directories(JPEG::JPEG INTERFACE "${JPEG_INCLUDE_DIR}")
+
+# Also add the build directory path because it contains jconfig.h,
+# which is included by jpeglib.h.
+target_include_directories(JPEG::JPEG INTERFACE "${LIB_DIR}")
diff --git a/third_party/libavif/src/cmake/Modules/LocalLibXml2.cmake b/third_party/libavif/src/cmake/Modules/LocalLibXml2.cmake
new file mode 100644
index 0000000000..894c485268
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalLibXml2.cmake
@@ -0,0 +1,46 @@
+set(AVIF_LOCAL_LIBXML_GIT_TAG "v2.13.4")
+
+set(LIB_FILENAME "${AVIF_SOURCE_DIR}/ext/libxml2/install.libavif/lib/${AVIF_LIBRARY_PREFIX}xml2${CMAKE_STATIC_LIBRARY_SUFFIX}")
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_LIBXML2=LOCAL): compiled library found at ${LIB_FILENAME}")
+    add_library(LibXml2 STATIC IMPORTED GLOBAL)
+    set_target_properties(LibXml2 PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON)
+    target_include_directories(LibXml2 INTERFACE "${AVIF_SOURCE_DIR}/ext/libxml2/install.libavif/include/libxml2")
+    add_library(LibXml2::LibXml2 ALIAS LibXml2)
+else()
+    message(STATUS "libavif(AVIF_LIBXML2=LOCAL): compiled library not found at ${LIB_FILENAME}; using FetchContent")
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libxml2")
+        message(STATUS "libavif(AVIF_LIBXML2=LOCAL): ext/libxml2 found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_LIBXML2 "${AVIF_SOURCE_DIR}/ext/libxml2")
+        message(CHECK_START "libavif(AVIF_LOCAL_LIBXML2): configuring libxml2")
+    else()
+        message(CHECK_START "libavif(AVIF_LOCAL_LIBXML2): fetching and configuring libxml2")
+    endif()
+
+    set(LIBXML2_WITH_PYTHON OFF CACHE INTERNAL "-")
+    set(LIBXML2_WITH_ZLIB OFF CACHE INTERNAL "-")
+    set(LIBXML2_WITH_LZMA OFF CACHE INTERNAL "-")
+    set(LIBXML2_WITH_ICONV OFF CACHE INTERNAL "-")
+    set(LIBXML2_WITH_TESTS OFF CACHE INTERNAL "-")
+    set(LIBXML2_WITH_PROGRAMS OFF CACHE INTERNAL "-")
+
+    set(LIBXML2_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/libxml2-build")
+    if(ANDROID_ABI)
+        set(LIBXML2_BINARY_DIR "${LIBXML2_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    FetchContent_Declare(
+        libxml2
+        GIT_REPOSITORY "https://github.com/GNOME/libxml2.git"
+        BINARY_DIR "${LIBXML2_BINARY_DIR}"
+        GIT_TAG "${AVIF_LOCAL_LIBXML_GIT_TAG}"
+        GIT_SHALLOW ON
+        UPDATE_COMMAND ""
+    )
+
+    avif_fetchcontent_populate_cmake(libxml2)
+
+    set_property(TARGET LibXml2 PROPERTY AVIF_LOCAL ON)
+
+    message(CHECK_PASS "complete")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalLibargparse.cmake b/third_party/libavif/src/cmake/Modules/LocalLibargparse.cmake
new file mode 100644
index 0000000000..870b272c50
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalLibargparse.cmake
@@ -0,0 +1,35 @@
+set(AVIF_LOCAL_LIBARGPARSE_GIT_TAG ee74d1b53bd680748af14e737378de57e2a0a954)
+
+set(LIBARGPARSE_FILENAME
+    "${AVIF_SOURCE_DIR}/ext/libargparse/build/${CMAKE_STATIC_LIBRARY_PREFIX}argparse${CMAKE_STATIC_LIBRARY_SUFFIX}"
+)
+
+if(EXISTS "${LIBARGPARSE_FILENAME}")
+    message(STATUS "libavif(AVIF_LOCAL_LIBARGPARSE): compiled library found at ${LIBARGPARSE_FILENAME}")
+    add_library(libargparse STATIC IMPORTED GLOBAL)
+    set_target_properties(libargparse PROPERTIES IMPORTED_LOCATION "${LIBARGPARSE_FILENAME}" AVIF_LOCAL ON)
+    target_include_directories(libargparse INTERFACE "${AVIF_SOURCE_DIR}/ext/libargparse/src")
+else()
+    message(STATUS "libavif(AVIF_LOCAL_LIBARGPARSE): compiled library not found at ${LIBARGPARSE_FILENAME}; using FetchContent")
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libargparse")
+        message(STATUS "libavif(AVIF_LOCAL_LIBARGPARSE): ext/libargparse found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_LIBARGPARSE "${AVIF_SOURCE_DIR}/ext/libargparse")
+        message(CHECK_START "libavif(AVIF_LOCAL_LIBARGPARSE): configuring libargparse")
+    else()
+        message(CHECK_START "libavif(AVIF_LOCAL_LIBARGPARSE): fetching and configuring libargparse")
+    endif()
+
+    FetchContent_Declare(
+        libargparse
+        GIT_REPOSITORY "https://github.com/kmurray/libargparse.git"
+        GIT_TAG ${AVIF_LOCAL_LIBARGPARSE_GIT_TAG}
+        UPDATE_COMMAND ""
+    )
+    avif_fetchcontent_populate_cmake(libargparse)
+
+    message(CHECK_PASS "complete")
+endif()
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/libargparse")
+    set_target_properties(libargparse PROPERTIES FOLDER "ext/libargparse")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalLibgav1.cmake b/third_party/libavif/src/cmake/Modules/LocalLibgav1.cmake
new file mode 100644
index 0000000000..d5f9f7264e
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalLibgav1.cmake
@@ -0,0 +1,54 @@
+set(AVIF_LOCAL_LIBGAV1_GIT_TAG "v0.19.0")
+
+set(AVIF_LIBGAV1_BUILD_DIR "${AVIF_SOURCE_DIR}/ext/libgav1/build")
+# If ${ANDROID_ABI} is set, look for the library under that subdirectory.
+if(DEFINED ANDROID_ABI)
+    set(AVIF_LIBGAV1_BUILD_DIR "${AVIF_LIBGAV1_BUILD_DIR}/${ANDROID_ABI}")
+endif()
+set(LIB_FILENAME "${AVIF_LIBGAV1_BUILD_DIR}/libgav1${CMAKE_STATIC_LIBRARY_SUFFIX}")
+
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_CODEC_LIBGAV1=LOCAL): compiled library found at ${LIB_FILENAME}")
+    add_library(libgav1_static STATIC IMPORTED GLOBAL)
+    set_target_properties(libgav1_static PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}")
+    target_include_directories(libgav1_static INTERFACE "${AVIF_SOURCE_DIR}/ext/libgav1/src")
+else()
+    message(STATUS "libavif(AVIF_CODEC_LIBGAV1=LOCAL): compiled library not found at ${LIB_FILENAME}; using FetchContent")
+
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libgav1")
+        message(STATUS "libavif(AVIF_CODEC_LIBGAV1=LOCAL): ext/libgav1 found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_LIBGAV1 "${AVIF_SOURCE_DIR}/ext/libgav1")
+        message(CHECK_START "libavif(AVIF_CODEC_LIBGAV1=LOCAL): configuring libgav1")
+    else()
+        message(CHECK_START "libavif(AVIF_CODEC_LIBGAV1=LOCAL): fetching and configuring libgav1")
+    endif()
+
+    set(LIBGAV1_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/libgav1-build")
+    if(ANDROID_ABI)
+        set(LIBGAV1_BINARY_DIR "${LIBGAV1_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    set(LIBGAV1_THREADPOOL_USE_STD_MUTEX 1 CACHE INTERNAL "")
+    set(LIBGAV1_ENABLE_EXAMPLES OFF CACHE INTERNAL "")
+    set(LIBGAV1_ENABLE_TESTS OFF CACHE INTERNAL "")
+    set(LIBGAV1_MAX_BITDEPTH 12 CACHE INTERNAL "")
+
+    FetchContent_Declare(
+        libgav1
+        GIT_REPOSITORY "https://chromium.googlesource.com/codecs/libgav1"
+        BINARY_DIR "${LIBGAV1_BINARY_DIR}"
+        GIT_TAG "${AVIF_LOCAL_LIBGAV1_GIT_TAG}"
+        GIT_SHALLOW ON
+        UPDATE_COMMAND ""
+    )
+
+    avif_fetchcontent_populate_cmake(libgav1)
+    message(CHECK_PASS "complete")
+endif()
+
+set_property(TARGET libgav1_static PROPERTY AVIF_LOCAL ON)
+add_library(libgav1::libgav1 ALIAS libgav1_static)
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/libgav1")
+    set_property(TARGET libgav1_static PROPERTY FOLDER "ext/libgav1")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalLibsharpyuv.cmake b/third_party/libavif/src/cmake/Modules/LocalLibsharpyuv.cmake
new file mode 100644
index 0000000000..99554e5270
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalLibsharpyuv.cmake
@@ -0,0 +1,62 @@
+set(AVIF_LOCAL_LIBSHARPYUV_GIT_TAG v1.4.0)
+
+set(LIB_FILENAME "${CMAKE_CURRENT_SOURCE_DIR}/ext/libwebp/build/libsharpyuv${CMAKE_STATIC_LIBRARY_SUFFIX}")
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_LIBSHARPYUV=LOCAL): compiled library found at ${LIB_FILENAME}")
+    add_library(sharpyuv::sharpyuv STATIC IMPORTED GLOBAL)
+    set_target_properties(sharpyuv::sharpyuv PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON FOLDER "ext/libwebp")
+    target_include_directories(sharpyuv::sharpyuv INTERFACE "${AVIF_SOURCE_DIR}/ext/libwebp")
+
+    set(libsharpyuv_FOUND ON)
+else()
+    message(STATUS "libavif(AVIF_LIBSHARPYUV=LOCAL): compiled library not found at ${LIB_FILENAME}; using FetchContent")
+
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libwebp")
+        message(STATUS "libavif(AVIF_LIBSHARPYUV=LOCAL): ext/libwebp found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_LIBWEBP "${AVIF_SOURCE_DIR}/ext/libwebp")
+        message(CHECK_START "libavif(AVIF_LIBSHARPYUV=LOCAL): configuring libwebp")
+    else()
+        message(CHECK_START "libavif(AVIF_LIBSHARPYUV=LOCAL): fetching and configuring libwebp")
+    endif()
+
+    set(WEBP_BUILD_ANIM_UTILS OFF CACHE BOOL "")
+    set(WEBP_BUILD_CWEBP OFF CACHE BOOL "")
+    set(WEBP_BUILD_DWEBP OFF CACHE BOOL "")
+    set(WEBP_BUILD_GIF2WEBP OFF CACHE BOOL "")
+    set(WEBP_BUILD_IMG2WEBP OFF CACHE BOOL "")
+    set(WEBP_BUILD_VWEBP OFF CACHE BOOL "")
+    set(WEBP_BUILD_WEBPINFO OFF CACHE BOOL "")
+    set(WEBP_BUILD_LIBWEBPMUX OFF CACHE BOOL "")
+    set(WEBP_BUILD_WEBPMUX OFF CACHE BOOL "")
+    set(WEBP_BUILD_EXTRAS OFF CACHE BOOL "")
+
+    set(LIBSHARPYUV_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/libwebp")
+    if(ANDROID_ABI)
+        set(LIBSHARPYUV_BINARY_DIR "${LIBSHARPYUV_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    FetchContent_Declare(
+        libwebp
+        GIT_REPOSITORY "https://chromium.googlesource.com/webm/libwebp"
+        BINARY_DIR "${LIBSHARPYUV_BINARY_DIR}"
+        GIT_TAG "${AVIF_LOCAL_LIBSHARPYUV_GIT_TAG}"
+        GIT_SHALLOW ON
+        UPDATE_COMMAND ""
+    )
+
+    avif_fetchcontent_populate_cmake(libwebp)
+
+    set_property(TARGET sharpyuv PROPERTY POSITION_INDEPENDENT_CODE ON)
+    set_property(TARGET sharpyuv PROPERTY AVIF_LOCAL ON)
+
+    target_include_directories(
+        sharpyuv INTERFACE $<BUILD_INTERFACE:${libwebp_SOURCE_DIR}> $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDE_DIR}>
+    )
+
+    add_library(sharpyuv::sharpyuv ALIAS sharpyuv)
+
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libwebp")
+        set_property(TARGET sharpyuv PROPERTY FOLDER "ext/libwebp")
+    endif()
+    message(CHECK_PASS "complete")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalLibyuv.cmake b/third_party/libavif/src/cmake/Modules/LocalLibyuv.cmake
new file mode 100644
index 0000000000..05a714803e
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalLibyuv.cmake
@@ -0,0 +1,79 @@
+set(AVIF_LOCAL_LIBYUV_TAG "a6a2ec654b1be1166b376476a7555c89eca0c275")
+
+set(AVIF_LIBYUV_BUILD_DIR "${AVIF_SOURCE_DIR}/ext/libyuv/build")
+# If ${ANDROID_ABI} is set, look for the library under that subdirectory.
+if(DEFINED ANDROID_ABI)
+    set(AVIF_LIBYUV_BUILD_DIR "${AVIF_LIBYUV_BUILD_DIR}/${ANDROID_ABI}")
+endif()
+set(LIB_FILENAME "${AVIF_LIBYUV_BUILD_DIR}/${AVIF_LIBRARY_PREFIX}yuv${CMAKE_STATIC_LIBRARY_SUFFIX}")
+
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_LIBYUV=LOCAL): compiled library found at ${LIB_FILENAME}")
+    set(LIBYUV_INCLUDE_DIR "${AVIF_SOURCE_DIR}/ext/libyuv/include")
+
+    add_library(yuv::yuv STATIC IMPORTED GLOBAL)
+    set_target_properties(yuv::yuv PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON)
+    target_include_directories(yuv::yuv INTERFACE "${LIBYUV_INCLUDE_DIR}")
+    set_target_properties(yuv::yuv PROPERTIES FOLDER "ext/libyuv")
+else()
+    message(STATUS "libavif(AVIF_LIBYUV=LOCAL): compiled library not found at ${LIB_FILENAME}; using FetchContent")
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libyuv")
+        message(STATUS "libavif(AVIF_LIBYUV=LOCAL): ext/libyuv found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_LIBYUV "${AVIF_SOURCE_DIR}/ext/libyuv")
+        message(CHECK_START "libavif(AVIF_LIBYUV=LOCAL): configuring libyuv")
+    else()
+        message(CHECK_START "libavif(AVIF_LIBYUV=LOCAL): fetching and configuring libyuv")
+    endif()
+
+    set(LIBYUV_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/libyuv-build")
+    if(ANDROID_ABI)
+        set(LIBYUV_BINARY_DIR "${LIBYUV_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    # unset JPEG_FOUND so that libyuv does not find it
+    set(JPEG_FOUND_ORIG ${JPEG_FOUND})
+    unset(JPEG_FOUND CACHE)
+    set(CMAKE_DISABLE_FIND_PACKAGE_JPEG TRUE)
+
+    FetchContent_Declare(
+        libyuv
+        GIT_REPOSITORY "https://chromium.googlesource.com/libyuv/libyuv"
+        BINARY_DIR "${LIBYUV_BINARY_DIR}"
+        GIT_TAG "${AVIF_LOCAL_LIBYUV_TAG}"
+        UPDATE_COMMAND ""
+    )
+
+    avif_fetchcontent_populate_cmake(libyuv)
+
+    set(JPEG_FOUND ${JPEG_FOUND_ORIG})
+    unset(JPEG_FOUND_ORIG CACHE)
+    set(CMAKE_DISABLE_FIND_PACKAGE_JPEG FALSE)
+
+    set_target_properties(yuv PROPERTIES AVIF_LOCAL ON POSITION_INDEPENDENT_CODE ON)
+
+    add_library(yuv::yuv ALIAS yuv)
+
+    set(LIBYUV_INCLUDE_DIR "${libyuv_SOURCE_DIR}/include")
+
+    target_include_directories(yuv INTERFACE ${LIBYUV_INCLUDE_DIR})
+
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/libyuv")
+        set_target_properties(yuv PROPERTIES FOLDER "ext/libyuv")
+    endif()
+
+    message(CHECK_PASS "complete")
+endif()
+
+set(libyuv_FOUND ON)
+
+set(LIBYUV_VERSION_H "${LIBYUV_INCLUDE_DIR}/libyuv/version.h")
+if(EXISTS ${LIBYUV_VERSION_H})
+    # message(STATUS "Reading: ${LIBYUV_VERSION_H}")
+    file(READ ${LIBYUV_VERSION_H} LIBYUV_VERSION_H_CONTENTS)
+    string(REGEX MATCH "#define LIBYUV_VERSION ([0-9]+)" _ ${LIBYUV_VERSION_H_CONTENTS})
+    set(LIBYUV_VERSION ${CMAKE_MATCH_1})
+    # message(STATUS "libyuv version detected: ${LIBYUV_VERSION}")
+endif()
+if(NOT LIBYUV_VERSION)
+    message(STATUS "libyuv version detection failed.")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalRav1e.cmake b/third_party/libavif/src/cmake/Modules/LocalRav1e.cmake
new file mode 100644
index 0000000000..786af57095
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalRav1e.cmake
@@ -0,0 +1,108 @@
+set(AVIF_LOCAL_RAV1E_GIT_TAG v0.7.1)
+set(AVIF_LOCAL_CORROSION_GIT_TAG v0.5.0)
+set(AVIF_LOCAL_CARGOC_GIT_TAG v0.10.2)
+
+set(RAV1E_LIB_FILENAME
+    "${AVIF_SOURCE_DIR}/ext/rav1e/build.libavif/usr/lib/${AVIF_LIBRARY_PREFIX}rav1e${CMAKE_STATIC_LIBRARY_SUFFIX}"
+)
+
+if(EXISTS "${RAV1E_LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_CODEC_RAV1E=LOCAL): compiled rav1e library found at ${RAV1E_LIB_FILENAME}")
+    add_library(rav1e::rav1e STATIC IMPORTED)
+    set_target_properties(rav1e::rav1e PROPERTIES IMPORTED_LOCATION "${RAV1E_LIB_FILENAME}" IMPORTED_SONAME rav1e AVIF_LOCAL ON)
+    target_include_directories(rav1e::rav1e INTERFACE "${AVIF_SOURCE_DIR}/ext/rav1e/build.libavif/usr/include/rav1e")
+else()
+    message(
+        STATUS "libavif(AVIF_CODEC_RAV1E=LOCAL): compiled rav1e library not found at ${RAV1E_LIB_FILENAME}; using FetchContent"
+    )
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/rav1e")
+        message(STATUS "libavif(AVIF_CODEC_RAV1E=LOCAL): ext/rav1e found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_RAV1E "${AVIF_SOURCE_DIR}/ext/rav1e")
+        message(CHECK_START "libavif(AVIF_CODEC_RAV1E=LOCAL): configuring rav1e")
+    else()
+        message(CHECK_START "libavif(AVIF_CODEC_RAV1E=LOCAL): fetching and configuring rav1e")
+    endif()
+
+    FetchContent_Declare(
+        Corrosion
+        GIT_REPOSITORY https://github.com/corrosion-rs/corrosion.git
+        GIT_TAG ${AVIF_LOCAL_CORROSION_GIT_TAG}
+        GIT_SHALLOW ON
+    )
+
+    if(APPLE)
+        if(CMAKE_OSX_ARCHITECTURES STREQUAL "arm64" OR CMAKE_SYSTEM_PROCESSOR STREQUAL "arm64")
+            set(Rust_CARGO_TARGET "aarch64-apple-darwin")
+        endif()
+    endif()
+
+    FetchContent_MakeAvailable(Corrosion)
+
+    find_program(CARGO_CINSTALL cargo-cinstall HINTS "$ENV{HOME}/.cargo/bin")
+
+    if(CARGO_CINSTALL)
+        add_executable(cargo-cinstall IMPORTED GLOBAL)
+        set_property(TARGET cargo-cinstall PROPERTY IMPORTED_LOCATION ${CARGO_CINSTALL})
+    endif()
+
+    if(NOT TARGET cargo-cinstall)
+        FetchContent_Declare(
+            cargoc
+            GIT_REPOSITORY https://github.com/lu-zero/cargo-c.git
+            GIT_TAG "${AVIF_LOCAL_CARGOC_GIT_TAG}"
+            GIT_SHALLOW ON
+        )
+        FetchContent_MakeAvailable(cargoc)
+
+        corrosion_import_crate(
+            MANIFEST_PATH ${cargoc_SOURCE_DIR}/Cargo.toml PROFILE release IMPORTED_CRATES MYVAR_IMPORTED_CRATES FEATURES
+            vendored-openssl
+        )
+
+        set(CARGO_CINSTALL $<TARGET_FILE:cargo-cinstall>)
+    endif()
+
+    FetchContent_Declare(
+        rav1e
+        GIT_REPOSITORY https://github.com/xiph/rav1e.git
+        GIT_TAG "${AVIF_LOCAL_RAV1E_GIT_TAG}"
+        GIT_SHALLOW ON
+    )
+    FetchContent_MakeAvailable(rav1e)
+
+    set(RAV1E_LIB_FILENAME
+        ${CMAKE_CURRENT_BINARY_DIR}/ext/rav1e/usr/lib/${CMAKE_STATIC_LIBRARY_PREFIX}rav1e${CMAKE_STATIC_LIBRARY_SUFFIX}
+    )
+    set(RAV1E_ENVVARS)
+    if(CMAKE_C_IMPLICIT_LINK_DIRECTORIES MATCHES "alpine-linux-musl")
+        list(APPEND RAV1E_ENVVARS "RUSTFLAGS=-C link-args=-Wl,-z,stack-size=2097152 -C target-feature=-crt-static")
+    endif()
+    if(CMAKE_HOST_SYSTEM_NAME STREQUAL "Darwin" AND CMAKE_OSX_SYSROOT)
+        list(APPEND RAV1E_ENVVARS "SDKROOT=${CMAKE_OSX_SYSROOT}")
+    endif()
+    if(CMAKE_HOST_SYSTEM_NAME STREQUAL "Darwin" AND CMAKE_OSX_DEPLOYMENT_TARGET)
+        list(APPEND RAV1E_ENVVARS "MACOSX_DEPLOYMENT_TARGET=${CMAKE_OSX_DEPLOYMENT_TARGET}")
+    endif()
+
+    add_custom_target(
+        rav1e
+        COMMAND ${CMAKE_COMMAND} -E env ${RAV1E_ENVVARS} ${CARGO_CINSTALL} cinstall -v --release --library-type=staticlib
+                --prefix=/usr --target ${Rust_CARGO_TARGET_CACHED} --destdir ${CMAKE_CURRENT_BINARY_DIR}/ext/rav1e
+        DEPENDS cargo-cinstall
+        BYPRODUCTS ${RAV1E_LIB_FILENAME}
+        USES_TERMINAL
+        WORKING_DIRECTORY ${rav1e_SOURCE_DIR}
+    )
+    set(RAV1E_INCLUDE_DIR "${CMAKE_CURRENT_BINARY_DIR}/ext/rav1e/usr/include/rav1e")
+    file(MAKE_DIRECTORY ${RAV1E_INCLUDE_DIR})
+    set(RAV1E_FOUND ON)
+
+    add_library(rav1e::rav1e STATIC IMPORTED)
+    add_dependencies(rav1e::rav1e rav1e)
+    target_link_libraries(rav1e::rav1e INTERFACE "${Rust_CARGO_TARGET_LINK_NATIVE_LIBS}")
+    target_link_options(rav1e::rav1e INTERFACE "${Rust_CARGO_TARGET_LINK_OPTIONS}")
+    set_target_properties(rav1e::rav1e PROPERTIES IMPORTED_LOCATION "${RAV1E_LIB_FILENAME}" AVIF_LOCAL ON FOLDER "ext/rav1e")
+    target_include_directories(rav1e::rav1e INTERFACE "${RAV1E_INCLUDE_DIR}")
+
+    message(CHECK_PASS "complete")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalSvt.cmake b/third_party/libavif/src/cmake/Modules/LocalSvt.cmake
new file mode 100644
index 0000000000..de69d3b994
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalSvt.cmake
@@ -0,0 +1,95 @@
+set(AVIF_LOCAL_SVT_GIT_TAG "v2.2.1")
+
+set(LIB_FILENAME "${AVIF_SOURCE_DIR}/ext/SVT-AV1/Bin/Release/${AVIF_LIBRARY_PREFIX}SvtAv1Enc${CMAKE_STATIC_LIBRARY_SUFFIX}")
+
+if(EXISTS "${LIB_FILENAME}")
+    message(STATUS "libavif(AVIF_CODEC_SVT=LOCAL): compiled library found at ${LIB_FILENAME}")
+    add_library(SvtAv1Enc STATIC IMPORTED GLOBAL)
+    set_target_properties(SvtAv1Enc PROPERTIES IMPORTED_LOCATION "${LIB_FILENAME}" AVIF_LOCAL ON)
+    target_include_directories(SvtAv1Enc INTERFACE "${AVIF_SOURCE_DIR}/ext/SVT-AV1/include")
+else()
+    message(STATUS "libavif(AVIF_CODEC_SVT=LOCAL): compiled library not found at ${LIB_FILENAME}; using FetchContent")
+    if(EXISTS "${AVIF_SOURCE_DIR}/ext/SVT-AV1")
+        message(STATUS "libavif(AVIF_CODEC_SVT=LOCAL): ext/SVT-AV1 found; using as FetchContent SOURCE_DIR")
+        set(FETCHCONTENT_SOURCE_DIR_SVT "${AVIF_SOURCE_DIR}/ext/SVT-AV1")
+        message(CHECK_START "libavif(AVIF_CODEC_SVT=LOCAL): configuring SVT-AV1")
+    else()
+        message(CHECK_START "libavif(AVIF_CODEC_SVT=LOCAL): fetching and configuring SVT-AV1")
+    endif()
+
+    set(SVT_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/svt-build")
+    if(ANDROID_ABI)
+        set(SVT_BINARY_DIR "${SVT_BINARY_DIR}/${ANDROID_ABI}")
+    endif()
+
+    # Workaround https://gitlab.kitware.com/cmake/cmake/-/issues/25042 by enabling ASM before ASM_NASM
+    if(NOT CMAKE_ASM_COMPILER)
+        include(CheckLanguage)
+        check_language(ASM)
+        if(CMAKE_ASM_COMPILER)
+            enable_language(ASM)
+        endif()
+    endif()
+    if(NOT CMAKE_ASM_NASM_COMPILER AND CMAKE_SYSTEM_PROCESSOR MATCHES "(x86_64|AMD64|amd64)")
+        include(CheckLanguage)
+        check_language(ASM_NASM)
+        if(CMAKE_ASM_NASM_COMPILER)
+            enable_language(ASM_NASM)
+        endif()
+    endif()
+
+    FetchContent_Declare(
+        svt
+        GIT_REPOSITORY "https://gitlab.com/AOMediaCodec/SVT-AV1.git"
+        BINARY_DIR "${SVT_BINARY_DIR}"
+        GIT_TAG "${AVIF_LOCAL_SVT_GIT_TAG}"
+        UPDATE_COMMAND ""
+        GIT_SHALLOW ON
+    )
+
+    set(BUILD_DEC OFF CACHE BOOL "")
+    set(BUILD_APPS OFF CACHE BOOL "")
+    set(NATIVE OFF CACHE BOOL "")
+
+    set(CMAKE_BUILD_TYPE_ORIG ${CMAKE_BUILD_TYPE})
+    set(CMAKE_BUILD_TYPE Release CACHE INTERNAL "")
+
+    set(CMAKE_OUTPUT_DIRECTORY_ORIG "${CMAKE_OUTPUT_DIRECTORY}")
+    set(CMAKE_OUTPUT_DIRECTORY "${SVT_BINARY_DIR}" CACHE INTERNAL "")
+
+    avif_fetchcontent_populate_cmake(svt)
+
+    set(CMAKE_BUILD_TYPE ${CMAKE_BUILD_TYPE_ORIG} CACHE STRING "" FORCE)
+    set(CMAKE_OUTPUT_DIRECTORY ${CMAKE_OUTPUT_DIRECTORY_ORIG} CACHE STRING "" FORCE)
+
+    set(SVT_INCLUDE_DIR ${SVT_BINARY_DIR}/include)
+    file(MAKE_DIRECTORY ${SVT_INCLUDE_DIR}/svt-av1)
+
+    file(GLOB _svt_header_files ${svt_SOURCE_DIR}/Source/API/*.h)
+
+    set(_svt_header_byproducts)
+
+    foreach(_svt_header_file ${_svt_header_files})
+        get_filename_component(_svt_header_name "${_svt_header_file}" NAME)
+        set(_svt_header_output ${SVT_INCLUDE_DIR}/svt-av1/${_svt_header_name})
+        add_custom_command(
+            OUTPUT ${_svt_header_output}
+            COMMAND ${CMAKE_COMMAND} -E copy_if_different ${_svt_header_file} ${_svt_header_output}
+            DEPENDS ${_svt_header_file}
+            VERBATIM
+        )
+        list(APPEND _svt_header_byproducts ${_svt_header_output})
+    endforeach()
+
+    add_custom_target(_svt_install_headers DEPENDS ${_svt_header_byproducts})
+    add_dependencies(SvtAv1Enc _svt_install_headers)
+    set_target_properties(SvtAv1Enc PROPERTIES AVIF_LOCAL ON)
+
+    target_include_directories(SvtAv1Enc INTERFACE ${SVT_INCLUDE_DIR})
+
+    message(CHECK_PASS "complete")
+endif()
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/SVT-AV1")
+    set_target_properties(SvtAv1Enc PROPERTIES FOLDER "ext/SVT-AV1")
+endif()
diff --git a/third_party/libavif/src/cmake/Modules/LocalZlibpng.cmake b/third_party/libavif/src/cmake/Modules/LocalZlibpng.cmake
new file mode 100644
index 0000000000..608ee8c8f4
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/LocalZlibpng.cmake
@@ -0,0 +1,107 @@
+# To upgrade libpng to > v1.6.40, you need zlib containing f1f503da85d52e56aae11557b4d79a42bcaa2b86
+# hence a version > v1.3.1 .
+set(AVIF_LOCAL_ZLIB_GIT_TAG v1.3.1)
+set(AVIF_LOCAL_LIBPNG_GIT_TAG v1.6.40)
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/zlib")
+    message(STATUS "libavif(AVIF_ZLIBPNG=LOCAL): ext/zlib found; using as FetchContent SOURCE_DIR")
+    set(FETCHCONTENT_SOURCE_DIR_ZLIB "${AVIF_SOURCE_DIR}/ext/zlib")
+    message(CHECK_START "libavif(AVIF_ZLIBPNG=LOCAL): configuring zlib")
+    set(ZLIB_SOURCE_DIR "${FETCHCONTENT_SOURCE_DIR_ZLIB}")
+else()
+    message(CHECK_START "libavif(AVIF_ZLIBPNG=LOCAL): fetching and configuring zlib")
+    set(ZLIB_SOURCE_DIR "${FETCHCONTENT_BASE_DIR}/zlib-src")
+endif()
+
+set(ZLIB_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/zlib")
+if(ANDROID_ABI)
+    set(ZLIB_BINARY_DIR "${ZLIB_BINARY_DIR}/${ANDROID_ABI}")
+endif()
+
+FetchContent_Declare(
+    zlib
+    GIT_REPOSITORY "https://github.com/madler/zlib.git"
+    SOURCE_DIR "${ZLIB_SOURCE_DIR}" BINARY_DIR "${ZLIB_BINARY_DIR}"
+    GIT_TAG "${AVIF_LOCAL_ZLIB_GIT_TAG}"
+    GIT_SHALLOW ON
+    UPDATE_COMMAND ""
+)
+
+# Put the value of ZLIB_INCLUDE_DIR in the cache. This works around cmake behavior that has been updated by
+# cmake policy CMP0102 in cmake 3.17. Remove the CACHE workaround when we require cmake 3.17 or later. See
+# https://gitlab.kitware.com/cmake/cmake/-/issues/21343.
+set(ZLIB_INCLUDE_DIR "${ZLIB_SOURCE_DIR}" CACHE PATH "zlib include dir")
+# This include_directories() call must be before add_subdirectory(ext/zlib) to work around the
+# zlib/CMakeLists.txt bug fixed by https://github.com/madler/zlib/pull/818.
+include_directories(SYSTEM $<BUILD_INTERFACE:${ZLIB_INCLUDE_DIR}>)
+
+if(NOT zlib_POPULATED)
+    avif_fetchcontent_populate_cmake(zlib)
+
+    # Re-enable example and example64 targets, as these are used by tests
+    if(AVIF_BUILD_TESTS)
+        set_property(TARGET example PROPERTY EXCLUDE_FROM_ALL FALSE)
+        if(TARGET example64)
+            set_property(TARGET example64 PROPERTY EXCLUDE_FROM_ALL FALSE)
+        endif()
+    endif()
+endif()
+
+target_include_directories(zlibstatic INTERFACE $<BUILD_INTERFACE:${ZLIB_INCLUDE_DIR}>)
+
+# This include_directories() call and the previous include_directories() call provide the zlib
+# include directories for add_subdirectory(ext/libpng). Because we set PNG_BUILD_ZLIB,
+# libpng/CMakeLists.txt won't call find_package(ZLIB REQUIRED) and will see an empty
+# ${ZLIB_INCLUDE_DIR}.
+include_directories("${zlib_BINARY_DIR}")
+set(CMAKE_DEBUG_POSTFIX "")
+
+add_library(ZLIB::ZLIB ALIAS zlibstatic)
+
+# TODO Uncomment for zlib > v1.3
+# install(TARGETS zlib zlibstatic EXPORT zlib)
+# install(EXPORT zlib
+#         DESTINATION ${CMAKE_INSTALL_LIBDIR}/zlib)
+
+message(CHECK_PASS "complete")
+
+if(EXISTS "${AVIF_SOURCE_DIR}/ext/libpng")
+    message(STATUS "libavif(AVIF_ZLIBPNG=LOCAL): ext/libpng found; using as FetchContent SOURCE_DIR")
+    set(FETCHCONTENT_SOURCE_DIR_LIBPNG "${AVIF_SOURCE_DIR}/ext/libpng")
+    message(CHECK_START "libavif(AVIF_ZLIBPNG=LOCAL): configuring libpng")
+else()
+    message(CHECK_START "libavif(AVIF_ZLIBPNG=LOCAL): fetching and configuring libpng")
+endif()
+
+# This is the only way I could avoid libpng going crazy if it found awk.exe, seems benign otherwise
+set(PREV_ANDROID ${ANDROID})
+set(ANDROID TRUE)
+set(PNG_BUILD_ZLIB "${zlib_SOURCE_DIR}" CACHE STRING "" FORCE)
+set(PNG_SHARED OFF CACHE BOOL "")
+set(PNG_TESTS OFF CACHE BOOL "")
+set(PNG_EXECUTABLES OFF CACHE BOOL "")
+
+set(LIBPNG_BINARY_DIR "${FETCHCONTENT_BASE_DIR}/libpng")
+if(ANDROID_ABI)
+    set(LIBPNG_BINARY_DIR "${LIBPNG_BINARY_DIR}/${ANDROID_ABI}")
+endif()
+
+FetchContent_Declare(
+    libpng
+    GIT_REPOSITORY "https://github.com/glennrp/libpng.git"
+    BINARY_DIR "${LIBPNG_BINARY_DIR}"
+    GIT_TAG "${AVIF_LOCAL_LIBPNG_GIT_TAG}"
+    GIT_SHALLOW ON
+    UPDATE_COMMAND ""
+)
+
+avif_fetchcontent_populate_cmake(libpng)
+
+set(PNG_PNG_INCLUDE_DIR "${libpng_SOURCE_DIR}")
+include_directories("${libpng_BINARY_DIR}")
+set(ANDROID ${PREV_ANDROID})
+
+set_target_properties(png_static zlibstatic PROPERTIES AVIF_LOCAL ON)
+add_library(PNG::PNG ALIAS png_static)
+
+message(CHECK_PASS "complete")
diff --git a/third_party/libavif/src/cmake/Modules/merge_static_libs.cmake b/third_party/libavif/src/cmake/Modules/merge_static_libs.cmake
new file mode 100644
index 0000000000..2f4826770e
--- /dev/null
+++ b/third_party/libavif/src/cmake/Modules/merge_static_libs.cmake
@@ -0,0 +1,128 @@
+function(avif_collect_deps target out_deps)
+    get_target_property(current_deps ${target} INTERFACE_LINK_LIBRARIES)
+
+    if(NOT current_deps)
+        set(current_deps "") # if no dependencies, replace "current_deps-NOTFOUND" with empty list
+    endif()
+
+    # Remove entries between ::@(directory-id) and ::@
+    # Such entries are added by target_link_libraries() calls outside the target's directory
+    set(filtered_deps "")
+    set(in_special_block FALSE)
+    foreach(dep IN LISTS current_deps)
+        if("${dep}" MATCHES "^::@\\(.*\\)$")
+            set(in_special_block TRUE) # Latch on
+        elseif("${dep}" STREQUAL "::@")
+            set(in_special_block FALSE) # Latch off
+        elseif(NOT in_special_block)
+            string(REGEX REPLACE "\\\$<BUILD_INTERFACE:([^>]*)>" "\\1" dep ${dep})
+            string(REGEX REPLACE "\\\$<LINK_ONLY:([^>]*)>" "\\1" dep ${dep})
+            if(TARGET ${dep})
+                get_target_property(_aliased_dep ${dep} ALIASED_TARGET)
+                if(_aliased_dep)
+                    list(APPEND filtered_deps ${_aliased_dep})
+                else()
+                    list(APPEND filtered_deps ${dep})
+                endif()
+            endif()
+        endif()
+    endforeach()
+
+    set(all_deps ${filtered_deps})
+
+    foreach(dep IN LISTS filtered_deps)
+        # Avoid infinite recursion if the target has a cyclic dependency
+        if(NOT "${dep}" IN_LIST ${out_deps})
+            avif_collect_deps(${dep} dep_child_deps)
+            list(APPEND all_deps ${dep_child_deps})
+        endif()
+    endforeach()
+
+    list(REMOVE_DUPLICATES all_deps)
+
+    set(${out_deps} "${all_deps}" PARENT_SCOPE)
+endfunction()
+
+function(merge_static_libs target in_target)
+    set(args ${ARGN})
+
+    set(dependencies ${in_target})
+    set(libs $<TARGET_FILE:${in_target}>)
+
+    set(source_file ${CMAKE_CURRENT_BINARY_DIR}/${target}_depends.c)
+    add_library(${target} STATIC ${source_file})
+
+    avif_collect_deps(${in_target} lib_deps)
+
+    foreach(lib ${lib_deps})
+        get_target_property(child_target_type ${lib} TYPE)
+        if(${child_target_type} STREQUAL "INTERFACE_LIBRARY")
+            continue()
+        endif()
+        get_target_property(link_dirs ${lib} INTERFACE_LINK_DIRECTORIES)
+        if(link_dirs)
+            target_link_directories(${target} PUBLIC ${link_dirs})
+        endif()
+        get_target_property(is_avif_local ${lib} AVIF_LOCAL)
+        if(is_avif_local)
+            list(APPEND libs $<TARGET_FILE:${lib}>)
+            list(APPEND dependencies "${lib}")
+        endif()
+    endforeach()
+
+    list(REMOVE_DUPLICATES libs)
+
+    add_custom_command(
+        OUTPUT ${source_file} DEPENDS ${dependencies} COMMAND ${CMAKE_COMMAND} -E echo \"const int dummy = 0\;\" > ${source_file}
+    )
+
+    add_custom_command(TARGET ${target} POST_BUILD COMMAND ${CMAKE_COMMAND} -E remove $<TARGET_FILE:${target}>)
+
+    if(APPLE)
+        add_custom_command(
+            TARGET ${target}
+            POST_BUILD
+            COMMENT "Merge static libraries with libtool"
+            COMMAND xcrun libtool -static -o $<TARGET_FILE:${target}> -no_warning_for_no_symbols ${libs}
+        )
+    elseif(CMAKE_C_COMPILER_ID MATCHES "^(Clang|GNU|Intel|IntelLLVM)$")
+        add_custom_command(
+            TARGET ${target}
+            POST_BUILD
+            COMMENT "Merge static libraries with ar"
+            COMMAND ${CMAKE_COMMAND} -E echo CREATE $<TARGET_FILE:${target}> >script.ar
+        )
+
+        foreach(lib ${libs})
+            add_custom_command(TARGET ${target} POST_BUILD COMMAND ${CMAKE_COMMAND} -E echo ADDLIB ${lib} >>script.ar)
+        endforeach()
+
+        add_custom_command(
+            TARGET ${target}
+            POST_BUILD
+            COMMAND ${CMAKE_COMMAND} -E echo SAVE >>script.ar
+            COMMAND ${CMAKE_COMMAND} -E echo END >>script.ar
+            COMMAND ${CMAKE_AR} -M <script.ar
+            COMMAND ${CMAKE_COMMAND} -E remove script.ar
+        )
+    elseif(MSVC)
+        if(CMAKE_LIBTOOL)
+            set(BUNDLE_TOOL ${CMAKE_LIBTOOL})
+        else()
+            find_program(BUNDLE_TOOL lib HINTS "${CMAKE_C_COMPILER}/..")
+
+            if(NOT BUNDLE_TOOL)
+                message(FATAL_ERROR "Cannot locate lib.exe to bundle libraries")
+            endif()
+        endif()
+
+        add_custom_command(
+            TARGET ${target}
+            POST_BUILD
+            COMMENT "Merge static libraries with lib.exe"
+            COMMAND ${BUNDLE_TOOL} /NOLOGO /OUT:$<TARGET_FILE:${target}> ${libs}
+        )
+    else()
+        message(FATAL_ERROR "Unsupported platform for static link merging")
+    endif()
+endfunction()
diff --git a/third_party/libavif/src/contrib/CMakeLists.txt b/third_party/libavif/src/contrib/CMakeLists.txt
new file mode 100644
index 0000000000..602e8aa348
--- /dev/null
+++ b/third_party/libavif/src/contrib/CMakeLists.txt
@@ -0,0 +1,4 @@
+# Copyright 2020 Joe Drago. All rights reserved.
+# SPDX-License-Identifier: BSD-2-Clause
+
+add_subdirectory(gdk-pixbuf)
diff --git a/third_party/libavif/src/contrib/README.md b/third_party/libavif/src/contrib/README.md
new file mode 100644
index 0000000000..fdb9851df7
--- /dev/null
+++ b/third_party/libavif/src/contrib/README.md
@@ -0,0 +1,9 @@
+# libavif external contributions
+
+Anything in this directory was contributed by an external author and is not officially maintained by
+libavif directly, nor are there any expectations of continued functionality. Any CMake options
+offered in libavif's CMakeLists that cite files in this subdirectory are guaranteed to be disabled
+by default.
+
+See libavif's `LICENSE` file to learn about any additional license requirements/information for any
+subdirectories in here.
diff --git a/third_party/libavif/src/contrib/gdk-pixbuf/.clang-format b/third_party/libavif/src/contrib/gdk-pixbuf/.clang-format
new file mode 100644
index 0000000000..2da5070110
--- /dev/null
+++ b/third_party/libavif/src/contrib/gdk-pixbuf/.clang-format
@@ -0,0 +1,23 @@
+# Coding style is similar to https://gitlab.gnome.org/GNOME/gdk-pixbuf/
+# IndentWidth is reduced to 4 instead of 8.
+Language: Cpp
+BasedOnStyle: GNU
+IndentWidth: 4
+AlwaysBreakAfterDefinitionReturnType: All
+BreakBeforeBinaryOperators: true
+BinPackParameters: false
+SpaceAfterCStyleCast: true
+IndentCaseLabels: false
+IndentCaseBlocks: false
+BreakBeforeBraces: Custom
+AlignAfterOpenBracket: Align
+BraceWrapping:
+  AfterCaseLabel: false
+  AfterEnum: true
+  AfterFunction: true
+  AfterStruct: true
+  AfterUnion: true
+  BeforeElse: false
+  BeforeWhile: false
+  IndentBraces: false
+ColumnLimit: 0
diff --git a/third_party/libavif/src/contrib/gdk-pixbuf/CMakeLists.txt b/third_party/libavif/src/contrib/gdk-pixbuf/CMakeLists.txt
new file mode 100644
index 0000000000..517a4c0ec1
--- /dev/null
+++ b/third_party/libavif/src/contrib/gdk-pixbuf/CMakeLists.txt
@@ -0,0 +1,29 @@
+# Copyright 2020 Emmanuel Gil Peyrot. All rights reserved.
+# SPDX-License-Identifier: BSD-2-Clause
+
+option(AVIF_BUILD_GDK_PIXBUF "Build a gdk-pixbuf loader" OFF)
+if(AVIF_BUILD_GDK_PIXBUF)
+    find_package(PkgConfig)
+    if(PKG_CONFIG_FOUND)
+        pkg_search_module(GDK_PIXBUF gdk-pixbuf-2.0)
+        if(GDK_PIXBUF_FOUND)
+            set(GDK_PIXBUF_SRCS loader.c)
+            add_library(pixbufloader-avif MODULE ${GDK_PIXBUF_SRCS})
+
+            target_link_libraries(pixbufloader-avif PUBLIC ${GDK_PIXBUF_LIBRARIES} avif)
+            target_link_directories(pixbufloader-avif PUBLIC ${GDK_PIXBUF_LIBRARY_DIRS})
+            target_include_directories(pixbufloader-avif SYSTEM PUBLIC ${GDK_PIXBUF_INCLUDE_DIRS})
+
+            pkg_get_variable(GDK_PIXBUF_MODULEDIR gdk-pixbuf-2.0 gdk_pixbuf_moduledir)
+            string(REPLACE ${GDK_PIXBUF_PREFIX} ${CMAKE_INSTALL_PREFIX} GDK_PIXBUF_MODULEDIR ${GDK_PIXBUF_MODULEDIR})
+            install(TARGETS pixbufloader-avif DESTINATION ${GDK_PIXBUF_MODULEDIR})
+
+            configure_file(avif.thumbnailer.in ${CMAKE_CURRENT_BINARY_DIR}/avif.thumbnailer @ONLY)
+            install(FILES ${CMAKE_CURRENT_BINARY_DIR}/avif.thumbnailer DESTINATION ${CMAKE_INSTALL_DATADIR}/thumbnailers)
+        else()
+            message(WARNING "gdk-pixbuf loader: disabled due to missing gdk-pixbuf-2.0")
+        endif()
+    else()
+        message(WARNING "gdk-pixbuf loader: disabled due to missing pkg-config")
+    endif()
+endif()
diff --git a/third_party/libavif/src/contrib/gdk-pixbuf/avif.thumbnailer.in b/third_party/libavif/src/contrib/gdk-pixbuf/avif.thumbnailer.in
new file mode 100644
index 0000000000..9fd8fcf636
--- /dev/null
+++ b/third_party/libavif/src/contrib/gdk-pixbuf/avif.thumbnailer.in
@@ -0,0 +1,4 @@
+[Thumbnailer Entry]
+TryExec=@CMAKE_INSTALL_FULL_BINDIR@/gdk-pixbuf-thumbnailer
+Exec=@CMAKE_INSTALL_FULL_BINDIR@/gdk-pixbuf-thumbnailer -s %s %u %o
+MimeType=image/avif;
diff --git a/third_party/libavif/src/contrib/gdk-pixbuf/loader.c b/third_party/libavif/src/contrib/gdk-pixbuf/loader.c
new file mode 100644
index 0000000000..8a8180aa50
--- /dev/null
+++ b/third_party/libavif/src/contrib/gdk-pixbuf/loader.c
@@ -0,0 +1,526 @@
+/* Copyright 2020 Emmanuel Gil Peyrot. All rights reserved.
+   SPDX-License-Identifier: BSD-2-Clause
+*/
+
+#include <avif/avif.h>
+#include <stdlib.h>
+
+#define GDK_PIXBUF_ENABLE_BACKEND
+#include <gdk-pixbuf/gdk-pixbuf-io.h>
+#include <gdk-pixbuf/gdk-pixbuf.h>
+
+G_MODULE_EXPORT void fill_vtable (GdkPixbufModule *module);
+G_MODULE_EXPORT void fill_info (GdkPixbufFormat *info);
+
+struct avif_context
+{
+    GdkPixbuf *pixbuf;
+
+    GdkPixbufModuleSizeFunc size_func;
+    GdkPixbufModuleUpdatedFunc updated_func;
+    GdkPixbufModulePreparedFunc prepared_func;
+    gpointer user_data;
+
+    avifDecoder *decoder;
+    GByteArray *data;
+    GBytes *bytes;
+};
+
+static void
+avif_context_free (struct avif_context *context)
+{
+    if (!context)
+        return;
+
+    if (context->decoder) {
+        avifDecoderDestroy (context->decoder);
+        context->decoder = NULL;
+    }
+
+    if (context->data) {
+        g_byte_array_unref (context->data);
+        context->bytes = NULL;
+    }
+
+    if (context->bytes) {
+        g_bytes_unref (context->bytes);
+        context->bytes = NULL;
+    }
+
+    if (context->pixbuf) {
+        g_object_unref (context->pixbuf);
+        context->pixbuf = NULL;
+    }
+
+    g_free (context);
+}
+
+static gboolean
+avif_context_try_load (struct avif_context *context, GError **error)
+{
+    avifResult ret;
+    avifDecoder *decoder = context->decoder;
+    avifImage *image;
+    avifRGBImage rgb;
+    const uint8_t *data;
+    size_t size;
+    int width, height;
+    GdkPixbuf *output;
+
+    data = g_bytes_get_data (context->bytes, &size);
+
+    ret = avifDecoderSetIOMemory (decoder, data, size);
+    if (ret != AVIF_RESULT_OK) {
+        g_set_error (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_CORRUPT_IMAGE,
+                     "Couldn't decode image: %s", avifResultToString (ret));
+        return FALSE;
+    }
+
+    ret = avifDecoderParse (decoder);
+    if (ret != AVIF_RESULT_OK) {
+        g_set_error (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_CORRUPT_IMAGE,
+                     "Couldn't decode image: %s", avifResultToString (ret));
+        return FALSE;
+    }
+
+    if (decoder->imageCount > 1) {
+        g_set_error_literal (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_FAILED,
+                             "Image sequences not yet implemented");
+        return FALSE;
+    }
+
+    ret = avifDecoderNextImage (decoder);
+    if (ret == AVIF_RESULT_NO_IMAGES_REMAINING) {
+        /* No more images, bail out. Verify that you got the expected amount of images decoded. */
+        return TRUE;
+    } else if (ret != AVIF_RESULT_OK) {
+        g_set_error (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_FAILED,
+                     "Failed to decode all frames: %s", avifResultToString (ret));
+        return FALSE;
+    }
+
+    image = decoder->image;
+    width = image->width;
+    height = image->height;
+
+    avifRGBImageSetDefaults (&rgb, image);
+    rgb.depth = 8;
+
+    if (image->alphaPlane) {
+        rgb.format = AVIF_RGB_FORMAT_RGBA;
+        output = gdk_pixbuf_new (GDK_COLORSPACE_RGB,
+                                 TRUE, 8, width, height);
+    } else {
+        rgb.format = AVIF_RGB_FORMAT_RGB;
+        output = gdk_pixbuf_new (GDK_COLORSPACE_RGB,
+                                 FALSE, 8, width, height);
+    }
+
+    if (output == NULL) {
+        g_set_error_literal (error,
+                             GDK_PIXBUF_ERROR,
+                             GDK_PIXBUF_ERROR_INSUFFICIENT_MEMORY,
+                             "Insufficient memory to open AVIF file");
+        return FALSE;
+    }
+
+    rgb.pixels = gdk_pixbuf_get_pixels (output);
+    rgb.rowBytes = gdk_pixbuf_get_rowstride (output);
+
+    ret = avifImageYUVToRGB (image, &rgb);
+    if (ret != AVIF_RESULT_OK) {
+        g_set_error (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_FAILED,
+                     "Failed to convert YUV to RGB: %s", avifResultToString (ret));
+        g_object_unref (output);
+        return FALSE;
+    }
+
+    /* transformations */
+    if (image->transformFlags & AVIF_TRANSFORM_CLAP) {
+        if ((image->clap.widthD > 0) && (image->clap.heightD > 0) && (image->clap.horizOffD > 0) && (image->clap.vertOffD > 0)) {
+
+            int new_width, new_height;
+
+            new_width = (int) ((double) (image->clap.widthN) / (image->clap.widthD) + 0.5);
+            if (new_width > width) {
+                new_width = width;
+            }
+
+            new_height = (int) ((double) (image->clap.heightN) / (image->clap.heightD) + 0.5);
+            if (new_height > height) {
+                new_height = height;
+            }
+
+            if (new_width > 0 && new_height > 0) {
+                int offx, offy;
+                GdkPixbuf *output_cropped;
+                GdkPixbuf *cropped_copy;
+
+                offx = ((double) ((int32_t) image->clap.horizOffN)) / (image->clap.horizOffD) + (width - new_width) / 2.0 + 0.5;
+                if (offx < 0) {
+                    offx = 0;
+                } else if (offx > (width - new_width)) {
+                    offx = width - new_width;
+                }
+
+                offy = ((double) ((int32_t) image->clap.vertOffN)) / (image->clap.vertOffD) + (height - new_height) / 2.0 + 0.5;
+                if (offy < 0) {
+                    offy = 0;
+                } else if (offy > (height - new_height)) {
+                    offy = height - new_height;
+                }
+
+                output_cropped = gdk_pixbuf_new_subpixbuf (output, offx, offy, new_width, new_height);
+                cropped_copy = gdk_pixbuf_copy (output_cropped);
+                g_clear_object (&output_cropped);
+
+                if (cropped_copy) {
+                    g_object_unref (output);
+                    output = cropped_copy;
+                }
+            }
+        } else {
+            /* Zero values, we need to avoid 0 divide. */
+            g_warning ("Wrong values in avifCleanApertureBox\n");
+        }
+    }
+
+    if (image->transformFlags & AVIF_TRANSFORM_IROT) {
+        GdkPixbuf *output_rotated = NULL;
+
+        switch (image->irot.angle) {
+        case 1:
+            output_rotated = gdk_pixbuf_rotate_simple (output, GDK_PIXBUF_ROTATE_COUNTERCLOCKWISE);
+            break;
+        case 2:
+            output_rotated = gdk_pixbuf_rotate_simple (output, GDK_PIXBUF_ROTATE_UPSIDEDOWN);
+            break;
+        case 3:
+            output_rotated = gdk_pixbuf_rotate_simple (output, GDK_PIXBUF_ROTATE_CLOCKWISE);
+            break;
+        }
+
+        if (output_rotated) {
+            g_object_unref (output);
+            output = output_rotated;
+        }
+    }
+
+    if (image->transformFlags & AVIF_TRANSFORM_IMIR) {
+        GdkPixbuf *output_mirrored = NULL;
+
+        switch (image->imir.axis) {
+        case 0:
+            output_mirrored = gdk_pixbuf_flip (output, FALSE);
+            break;
+        case 1:
+            output_mirrored = gdk_pixbuf_flip (output, TRUE);
+            break;
+        }
+
+        if (output_mirrored) {
+            g_object_unref (output);
+            output = output_mirrored;
+        }
+    }
+
+    /* width, height could be different after applied transformations */
+    width = gdk_pixbuf_get_width (output);
+    height = gdk_pixbuf_get_height (output);
+
+    if (context->size_func) {
+        (*context->size_func) (&width, &height, context->user_data);
+    }
+
+    if (width == 0 || height == 0) {
+        g_set_error_literal (error,
+                             GDK_PIXBUF_ERROR,
+                             GDK_PIXBUF_ERROR_CORRUPT_IMAGE,
+                             "Transformed AVIF has zero width or height");
+        g_object_unref (output);
+        return FALSE;
+    }
+
+    if (width < gdk_pixbuf_get_width (output) || height < gdk_pixbuf_get_height (output)) {
+        GdkPixbuf *output_scaled = NULL;
+
+        output_scaled = gdk_pixbuf_scale_simple (output, width, height, GDK_INTERP_HYPER);
+        if (output_scaled) {
+            g_object_unref (output);
+            output = output_scaled;
+        }
+    }
+
+    if (image->icc.size != 0) {
+        gchar *icc_base64 = g_base64_encode ((const guchar *) image->icc.data, image->icc.size);
+        gdk_pixbuf_set_option (output, "icc-profile", icc_base64);
+        g_free (icc_base64);
+    }
+
+    if (context->pixbuf) {
+        g_object_unref (context->pixbuf);
+        context->pixbuf = NULL;
+    }
+
+    context->pixbuf = output;
+    context->prepared_func (context->pixbuf, NULL, context->user_data);
+
+    return TRUE;
+}
+
+static gpointer
+begin_load (GdkPixbufModuleSizeFunc size_func,
+            GdkPixbufModulePreparedFunc prepared_func,
+            GdkPixbufModuleUpdatedFunc updated_func,
+            gpointer user_data,
+            GError **error)
+{
+    struct avif_context *context;
+    avifDecoder *decoder;
+
+    g_assert (prepared_func != NULL);
+
+    decoder = avifDecoderCreate ();
+    if (!decoder) {
+        g_set_error_literal (error, GDK_PIXBUF_ERROR, GDK_PIXBUF_ERROR_INSUFFICIENT_MEMORY,
+                             "Couldn't allocate memory for decoder");
+        return NULL;
+    }
+
+    context = g_new0 (struct avif_context, 1);
+    if (!context)
+        return NULL;
+
+    context->size_func = size_func;
+    context->updated_func = updated_func;
+    context->prepared_func = prepared_func;
+    context->user_data = user_data;
+
+    context->decoder = decoder;
+    context->data = g_byte_array_sized_new (40000);
+
+    return context;
+}
+
+static gboolean
+stop_load (gpointer data, GError **error)
+{
+    struct avif_context *context = (struct avif_context *) data;
+    gboolean ret;
+
+    context->bytes = g_byte_array_free_to_bytes (context->data);
+    context->data = NULL;
+    ret = avif_context_try_load (context, error);
+
+    avif_context_free (context);
+
+    return ret;
+}
+
+static gboolean
+load_increment (gpointer data, const guchar *buf, guint size, GError **error)
+{
+    struct avif_context *context = (struct avif_context *) data;
+    g_byte_array_append (context->data, buf, size);
+    if (error)
+        *error = NULL;
+    return TRUE;
+}
+
+static gboolean
+avif_is_save_option_supported (const gchar *option_key)
+{
+    if (g_strcmp0 (option_key, "quality") == 0) {
+        return TRUE;
+    }
+
+    return FALSE;
+}
+
+static gboolean
+avif_image_saver (FILE *f,
+                  GdkPixbuf *pixbuf,
+                  gchar **keys,
+                  gchar **values,
+                  GError **error)
+{
+    int width, height;
+    long quality = 68; /* default; must be between 0 and 100 */
+    gboolean save_alpha;
+    avifImage *avif;
+    avifRGBImage rgb;
+    avifResult res;
+    avifRWData raw = AVIF_DATA_EMPTY;
+    avifEncoder *encoder;
+    guint maxThreads;
+
+    if (f == NULL || pixbuf == NULL) {
+        return FALSE;
+    }
+
+    if (keys && *keys) {
+        gchar **kiter = keys;
+        gchar **viter = values;
+
+        while (*kiter) {
+            if (strcmp (*kiter, "quality") == 0) {
+                char *endptr = NULL;
+                quality = strtol (*viter, &endptr, 10);
+
+                if (endptr == *viter) {
+                    g_set_error (error,
+                                 GDK_PIXBUF_ERROR,
+                                 GDK_PIXBUF_ERROR_BAD_OPTION,
+                                 "AVIF quality must be a value between 0 and 100; value \"%s\" could not be parsed.",
+                                 *viter);
+
+                    return FALSE;
+                }
+
+                if (quality < 0 || quality > 100) {
+                    g_set_error (error,
+                                 GDK_PIXBUF_ERROR,
+                                 GDK_PIXBUF_ERROR_BAD_OPTION,
+                                 "AVIF quality must be a value between 0 and 100; value \"%ld\" is not allowed.",
+                                 quality);
+
+                    return FALSE;
+                }
+            } else {
+                g_warning ("Unrecognized parameter (%s) passed to AVIF saver.", *kiter);
+            }
+
+            ++kiter;
+            ++viter;
+        }
+    }
+
+    if (gdk_pixbuf_get_bits_per_sample (pixbuf) != 8) {
+        g_set_error (error,
+                     GDK_PIXBUF_ERROR,
+                     GDK_PIXBUF_ERROR_UNKNOWN_TYPE,
+                     "Sorry, only 8bit images are supported by this AVIF saver");
+        return FALSE;
+    }
+
+    width = gdk_pixbuf_get_width (pixbuf);
+    height = gdk_pixbuf_get_height (pixbuf);
+
+    if (width == 0 || height == 0) {
+        g_set_error (error,
+                     GDK_PIXBUF_ERROR,
+                     GDK_PIXBUF_ERROR_CORRUPT_IMAGE,
+                     "Empty image, nothing to save");
+        return FALSE;
+    }
+
+    save_alpha = gdk_pixbuf_get_has_alpha (pixbuf);
+
+    if (save_alpha) {
+        if (gdk_pixbuf_get_n_channels (pixbuf) != 4) {
+            g_set_error (error,
+                         GDK_PIXBUF_ERROR,
+                         GDK_PIXBUF_ERROR_UNKNOWN_TYPE,
+                         "Unsupported number of channels");
+            return FALSE;
+        }
+    } else {
+        if (gdk_pixbuf_get_n_channels (pixbuf) != 3) {
+            g_set_error (error,
+                         GDK_PIXBUF_ERROR,
+                         GDK_PIXBUF_ERROR_UNKNOWN_TYPE,
+                         "Unsupported number of channels");
+            return FALSE;
+        }
+    }
+
+    avif = avifImageCreate (width, height, 8, quality >= 90 ? AVIF_PIXEL_FORMAT_YUV444 : AVIF_PIXEL_FORMAT_YUV420);
+    avif->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;
+    avifRGBImageSetDefaults (&rgb, avif);
+
+    rgb.depth = 8;
+    rgb.pixels = (uint8_t *) gdk_pixbuf_read_pixels (pixbuf);
+    rgb.rowBytes = gdk_pixbuf_get_rowstride (pixbuf);
+
+    if (save_alpha) {
+        rgb.format = AVIF_RGB_FORMAT_RGBA;
+    } else {
+        rgb.format = AVIF_RGB_FORMAT_RGB;
+    }
+
+    res = avifImageRGBToYUV (avif, &rgb);
+    if (res != AVIF_RESULT_OK) {
+        g_set_error (error,
+                     GDK_PIXBUF_ERROR,
+                     GDK_PIXBUF_ERROR_FAILED,
+                     "Problem in RGB->YUV conversion: %s", avifResultToString (res));
+        avifImageDestroy (avif);
+        return FALSE;
+    }
+
+    maxThreads = g_get_num_processors ();
+    encoder = avifEncoderCreate ();
+
+    encoder->maxThreads = CLAMP (maxThreads, 1, 64);
+    encoder->quality = (int) quality;
+    if (save_alpha) {
+        if (quality >= 50) {
+            encoder->qualityAlpha = 100;
+        } else {
+            encoder->qualityAlpha = 75 + (int) quality / 2;
+        }
+    }
+    encoder->speed = 6;
+
+    res = avifEncoderWrite (encoder, avif, &raw);
+    avifEncoderDestroy (encoder);
+    avifImageDestroy (avif);
+
+    if (res == AVIF_RESULT_OK) {
+        fwrite (raw.data, 1, raw.size, f);
+        avifRWDataFree (&raw);
+        return TRUE;
+    }
+
+    g_set_error (error,
+                 GDK_PIXBUF_ERROR,
+                 GDK_PIXBUF_ERROR_FAILED,
+                 "AVIF encoder problem: %s", avifResultToString (res));
+    return FALSE;
+}
+
+G_MODULE_EXPORT void
+fill_vtable (GdkPixbufModule *module)
+{
+    module->begin_load = begin_load;
+    module->stop_load = stop_load;
+    module->load_increment = load_increment;
+    module->is_save_option_supported = avif_is_save_option_supported;
+    module->save = avif_image_saver;
+}
+
+G_MODULE_EXPORT void
+fill_info (GdkPixbufFormat *info)
+{
+    static GdkPixbufModulePattern signature[] = {
+        { "    ftypavif", "zzz         ", 100 }, /* file begins with 'ftypavif' at offset 4 */
+        { NULL, NULL, 0 }
+    };
+    static gchar *mime_types[] = {
+        "image/avif",
+        NULL
+    };
+    static gchar *extensions[] = {
+        "avif",
+        NULL
+    };
+
+    info->name = "avif";
+    info->signature = (GdkPixbufModulePattern *) signature;
+    info->description = "AV1 Image File Format";
+    info->mime_types = (gchar **) mime_types;
+    info->extensions = (gchar **) extensions;
+    info->flags = GDK_PIXBUF_FORMAT_WRITABLE | GDK_PIXBUF_FORMAT_THREADSAFE;
+    info->license = "BSD";
+    info->disabled = FALSE;
+}
diff --git a/third_party/libavif/src/contrib/irefmerge.coffee b/third_party/libavif/src/contrib/irefmerge.coffee
new file mode 100644
index 0000000000..119b6ec75e
--- /dev/null
+++ b/third_party/libavif/src/contrib/irefmerge.coffee
@@ -0,0 +1,212 @@
+# Copyright 2021 Joe Drago. All rights reserved.
+# SPDX-License-Identifier: BSD-2-Clause
+
+# READ THIS WHOLE COMMENT FIRST, BEFORE RUNNING THIS SCRIPT:
+
+# The goal of this script is to detect AVIFs containing multiple adjacent iref boxes and merge them,
+# filling leftover space with a free box (to avoid ruining file offsets elsewhere in the file). The
+# syntax is simple:
+
+#     coffee irefmerge.coffee filename.avif
+
+# This will look over the file's contents and if it detects multiple irefs, it will fix it in
+# memory, make a adjacent backup of the file (filename.avif.irefmergeBackup), and then overwrite the
+# original file with the fixed contents. Using -v on the commandline will enable Verbose mode, and
+# using -n will disable the creation of backups (.irefmergeBackup files).
+
+# This should be well-behaved on files created by old versions of avifenc, but **PLEASE** make
+# backups of your images before running this script on them, **especially** if you plan to run with
+# "-n". I do not advise running this script on AVIFs generated by anything other than avifenc.
+
+# Possible responses for a file:
+# * [NotAvif] This file isn't an AVIF.
+# * [BadAvif] This file thinks it is an AVIF, but is missing important things.
+# * [Skipped] This file is an AVIF, but didn't need any fixes.
+# * [Success] This file is an AVIF, had to be fixed, and was fixed.
+# * (the script crashes) I probably have a bug; let me know.
+
+# Note on CoffeeScript:
+# If you don't want to invoke coffeescript every time, you can compile it once with:
+#     coffee -c -b irefmerge.coffee
+# ... and run the adjacent irefmerge.js with node instead. "It's just JavaScript."
+
+# -------------------------------------------------------------------------------------------------
+# Syntax
+
+syntax = ->
+  console.log "Syntax: irefmerge [-v] [-n] file1 [file2 ...]"
+  console.log "        -v : Verbose mode"
+  console.log "        -n : No Backups (Don't generate adjacent .irefmergeBackup files when overwriting in-place)"
+
+# -------------------------------------------------------------------------------------------------
+# Constants and helpers
+
+fs = require 'fs'
+
+INDENT = "         "
+VERBOSE = false
+
+verboseLog = ->
+  if VERBOSE
+    console.log.apply(null, arguments)
+
+fatalError = (reason) ->
+  console.error "ERROR: #{reason}"
+  process.exit(1)
+
+# -------------------------------------------------------------------------------------------------
+# Box
+
+class Box
+  constructor: (@filename, @type, @buffer, @start, @size) ->
+    @offset = @start
+    @bytesLeft = @size
+    @version = 0
+    @flags = 0
+    @boxes = {} # child boxes
+
+  nextBox: ->
+    if @bytesLeft < 8
+      return null
+    boxSize = @buffer.readUInt32BE(@offset)
+    boxType = @buffer.toString('utf8', @offset + 4, @offset + 8)
+    if boxSize > @bytesLeft
+      verboseLog("#{INDENT} * Truncated box of type #{boxType} (#{boxSize} bytes with only #{@bytesLeft} bytes left)")
+      return null
+    if boxSize < 8
+      verboseLog("#{INDENT} * Bad box size of type #{boxType} (#{boxSize} bytes")
+      return null
+    newBox = new Box(@filename, boxType, @buffer, @offset + 8, boxSize - 8)
+    @offset += boxSize
+    @bytesLeft -= boxSize
+    verboseLog "#{INDENT} * Discovered box type: #{newBox.type} offset: #{newBox.offset - 8} size: #{newBox.size + 8}"
+    return newBox
+
+  walkBoxes: ->
+    while box = @nextBox()
+      @boxes[box.type] = box
+    return
+
+  readFullBoxHeader: ->
+    if @bytesLeft < 4
+      fatalError("#{INDENT} * Truncated FullBox of type #{boxType} (only #{@bytesLeft} bytes left)")
+    versionAndFlags = @buffer.readUInt32BE(@offset)
+    @version = (versionAndFlags >> 24) & 0xFF
+    @flags = versionAndFlags & 0xFFFFFF
+    @offset += 4
+    @bytesLeft -= 4
+    return
+
+  ftypHasBrand: (brand) ->
+    if @type != 'ftyp'
+      fatalError("#{INDENT} * Calling Box.ftypHasBrand() on a non-ftyp box")
+    majorBrand = @buffer.toString('utf8', @offset, @offset + 4)
+    compatibleBrands = []
+    compatibleBrandCount = Math.floor((@size - 8) / 4)
+    for i in [0...compatibleBrandCount]
+      o = @offset + 8 + (i * 4)
+      compatibleBrand = @buffer.toString('utf8', o, o + 4)
+      compatibleBrands.push compatibleBrand
+
+    verboseLog "#{INDENT}   * ftyp majorBrand: #{majorBrand} compatibleBrands: [#{compatibleBrands.join(', ')}]"
+
+    if majorBrand == brand
+      return true
+    for compatibleBrand in compatibleBrands
+      if compatibleBrand == brand
+        return true
+    return false
+
+# -------------------------------------------------------------------------------------------------
+# Main
+
+irefMerge = (filename, makeBackups) ->
+  if not fs.existsSync(filename)
+    fatalError("File doesn't exist: #{filename}")
+  try
+    fileBuffer = fs.readFileSync(filename)
+  catch e
+    fatalError "Failed to read \"#{filename}\": #{e}"
+
+  fileBox = new Box(filename, "<file>", fileBuffer, 0, fileBuffer.length)
+  fileBox.walkBoxes()
+
+  ftypBox = fileBox.boxes.ftyp
+  if not ftypBox?
+    return "NotAvif"
+  if ftypBox.type != 'ftyp'
+    return "NotAvif"
+  if !ftypBox.ftypHasBrand('avif')
+    return "NotAvif"
+
+  metaBox = fileBox.boxes.meta
+  if not metaBox?
+    return "BadAvif"
+  metaBox.readFullBoxHeader()
+
+  merged = false
+  irefs = []
+  while box = metaBox.nextBox()
+    if box.type == 'iref'
+      irefs.push box
+
+  # console.log irefs
+  if irefs.length > 1
+    verboseLog "#{INDENT} * Discovered multiple (#{irefs.length}) iref boxes, merging..."
+    # merge irefs, and leave a free block in the dead space
+    newTotalSize = 8 + 4 # the new single iref header's size + fullbox
+    for iref in irefs
+      newTotalSize += iref.size - 4
+    fileBuffer.writeUInt32BE(newTotalSize, irefs[0].start - 8)
+
+    writeOffset = irefs[0].start + 4 # skip past the fullbox's version[1]+flags[3]
+    for iref in irefs
+      fileBuffer.copy(fileBuffer, writeOffset, iref.start + 4, iref.start + iref.size)
+      writeOffset += iref.size - 4
+    freeBoxSize = (irefs.length - 1) * 12
+    freeBox = Buffer.alloc(freeBoxSize)
+    freeBox.fill(0)
+    freeBox.writeUInt32BE(freeBoxSize)
+    freeBox.write("free", 4)
+    freeBox.copy(fileBuffer, writeOffset, 0, freeBoxSize)
+    verboseLog "#{INDENT}   * Wrote a free chunk of size #{freeBoxSize} at offset #{writeOffset}"
+    merged = true
+
+  if merged
+    if makeBackups
+      backupFilename = filename + ".irefmergeBackup"
+      fs.writeFileSync(backupFilename, fs.readFileSync(filename))
+    fs.writeFileSync(filename, fileBuffer)
+    return "Success"
+  return "Skipped"
+
+main = ->
+  showSyntax = false
+  makeBackups = true
+  files = []
+
+  for arg in process.argv.slice(2)
+    switch arg
+      when '-h', '--help'
+        showSyntax = true
+        break
+      when '-n', '--no-backups'
+        makeBackups = false
+        break
+      when '-v', '--verbose'
+        VERBOSE = true
+        break
+      else
+        files.push arg
+
+  if showSyntax or files.length == 0
+    return syntax()
+
+  for filename in files
+    verboseLog("[Reading] #{filename}")
+    result = irefMerge(filename, makeBackups)
+    console.log("[#{result}] #{filename}") # Always print this
+
+  return 0
+
+main()
diff --git a/third_party/libavif/src/doc/README.md b/third_party/libavif/src/doc/README.md
new file mode 100644
index 0000000000..6f87a9171d
--- /dev/null
+++ b/third_party/libavif/src/doc/README.md
@@ -0,0 +1,8 @@
+# libavif man pages
+
+This contains the man pages for `avifenc` and `avifdec`. These are written in
+[pandoc's Markdown](https://pandoc.org/MANUAL.html#pandocs-markdown), so
+[pandoc](https://pandoc.org/) is required to build these.
+
+Building man pages is disabled by default. Enable the CMake option
+`AVIF_BUILD_MAN_PAGES` to build these.
diff --git a/third_party/libavif/src/doc/avifdec.1.md b/third_party/libavif/src/doc/avifdec.1.md
new file mode 100644
index 0000000000..05d0044e65
--- /dev/null
+++ b/third_party/libavif/src/doc/avifdec.1.md
@@ -0,0 +1,135 @@
+% AVIFDEC(1) | General Commands Manual
+%
+% 2022-04-30
+
+<!--
+This man page is written in pandoc's Markdown.
+See: https://pandoc.org/MANUAL.html#pandocs-markdown
+-->
+
+# NAME
+
+avifdec - decompress an AVIF file to an image file
+
+# SYNOPSIS
+
+**avifdec** [_options_] _input.avif_ _output._[_jpg_|_jpeg_|_png_|_y4m_]
+
+**avifdec** **\--info** _input.avif_
+
+# DESCRIPTION
+
+**avifdec** decompresses an AVIF file to an image file.
+Output format can be either JPEG, PNG or YUV4MPEG2 (Y4M).
+
+# OPTIONS
+
+**-h**, **\--help**
+:   Show syntax help.
+
+**-V**, **\--version**
+:   Show the version number.
+
+**-j**, **\--jobs** _J_
+:   Number of jobs (worker threads).
+    1 or less means single-threaded.
+    Default is 1.
+    Use **all** to use all available cores.
+
+**-c**, **\--codec** _C_
+:   AV1 codec to use.
+    Possible values depend on the codecs enabled at build time (see **\--help**
+    or **\--version** for the available codecs).
+    Default is auto-selected from the available codecs.
+
+    Possible values are:
+
+    :   - **aom**
+        - **dav1d**
+        - **libgav1**
+
+**-d**, **\--depth** _D_
+:   Output PNG depth.
+    Ignored when the output format is JPEG (always 8 bits per channel) or Y4M
+    (input depth is retained).
+
+    Possible values are:
+
+    :   - **8**
+        - **16**
+
+**-q**, **\--quality** _Q_
+:   Output JPEG quality in the range **0**-**100**.
+    Default is 90.
+    Ignored if the output format is not JPEG.
+
+**\--png-compress** _L_
+:   Output PNG compression level in the range **0**-**9** (fastest to maximum
+    compression).
+    Default is libpng's built-in default.
+    Ignored if the output format is not PNG.
+
+**-u**, **\--upsampling** _U_
+:   Chroma upsampling method.
+    Ignored unless the input format is 4:2:0 or 4:2:2.
+
+    Possible values are:
+
+    :   - **automatic** (default)
+        - **fastest**
+        - **best**
+        - **nearest**
+        - **bilinear**
+
+**-r**, **\--raw-color**
+:   Output raw RGB values instead of multiplying by alpha when saving to opaque
+    formats.
+    This is available if the output format is JPEG, and not applicable to y4m.
+
+**\--index** _I_
+:   When decoding an image sequence or progressive image, specify which frame
+    index to decode.
+    Default is 0.
+
+**\--progressive**
+:   Enable progressive AVIF processing.
+    If a progressive image is encountered and **\--progressive** is passed,
+    **avifdec** will use **\--index** to choose which layer to decode (in
+    progressive order).
+
+**\--no-strict**
+:   Disable strict decoding, which disables strict validation checks and errors.
+
+**-i**, **\--info**
+:   Decode all frames and display all image information instead of saving to
+    disk.
+
+**\--ignore-icc**
+:   If the input file contains an embedded ICC profile, ignore it (no-op if
+    absent).
+
+**\--size-limit** _C_
+:   Specifies the image size limit (in total pixels) that should be tolerated.
+    Default is 268,435,456 pixels (16,384 by 16,384 pixels for a square image).
+
+**\--dimension-limit** _C_
+:   Specifies the image dimension limit (width or height) that should be
+    tolerated.
+    Default is 32,768. Set it to 0 to ignore the limit.
+
+**\--**
+:   Signals the end of options. Everything after this is interpreted as file names.
+
+# EXAMPLES
+
+Decompress an AVIF file to a PNG file:
+:   $ **avifdec input.avif output.png**
+
+# REPORTING BUGS
+
+Bugs can be reported on GitHub at:
+:   <https://github.com/AOMediaCodec/libavif/issues>
+
+# SEE ALSO
+
+**avifenc**(1)
diff --git a/third_party/libavif/src/doc/avifenc.1.md b/third_party/libavif/src/doc/avifenc.1.md
new file mode 100644
index 0000000000..057a7195b1
--- /dev/null
+++ b/third_party/libavif/src/doc/avifenc.1.md
@@ -0,0 +1,262 @@
+% AVIFENC(1) | General Commands Manual
+%
+% 2022-04-30
+
+<!--
+This man page is written in pandoc's Markdown.
+See: https://pandoc.org/MANUAL.html#pandocs-markdown
+-->
+
+# NAME
+
+avifenc - compress an image file to an AVIF file
+
+# SYNOPSIS
+
+**avifenc** [_options_] _input._[_jpg_|_jpeg_|_png_|_y4m_] _output.avif_
+
+# DESCRIPTION
+
+**avifenc** compresses an image file to an AVIF file.
+Input format can be either JPEG, PNG or YUV4MPEG2 (Y4M).
+
+# OPTIONS
+
+**-h**, **\--help**
+:   Show syntax help.
+
+**-V**, **\--version**
+:   Show the version number.
+
+**-j**, **\--jobs** _J_
+:   Number of jobs (worker threads).
+    1 or less means single-threaded.
+    Default is 1.
+    Use **all** to use all available cores.
+
+**-o**, **\--output** _FILENAME_
+:   Instead of using the last filename given as output, use this filename.
+
+**-l**, **\--lossless**
+:   Set all defaults to encode losslessly, and emit warnings when
+    settings/input don't allow for it.
+
+**-d**, **\--depth** _D_
+:   Output depth.
+    This is available if the input format is JPEG/PNG, and for y4m or stdin,
+    depth is retained.
+
+    Possible values are:
+
+    :   - **8**
+        - **10**
+        - **12**
+
+**-y**, **\--yuv** _FORMAT_
+:   Output format.
+    Ignored for y4m or stdin (y4m format is retained).
+    For JPEG, auto honors the JPEG's internal format, if possible.
+    For all other cases, auto defaults to 444.
+
+    Possible values are:
+
+    :   - **auto** (default)
+        - **444**
+        - **422**
+        - **420**
+        - **400**
+
+**-p**, **\--premultiply**
+:   Premultiply color by the alpha channel and signal this in the AVIF.
+
+**\--sharpyuv**
+:   Use sharp RGB to YUV420 conversion (if supported). Ignored for y4m or if
+    output is not 420.
+
+**\--stdin**
+:   Read y4m frames from stdin instead of files.
+    No input filenames allowed, must be set before specifying the output
+    filename.
+
+**\--cicp**, **\--nclx** *P***/***T***/***M*
+:   Specify CICP values (nclx colr box) by 3 raw numbers.
+    Use **2** for any you wish to leave unspecified.
+
+    - _P_ = color primaries
+    - _T_ = transfer characteristics
+    - _M_ = matrix coefficients
+
+**-r**, **\--range** _RANGE_
+:   YUV range.
+    This is available if the input format is JPEG/PNG, and for y4m or stdin,
+    range is retained.
+
+    Possible values are:
+
+    :   - **full**, **f** (default)
+        - **limited**, **l**
+
+**\--min** _Q_
+:   Set min quantizer for color.
+    Possible values are in the range **0**-**63**, where 0 is lossless.
+
+**\--max** _Q_
+:   Set max quantizer for color.
+    Possible values are in the range **0**-**63**, where 0 is lossless.
+
+**\--minalpha** _Q_
+:   Set min quantizer for alpha.
+    Possible values are in the range **0**-**63**, where 0 is lossless.
+
+**\--maxalpha** _Q_
+:   Set max quantizer for alpha.
+    Possible values are in the range **0**-**63**, where 0 is lossless.
+
+**\--tilerowslog2** _R_
+:   Set log2 of number of tile rows.
+    Possible values are in the range **0**-**6**.
+    Default is 0.
+
+**\--tilecolslog2** _C_
+:   Set log2 of number of tile columns.
+    Possible values are in the range **0**-**6**.
+    Default is 0.
+
+**\--autotiling**
+:   Set **\--tilerowslog2** and **\--tilecolslog2** automatically.
+
+**-g**, **\--grid** *M***x***N*
+:   Encode a single-image grid AVIF with _M_ cols and _N_ rows.
+    Either supply MxN images of the same width, height and depth, or a single
+    image that can be evenly split into the MxN grid and follow AVIF grid image
+    restrictions.
+    The grid will adopt the color profile of the first image supplied.
+    Possible values for _M_ and _N_ are in the range **1**-**256**.
+
+**-s**, **\--speed** _S_
+:   Encoder speed.
+    Default is 6.
+
+    Possible values are:
+
+    :   - **0**-**10** (slowest-fastest)
+        - **default**, **d** (codec internal defaults)
+
+**-c**, **\--codec** _C_
+:   AV1 codec to use.
+    Possible values depend on the codecs enabled at build time (see **\--help**
+    or **\--version** for the available codecs).
+    Default is auto-selected from the available codecs.
+
+    Possible values are:
+
+    :   - **aom**
+        - **rav1e**
+        - **svt**
+
+**\--exif** _FILENAME_
+:   Provide an Exif metadata payload to be associated with the primary item
+    (implies --ignore-exif).
+
+**\--xmp** _FILENAME_
+:   Provide an XMP metadata payload to be associated with the primary item
+    (implies --ignore-xmp).
+
+**\--icc** _FILENAME_
+:   Provide an ICC profile payload to be associated with the primary item
+    (implies --ignore-icc).
+
+**-a**, **\--advanced** _KEY_[_=VALUE_]
+:   Pass an advanced, codec-specific key/value string pair directly to the
+    codec.
+    **avifenc** will warn on any unused by the codec.
+    The aom-specific advanced options can be used if the AOM codec is available
+    (see **\--help** for details).
+
+**\--duration** _D_
+:   Set all following frame durations (in timescales) to _D_.
+    Can be set multiple times (before supplying each filename).
+    Default is 1.
+
+**\--timescale**, **\--fps** _V_
+:   Set the timescale to _V_.
+    If all frames are 1 timescale in length, this is equivalent to frames per
+    second.
+    If neither duration nor timescale are set, **avifenc** will attempt to use
+    the framerate stored in a y4m header, if present.
+    Default is 30.
+
+**-k**, **\--keyframe** _INTERVAL_
+:   Set the forced keyframe interval (maximum frames between keyframes).
+    Set to **0** to disable.
+    Default is 0.
+
+**\--ignore-exif**
+:   If the input file contains embedded Exif metadata, ignore it (no-op if
+    absent).
+
+**\--ignore-xmp**
+:   If the input file contains embedded XMP metadata, ignore it (no-op if
+    absent).
+
+**\--ignore-icc**
+:   If the input file contains an embedded ICC profile, ignore it (no-op if
+    absent).
+
+**\--pasp** *H***,***V*
+:   Add pasp property (aspect ratio).
+
+    - _H_ = horizontal spacing
+    - _V_ = vertical spacing
+
+**\--crop** *CROPX***,***CROPY***,***CROPW***,***CROPH*
+:   Add clap property (clean aperture), but calculated from a crop rectangle.
+
+    - _CROPX_ = X-axis of a crop rectangle
+    - _CROPY_ = Y-axis of a crop rectangle
+    - _CROPW_ = width of a crop rectangle
+    - _CROPH_ = height of a crop rectangle
+
+**\--clap** *WN***,***WD***,***HN***,***HD***,***HON***,***HOD***,***VON***,***VOD*
+:   Add clap property (clean aperture).
+
+    - _WN_ = numerator of width
+    - _WD_ = denominator of width
+    - _HN_ = numerator of height
+    - _HD_ = denominator of height
+    - _HON_ = numerator of horizontal offset
+    - _HOD_ = denominator of horizontal offset
+    - _VON_ = numerator of vertical offset
+    - _VOD_ = denominator of vertical offset
+
+**\--irot** _ANGLE_
+:   Add irot property (rotation).
+    Possible values are in the range **0**-**3**, and makes (90 * _ANGLE_)
+    degree rotation anti-clockwise.
+
+**\--imir** _MODE_
+:   Add imir property (mirroring).
+
+    Note: Rotation is applied before mirroring at rendering.
+
+    Possible values are:
+
+    :   - **0** (top-to-bottom)
+        - **1** (left-to-right)
+
+**\--**
+:   Signals the end of options. Everything after this is interpreted as file names.
+
+# EXAMPLES
+
+Compress a PNG file to an AVIF file:
+:   $ **avifenc input.png output.avif**
+
+# REPORTING BUGS
+
+Bugs can be reported on GitHub at:
+:   <https://github.com/AOMediaCodec/libavif/issues>
+
+# SEE ALSO
+
+**avifdec**(1)
diff --git a/third_party/libavif/src/examples/avif_example_decode_file.c b/third_party/libavif/src/examples/avif_example_decode_file.c
new file mode 100644
index 0000000000..4cf81c16b3
--- /dev/null
+++ b/third_party/libavif/src/examples/avif_example_decode_file.c
@@ -0,0 +1,94 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <string.h>
+
+int main(int argc, char * argv[])
+{
+    if (argc != 2) {
+        fprintf(stderr, "avif_example_decode_file [filename.avif]\n");
+        return 1;
+    }
+    const char * inputFilename = argv[1];
+
+    int returnCode = 1;
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(rgb));
+
+    avifDecoder * decoder = avifDecoderCreate();
+    if (decoder == NULL) {
+        fprintf(stderr, "Memory allocation failure\n");
+        return 1;
+    }
+    // Override decoder defaults here (codecChoice, requestedSource, ignoreExif, ignoreXMP, etc)
+
+    avifResult result = avifDecoderSetIOFile(decoder, inputFilename);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    result = avifDecoderParse(decoder);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "Failed to decode image: %s\n", avifResultToString(result));
+        goto cleanup;
+    }
+
+    // Now available:
+    // * All decoder->image information other than pixel data:
+    //   * width, height, depth
+    //   * transformations (pasp, clap, irot, imir)
+    //   * color profile (icc, CICP)
+    //   * metadata (Exif, XMP)
+    // * decoder->alphaPresent
+    // * number of total images in the AVIF (decoder->imageCount)
+    // * overall image sequence timing (including per-frame timing with avifDecoderNthImageTiming())
+
+    printf("Parsed AVIF: %ux%u (%ubpc)\n", decoder->image->width, decoder->image->height, decoder->image->depth);
+
+    while (avifDecoderNextImage(decoder) == AVIF_RESULT_OK) {
+        // Now available (for this frame):
+        // * All decoder->image YUV pixel data (yuvFormat, yuvPlanes, yuvRange, yuvChromaSamplePosition, yuvRowBytes)
+        // * decoder->image alpha data (alphaPlane, alphaRowBytes)
+        // * this frame's sequence timing
+
+        avifRGBImageSetDefaults(&rgb, decoder->image);
+        // Override YUV(A)->RGB(A) defaults here:
+        //   depth, format, chromaUpsampling, avoidLibYUV, ignoreAlpha, alphaPremultiplied, etc.
+
+        // Alternative: set rgb.pixels and rgb.rowBytes yourself, which should match your chosen rgb.format
+        // Be sure to use uint16_t* instead of uint8_t* for rgb.pixels/rgb.rowBytes if (rgb.depth > 8)
+        result = avifRGBImageAllocatePixels(&rgb);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Allocation of RGB samples failed: %s (%s)\n", inputFilename, avifResultToString(result));
+            goto cleanup;
+        }
+
+        result = avifImageYUVToRGB(decoder->image, &rgb);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion from YUV failed: %s (%s)\n", inputFilename, avifResultToString(result));
+            goto cleanup;
+        }
+
+        // Now available:
+        // * RGB(A) pixel data (rgb.pixels, rgb.rowBytes)
+
+        if (rgb.depth > 8) {
+            uint16_t * firstPixel = (uint16_t *)rgb.pixels;
+            printf(" * First pixel: RGBA(%u,%u,%u,%u)\n", firstPixel[0], firstPixel[1], firstPixel[2], firstPixel[3]);
+        } else {
+            uint8_t * firstPixel = rgb.pixels;
+            printf(" * First pixel: RGBA(%u,%u,%u,%u)\n", firstPixel[0], firstPixel[1], firstPixel[2], firstPixel[3]);
+        }
+    }
+
+    returnCode = 0;
+cleanup:
+    avifRGBImageFreePixels(&rgb); // Only use in conjunction with avifRGBImageAllocatePixels()
+    avifDecoderDestroy(decoder);
+    return returnCode;
+}
diff --git a/third_party/libavif/src/examples/avif_example_decode_memory.c b/third_party/libavif/src/examples/avif_example_decode_memory.c
new file mode 100644
index 0000000000..139f1510ee
--- /dev/null
+++ b/third_party/libavif/src/examples/avif_example_decode_memory.c
@@ -0,0 +1,120 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+
+int main(int argc, char * argv[])
+{
+    if (argc != 2) {
+        fprintf(stderr, "avif_example_decode_memory [filename.avif]\n");
+        return 1;
+    }
+    const char * inputFilename = argv[1];
+
+    int returnCode = 1;
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(rgb));
+
+    avifDecoder * decoder = avifDecoderCreate();
+    if (decoder == NULL) {
+        fprintf(stderr, "Memory allocation failure\n");
+        return 1;
+    }
+    // Override decoder defaults here (codecChoice, requestedSource, ignoreExif, ignoreXMP, etc)
+
+    // Read entire file into fileBuffer
+    FILE * f = NULL;
+    uint8_t * fileBuffer = NULL;
+    f = fopen(inputFilename, "rb");
+    if (!f) {
+        fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+        goto cleanup;
+    }
+    fseek(f, 0, SEEK_END);
+    long fileSize = ftell(f);
+    if (fileSize < 0) {
+        fprintf(stderr, "Truncated file: %s\n", inputFilename);
+    }
+    fseek(f, 0, SEEK_SET);
+    fileBuffer = malloc(fileSize);
+    long bytesRead = (long)fread(fileBuffer, 1, fileSize, f);
+    if (bytesRead != fileSize) {
+        fprintf(stderr, "Cannot read file: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    avifResult result = avifDecoderSetIOMemory(decoder, fileBuffer, fileSize);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "Cannot set IO on avifDecoder: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    result = avifDecoderParse(decoder);
+    if (result != AVIF_RESULT_OK) {
+        fprintf(stderr, "Failed to decode image: %s\n", avifResultToString(result));
+        goto cleanup;
+    }
+
+    // Now available:
+    // * All decoder->image information other than pixel data:
+    //   * width, height, depth
+    //   * transformations (pasp, clap, irot, imir)
+    //   * color profile (icc, CICP)
+    //   * metadata (Exif, XMP)
+    // * decoder->alphaPresent
+    // * number of total images in the AVIF (decoder->imageCount)
+    // * overall image sequence timing (including per-frame timing with avifDecoderNthImageTiming())
+
+    printf("Parsed AVIF: %ux%u (%ubpc)\n", decoder->image->width, decoder->image->height, decoder->image->depth);
+
+    while (avifDecoderNextImage(decoder) == AVIF_RESULT_OK) {
+        // Now available (for this frame):
+        // * All decoder->image YUV pixel data (yuvFormat, yuvPlanes, yuvRange, yuvChromaSamplePosition, yuvRowBytes)
+        // * decoder->image alpha data (alphaPlane, alphaRowBytes)
+        // * this frame's sequence timing
+
+        avifRGBImageSetDefaults(&rgb, decoder->image);
+        // Override YUV(A)->RGB(A) defaults here:
+        //   depth, format, chromaUpsampling, avoidLibYUV, ignoreAlpha, alphaPremultiplied, etc.
+
+        // Alternative: set rgb.pixels and rgb.rowBytes yourself, which should match your chosen rgb.format
+        // Be sure to use uint16_t* instead of uint8_t* for rgb.pixels/rgb.rowBytes if (rgb.depth > 8)
+        result = avifRGBImageAllocatePixels(&rgb);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Allocation of RGB samples failed: %s (%s)\n", inputFilename, avifResultToString(result));
+            goto cleanup;
+        }
+
+        result = avifImageYUVToRGB(decoder->image, &rgb);
+        if (result != AVIF_RESULT_OK) {
+            fprintf(stderr, "Conversion from YUV failed: %s (%s)\n", inputFilename, avifResultToString(result));
+            goto cleanup;
+        }
+
+        // Now available:
+        // * RGB(A) pixel data (rgb.pixels, rgb.rowBytes)
+
+        if (rgb.depth > 8) {
+            uint16_t * firstPixel = (uint16_t *)rgb.pixels;
+            printf(" * First pixel: RGBA(%u,%u,%u,%u)\n", firstPixel[0], firstPixel[1], firstPixel[2], firstPixel[3]);
+        } else {
+            uint8_t * firstPixel = rgb.pixels;
+            printf(" * First pixel: RGBA(%u,%u,%u,%u)\n", firstPixel[0], firstPixel[1], firstPixel[2], firstPixel[3]);
+        }
+    }
+
+    returnCode = 0;
+cleanup:
+    avifRGBImageFreePixels(&rgb); // Only use in conjunction with avifRGBImageAllocatePixels()
+    avifDecoderDestroy(decoder);
+    if (f) {
+        fclose(f);
+    }
+    free(fileBuffer);
+    return returnCode;
+}
diff --git a/third_party/libavif/src/examples/avif_example_decode_streaming.c b/third_party/libavif/src/examples/avif_example_decode_streaming.c
new file mode 100644
index 0000000000..ce50a7f235
--- /dev/null
+++ b/third_party/libavif/src/examples/avif_example_decode_streaming.c
@@ -0,0 +1,232 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <stdlib.h>
+
+// This example intends to show how a custom avifIO implementation can be used to decode
+// partially-downloaded AVIFs. Read either the avif_example_decode_file or
+// avif_example_decode_memory examples for something more basic.
+//
+// This test will emit something like this:
+//
+//     File: [file.avif @ 4823 / 125867 bytes, Metadata] parse returned: OK
+//     File: [file.avif @ 125867 / 125867 bytes, Metadata] nextImage returned: OK
+//     File: [file.avif @ 390 / 125867 bytes, IgnoreMetadata] parse returned: OK
+//     File: [file.avif @ 125867 / 125867 bytes, IgnoreMetadata] nextImage returned: OK
+//
+// In the above output, file.avif is 125867 bytes. If parsing Exif/XMP metadata is enabled,
+// avifDecoderParse() finally returns AVIF_RESULT_OK once 4823 bytes are "downloaded".
+// and requires the entire file to decode the first image (this example is a single image AVIF).
+// If Exif/XMP metadata is ignored, avifDecoderParse() only needs the first 390 bytes to return OK.
+//
+// How much of an AVIF is required to be downloaded in order to return OK from avifDecoderParse()
+// or avifDecoderNextImage() varies wildly due to the packing of the file. Ideally, the end of the
+// AVIF is simply a large mdat or moov box full of AV1 payloads, and all metadata (meta boxes,
+// Exif/XMP payloads, etc) are as close to the front as possible. Any trailing MP4 boxes (free, etc)
+// will cause avifDecoderParse() to have to wait to download those, as it can't ensure a successful
+// parse without knowing what boxes are remaining.
+
+typedef struct avifIOStreamingReader
+{
+    avifIO io;              // This must be first if you plan to cast this struct to an (avifIO *).
+    avifROData rodata;      // The actual data.
+    size_t downloadedBytes; // How many bytes have been "downloaded" so far. This is what will
+                            // dictate when we return AVIF_RESULT_WAITING_ON_IO in this example.
+                            // The example will slowly increment this value (from 0) until
+                            // avifDecoderParse() returns something other than AVIF_RESULT_WAITING_ON_IO,
+                            // and then it will continue to incremement it until avifDecoderNextImage()
+                            // returns something other than AVIF_RESULT_WAITING_ON_IO.
+} avifIOStreamingReader;
+
+// This example has interleaved the documentation above avifIOReadFunc in avif/avif.h to help
+// explain why these checks are here.
+static avifResult avifIOStreamingReaderRead(struct avifIO * io, uint32_t readFlags, uint64_t offset, size_t size, avifROData * out)
+{
+    avifIOStreamingReader * reader = (avifIOStreamingReader *)io;
+
+    if (readFlags != 0) {
+        // Unsupported readFlags
+        return AVIF_RESULT_IO_ERROR;
+    }
+
+    // * If offset exceeds the size of the content (past EOF), return AVIF_RESULT_IO_ERROR.
+    if (offset > reader->rodata.size) {
+        return AVIF_RESULT_IO_ERROR;
+    }
+
+    // * If offset is *exactly* at EOF, provide any 0-byte buffer and return AVIF_RESULT_OK.
+    if (offset == reader->rodata.size) {
+        out->data = reader->rodata.data;
+        out->size = 0;
+        return AVIF_RESULT_OK;
+    }
+
+    // * If (offset+size) exceeds the contents' size, it must provide a truncated buffer that provides
+    //   all bytes from the offset to EOF, and return AVIF_RESULT_OK.
+    uint64_t availableSize = reader->rodata.size - offset;
+    if (size > availableSize) {
+        size = (size_t)availableSize;
+    }
+
+    // * If (offset+size) does not exceed the contents' size but the *entire range* is unavailable yet
+    //   (due to network conditions or any other reason), return AVIF_RESULT_WAITING_ON_IO.
+    if (offset > reader->downloadedBytes) {
+        return AVIF_RESULT_WAITING_ON_IO;
+    }
+    if (size > (reader->downloadedBytes - offset)) {
+        return AVIF_RESULT_WAITING_ON_IO;
+    }
+
+    // * If (offset+size) does not exceed the contents' size, it must provide the *entire range* and
+    //   return AVIF_RESULT_OK.
+    out->data = reader->rodata.data + offset;
+    out->size = size;
+    return AVIF_RESULT_OK;
+}
+
+static void avifIOStreamingReaderDestroy(struct avifIO * io)
+{
+    free(io);
+}
+
+// Returns null in case of memory allocation failure.
+static avifIOStreamingReader * avifIOCreateStreamingReader(const uint8_t * data, size_t size)
+{
+    avifIOStreamingReader * reader = calloc(1, sizeof(avifIOStreamingReader));
+    if (!reader)
+        return NULL;
+
+    // It is legal for io.destroy to be NULL, in which you are responsible for cleaning up
+    // your own reader. This allows for a pre-existing, on-the-stack, or member variable to be
+    // used as an avifIO*.
+    reader->io.destroy = avifIOStreamingReaderDestroy;
+
+    // The heart of the reader is this function. See the implementation and comments above.
+    reader->io.read = avifIOStreamingReaderRead;
+
+    // See the documentation for sizeHint in avif/avif.h. It is not required to be set, but it is recommended.
+    reader->io.sizeHint = size;
+
+    // See the documentation for persistent in avif/avif.h. Enabling this adds heavy restrictions to
+    // the lifetime of the buffers you return from io.read, but cuts down on memory overhead and memcpys.
+    reader->io.persistent = AVIF_TRUE;
+
+    reader->rodata.data = data;
+    reader->rodata.size = size;
+    return reader;
+}
+
+int main(int argc, char * argv[])
+{
+    if (argc != 2) {
+        fprintf(stderr, "avif_example_decode_streaming [filename.avif]\n");
+        return 1;
+    }
+    const char * inputFilename = argv[1];
+
+    int returnCode = 1;
+    avifDecoder * decoder = NULL;
+
+    // Read entire file into fileBuffer
+    FILE * f = NULL;
+    uint8_t * fileBuffer = NULL;
+    f = fopen(inputFilename, "rb");
+    if (!f) {
+        fprintf(stderr, "Cannot open file for read: %s\n", inputFilename);
+        goto cleanup;
+    }
+    fseek(f, 0, SEEK_END);
+    long fileSize = ftell(f);
+    if (fileSize < 0) {
+        fprintf(stderr, "Truncated file: %s\n", inputFilename);
+        goto cleanup;
+    }
+    fseek(f, 0, SEEK_SET);
+    fileBuffer = malloc(fileSize);
+    long bytesRead = (long)fread(fileBuffer, 1, fileSize, f);
+    if (bytesRead != fileSize) {
+        fprintf(stderr, "Cannot read file: %s\n", inputFilename);
+        goto cleanup;
+    }
+
+    decoder = avifDecoderCreate();
+    if (!decoder) {
+        fprintf(stderr, "Memory allocation failure\n");
+        goto cleanup;
+    }
+    // Override decoder defaults here (codecChoice, requestedSource, ignoreExif, ignoreXMP, etc)
+
+    avifIOStreamingReader * io = avifIOCreateStreamingReader(fileBuffer, fileSize);
+    if (!io) {
+        fprintf(stderr, "Memory allocation failure\n");
+        goto cleanup;
+    }
+    avifDecoderSetIO(decoder, (avifIO *)io);
+
+    for (int pass = 0; pass < 2; ++pass) {
+        // This shows the difference in how much data avifDecoderParse() needs from the file
+        // depending on whether or not Exif/XMP metadata is necessary. If the caller plans to
+        // interpret this metadata, avifDecoderParse() will continue to return
+        // AVIF_RESULT_WAITING_ON_IO until it has those payloads in their entirety (if they exist).
+        decoder->ignoreExif = decoder->ignoreXMP = (pass > 0);
+
+        // Slowly pretend to have streamed-in / downloaded more and more bytes by incrementing io->downloadedBytes
+        avifResult parseResult = AVIF_RESULT_UNKNOWN_ERROR;
+        for (io->downloadedBytes = 0; io->downloadedBytes <= io->io.sizeHint; ++io->downloadedBytes) {
+            parseResult = avifDecoderParse(decoder);
+            if (parseResult == AVIF_RESULT_WAITING_ON_IO) {
+                continue;
+            }
+            if (parseResult != AVIF_RESULT_OK) {
+                returnCode = 1;
+            }
+
+            // See other examples on how to access the parsed information.
+
+            printf("File: [%s @ %zu / %" PRIu64 " bytes, %s] parse returned: %s\n",
+                   inputFilename,
+                   io->downloadedBytes,
+                   io->io.sizeHint,
+                   decoder->ignoreExif ? "IgnoreMetadata" : "Metadata",
+                   avifResultToString(parseResult));
+            break;
+        }
+
+        if (parseResult == AVIF_RESULT_OK) {
+            for (; io->downloadedBytes <= io->io.sizeHint; ++io->downloadedBytes) {
+                avifResult nextImageResult = avifDecoderNextImage(decoder);
+                if (nextImageResult == AVIF_RESULT_WAITING_ON_IO) {
+                    continue;
+                }
+                if (nextImageResult != AVIF_RESULT_OK) {
+                    returnCode = 1;
+                }
+
+                // See other examples on how to access the pixel content of the images.
+
+                printf("File: [%s @ %zu / %" PRIu64 " bytes, %s] nextImage returned: %s\n",
+                       inputFilename,
+                       io->downloadedBytes,
+                       io->io.sizeHint,
+                       decoder->ignoreExif ? "IgnoreMetadata" : "Metadata",
+                       avifResultToString(nextImageResult));
+                break;
+            }
+        }
+    }
+
+    returnCode = 0;
+cleanup:
+    if (decoder) {
+        avifDecoderDestroy(decoder); // this calls avifIOStreamingReaderDestroy for us
+    }
+    if (f) {
+        fclose(f);
+    }
+    free(fileBuffer);
+    return returnCode;
+}
diff --git a/third_party/libavif/src/examples/avif_example_encode.c b/third_party/libavif/src/examples/avif_example_encode.c
new file mode 100644
index 0000000000..ec508db090
--- /dev/null
+++ b/third_party/libavif/src/examples/avif_example_encode.c
@@ -0,0 +1,139 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include <inttypes.h>
+#include <stdio.h>
+#include <string.h>
+
+int main(int argc, char * argv[])
+{
+    if (argc != 3) {
+        fprintf(stderr, "avif_example_encode [encodeYUVDirectly:0/1] [output.avif]\n");
+        return 1;
+    }
+    avifBool encodeYUVDirectly = AVIF_FALSE;
+    if (argv[1][0] == '1') {
+        encodeYUVDirectly = AVIF_TRUE;
+    }
+    const char * outputFilename = argv[2];
+
+    int returnCode = 1;
+    avifEncoder * encoder = NULL;
+    avifRWData avifOutput = AVIF_DATA_EMPTY;
+    avifRGBImage rgb;
+    memset(&rgb, 0, sizeof(rgb));
+
+    avifImage * image = avifImageCreate(128, 128, 8, AVIF_PIXEL_FORMAT_YUV444); // these values dictate what goes into the final AVIF
+    if (!image) {
+        fprintf(stderr, "Out of memory\n");
+        goto cleanup;
+    }
+    // Configure image here: (see avif/avif.h)
+    // * colorPrimaries
+    // * transferCharacteristics
+    // * matrixCoefficients
+    // * avifImageSetProfileICC()
+    // * avifImageSetMetadataExif()
+    // * avifImageSetMetadataXMP()
+    // * yuvRange
+    // * alphaPremultiplied
+    // * transforms (transformFlags, pasp, clap, irot, imir)
+
+    if (encodeYUVDirectly) {
+        // If you have YUV(A) data you want to encode, use this path
+        printf("Encoding raw YUVA data\n");
+
+        const avifResult allocateResult = avifImageAllocatePlanes(image, AVIF_PLANES_ALL);
+        if (allocateResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "Failed to allocate the planes: %s\n", avifResultToString(allocateResult));
+            goto cleanup;
+        }
+
+        // Fill your YUV(A) data here
+        memset(image->yuvPlanes[AVIF_CHAN_Y], 255, image->yuvRowBytes[AVIF_CHAN_Y] * image->height);
+        memset(image->yuvPlanes[AVIF_CHAN_U], 128, image->yuvRowBytes[AVIF_CHAN_U] * image->height);
+        memset(image->yuvPlanes[AVIF_CHAN_V], 128, image->yuvRowBytes[AVIF_CHAN_V] * image->height);
+        memset(image->alphaPlane, 255, image->alphaRowBytes * image->height);
+    } else {
+        // If you have RGB(A) data you want to encode, use this path
+        printf("Encoding from converted RGBA\n");
+
+        avifRGBImageSetDefaults(&rgb, image);
+        // Override RGB(A)->YUV(A) defaults here:
+        //   depth, format, chromaDownsampling, avoidLibYUV, ignoreAlpha, alphaPremultiplied, etc.
+
+        // Alternative: set rgb.pixels and rgb.rowBytes yourself, which should match your chosen rgb.format
+        // Be sure to use uint16_t* instead of uint8_t* for rgb.pixels/rgb.rowBytes if (rgb.depth > 8)
+        avifResult allocationResult = avifRGBImageAllocatePixels(&rgb);
+        if (allocationResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "Allocation of RGB samples failed: %s\n", avifResultToString(allocationResult));
+            goto cleanup;
+        }
+
+        // Fill your RGB(A) data here
+        memset(rgb.pixels, 255, rgb.rowBytes * image->height);
+
+        avifResult convertResult = avifImageRGBToYUV(image, &rgb);
+        if (convertResult != AVIF_RESULT_OK) {
+            fprintf(stderr, "Failed to convert to YUV(A): %s\n", avifResultToString(convertResult));
+            goto cleanup;
+        }
+    }
+
+    encoder = avifEncoderCreate();
+    if (!encoder) {
+        fprintf(stderr, "Out of memory\n");
+        goto cleanup;
+    }
+    // Configure your encoder here (see avif/avif.h):
+    // * maxThreads
+    // * quality
+    // * qualityAlpha
+    // * tileRowsLog2
+    // * tileColsLog2
+    // * speed
+    // * keyframeInterval
+    // * timescale
+    encoder->quality = 60;
+    encoder->qualityAlpha = AVIF_QUALITY_LOSSLESS;
+
+    // Call avifEncoderAddImage() for each image in your sequence
+    // Only set AVIF_ADD_IMAGE_FLAG_SINGLE if you're not encoding a sequence
+    // Use avifEncoderAddImageGrid() instead with an array of avifImage* to make a grid image
+    avifResult addImageResult = avifEncoderAddImage(encoder, image, 1, AVIF_ADD_IMAGE_FLAG_SINGLE);
+    if (addImageResult != AVIF_RESULT_OK) {
+        fprintf(stderr, "Failed to add image to encoder: %s\n", avifResultToString(addImageResult));
+        goto cleanup;
+    }
+
+    avifResult finishResult = avifEncoderFinish(encoder, &avifOutput);
+    if (finishResult != AVIF_RESULT_OK) {
+        fprintf(stderr, "Failed to finish encode: %s\n", avifResultToString(finishResult));
+        goto cleanup;
+    }
+
+    printf("Encode success: %zu total bytes\n", avifOutput.size);
+
+    FILE * f = fopen(outputFilename, "wb");
+    size_t bytesWritten = fwrite(avifOutput.data, 1, avifOutput.size, f);
+    fclose(f);
+    if (bytesWritten != avifOutput.size) {
+        fprintf(stderr, "Failed to write %zu bytes\n", avifOutput.size);
+        goto cleanup;
+    }
+    printf("Wrote: %s\n", outputFilename);
+
+    returnCode = 0;
+cleanup:
+    if (image) {
+        avifImageDestroy(image);
+    }
+    if (encoder) {
+        avifEncoderDestroy(encoder);
+    }
+    avifRWDataFree(&avifOutput);
+    avifRGBImageFreePixels(&rgb); // Only use in conjunction with avifRGBImageAllocatePixels()
+    return returnCode;
+}
diff --git a/third_party/libavif/src/ext/README.md b/third_party/libavif/src/ext/README.md
new file mode 100644
index 0000000000..0d6da9fea5
--- /dev/null
+++ b/third_party/libavif/src/ext/README.md
@@ -0,0 +1,14 @@
+# libavif ext dir
+
+This contains references to various external repositories which are known to
+build and work properly with the current libavif. If you are building for
+Windows or any kind of fully static (embedded) release, using these scripts in
+conjunction with the `BUILD_SHARED_LIBS=0` and `AVIF_*` CMake flags make
+for a convenient way to get all of the dependencies necessary. This method is
+how many of libavif's continuous builders work.
+
+However, if you are building this for a distribution or Unix-like environment
+in general, you can safely *ignore* this directory. Allow `BUILD_SHARED_LIBS`
+to keep its default (`ON`), enable the appropriate `AVIF_BUILD_*` CMake flags
+depending on which shared AV1 codec libraries you plan to leverage and depend
+on, and use the system's zlib, libpng, and libjpeg.
diff --git a/third_party/libavif/src/ext/aom.cmd b/third_party/libavif/src/ext/aom.cmd
new file mode 100755
index 0000000000..763f25c459
--- /dev/null
+++ b/third_party/libavif/src/ext/aom.cmd
@@ -0,0 +1,19 @@
+: # If you want to use a local build of libaom, you must clone the aom repo in this directory first, then set CMake's AVIF_CODEC_AOM to LOCAL options.
+: # The git SHA below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone -b v3.10.0 --depth 1 https://aomedia.googlesource.com/aom
+
+cd aom
+mkdir build.libavif
+cd build.libavif
+
+cmake -G Ninja -DBUILD_SHARED_LIBS=OFF -DCONFIG_PIC=1 -DCMAKE_BUILD_TYPE=Release -DENABLE_DOCS=0 -DENABLE_EXAMPLES=0 -DENABLE_TESTDATA=0 -DENABLE_TESTS=0 -DENABLE_TOOLS=0 ..
+cd ../..
+ninja -C aom/build.libavif
diff --git a/third_party/libavif/src/ext/avm.cmd b/third_party/libavif/src/ext/avm.cmd
new file mode 100755
index 0000000000..976a0ad470
--- /dev/null
+++ b/third_party/libavif/src/ext/avm.cmd
@@ -0,0 +1,20 @@
+: # If you want to use a local build of libavm, you must clone the avm repo in this directory first, then set CMake's AVIF_CODEC_AVM to LOCAL.
+: # The git SHA below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone -b research-v8.0.0 --depth 1 https://gitlab.com/AOMediaCodec/avm.git
+
+cd avm
+
+mkdir build.libavif
+cd build.libavif
+
+cmake -G Ninja -DBUILD_SHARED_LIBS=OFF -DCONFIG_PIC=1 -DCMAKE_BUILD_TYPE=Release -DENABLE_DOCS=0 -DENABLE_EXAMPLES=0 -DENABLE_TESTS=0 -DENABLE_TOOLS=0 ..
+cd ../..
+ninja -C avm/build.libavif
diff --git a/third_party/libavif/src/ext/compliance_warden.sh b/third_party/libavif/src/ext/compliance_warden.sh
new file mode 100755
index 0000000000..920e70a868
--- /dev/null
+++ b/third_party/libavif/src/ext/compliance_warden.sh
@@ -0,0 +1,21 @@
+#!/bin/bash
+#
+# Local clone of ComplianceWarden (part of the gpac organization) for tests.
+# Used when AVIF_ENABLE_COMPLIANCE_WARDEN is ON.
+
+set -e
+
+git clone https://github.com/gpac/ComplianceWarden.git
+cd ComplianceWarden && git checkout e26973641f747cf3282004dcfb0747881207e748 && cd ..
+# The provided Makefile only builds bin/cw.exe and objects.
+# We are interested in the library, so the files are directly used instead of building with make -j.
+ComplianceWarden/scripts/version.sh > ComplianceWarden/src/cw_version.cpp
+
+# registerSpec() does not seem to be called in the static 'registered' local variables,
+# for example in avif.cpp. Use the following hack to access the static SpecDescs.
+# Feel free to replace by a prettier solution.
+printf "extern const SpecDesc *const globalSpecAvif = &specAvif;\n" >> ComplianceWarden/src/specs/avif/avif.cpp
+printf "extern const SpecDesc *const globalSpecAv1Hdr10plus = &specAv1Hdr10plus;\n" >> ComplianceWarden/src/specs/av1_hdr10plus/av1_hdr10plus.cpp
+printf "extern const SpecDesc *const globalSpecHeif = &specHeif;\n" >> ComplianceWarden/src/specs/heif/heif.cpp
+printf "extern const SpecDesc *const globalSpecIsobmff = &specIsobmff;\n" >> ComplianceWarden/src/specs/isobmff/isobmff.cpp
+printf "extern const SpecDesc *const globalSpecMiaf = &specMiaf;\n" >> ComplianceWarden/src/specs/miaf/miaf.cpp
diff --git a/third_party/libavif/src/ext/dav1d.cmd b/third_party/libavif/src/ext/dav1d.cmd
new file mode 100755
index 0000000000..8b05f1351a
--- /dev/null
+++ b/third_party/libavif/src/ext/dav1d.cmd
@@ -0,0 +1,24 @@
+: # If you want to use a local build of dav1d, you must clone the dav1d repo in this directory first, then set CMake's AVIF_CODEC_DAV1D to LOCAL.
+: # The git SHA below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # meson and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+: # When updating the dav1d version, make the same change to dav1d_android.sh.
+git clone -b 1.5.0 --depth 1 https://code.videolan.org/videolan/dav1d.git
+
+cd dav1d
+mkdir build
+cd build
+
+: # macOS might require: -Dc_args=-fno-stack-check
+: # Build with asan: -Db_sanitize=address -Db_lundef=false
+: # Build with msan: -Db_sanitize=memory -Db_lundef=false -Denable_asm=false
+: # Build with ubsan: -Db_sanitize=undefined -Db_lundef=false
+meson setup --default-library=static --buildtype release -Denable_tools=false -Denable_tests=false ..
+cd ../..
+ninja -C dav1d/build
diff --git a/third_party/libavif/src/ext/dav1d_android.sh b/third_party/libavif/src/ext/dav1d_android.sh
new file mode 100755
index 0000000000..97fdbca6e7
--- /dev/null
+++ b/third_party/libavif/src/ext/dav1d_android.sh
@@ -0,0 +1,44 @@
+#!/bin/bash
+
+# This script will build dav1d for the default ABI targets supported by android.
+# This script only works on linux. You must pass the path to the android NDK as
+# a parameter to this script.
+#
+# Android NDK: https://developer.android.com/ndk/downloads
+#
+# The git tag below is known to work, and will occasionally be updated. Feel
+# free to use a more recent commit.
+
+set -e
+
+if [ $# -ne 1 ]; then
+  echo "Usage: ${0} <path_to_android_ndk>"
+  exit 1
+fi
+git clone -b 1.5.0 --depth 1 https://code.videolan.org/videolan/dav1d.git
+cd dav1d
+mkdir build
+cd build
+
+# This only works on linux and mac.
+if [ "$(uname)" == "Darwin" ]; then
+  HOST_TAG="darwin"
+else
+  HOST_TAG="linux"
+fi
+android_bin="${1}/toolchains/llvm/prebuilt/${HOST_TAG}-x86_64/bin"
+
+ABI_LIST=("armeabi-v7a" "arm64-v8a" "x86" "x86_64")
+ARCH_LIST=("arm" "aarch64" "x86" "x86_64")
+for i in "${!ABI_LIST[@]}"; do
+  abi="${ABI_LIST[i]}"
+  mkdir "${abi}"
+  cd "${abi}"
+  PATH=$PATH:${android_bin} meson setup --default-library=static --buildtype release \
+    --cross-file="../../package/crossfiles/${ARCH_LIST[i]}-android.meson" \
+    -Denable_tools=false -Denable_tests=false ../..
+  PATH=$PATH:${android_bin} ninja
+  cd ..
+done
+
+cd ../..
diff --git a/third_party/libavif/src/ext/fuzztest.cmd b/third_party/libavif/src/ext/fuzztest.cmd
new file mode 100755
index 0000000000..b177a057b3
--- /dev/null
+++ b/third_party/libavif/src/ext/fuzztest.cmd
@@ -0,0 +1,22 @@
+: # If you want to use a local build of fuzztest, you must clone the fuzztest repo in this directory.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone https://github.com/google/fuzztest.git
+cd fuzztest
+: # There is no tagged release as of 2024/06/21. Pick the latest commit that works.
+git checkout 078ea0871cc96d3a69bad406577f176a4fa14ae9
+: # Fixes for https://github.com/google/fuzztest/issues/1124
+sed -i 's/-fsanitize=address//g' ./cmake/FuzzTestFlagSetup.cmake
+sed -i 's/-DADDRESS_SANITIZER//g' ./cmake/FuzzTestFlagSetup.cmake
+: # Fixes for https://github.com/google/fuzztest/issues/1125
+sed -i 's/if (IsEnginePlaceholderInput(data)) return;/if (data.size() == 0) return;/g' ./fuzztest/internal/compatibility_mode.cc
+sed -i 's/set(GTEST_HAS_ABSL ON)/set(GTEST_HAS_ABSL OFF)/g' ./cmake/BuildDependencies.cmake
+
+: # fuzztest is built by the main CMake project through add_subdirectory as recommended at:
+: # https://github.com/google/fuzztest/blob/main/doc/quickstart-cmake.md
diff --git a/third_party/libavif/src/ext/googletest.cmd b/third_party/libavif/src/ext/googletest.cmd
new file mode 100755
index 0000000000..1c0ce97c08
--- /dev/null
+++ b/third_party/libavif/src/ext/googletest.cmd
@@ -0,0 +1,19 @@
+: # If you want to use a local build of googletest, you must clone the googletest repo in this directory.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone -b v1.14.0 --depth 1 https://github.com/google/googletest.git
+cd googletest
+mkdir build
+cd build
+: # The gtest_force_shared_crt option makes gtest link the Microsoft C runtime library (CRT) dynamically
+: # on Windows:
+: # https://github.com/google/googletest/blob/main/googletest/README.md#visual-studio-dynamic-vs-static-runtimes
+cmake -G Ninja -DBUILD_SHARED_LIBS=OFF -DCMAKE_POSITION_INDEPENDENT_CODE=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_GMOCK=OFF -Dgtest_force_shared_crt=ON ..
+cd ../..
+ninja -C googletest/build
diff --git a/third_party/libavif/src/ext/libargparse.cmd b/third_party/libavif/src/ext/libargparse.cmd
new file mode 100755
index 0000000000..d04045cfe9
--- /dev/null
+++ b/third_party/libavif/src/ext/libargparse.cmd
@@ -0,0 +1,20 @@
+: # Script to get a local build of libargparse (not to be confused with other similarly named libraries)
+: # needed by some of the command line tools in the apps/ directory e.g. avifgainmaputil.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone https://github.com/maryla-uc/libargparse.git
+
+cd libargparse
+git checkout 81998ffafb9c2ac8cf488d31e536a2e6fd6b3fdf
+
+mkdir build
+cd build
+cmake -G Ninja -DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=Release  ..
+cd ../..
+ninja -C libargparse/build
diff --git a/third_party/libavif/src/ext/libgav1.cmd b/third_party/libavif/src/ext/libgav1.cmd
new file mode 100755
index 0000000000..9134abcc57
--- /dev/null
+++ b/third_party/libavif/src/ext/libgav1.cmd
@@ -0,0 +1,20 @@
+: # If you want to use a local build of libgav1, you must clone the libgav1 repo in this directory first, then set CMake's AVIF_CODEC_LIBGAV1 to LOCAL.
+: # The git SHA below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+: # When updating the libgav1 version, make the same change to libgav1_android.sh.
+git clone -b v0.19.0 --depth 1 https://chromium.googlesource.com/codecs/libgav1
+
+cd libgav1
+mkdir build
+cd build
+
+cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -DCMAKE_POSITION_INDEPENDENT_CODE=ON -DLIBGAV1_THREADPOOL_USE_STD_MUTEX=1 -DLIBGAV1_ENABLE_EXAMPLES=0 -DLIBGAV1_ENABLE_TESTS=0 -DLIBGAV1_MAX_BITDEPTH=12 ..
+cd ../..
+ninja -C libgav1/build
diff --git a/third_party/libavif/src/ext/libgav1_android.sh b/third_party/libavif/src/ext/libgav1_android.sh
new file mode 100755
index 0000000000..194a0fef1d
--- /dev/null
+++ b/third_party/libavif/src/ext/libgav1_android.sh
@@ -0,0 +1,44 @@
+#!/bin/bash
+
+# This script will build libgav1 for the default ABI targets supported by
+# android. You must pass the path to the android NDK as a parameter to this
+# script.
+#
+# Android NDK: https://developer.android.com/ndk/downloads
+#
+# The git tag below is known to work, and will occasionally be updated. Feel
+# free to use a more recent commit.
+
+set -e
+
+if [ $# -ne 1 ]; then
+  echo "Usage: ${0} <path_to_android_ndk>"
+  exit 1
+fi
+# When updating the libgav1 version, make the same change to libgav1.cmd.
+git clone -b v0.19.0 --depth 1 https://chromium.googlesource.com/codecs/libgav1
+
+cd libgav1
+mkdir build
+cd build
+
+ABI_LIST="armeabi-v7a arm64-v8a x86 x86_64"
+for abi in ${ABI_LIST}; do
+  mkdir "${abi}"
+  cd "${abi}"
+  cmake ../.. \
+    -G Ninja \
+    -DCMAKE_TOOLCHAIN_FILE=../../cmake/toolchains/android.cmake \
+    -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
+    -DCMAKE_BUILD_TYPE=Release \
+    -DLIBGAV1_ANDROID_NDK_PATH=${1} \
+    -DLIBGAV1_THREADPOOL_USE_STD_MUTEX=1 \
+    -DLIBGAV1_ENABLE_EXAMPLES=0 \
+    -DLIBGAV1_ENABLE_TESTS=0 \
+    -DLIBGAV1_MAX_BITDEPTH=12 \
+    -DANDROID_ABI=${abi}
+  ninja
+  cd ..
+done
+
+cd ../..
diff --git a/third_party/libavif/src/ext/libjpeg.cmd b/third_party/libavif/src/ext/libjpeg.cmd
new file mode 100755
index 0000000000..6a97c420de
--- /dev/null
+++ b/third_party/libavif/src/ext/libjpeg.cmd
@@ -0,0 +1,17 @@
+: # If you want to use a local build of jpeg, you must clone the repos in this directory first,
+: # then set CMake's AVIF_JPEG=LOCAL.
+: # The git tag below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+git clone -b 3.0.4 --depth 1 https://github.com/libjpeg-turbo/libjpeg-turbo.git
+
+# Set WITH_CRT_DLL to ON to compile libjpeg-turbo with /MD (use the DLL
+# version of the run-time library) instead of /MT (use the static version
+# of the run-time library) on Windows. On non-Windows platform, this causes
+# a CMake warning, which is safe to ignore:
+#   Manually-specified variables were not used by the project:
+#
+#     WITH_CRT_DLL
+cmake -S libjpeg-turbo -B libjpeg-turbo/build.libavif -G Ninja -DENABLE_SHARED=OFF -DENABLE_STATIC=ON -DCMAKE_BUILD_TYPE=Release -DWITH_TURBOJPEG=OFF -DWITH_CRT_DLL=ON
+cmake --build libjpeg-turbo/build.libavif --parallel
diff --git a/third_party/libavif/src/ext/libsharpyuv.cmd b/third_party/libavif/src/ext/libsharpyuv.cmd
new file mode 100755
index 0000000000..11be448af9
--- /dev/null
+++ b/third_party/libavif/src/ext/libsharpyuv.cmd
@@ -0,0 +1,19 @@
+: # If you want to use a local build of libsharpyuv, you must clone the libwebp repo in this directory first,
+: # then set CMake's AVIF_LIBSHARPYUV to LOCAL.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+: # libsharpyuv is part of the libwebp repo.
+git clone -b v1.4.0 --depth 1 https://chromium.googlesource.com/webm/libwebp
+
+cd libwebp
+mkdir build
+cd build
+cmake -G Ninja -DBUILD_SHARED_LIBS=OFF -DCMAKE_BUILD_TYPE=Release -DWEBP_BUILD_ANIM_UTILS=OFF -DWEBP_BUILD_CWEBP=OFF -DWEBP_BUILD_DWEBP=OFF -DWEBP_BUILD_GIF2WEBP=OFF -DWEBP_BUILD_IMG2WEBP=OFF -DWEBP_BUILD_VWEBP=OFF -DWEBP_BUILD_WEBPINFO=OFF -DWEBP_BUILD_LIBWEBPMUX=OFF -DWEBP_BUILD_WEBPMUX=OFF -DWEBP_BUILD_EXTRAS=OFF  ..
+cd ../..
+ninja -C libwebp/build sharpyuv
diff --git a/third_party/libavif/src/ext/libxml2.cmd b/third_party/libavif/src/ext/libxml2.cmd
new file mode 100755
index 0000000000..27ea14887e
--- /dev/null
+++ b/third_party/libavif/src/ext/libxml2.cmd
@@ -0,0 +1,14 @@
+: # If you want to use a local build of libxml2, you must clone the libxml2 repo in this directory first, then enable CMake's AVIF_LOCAL_LIBXML2 option.
+: # The git tag below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # libxml2 is released under the MIT License.
+
+git clone -b v2.13.4 --depth 1 https://github.com/GNOME/libxml2.git
+
+mkdir -p libxml2/build.libavif
+cmake libxml2 -B libxml2/build.libavif/ -G Ninja -DBUILD_SHARED_LIBS=OFF -DCMAKE_INSTALL_PREFIX=libxml2/install.libavif \
+    -DLIBXML2_WITH_PYTHON=OFF -DLIBXML2_WITH_ZLIB=OFF -DLIBXML2_WITH_LZMA=OFF
+ninja -C libxml2/build.libavif
+ninja -C libxml2/build.libavif install
diff --git a/third_party/libavif/src/ext/libyuv.cmd b/third_party/libavif/src/ext/libyuv.cmd
new file mode 100755
index 0000000000..b553d29a5d
--- /dev/null
+++ b/third_party/libavif/src/ext/libyuv.cmd
@@ -0,0 +1,27 @@
+: # If you want to use a local build of libyuv, you must clone the libyuv repo in this directory first, then set CMake's AVIF_LIBYUV to LOCAL.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cmake and ninja must be in your PATH.
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+: # We recommend building libyuv with clang-cl on Windows, because most of libyuv's assembly code is
+: # written in GCC inline assembly syntax, which MSVC doesn't support. Run this if you have clang-cl
+: # installed:
+: #     set "CC=clang-cl" && set "CXX=clang-cl"
+
+git clone --single-branch https://chromium.googlesource.com/libyuv/libyuv
+
+cd libyuv
+: # When changing the commit below to a newer version of libyuv, it is best to make sure it is being used by chromium,
+: # because the test suite of chromium provides additional test coverage of libyuv.
+: # It can be looked up at https://source.chromium.org/chromium/chromium/src/+/main:DEPS?q=libyuv.
+git checkout a6a2ec65
+
+mkdir build
+cd build
+
+cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -DCMAKE_POSITION_INDEPENDENT_CODE=ON ..
+cd ../..
+ninja -C libyuv/build yuv
diff --git a/third_party/libavif/src/ext/libyuv_android.sh b/third_party/libavif/src/ext/libyuv_android.sh
new file mode 100755
index 0000000000..5e46532840
--- /dev/null
+++ b/third_party/libavif/src/ext/libyuv_android.sh
@@ -0,0 +1,40 @@
+#!/bin/bash
+
+# This script will build libyuv for the default ABI targets supported by
+# android. You must pass the path to the android NDK as a parameter to this
+# script.
+#
+# Android NDK: https://developer.android.com/ndk/downloads
+
+set -e
+
+if [ $# -ne 1 ]; then
+  echo "Usage: ${0} <path_to_android_ndk>"
+  exit 1
+fi
+
+git clone --single-branch https://chromium.googlesource.com/libyuv/libyuv
+
+cd libyuv
+: # When changing the commit below to a newer version of libyuv, it is best to make sure it is being used by chromium,
+: # because the test suite of chromium provides additional test coverage of libyuv.
+: # It can be looked up at https://source.chromium.org/chromium/chromium/src/+/main:DEPS?q=libyuv.
+git checkout 464c51a0
+
+mkdir build
+cd build
+
+ABI_LIST="armeabi-v7a arm64-v8a x86 x86_64"
+for abi in ${ABI_LIST}; do
+  mkdir "${abi}"
+  cd "${abi}"
+  cmake ../.. \
+    -DCMAKE_POSITION_INDEPENDENT_CODE=ON \
+    -DCMAKE_TOOLCHAIN_FILE=${1}/build/cmake/android.toolchain.cmake \
+    -DCMAKE_BUILD_TYPE=Release \
+    -DANDROID_ABI=${abi}
+  make yuv
+  cd ..
+done
+
+cd ../..
diff --git a/third_party/libavif/src/ext/mp4box.sh b/third_party/libavif/src/ext/mp4box.sh
new file mode 100755
index 0000000000..dbb369e98b
--- /dev/null
+++ b/third_party/libavif/src/ext/mp4box.sh
@@ -0,0 +1,16 @@
+#!/bin/bash
+#
+# Local build of MP4Box (part of the gpac project) for tests.
+
+set -e
+
+git clone https://github.com/gpac/gpac.git
+
+cd gpac
+git checkout 5d70253 # GPAC 2.4.0
+
+./configure --static-bin
+make -j
+# MP4Box is in ext/gpac/bin/gcc/MP4Box
+
+cd ..
diff --git a/third_party/libavif/src/ext/rav1e.cmd b/third_party/libavif/src/ext/rav1e.cmd
new file mode 100755
index 0000000000..05d0f72258
--- /dev/null
+++ b/third_party/libavif/src/ext/rav1e.cmd
@@ -0,0 +1,20 @@
+: # If you want to use a local build of rav1e, you must clone the rav1e repo in this directory first, then set CMake's AVIF_CODEC_RAV1E to LOCAL.
+: # The git SHA below is known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # cargo must be in your PATH. (use rustup or brew to install)
+
+: # If you're running this on Windows targeting Rust's windows-msvc, be sure you've already run this (from your VC2019 install dir):
+: #     "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+: #
+: # On a successful local build, rav1e/build.libavif/ should contain the necessary headers and static library.
+
+git clone -b v0.7.1 --depth 1 https://github.com/xiph/rav1e.git
+
+cd rav1e
+cargo install --locked cargo-c
+
+mkdir build.libavif
+cargo cinstall --release --library-type=staticlib --prefix=/usr --destdir build.libavif
+cd ..
diff --git a/third_party/libavif/src/ext/svt.cmd b/third_party/libavif/src/ext/svt.cmd
new file mode 100755
index 0000000000..61b690a4a3
--- /dev/null
+++ b/third_party/libavif/src/ext/svt.cmd
@@ -0,0 +1,24 @@
+: # If you want to use a local build of SVT-AV1, you must clone the SVT-AV1 repo in this directory first,
+: # then set CMake's AVIF_CODEC_SVT to LOCAL.
+: # cmake and ninja must be in your PATH.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+: # Switch to a sh-like command if not running in windows
+: ; $SHELL svt.sh
+: ; exit $?
+
+: # If you're running this on Windows, be sure you've already run this (from your VC2019 install dir):
+: #    "C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Auxiliary\Build\vcvars64.bat"
+
+git clone -b v2.2.1 --depth 1 https://gitlab.com/AOMediaCodec/SVT-AV1.git
+
+cd SVT-AV1
+cd Build/windows
+
+call build.bat release static no-apps
+cd ../..
+mkdir include\svt-av1
+copy Source\API\*.h include\svt-av1
+
+cd ..
diff --git a/third_party/libavif/src/ext/svt.sh b/third_party/libavif/src/ext/svt.sh
new file mode 100644
index 0000000000..404cfcb581
--- /dev/null
+++ b/third_party/libavif/src/ext/svt.sh
@@ -0,0 +1,17 @@
+# If you want to use a local build of SVT-AV1, you must clone the SVT-AV1 repo in this directory first,
+# then set CMake's AVIF_CODEC_SVT to LOCAL.
+# cmake and ninja must be in your PATH.
+
+set -e
+
+git clone -b v2.2.1 --depth 1 https://gitlab.com/AOMediaCodec/SVT-AV1.git
+
+cd SVT-AV1
+cd Build/linux
+
+./build.sh disable-native release static no-apps
+cd ../..
+mkdir -p include/svt-av1
+cp Source/API/*.h include/svt-av1
+
+cd ..
diff --git a/third_party/libavif/src/ext/zlibpng.cmd b/third_party/libavif/src/ext/zlibpng.cmd
new file mode 100755
index 0000000000..e36877541f
--- /dev/null
+++ b/third_party/libavif/src/ext/zlibpng.cmd
@@ -0,0 +1,8 @@
+: # If you want to use a local build of zlib/libpng, you must clone the repos in this directory first,
+: # then set CMake's AVIF_ZLIBPNG=LOCAL.
+: # The git tags below are known to work, and will occasionally be updated. Feel free to use a more recent commit.
+
+: # The odd choice of comment style in this file is to try to share this script between *nix and win32.
+
+git clone -b v1.3.1 --depth 1 https://github.com/madler/zlib.git
+git clone -b v1.6.40 --depth 1 https://github.com/glennrp/libpng.git
diff --git a/third_party/libavif/src/include/avif/avif.h b/third_party/libavif/src/include/avif/avif.h
new file mode 100644
index 0000000000..19ea2e097e
--- /dev/null
+++ b/third_party/libavif/src/include/avif/avif.h
@@ -0,0 +1,1648 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef AVIF_AVIF_H
+#define AVIF_AVIF_H
+
+#include <stddef.h>
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// ---------------------------------------------------------------------------
+// Export macros
+
+// AVIF_BUILDING_SHARED_LIBS should only be defined when libavif is being built
+// as a shared library.
+// AVIF_DLL should be defined if libavif is a shared library. If you are using
+// libavif as a CMake dependency, through a CMake package config file or through
+// pkg-config, this is defined automatically.
+//
+// Here's what AVIF_API will be defined as in shared build:
+// |       |        Windows        |                  Unix                  |
+// | Build | __declspec(dllexport) | __attribute__((visibility("default"))) |
+// |  Use  | __declspec(dllimport) |                                        |
+//
+// For static build, AVIF_API is always defined as nothing.
+
+#if defined(_WIN32)
+#define AVIF_HELPER_EXPORT __declspec(dllexport)
+#define AVIF_HELPER_IMPORT __declspec(dllimport)
+#elif defined(__GNUC__) && __GNUC__ >= 4
+#define AVIF_HELPER_EXPORT __attribute__((visibility("default")))
+#define AVIF_HELPER_IMPORT
+#else
+#define AVIF_HELPER_EXPORT
+#define AVIF_HELPER_IMPORT
+#endif
+
+#if defined(AVIF_DLL)
+#if defined(AVIF_BUILDING_SHARED_LIBS)
+#define AVIF_API AVIF_HELPER_EXPORT
+#else
+#define AVIF_API AVIF_HELPER_IMPORT
+#endif // defined(AVIF_BUILDING_SHARED_LIBS)
+#else
+#define AVIF_API
+#endif // defined(AVIF_DLL)
+
+// [[nodiscard]] requires C++17 and C23.
+//
+// If the -std=c2x or -std=gnu2x option is specified, __STDC_VERSION__ is
+//   * 202000L in GCC 13.2.0, Clang 16.0.6, and Apple Clang 15.0.0; or
+//   * 202311L in Clang 19.0.0git.
+// If the /std:clatest option is specified, __STDC_VERSION__ is
+//   * 202312L in Microsoft Visual Studio 17.10.5.
+#if (defined(__cplusplus) && __cplusplus >= 201703L) || (defined(__STDC_VERSION__) && __STDC_VERSION__ >= 202000L)
+#define AVIF_NODISCARD [[nodiscard]]
+#else
+// Starting with 3.9, clang allows defining the warn_unused_result attribute for enums.
+#if defined(__clang__) && defined(__has_attribute) && ((__clang_major__ << 8) | __clang_minor__) >= ((3 << 8) | 9)
+#if __has_attribute(warn_unused_result)
+#define AVIF_NODISCARD __attribute__((warn_unused_result))
+#else
+#define AVIF_NODISCARD
+#endif
+#else
+#define AVIF_NODISCARD
+#endif
+#endif
+
+// ---------------------------------------------------------------------------
+// Constants
+
+// AVIF_VERSION_DEVEL should always be 0 for official releases / version tags,
+// and non-zero during development of the next release. This should allow for
+// downstream projects to do greater-than preprocessor checks on AVIF_VERSION
+// to leverage in-development code without breaking their stable builds.
+#define AVIF_VERSION_MAJOR 1
+#define AVIF_VERSION_MINOR 1
+#define AVIF_VERSION_PATCH 1
+#define AVIF_VERSION_DEVEL 1
+#define AVIF_VERSION \
+    ((AVIF_VERSION_MAJOR * 1000000) + (AVIF_VERSION_MINOR * 10000) + (AVIF_VERSION_PATCH * 100) + AVIF_VERSION_DEVEL)
+
+typedef int avifBool;
+#define AVIF_TRUE 1
+#define AVIF_FALSE 0
+
+#define AVIF_DIAGNOSTICS_ERROR_BUFFER_SIZE 256
+
+// A reasonable default for maximum image size (in pixel count) to avoid out-of-memory errors or
+// integer overflow in (32-bit) int or unsigned int arithmetic operations.
+#define AVIF_DEFAULT_IMAGE_SIZE_LIMIT (16384 * 16384)
+
+// A reasonable default for maximum image dimension (width or height).
+#define AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT 32768
+
+// a 12 hour AVIF image sequence, running at 60 fps (a basic sanity check as this is quite ridiculous)
+#define AVIF_DEFAULT_IMAGE_COUNT_LIMIT (12 * 3600 * 60)
+
+#define AVIF_QUALITY_DEFAULT -1
+#define AVIF_QUALITY_LOSSLESS 100
+#define AVIF_QUALITY_WORST 0
+#define AVIF_QUALITY_BEST 100
+
+#define AVIF_QUANTIZER_LOSSLESS 0
+#define AVIF_QUANTIZER_BEST_QUALITY 0
+#define AVIF_QUANTIZER_WORST_QUALITY 63
+
+#define AVIF_PLANE_COUNT_YUV 3
+
+#define AVIF_SPEED_DEFAULT -1
+#define AVIF_SPEED_SLOWEST 0
+#define AVIF_SPEED_FASTEST 10
+
+// This value is used to indicate that an animated AVIF file has to be repeated infinitely.
+#define AVIF_REPETITION_COUNT_INFINITE -1
+// This value is used if an animated AVIF file does not have repetitions specified using an EditList box. Applications can choose
+// to handle this case however they want.
+#define AVIF_REPETITION_COUNT_UNKNOWN -2
+
+// The number of spatial layers in AV1, with spatial_id = 0..3.
+#define AVIF_MAX_AV1_LAYER_COUNT 4
+
+typedef enum avifPlanesFlag
+{
+    AVIF_PLANES_YUV = (1 << 0),
+    AVIF_PLANES_A = (1 << 1),
+
+    AVIF_PLANES_ALL = 0xff
+} avifPlanesFlag;
+typedef uint32_t avifPlanesFlags;
+
+typedef enum avifChannelIndex
+{
+    // These can be used as the index for the yuvPlanes and yuvRowBytes arrays in avifImage.
+    AVIF_CHAN_Y = 0,
+    AVIF_CHAN_U = 1,
+    AVIF_CHAN_V = 2,
+
+    // This may not be used in yuvPlanes and yuvRowBytes, but is available for use with avifImagePlane().
+    AVIF_CHAN_A = 3
+} avifChannelIndex;
+
+// ---------------------------------------------------------------------------
+// Version
+
+AVIF_API const char * avifVersion(void);
+AVIF_API void avifCodecVersions(char outBuffer[256]);
+AVIF_API unsigned int avifLibYUVVersion(void); // returns 0 if libavif wasn't compiled with libyuv support
+
+// ---------------------------------------------------------------------------
+// Memory management
+
+// Returns NULL on memory allocation failure.
+AVIF_API void * avifAlloc(size_t size);
+AVIF_API void avifFree(void * p);
+
+// ---------------------------------------------------------------------------
+// avifResult
+
+typedef enum AVIF_NODISCARD avifResult
+{
+    AVIF_RESULT_OK = 0,
+    AVIF_RESULT_UNKNOWN_ERROR = 1,
+    AVIF_RESULT_INVALID_FTYP = 2,
+    AVIF_RESULT_NO_CONTENT = 3,
+    AVIF_RESULT_NO_YUV_FORMAT_SELECTED = 4,
+    AVIF_RESULT_REFORMAT_FAILED = 5,
+    AVIF_RESULT_UNSUPPORTED_DEPTH = 6,
+    AVIF_RESULT_ENCODE_COLOR_FAILED = 7,
+    AVIF_RESULT_ENCODE_ALPHA_FAILED = 8,
+    AVIF_RESULT_BMFF_PARSE_FAILED = 9,
+    AVIF_RESULT_MISSING_IMAGE_ITEM = 10,
+    AVIF_RESULT_DECODE_COLOR_FAILED = 11,
+    AVIF_RESULT_DECODE_ALPHA_FAILED = 12,
+    AVIF_RESULT_COLOR_ALPHA_SIZE_MISMATCH = 13,
+    AVIF_RESULT_ISPE_SIZE_MISMATCH = 14,
+    AVIF_RESULT_NO_CODEC_AVAILABLE = 15,
+    AVIF_RESULT_NO_IMAGES_REMAINING = 16,
+    AVIF_RESULT_INVALID_EXIF_PAYLOAD = 17,
+    AVIF_RESULT_INVALID_IMAGE_GRID = 18,
+    AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION = 19,
+    AVIF_RESULT_TRUNCATED_DATA = 20,
+    AVIF_RESULT_IO_NOT_SET = 21, // the avifIO field of avifDecoder is not set
+    AVIF_RESULT_IO_ERROR = 22,
+    AVIF_RESULT_WAITING_ON_IO = 23, // similar to EAGAIN/EWOULDBLOCK, this means the avifIO doesn't have necessary data available yet
+    AVIF_RESULT_INVALID_ARGUMENT = 24, // an argument passed into this function is invalid
+    AVIF_RESULT_NOT_IMPLEMENTED = 25,  // a requested code path is not (yet) implemented
+    AVIF_RESULT_OUT_OF_MEMORY = 26,
+    AVIF_RESULT_CANNOT_CHANGE_SETTING = 27, // a setting that can't change is changed during encoding
+    AVIF_RESULT_INCOMPATIBLE_IMAGE = 28,    // the image is incompatible with already encoded images
+    AVIF_RESULT_INTERNAL_ERROR = 29,        // some invariants have not been satisfied (likely a bug in libavif)
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    AVIF_RESULT_ENCODE_GAIN_MAP_FAILED = 30,
+    AVIF_RESULT_DECODE_GAIN_MAP_FAILED = 31,
+    AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE = 32,
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    AVIF_RESULT_ENCODE_SAMPLE_TRANSFORM_FAILED = 33,
+    AVIF_RESULT_DECODE_SAMPLE_TRANSFORM_FAILED = 34,
+#endif
+
+    // Kept for backward compatibility; please use the symbols above instead.
+    AVIF_RESULT_NO_AV1_ITEMS_FOUND = AVIF_RESULT_MISSING_IMAGE_ITEM
+} avifResult;
+
+AVIF_API const char * avifResultToString(avifResult result);
+
+// ---------------------------------------------------------------------------
+// avifHeaderFormat
+
+typedef enum avifHeaderFormat
+{
+    // AVIF file with an "avif" brand, a MetaBox and all its required boxes for maximum compatibility.
+    AVIF_HEADER_FULL,
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    // AVIF file with a "mif3" brand and a MinimizedImageBox to reduce the encoded file size.
+    // This is based on the w24144 "Low-overhead image file format" MPEG proposal for HEIF.
+    // WARNING: Experimental feature. Produces files that are incompatible with older decoders.
+    AVIF_HEADER_REDUCED,
+#endif
+} avifHeaderFormat;
+
+// ---------------------------------------------------------------------------
+// avifROData/avifRWData: Generic raw memory storage
+
+typedef struct avifROData
+{
+    const uint8_t * data;
+    size_t size;
+} avifROData;
+
+// Note: Use avifRWDataFree() if any avif*() function populates one of these.
+
+typedef struct avifRWData
+{
+    uint8_t * data;
+    size_t size;
+} avifRWData;
+
+// clang-format off
+// Initialize avifROData/avifRWData on the stack with this
+#define AVIF_DATA_EMPTY { NULL, 0 }
+// clang-format on
+
+// The avifRWData input must be zero-initialized before being manipulated with these functions.
+// If AVIF_RESULT_OUT_OF_MEMORY is returned, raw is left unchanged.
+AVIF_API avifResult avifRWDataRealloc(avifRWData * raw, size_t newSize);
+AVIF_API avifResult avifRWDataSet(avifRWData * raw, const uint8_t * data, size_t len);
+AVIF_API void avifRWDataFree(avifRWData * raw);
+
+// ---------------------------------------------------------------------------
+// Metadata
+
+// Validates the first bytes of the Exif payload and finds the TIFF header offset (up to UINT32_MAX).
+AVIF_API avifResult avifGetExifTiffHeaderOffset(const uint8_t * exif, size_t exifSize, size_t * offset);
+// Returns the offset to the Exif 8-bit orientation value and AVIF_RESULT_OK, or an error.
+// If the offset is set to exifSize, there was no parsing error but no orientation tag was found.
+AVIF_API avifResult avifGetExifOrientationOffset(const uint8_t * exif, size_t exifSize, size_t * offset);
+
+// ---------------------------------------------------------------------------
+// avifPixelFormat
+//
+// Note to libavif maintainers: The lookup tables in avifImageYUVToRGBLibYUV
+// rely on the ordering of this enum values for their correctness. So changing
+// the values in this enum will require auditing avifImageYUVToRGBLibYUV for
+// correctness.
+typedef enum avifPixelFormat
+{
+    // No YUV pixels are present. Alpha plane can still be present.
+    AVIF_PIXEL_FORMAT_NONE = 0,
+
+    AVIF_PIXEL_FORMAT_YUV444,
+    AVIF_PIXEL_FORMAT_YUV422,
+    AVIF_PIXEL_FORMAT_YUV420,
+    AVIF_PIXEL_FORMAT_YUV400,
+    AVIF_PIXEL_FORMAT_COUNT
+} avifPixelFormat;
+AVIF_API const char * avifPixelFormatToString(avifPixelFormat format);
+
+typedef struct avifPixelFormatInfo
+{
+    avifBool monochrome;
+    int chromaShiftX;
+    int chromaShiftY;
+} avifPixelFormatInfo;
+
+// Returns the avifPixelFormatInfo depending on the avifPixelFormat.
+// When monochrome is AVIF_TRUE, chromaShiftX and chromaShiftY are set to 1 according to the AV1 specification but they should be ignored.
+//
+// Note: This function implements the second table on page 119 of the AV1 specification version 1.0.0 with Errata 1.
+// For monochrome 4:0:0, subsampling_x and subsampling are specified as 1 to allow
+// an AV1 implementation that only supports profile 0 to hardcode subsampling_x and subsampling_y to 1.
+AVIF_API void avifGetPixelFormatInfo(avifPixelFormat format, avifPixelFormatInfo * info);
+
+// ---------------------------------------------------------------------------
+// avifChromaSamplePosition
+
+typedef enum avifChromaSamplePosition
+{
+    AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN = 0,
+    AVIF_CHROMA_SAMPLE_POSITION_VERTICAL = 1,
+    AVIF_CHROMA_SAMPLE_POSITION_COLOCATED = 2,
+    AVIF_CHROMA_SAMPLE_POSITION_RESERVED = 3
+} avifChromaSamplePosition;
+
+// ---------------------------------------------------------------------------
+// avifRange
+
+typedef enum avifRange
+{
+    // avifRange is only applicable to YUV planes. RGB and alpha planes are always full range.
+    AVIF_RANGE_LIMITED = 0, /**<- Y  [16..235],  UV  [16..240]  (bit depth 8) */
+                            /**<- Y  [64..940],  UV  [64..960]  (bit depth 10) */
+                            /**<- Y [256..3760], UV [256..3840] (bit depth 12) */
+    AVIF_RANGE_FULL = 1     /**<- [0..255]  (bit depth 8) */
+                            /**<- [0..1023] (bit depth 10) */
+                            /**<- [0..4095] (bit depth 12) */
+} avifRange;
+
+// ---------------------------------------------------------------------------
+// CICP enums - https://www.itu.int/rec/T-REC-H.273-201612-S/en
+
+enum
+{
+    // This is actually reserved, but libavif uses it as a sentinel value.
+    AVIF_COLOR_PRIMARIES_UNKNOWN = 0,
+
+    AVIF_COLOR_PRIMARIES_BT709 = 1,
+    AVIF_COLOR_PRIMARIES_SRGB = 1,
+    AVIF_COLOR_PRIMARIES_IEC61966_2_4 = 1,
+    AVIF_COLOR_PRIMARIES_UNSPECIFIED = 2,
+    AVIF_COLOR_PRIMARIES_BT470M = 4,
+    AVIF_COLOR_PRIMARIES_BT470BG = 5,
+    AVIF_COLOR_PRIMARIES_BT601 = 6,
+    AVIF_COLOR_PRIMARIES_SMPTE240 = 7,
+    AVIF_COLOR_PRIMARIES_GENERIC_FILM = 8,
+    AVIF_COLOR_PRIMARIES_BT2020 = 9,
+    AVIF_COLOR_PRIMARIES_BT2100 = 9,
+    AVIF_COLOR_PRIMARIES_XYZ = 10,
+    AVIF_COLOR_PRIMARIES_SMPTE431 = 11,
+    AVIF_COLOR_PRIMARIES_SMPTE432 = 12,
+    AVIF_COLOR_PRIMARIES_DCI_P3 = 12,
+    AVIF_COLOR_PRIMARIES_EBU3213 = 22
+};
+typedef uint16_t avifColorPrimaries; // AVIF_COLOR_PRIMARIES_*
+
+// outPrimaries: rX, rY, gX, gY, bX, bY, wX, wY
+AVIF_API void avifColorPrimariesGetValues(avifColorPrimaries acp, float outPrimaries[8]);
+AVIF_API avifColorPrimaries avifColorPrimariesFind(const float inPrimaries[8], const char ** outName);
+
+enum
+{
+    // This is actually reserved, but libavif uses it as a sentinel value.
+    AVIF_TRANSFER_CHARACTERISTICS_UNKNOWN = 0,
+
+    AVIF_TRANSFER_CHARACTERISTICS_BT709 = 1,
+    AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED = 2,
+    AVIF_TRANSFER_CHARACTERISTICS_BT470M = 4,  // 2.2 gamma
+    AVIF_TRANSFER_CHARACTERISTICS_BT470BG = 5, // 2.8 gamma
+    AVIF_TRANSFER_CHARACTERISTICS_BT601 = 6,
+    AVIF_TRANSFER_CHARACTERISTICS_SMPTE240 = 7,
+    AVIF_TRANSFER_CHARACTERISTICS_LINEAR = 8,
+    AVIF_TRANSFER_CHARACTERISTICS_LOG100 = 9,
+    AVIF_TRANSFER_CHARACTERISTICS_LOG100_SQRT10 = 10,
+    AVIF_TRANSFER_CHARACTERISTICS_IEC61966 = 11,
+    AVIF_TRANSFER_CHARACTERISTICS_BT1361 = 12,
+    AVIF_TRANSFER_CHARACTERISTICS_SRGB = 13,
+    AVIF_TRANSFER_CHARACTERISTICS_BT2020_10BIT = 14,
+    AVIF_TRANSFER_CHARACTERISTICS_BT2020_12BIT = 15,
+    AVIF_TRANSFER_CHARACTERISTICS_PQ = 16, // Perceptual Quantizer (HDR); BT.2100 PQ
+    AVIF_TRANSFER_CHARACTERISTICS_SMPTE2084 = 16,
+    AVIF_TRANSFER_CHARACTERISTICS_SMPTE428 = 17,
+    AVIF_TRANSFER_CHARACTERISTICS_HLG = 18 // Hybrid Log-Gamma (HDR); ARIB STD-B67; BT.2100 HLG
+};
+typedef uint16_t avifTransferCharacteristics; // AVIF_TRANSFER_CHARACTERISTICS_*
+
+// If the given transfer characteristics can be expressed with a simple gamma value, sets 'gamma'
+// to that value and returns AVIF_RESULT_OK. Returns an error otherwise.
+AVIF_API avifResult avifTransferCharacteristicsGetGamma(avifTransferCharacteristics atc, float * gamma);
+AVIF_API avifTransferCharacteristics avifTransferCharacteristicsFindByGamma(float gamma);
+
+enum
+{
+    AVIF_MATRIX_COEFFICIENTS_IDENTITY = 0,
+    AVIF_MATRIX_COEFFICIENTS_BT709 = 1,
+    AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED = 2,
+    AVIF_MATRIX_COEFFICIENTS_FCC = 4,
+    AVIF_MATRIX_COEFFICIENTS_BT470BG = 5,
+    AVIF_MATRIX_COEFFICIENTS_BT601 = 6,
+    AVIF_MATRIX_COEFFICIENTS_SMPTE240 = 7,
+    AVIF_MATRIX_COEFFICIENTS_YCGCO = 8,
+    AVIF_MATRIX_COEFFICIENTS_BT2020_NCL = 9,
+    AVIF_MATRIX_COEFFICIENTS_BT2020_CL = 10,
+    AVIF_MATRIX_COEFFICIENTS_SMPTE2085 = 11,
+    AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_NCL = 12,
+    AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL = 13,
+    AVIF_MATRIX_COEFFICIENTS_ICTCP = 14,
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    AVIF_MATRIX_COEFFICIENTS_YCGCO_RE = 16,
+    AVIF_MATRIX_COEFFICIENTS_YCGCO_RO = 17,
+#endif
+    AVIF_MATRIX_COEFFICIENTS_LAST
+};
+typedef uint16_t avifMatrixCoefficients; // AVIF_MATRIX_COEFFICIENTS_*
+
+// ---------------------------------------------------------------------------
+// avifDiagnostics
+
+typedef struct avifDiagnostics
+{
+    // Upon receiving an error from any non-const libavif API call, if the toplevel structure used
+    // in the API call (avifDecoder, avifEncoder) contains a diag member, this buffer may be
+    // populated with a NULL-terminated, freeform error string explaining the first encountered error in
+    // more detail. It will be cleared at the beginning of every non-const API call.
+    //
+    // Note: If an error string contains the "[Strict]" prefix, it means that you encountered an
+    // error that only occurs during strict decoding. If you disable strict mode, you will no
+    // longer encounter this error.
+    char error[AVIF_DIAGNOSTICS_ERROR_BUFFER_SIZE];
+} avifDiagnostics;
+
+AVIF_API void avifDiagnosticsClearError(avifDiagnostics * diag);
+
+// ---------------------------------------------------------------------------
+// Fraction utilities
+
+typedef struct avifFraction
+{
+    int32_t n;
+    int32_t d;
+} avifFraction;
+
+typedef struct avifSignedFraction
+{
+    int32_t n;
+    uint32_t d;
+} avifSignedFraction;
+
+typedef struct avifUnsignedFraction
+{
+    uint32_t n;
+    uint32_t d;
+} avifUnsignedFraction;
+
+// Creates an int32/uint32 fraction that is approximately equal to 'v'.
+// Returns AVIF_FALSE if 'v' is NaN or abs(v) is > INT32_MAX.
+AVIF_NODISCARD AVIF_API avifBool avifDoubleToSignedFraction(double v, avifSignedFraction * fraction);
+// Creates a uint32/uint32 fraction that is approximately equal to 'v'.
+// Returns AVIF_FALSE if 'v' is < 0 or > UINT32_MAX or NaN.
+AVIF_NODISCARD AVIF_API avifBool avifDoubleToUnsignedFraction(double v, avifUnsignedFraction * fraction);
+
+// ---------------------------------------------------------------------------
+// Optional transformation structs
+
+typedef enum avifTransformFlag
+{
+    AVIF_TRANSFORM_NONE = 0,
+
+    AVIF_TRANSFORM_PASP = (1 << 0),
+    AVIF_TRANSFORM_CLAP = (1 << 1),
+    AVIF_TRANSFORM_IROT = (1 << 2),
+    AVIF_TRANSFORM_IMIR = (1 << 3)
+} avifTransformFlag;
+typedef uint32_t avifTransformFlags;
+
+typedef struct avifPixelAspectRatioBox
+{
+    // 'pasp' from ISO/IEC 14496-12:2022 12.1.4.3
+
+    // define the relative width and height of a pixel
+    uint32_t hSpacing;
+    uint32_t vSpacing;
+} avifPixelAspectRatioBox;
+
+// NOTE: The members of the avifCleanApertureBox struct are declared as uint32_t to match the
+// unsigned int(32) type used in ISO/IEC 14496-12:2022 faithfully. However, ISO/IEC 14496-12:2022
+// 12.1.4.1 clearly interprets these values as signed int(32) and talks about them being strictly
+// positive, positive, or negative. Cast these struct members to int32_t before use. See also the
+// clean aperture extension in the QuickTime File Format:
+// https://developer.apple.com/documentation/quicktime-file-format/clean_aperture
+
+typedef struct avifCleanApertureBox
+{
+    // 'clap' from ISO/IEC 14496-12:2022 12.1.4.3
+
+    // a fractional number which defines the width of the clean aperture image
+    uint32_t widthN;
+    uint32_t widthD;
+
+    // a fractional number which defines the height of the clean aperture image
+    uint32_t heightN;
+    uint32_t heightD;
+
+    // a fractional number which defines the horizontal offset between the clean aperture image
+    // centre and the full aperture image centre. Typically 0.
+    uint32_t horizOffN;
+    uint32_t horizOffD;
+
+    // a fractional number which defines the vertical offset between clean aperture image centre
+    // and the full aperture image centre. Typically 0.
+    uint32_t vertOffN;
+    uint32_t vertOffD;
+} avifCleanApertureBox;
+
+typedef struct avifImageRotation
+{
+    // 'irot' from ISO/IEC 23008-12:2017 6.5.10
+
+    // angle * 90 specifies the angle (in anti-clockwise direction) in units of degrees.
+    uint8_t angle; // legal values: [0-3]
+} avifImageRotation;
+
+typedef struct avifImageMirror
+{
+    // 'imir' from ISO/IEC 23008-12:2022 6.5.12:
+    //
+    //     'axis' specifies how the mirroring is performed:
+    //
+    //     0 indicates that the top and bottom parts of the image are exchanged;
+    //     1 specifies that the left and right parts are exchanged.
+    //
+    //     NOTE In Exif, orientation tag can be used to signal mirroring operations. Exif
+    //     orientation tag 4 corresponds to axis = 0 of ImageMirror, and Exif orientation tag 2
+    //     corresponds to axis = 1 accordingly.
+    //
+    // Legal values: [0, 1]
+    uint8_t axis;
+} avifImageMirror;
+
+// ---------------------------------------------------------------------------
+// avifCropRect - Helper struct/functions to work with avifCleanApertureBox
+
+typedef struct avifCropRect
+{
+    uint32_t x;
+    uint32_t y;
+    uint32_t width;
+    uint32_t height;
+} avifCropRect;
+
+// These will return AVIF_FALSE if the resultant values violate any standards, and if so, the output
+// values are not guaranteed to be complete or correct and should not be used.
+AVIF_NODISCARD AVIF_API avifBool avifCropRectConvertCleanApertureBox(avifCropRect * cropRect,
+                                                                     const avifCleanApertureBox * clap,
+                                                                     uint32_t imageW,
+                                                                     uint32_t imageH,
+                                                                     avifPixelFormat yuvFormat,
+                                                                     avifDiagnostics * diag);
+AVIF_NODISCARD AVIF_API avifBool avifCleanApertureBoxConvertCropRect(avifCleanApertureBox * clap,
+                                                                     const avifCropRect * cropRect,
+                                                                     uint32_t imageW,
+                                                                     uint32_t imageH,
+                                                                     avifPixelFormat yuvFormat,
+                                                                     avifDiagnostics * diag);
+
+// ---------------------------------------------------------------------------
+// avifContentLightLevelInformationBox
+
+typedef struct avifContentLightLevelInformationBox
+{
+    // 'clli' from ISO/IEC 23000-22:2019 (MIAF) 7.4.4.2.2. The SEI message semantics written above
+    // each entry were originally described in ISO/IEC 23008-2:2020 (HEVC) section D.3.35,
+    // available at https://standards.iso.org/ittf/PubliclyAvailableStandards/
+
+    // Given the red, green, and blue colour primary intensities in the linear light domain for the
+    // location of a luma sample in a corresponding 4:4:4 representation, denoted as E_R, E_G, and E_B,
+    // the maximum component intensity is defined as E_Max = Max(E_R, Max(E_G, E_B)).
+    // The light level corresponding to the stimulus is then defined as the CIE 1931 luminance
+    // corresponding to equal amplitudes of E_Max for all three colour primary intensities for red,
+    // green, and blue (with appropriate scaling to reflect the nominal luminance level associated
+    // with peak white, e.g. ordinarily scaling to associate peak white with 10 000 candelas per
+    // square metre when transfer_characteristics is equal to 16).
+
+    // max_content_light_level, when not equal to 0, indicates an upper bound on the maximum light
+    // level among all individual samples in a 4:4:4 representation of red, green, and blue colour
+    // primary intensities (in the linear light domain) for the pictures of the CLVS, in units of
+    // candelas per square metre. When equal to 0, no such upper bound is indicated by
+    // max_content_light_level.
+    uint16_t maxCLL;
+
+    // max_pic_average_light_level, when not equal to 0, indicates an upper bound on the maximum
+    // average light level among the samples in a 4:4:4 representation of red, green, and blue
+    // colour primary intensities (in the linear light domain) for any individual picture of the
+    // CLVS, in units of candelas per square metre. When equal to 0, no such upper bound is
+    // indicated by max_pic_average_light_level.
+    uint16_t maxPALL;
+} avifContentLightLevelInformationBox;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+// ---------------------------------------------------------------------------
+// avifGainMap
+// Gain Maps are a solution for a consistent and adaptive display of HDR images.
+// Gain Maps are a HIGHLY EXPERIMENTAL FEATURE. The format might still change and
+// images containing a gain map encoded with the current version of libavif might
+// not decode with a future version of libavif. The API is not guaranteed
+// to be stable, and might even be removed in the future. Use at your own risk.
+// This is based on ISO/IEC JTC 1/SC 29/WG 3 m64379
+// This product includes Gain Map technology under license by Adobe.
+//
+// Terms:
+// base image: main image stored in the file, shown by viewers that do not support
+//     gain maps
+// alternate image: image  obtained by combining the base image and the gain map
+// gain map: data structure that contains pixels and metadata used for conversion
+//     between the base image and the alternate image
+
+struct avifImage;
+
+// Gain map image and associated metadata.
+// Must be allocated by calling avifGainMapCreate().
+typedef struct avifGainMap
+{
+    // Gain map pixels.
+    // Owned by the avifGainMap and gets freed when calling avifGainMapDestroy().
+    // Used fields: width, height, depth, yuvFormat, yuvRange,
+    // yuvChromaSamplePosition, yuvPlanes, yuvRowBytes, imageOwnsYUVPlanes,
+    // matrixCoefficients. The colorPrimaries and transferCharacteristics fields
+    // shall be 2. Other fields are ignored.
+    struct avifImage * image;
+
+    // Gain map metadata used to interpret and apply the gain map pixel data.
+    // When encoding an image grid, all metadata below shall be identical for all
+    // cells.
+
+    // Parameters for converting the gain map from its image encoding to log2 space.
+    // gainMapLog2 = lerp(gainMapMin, gainMapMax, pow(gainMapEncoded, gainMapGamma));
+    // where 'lerp' is a linear interpolation function.
+    // Minimum value in the gain map, log2-encoded, per RGB channel.
+    avifSignedFraction gainMapMin[3];
+    // Maximum value in the gain map, log2-encoded, per RGB channel.
+    avifSignedFraction gainMapMax[3];
+    // Gain map gamma value with which the gain map was encoded, per RGB channel.
+    // For decoding, the inverse value (1/gamma) should be used.
+    avifUnsignedFraction gainMapGamma[3];
+
+    // Parameters used in gain map computation/tone mapping to avoid numerical
+    // instability.
+    // toneMappedLinear = ((baseImageLinear + baseOffset) * exp(gainMapLog * w)) - alternateOffset;
+    // Where 'w' is a weight parameter based on the display's HDR capacity
+    // (see below).
+
+    // Offset constants for the base image, per RGB channel.
+    avifSignedFraction baseOffset[3];
+    // Offset constants for the alternate image, per RGB channel.
+    avifSignedFraction alternateOffset[3];
+
+    // Log2-encoded HDR headroom of the base and alternate images respectively.
+    // If baseHdrHeadroom is < alternateHdrHeadroom, the result of tone mapping
+    // for a display with an HDR headroom that is <= baseHdrHeadroom is the base
+    // image, and the result of tone mapping for a display with an HDR headroom >=
+    // alternateHdrHeadroom is the alternate image.
+    // Conversely, if baseHdrHeadroom is > alternateHdrHeadroom, the result of
+    // tone mapping for a display with an HDR headroom that is >= baseHdrHeadroom
+    // is the base image, and the result of tone mapping for a display with an HDR
+    // headroom <= alternateHdrHeadroom is the alternate image.
+    // For a display with a capacity between baseHdrHeadroom and alternateHdrHeadroom,
+    // tone mapping results in an interpolation between the base and alternate
+    // versions. baseHdrHeadroom and alternateHdrHeadroom can be tuned to change how
+    // the gain map should be applied.
+    //
+    // If 'H' is the display's current log2-encoded HDR capacity (HDR to SDR ratio),
+    // then the weight 'w' to apply the gain map is computed as follows:
+    // f = clamp((H - baseHdrHeadroom) /
+    //           (alternateHdrHeadroom - baseHdrHeadroom), 0, 1);
+    // w = sign(alternateHdrHeadroom - baseHdrHeadroom) * f
+    avifUnsignedFraction baseHdrHeadroom;
+    avifUnsignedFraction alternateHdrHeadroom;
+
+    // True if tone mapping should be performed in the color space of the
+    // base image. If false, the color space of the alternate image should
+    // be used.
+    avifBool useBaseColorSpace;
+
+    // Colorimetry of the alternate image (ICC profile and/or CICP information
+    // of the alternate image that the gain map was created from).
+    avifRWData altICC;
+    avifColorPrimaries altColorPrimaries;
+    avifTransferCharacteristics altTransferCharacteristics;
+    avifMatrixCoefficients altMatrixCoefficients;
+    avifRange altYUVRange;
+
+    // Hint on the approximate amount of colour resolution available after fully
+    // applying the gain map ('pixi' box content of the alternate image that the
+    // gain map was created from).
+    uint32_t altDepth;
+    uint32_t altPlaneCount;
+
+    // Optimal viewing conditions of the alternate image ('clli' box content
+    // of the alternate image that the gain map was created from).
+    avifContentLightLevelInformationBox altCLLI;
+} avifGainMap;
+
+// Allocates a gain map. Returns NULL if a memory allocation failed.
+// The 'image' field is NULL by default and must be allocated separately.
+AVIF_API avifGainMap * avifGainMapCreate(void);
+// Frees a gain map, including the 'image' field if non NULL.
+AVIF_API void avifGainMapDestroy(avifGainMap * gainMap);
+
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+// ---------------------------------------------------------------------------
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+// Sample Transforms are a HIGHLY EXPERIMENTAL FEATURE. The format might still
+// change and images containing a sample transform item encoded with the current
+// version of libavif might not decode with a future version of libavif.
+// Use at your own risk.
+// This is based on a proposal from the Alliance for Open Media.
+
+typedef enum avifSampleTransformRecipe
+{
+    AVIF_SAMPLE_TRANSFORM_NONE,
+    // Encode the 8 most significant bits of each input image sample losslessly
+    // into a base image. The remaining 8 least significant bits are encoded in
+    // a separate hidden image item. The two are combined at decoding into one
+    // image with the same bit depth as the original image. It is backward
+    // compatible in the sense that it is possible to decode only the base image
+    // (ignoring the hidden image item), leading to a valid image but with
+    // precision loss (16-bit samples truncated to the 8 most significant bits).
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B,
+    // Encode the 12 most significant bits of each input image sample losslessly
+    // into a base image. The remaining 4 least significant bits are encoded in
+    // a separate hidden image item. The two are combined at decoding into one
+    // image with the same bit depth as the original image. It is backward
+    // compatible in the sense that it is possible to decode only the base image
+    // (ignoring the hidden image item), leading to a valid image but with
+    // precision loss (16-bit samples truncated to the 12 most significant
+    // bits).
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B,
+    // Encode the 12 most significant bits of each input image sample lossily or
+    // losslessly into a base image. The difference between the original and
+    // decoded values of these samples is encoded as a separate 8-bit hidden
+    // image item. The two are combined at decoding into one image with the same
+    // bit depth as the original image. It is backward compatible in the sense
+    // that it is possible to decode only the base image (ignoring the hidden
+    // image item), leading to a valid image but with loss due to precision
+    // truncation and/or compression.
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B
+} avifSampleTransformRecipe;
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+// ---------------------------------------------------------------------------
+// avifImage
+
+// NOTE: The avifImage struct may be extended in a future release. Code outside the libavif library
+// must allocate avifImage by calling the avifImageCreate() or avifImageCreateEmpty() function.
+typedef struct avifImage
+{
+    // Image information
+    uint32_t width;
+    uint32_t height;
+    uint32_t depth; // all planes must share this depth; if depth>8, all planes are uint16_t internally
+
+    avifPixelFormat yuvFormat;
+    avifRange yuvRange;
+    avifChromaSamplePosition yuvChromaSamplePosition;
+    uint8_t * yuvPlanes[AVIF_PLANE_COUNT_YUV];
+    uint32_t yuvRowBytes[AVIF_PLANE_COUNT_YUV];
+    avifBool imageOwnsYUVPlanes;
+
+    uint8_t * alphaPlane;
+    uint32_t alphaRowBytes;
+    avifBool imageOwnsAlphaPlane;
+    avifBool alphaPremultiplied;
+
+    // ICC Profile
+    avifRWData icc;
+
+    // CICP information:
+    // These are stored in the AV1 payload and used to signal YUV conversion. Additionally, if an
+    // ICC profile is not specified, these will be stored in the AVIF container's `colr` box with
+    // a type of `nclx`. If your system supports ICC profiles, be sure to check for the existence
+    // of one (avifImage.icc) before relying on the values listed here!
+    avifColorPrimaries colorPrimaries;
+    avifTransferCharacteristics transferCharacteristics;
+    avifMatrixCoefficients matrixCoefficients;
+
+    // CLLI information:
+    // Content Light Level Information. Used to represent maximum and average light level of an
+    // image. Useful for tone mapping HDR images, especially when using transfer characteristics
+    // SMPTE2084 (PQ). The default value of (0, 0) means the content light level information is
+    // unknown or unavailable, and will cause libavif to avoid writing a clli box for it.
+    avifContentLightLevelInformationBox clli;
+
+    // Transformations - These metadata values are encoded/decoded when transformFlags are set
+    // appropriately, but do not impact/adjust the actual pixel buffers used (images won't be
+    // pre-cropped or mirrored upon decode). Basic explanations from the standards are offered in
+    // comments above, but for detailed explanations, please refer to the HEIF standard (ISO/IEC
+    // 23008-12:2017) and the BMFF standard (ISO/IEC 14496-12:2022).
+    //
+    // To encode any of these boxes, set the values in the associated box, then enable the flag in
+    // transformFlags. On decode, only honor the values in boxes with the associated transform flag set.
+    // These also apply to gainMap->image, if any.
+    avifTransformFlags transformFlags;
+    avifPixelAspectRatioBox pasp;
+    avifCleanApertureBox clap;
+    avifImageRotation irot;
+    avifImageMirror imir;
+
+    // Metadata - set with avifImageSetMetadata*() before write, check .size>0 for existence after read
+    avifRWData exif; // exif_payload chunk from the ExifDataBlock specified in ISO/IEC 23008-12:2022 Section A.2.1.
+                     // The value of the 4-byte exif_tiff_header_offset field, which is not part of this avifRWData
+                     // byte sequence, can be retrieved by calling avifGetExifTiffHeaderOffset(avifImage.exif).
+    avifRWData xmp;
+
+    // Version 1.0.0 ends here. Add any new members after this line.
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    // Gain map image and metadata. NULL if no gain map is present.
+    // Owned by the avifImage and gets freed when calling avifImageDestroy().
+    // gainMap->image->transformFlags is always AVIF_TRANSFORM_NONE.
+    avifGainMap * gainMap;
+#endif
+} avifImage;
+
+// avifImageCreate() and avifImageCreateEmpty() return NULL if arguments are invalid or if a memory allocation failed.
+AVIF_NODISCARD AVIF_API avifImage * avifImageCreate(uint32_t width, uint32_t height, uint32_t depth, avifPixelFormat yuvFormat);
+AVIF_NODISCARD AVIF_API avifImage * avifImageCreateEmpty(void); // helper for making an image to decode into
+// Performs a deep copy of an image, including all metadata and planes, and the gain map metadata/planes if present
+// and if AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is defined.
+AVIF_API avifResult avifImageCopy(avifImage * dstImage, const avifImage * srcImage, avifPlanesFlags planes);
+// Performs a shallow copy of a rectangular area of an image. 'dstImage' does not own the planes.
+// Ignores the gainMap field (which exists only if AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is defined).
+AVIF_API avifResult avifImageSetViewRect(avifImage * dstImage, const avifImage * srcImage, const avifCropRect * rect);
+AVIF_API void avifImageDestroy(avifImage * image);
+
+AVIF_API avifResult avifImageSetProfileICC(avifImage * image, const uint8_t * icc, size_t iccSize);
+// Sets Exif metadata. Attempts to parse the Exif metadata for Exif orientation. Sets
+// image->transformFlags, image->irot and image->imir if the Exif metadata is parsed successfully,
+// otherwise leaves image->transformFlags, image->irot and image->imir unchanged.
+// Warning: If the Exif payload is set and invalid, avifEncoderWrite() may return AVIF_RESULT_INVALID_EXIF_PAYLOAD.
+AVIF_API avifResult avifImageSetMetadataExif(avifImage * image, const uint8_t * exif, size_t exifSize);
+// Sets XMP metadata.
+AVIF_API avifResult avifImageSetMetadataXMP(avifImage * image, const uint8_t * xmp, size_t xmpSize);
+
+// Allocate/free/steal planes. These functions ignore the gainMap field (which exists only if
+// AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is defined).
+AVIF_API avifResult avifImageAllocatePlanes(avifImage * image, avifPlanesFlags planes); // Ignores any pre-existing planes
+AVIF_API void avifImageFreePlanes(avifImage * image, avifPlanesFlags planes);           // Ignores already-freed planes
+AVIF_API void avifImageStealPlanes(avifImage * dstImage, avifImage * srcImage, avifPlanesFlags planes);
+
+// ---------------------------------------------------------------------------
+// Understanding maxThreads
+//
+// libavif's structures and API use the setting 'maxThreads' in a few places. The intent of this
+// setting is to limit concurrent thread activity/usage, not necessarily to put a hard ceiling on
+// how many sleeping threads happen to exist behind the scenes. The goal of this setting is to
+// ensure that at any given point during libavif's encoding or decoding, no more than *maxThreads*
+// threads are simultaneously **active and taking CPU time**.
+//
+// As an important example, when encoding an image sequence that has an alpha channel, two
+// long-lived underlying AV1 encoders must simultaneously exist (one for color, one for alpha). For
+// each additional frame fed into libavif, its YUV planes are fed into one instance of the AV1
+// encoder, and its alpha plane is fed into another. These operations happen serially, so only one
+// of these AV1 encoders is ever active at a time. However, the AV1 encoders might pre-create a
+// pool of worker threads upon initialization, so during this process, twice the amount of worker
+// threads actually simultaneously exist on the machine, but half of them are guaranteed to be
+// sleeping.
+//
+// This design ensures that AV1 implementations are given as many threads as possible to ensure a
+// speedy encode or decode, despite the complexities of occasionally needing two AV1 codec instances
+// (due to alpha payloads being separate from color payloads). If your system has a hard ceiling on
+// the number of threads that can ever be in flight at a given time, please account for this
+// accordingly.
+
+// ---------------------------------------------------------------------------
+// Scaling
+
+// Scales the YUV/A planes in-place. dstWidth and dstHeight must both be <= AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT and
+// dstWidth*dstHeight should be <= AVIF_DEFAULT_IMAGE_SIZE_LIMIT.
+AVIF_API avifResult avifImageScale(avifImage * image, uint32_t dstWidth, uint32_t dstHeight, avifDiagnostics * diag);
+
+// ---------------------------------------------------------------------------
+// Optional YUV<->RGB support
+
+// To convert to/from RGB, create an avifRGBImage on the stack, call avifRGBImageSetDefaults() on
+// it, and then tweak the values inside of it accordingly. At a minimum, you should populate
+// ->pixels and ->rowBytes with an appropriately sized pixel buffer, which should be at least
+// (->rowBytes * ->height) bytes, where ->rowBytes is at least (->width * avifRGBImagePixelSize()).
+// If you don't want to supply your own pixel buffer, you can use the
+// avifRGBImageAllocatePixels()/avifRGBImageFreePixels() convenience functions.
+
+// avifImageRGBToYUV() and avifImageYUVToRGB() will perform depth rescaling and limited<->full range
+// conversion, if necessary. Pixels in an avifRGBImage buffer are always full range, and conversion
+// routines will fail if the width and height don't match the associated avifImage.
+
+// If libavif is built with a version of libyuv offering a fast conversion between RGB and YUV for
+// the given inputs, libavif will use it. See reformat_libyuv.c for the details.
+// libyuv is faster but may have slightly less precision than built-in conversion, so avoidLibYUV
+// can be set to AVIF_TRUE when AVIF_CHROMA_UPSAMPLING_BEST_QUALITY or
+// AVIF_CHROMA_DOWNSAMPLING_BEST_QUALITY is used, to get the most precise but slowest results.
+
+// Note to libavif maintainers: The lookup tables in avifImageYUVToRGBLibYUV
+// rely on the ordering of this enum values for their correctness. So changing
+// the values in this enum will require auditing avifImageYUVToRGBLibYUV for
+// correctness.
+typedef enum avifRGBFormat
+{
+    AVIF_RGB_FORMAT_RGB = 0,
+    AVIF_RGB_FORMAT_RGBA, // This is the default format set in avifRGBImageSetDefaults().
+    AVIF_RGB_FORMAT_ARGB,
+    AVIF_RGB_FORMAT_BGR,
+    AVIF_RGB_FORMAT_BGRA,
+    AVIF_RGB_FORMAT_ABGR,
+    // RGB_565 format uses five bits for the red and blue components and six
+    // bits for the green component. Each RGB pixel is 16 bits (2 bytes), which
+    // is packed as follows:
+    //   uint16_t: [r4 r3 r2 r1 r0 g5 g4 g3 g2 g1 g0 b4 b3 b2 b1 b0]
+    //   r4 and r0 are the MSB and LSB of the red component respectively.
+    //   g5 and g0 are the MSB and LSB of the green component respectively.
+    //   b4 and b0 are the MSB and LSB of the blue component respectively.
+    // This format is only supported for YUV -> RGB conversion and when
+    // avifRGBImage.depth is set to 8.
+    AVIF_RGB_FORMAT_RGB_565,
+    AVIF_RGB_FORMAT_COUNT
+} avifRGBFormat;
+AVIF_API uint32_t avifRGBFormatChannelCount(avifRGBFormat format);
+AVIF_API avifBool avifRGBFormatHasAlpha(avifRGBFormat format);
+
+typedef enum avifChromaUpsampling
+{
+    AVIF_CHROMA_UPSAMPLING_AUTOMATIC = 0,    // Chooses best trade off of speed/quality (uses BILINEAR libyuv if available,
+                                             // or falls back to NEAREST libyuv if available, or falls back to BILINEAR built-in)
+    AVIF_CHROMA_UPSAMPLING_FASTEST = 1,      // Chooses speed over quality (same as NEAREST)
+    AVIF_CHROMA_UPSAMPLING_BEST_QUALITY = 2, // Chooses the best quality upsampling, given settings (same as BILINEAR)
+    AVIF_CHROMA_UPSAMPLING_NEAREST = 3,      // Uses nearest-neighbor filter
+    AVIF_CHROMA_UPSAMPLING_BILINEAR = 4      // Uses bilinear filter
+} avifChromaUpsampling;
+
+typedef enum avifChromaDownsampling
+{
+    AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC = 0,    // Chooses best trade off of speed/quality (same as AVERAGE)
+    AVIF_CHROMA_DOWNSAMPLING_FASTEST = 1,      // Chooses speed over quality (same as AVERAGE)
+    AVIF_CHROMA_DOWNSAMPLING_BEST_QUALITY = 2, // Chooses the best quality upsampling (same as AVERAGE)
+    AVIF_CHROMA_DOWNSAMPLING_AVERAGE = 3,      // Uses averaging filter
+    AVIF_CHROMA_DOWNSAMPLING_SHARP_YUV = 4     // Uses sharp yuv filter (libsharpyuv), available for 4:2:0 only, ignored for 4:2:2
+} avifChromaDownsampling;
+
+// NOTE: avifRGBImage must be initialized with avifRGBImageSetDefaults() (preferred) or memset()
+// before use.
+typedef struct avifRGBImage
+{
+    uint32_t width;                        // must match associated avifImage
+    uint32_t height;                       // must match associated avifImage
+    uint32_t depth;                        // legal depths [8, 10, 12, 16]. if depth>8, pixels must be uint16_t internally
+    avifRGBFormat format;                  // all channels are always full range
+    avifChromaUpsampling chromaUpsampling; // How to upsample from 4:2:0 or 4:2:2 UV when converting to RGB (ignored for 4:4:4 and 4:0:0).
+                                           // Ignored when converting to YUV. Defaults to AVIF_CHROMA_UPSAMPLING_AUTOMATIC.
+    avifChromaDownsampling chromaDownsampling; // How to downsample to 4:2:0 or 4:2:2 UV when converting from RGB (ignored for 4:4:4 and 4:0:0).
+                                               // Ignored when converting to RGB. Defaults to AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC.
+    avifBool avoidLibYUV; // If AVIF_FALSE and libyuv conversion between RGB and YUV (including upsampling or downsampling if any)
+                          // is available for the avifImage/avifRGBImage combination, then libyuv is used. Default is AVIF_FALSE.
+    avifBool ignoreAlpha; // Used for XRGB formats, treats formats containing alpha (such as ARGB) as if they were RGB, treating
+                          // the alpha bits as if they were all 1.
+    avifBool alphaPremultiplied; // indicates if RGB value is pre-multiplied by alpha. Default: false
+    avifBool isFloat; // indicates if RGBA values are in half float (f16) format. Valid only when depth == 16. Default: false
+    int maxThreads; // Number of threads to be used for the YUV to RGB conversion. Note that this value is ignored for RGB to YUV
+                    // conversion. Setting this to zero has the same effect as setting it to one. Negative values are invalid.
+                    // Default: 1.
+
+    uint8_t * pixels;
+    uint32_t rowBytes;
+} avifRGBImage;
+
+// Sets rgb->width, rgb->height, and rgb->depth to image->width, image->height, and image->depth.
+// Sets rgb->pixels to NULL and rgb->rowBytes to 0. Sets the other fields of 'rgb' to default
+// values.
+AVIF_API void avifRGBImageSetDefaults(avifRGBImage * rgb, const avifImage * image);
+AVIF_API uint32_t avifRGBImagePixelSize(const avifRGBImage * rgb);
+
+// Convenience functions. If you supply your own pixels/rowBytes, you do not need to use these.
+AVIF_API avifResult avifRGBImageAllocatePixels(avifRGBImage * rgb);
+AVIF_API void avifRGBImageFreePixels(avifRGBImage * rgb);
+
+// The main conversion functions
+AVIF_API avifResult avifImageRGBToYUV(avifImage * image, const avifRGBImage * rgb);
+AVIF_API avifResult avifImageYUVToRGB(const avifImage * image, avifRGBImage * rgb);
+
+// Premultiply handling functions.
+// (Un)premultiply is automatically done by the main conversion functions above,
+// so usually you don't need to call these. They are there for convenience.
+AVIF_API avifResult avifRGBImagePremultiplyAlpha(avifRGBImage * rgb);
+AVIF_API avifResult avifRGBImageUnpremultiplyAlpha(avifRGBImage * rgb);
+
+// ---------------------------------------------------------------------------
+// YUV Utils
+
+AVIF_API int avifFullToLimitedY(uint32_t depth, int v);
+AVIF_API int avifFullToLimitedUV(uint32_t depth, int v);
+AVIF_API int avifLimitedToFullY(uint32_t depth, int v);
+AVIF_API int avifLimitedToFullUV(uint32_t depth, int v);
+
+// ---------------------------------------------------------------------------
+// Codec selection
+
+typedef enum avifCodecChoice
+{
+    AVIF_CODEC_CHOICE_AUTO = 0,
+    AVIF_CODEC_CHOICE_AOM,
+    AVIF_CODEC_CHOICE_DAV1D,   // Decode only
+    AVIF_CODEC_CHOICE_LIBGAV1, // Decode only
+    AVIF_CODEC_CHOICE_RAV1E,   // Encode only
+    AVIF_CODEC_CHOICE_SVT,     // Encode only
+    AVIF_CODEC_CHOICE_AVM      // Experimental (AV2)
+} avifCodecChoice;
+
+typedef enum avifCodecFlag
+{
+    AVIF_CODEC_FLAG_CAN_DECODE = (1 << 0),
+    AVIF_CODEC_FLAG_CAN_ENCODE = (1 << 1)
+} avifCodecFlag;
+typedef uint32_t avifCodecFlags;
+
+// If this returns NULL, the codec choice/flag combination is unavailable
+AVIF_API const char * avifCodecName(avifCodecChoice choice, avifCodecFlags requiredFlags);
+AVIF_API avifCodecChoice avifCodecChoiceFromName(const char * name);
+
+// ---------------------------------------------------------------------------
+// avifIO
+
+struct avifIO;
+
+// Destroy must completely destroy all child structures *and* free the avifIO object itself.
+// This function pointer is optional, however, if the avifIO object isn't intended to be owned by
+// a libavif encoder/decoder.
+typedef void (*avifIODestroyFunc)(struct avifIO * io);
+
+// This function should return a block of memory that *must* remain valid until another read call to
+// this avifIO struct is made (reusing a read buffer is acceptable/expected).
+//
+// * If offset exceeds the size of the content (past EOF), return AVIF_RESULT_IO_ERROR.
+// * If offset is *exactly* at EOF, provide a 0-byte buffer and return AVIF_RESULT_OK.
+// * If (offset+size) exceeds the contents' size, it must truncate the range to provide all
+//   bytes from the offset to EOF.
+// * If the range is unavailable yet (due to network conditions or any other reason),
+//   return AVIF_RESULT_WAITING_ON_IO.
+// * Otherwise, provide the range and return AVIF_RESULT_OK.
+typedef avifResult (*avifIOReadFunc)(struct avifIO * io, uint32_t readFlags, uint64_t offset, size_t size, avifROData * out);
+
+typedef avifResult (*avifIOWriteFunc)(struct avifIO * io, uint32_t writeFlags, uint64_t offset, const uint8_t * data, size_t size);
+
+typedef struct avifIO
+{
+    avifIODestroyFunc destroy;
+    avifIOReadFunc read;
+
+    // This is reserved for future use - but currently ignored. Set it to a null pointer.
+    avifIOWriteFunc write;
+
+    // If non-zero, this is a hint to internal structures of the max size offered by the content
+    // this avifIO structure is reading. If it is a static memory source, it should be the size of
+    // the memory buffer; if it is a file, it should be the file's size. If this information cannot
+    // be known (as it is streamed-in), set a reasonable upper boundary here (larger than the file
+    // can possibly be for your environment, but within your environment's memory constraints). This
+    // is used for sanity checks when allocating internal buffers to protect against
+    // malformed/malicious files.
+    uint64_t sizeHint;
+
+    // If true, *all* memory regions returned from *all* calls to read are guaranteed to be
+    // persistent and exist for the lifetime of the avifIO object. If false, libavif will make
+    // in-memory copies of samples and metadata content, and a memory region returned from read must
+    // only persist until the next call to read.
+    avifBool persistent;
+
+    // The contents of this are defined by the avifIO implementation, and should be fully destroyed
+    // by the implementation of the associated destroy function, unless it isn't owned by the avifIO
+    // struct. It is not necessary to use this pointer in your implementation.
+    void * data;
+} avifIO;
+
+// Returns NULL if the reader cannot be allocated.
+AVIF_API avifIO * avifIOCreateMemoryReader(const uint8_t * data, size_t size);
+// Returns NULL if the file cannot be opened or if the reader cannot be allocated.
+AVIF_API avifIO * avifIOCreateFileReader(const char * filename);
+AVIF_API void avifIODestroy(avifIO * io);
+
+// ---------------------------------------------------------------------------
+// avifDecoder
+
+// Some encoders (including very old versions of avifenc) do not implement the AVIF standard
+// perfectly, and thus create invalid files. However, these files are likely still recoverable /
+// decodable, if it wasn't for the strict requirements imposed by libavif's decoder. These flags
+// allow a user of avifDecoder to decide what level of strictness they want in their project.
+typedef enum avifStrictFlag
+{
+    // Disables all strict checks.
+    AVIF_STRICT_DISABLED = 0,
+
+    // Requires the PixelInformationProperty ('pixi') be present in AV1 image items. libheif v1.11.0
+    // or older does not add the 'pixi' item property to AV1 image items. If you need to decode AVIF
+    // images encoded by libheif v1.11.0 or older, be sure to disable this bit. (This issue has been
+    // corrected in libheif v1.12.0.)
+    AVIF_STRICT_PIXI_REQUIRED = (1 << 0),
+
+    // This demands that the values surfaced in the clap box are valid, determined by attempting to
+    // convert the clap box to a crop rect using avifCropRectConvertCleanApertureBox(). If this
+    // function returns AVIF_FALSE and this strict flag is set, the decode will fail.
+    AVIF_STRICT_CLAP_VALID = (1 << 1),
+
+    // Requires the ImageSpatialExtentsProperty ('ispe') be present in alpha auxiliary image items.
+    // avif-serialize 0.7.3 or older does not add the 'ispe' item property to alpha auxiliary image
+    // items. If you need to decode AVIF images encoded by the cavif encoder with avif-serialize
+    // 0.7.3 or older, be sure to disable this bit. (This issue has been corrected in avif-serialize
+    // 0.7.4.) See https://github.com/kornelski/avif-serialize/issues/3 and
+    // https://crbug.com/1246678.
+    AVIF_STRICT_ALPHA_ISPE_REQUIRED = (1 << 2),
+
+    // Maximum strictness; enables all bits above. This is avifDecoder's default.
+    AVIF_STRICT_ENABLED = AVIF_STRICT_PIXI_REQUIRED | AVIF_STRICT_CLAP_VALID | AVIF_STRICT_ALPHA_ISPE_REQUIRED
+} avifStrictFlag;
+typedef uint32_t avifStrictFlags;
+
+// Useful stats related to a read/write
+typedef struct avifIOStats
+{
+    // Size in bytes of the AV1 image item or track data containing color samples.
+    size_t colorOBUSize;
+    // Size in bytes of the AV1 image item or track data containing alpha samples.
+    size_t alphaOBUSize;
+} avifIOStats;
+
+struct avifDecoderData;
+
+typedef enum avifDecoderSource
+{
+    // Honor the major brand signaled in the beginning of the file to pick between an AVIF sequence
+    // ('avis', tracks-based) or a single image ('avif', item-based). If the major brand is neither
+    // of these, prefer the AVIF sequence ('avis', tracks-based), if present.
+    AVIF_DECODER_SOURCE_AUTO = 0,
+
+    // Use the primary item and the aux (alpha) item in the avif(s).
+    // This is where single-image avifs store their image.
+    AVIF_DECODER_SOURCE_PRIMARY_ITEM,
+
+    // Use the chunks inside primary/aux tracks in the moov block.
+    // This is where avifs image sequences store their images.
+    AVIF_DECODER_SOURCE_TRACKS
+
+    // Decode the thumbnail item. Currently unimplemented.
+    // AVIF_DECODER_SOURCE_THUMBNAIL_ITEM
+} avifDecoderSource;
+
+// Information about the timing of a single image in an image sequence
+typedef struct avifImageTiming
+{
+    uint64_t timescale;            // timescale of the media (Hz)
+    double pts;                    // presentation timestamp in seconds (ptsInTimescales / timescale)
+    uint64_t ptsInTimescales;      // presentation timestamp in "timescales"
+    double duration;               // in seconds (durationInTimescales / timescale)
+    uint64_t durationInTimescales; // duration in "timescales"
+} avifImageTiming;
+
+typedef enum avifProgressiveState
+{
+    // The current AVIF/Source does not offer a progressive image. This will always be the state
+    // for an image sequence.
+    AVIF_PROGRESSIVE_STATE_UNAVAILABLE = 0,
+
+    // The current AVIF/Source offers a progressive image, but avifDecoder.allowProgressive is not
+    // enabled, so it will behave as if the image was not progressive and will simply decode the
+    // best version of this item.
+    AVIF_PROGRESSIVE_STATE_AVAILABLE,
+
+    // The current AVIF/Source offers a progressive image, and avifDecoder.allowProgressive is true.
+    // In this state, avifDecoder.imageCount will be the count of all of the available progressive
+    // layers, and any specific layer can be decoded using avifDecoderNthImage() as if it was an
+    // image sequence, or simply using repeated calls to avifDecoderNextImage() to decode better and
+    // better versions of this image.
+    AVIF_PROGRESSIVE_STATE_ACTIVE
+} avifProgressiveState;
+AVIF_API const char * avifProgressiveStateToString(avifProgressiveState progressiveState);
+
+// Types of image content that can be decoded.
+typedef enum avifImageContentTypeFlag
+{
+    AVIF_IMAGE_CONTENT_NONE = 0,
+    // Color only or alpha only is not currently supported.
+    AVIF_IMAGE_CONTENT_COLOR_AND_ALPHA = (1 << 0) | (1 << 1),
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    AVIF_IMAGE_CONTENT_GAIN_MAP = (1 << 2),
+    AVIF_IMAGE_CONTENT_ALL = AVIF_IMAGE_CONTENT_COLOR_AND_ALPHA | AVIF_IMAGE_CONTENT_GAIN_MAP,
+#else
+    AVIF_IMAGE_CONTENT_ALL = AVIF_IMAGE_CONTENT_COLOR_AND_ALPHA,
+#endif
+
+    AVIF_IMAGE_CONTENT_DECODE_DEFAULT = AVIF_IMAGE_CONTENT_COLOR_AND_ALPHA,
+} avifImageContentTypeFlag;
+typedef uint32_t avifImageContentTypeFlags;
+
+// NOTE: The avifDecoder struct may be extended in a future release. Code outside the libavif
+// library must allocate avifDecoder by calling the avifDecoderCreate() function.
+typedef struct avifDecoder
+{
+    // --------------------------------------------------------------------------------------------
+    // Inputs
+
+    // Defaults to AVIF_CODEC_CHOICE_AUTO: Preference determined by order in availableCodecs table (avif.c)
+    avifCodecChoice codecChoice;
+
+    // Defaults to 1. -- NOTE: Please see the "Understanding maxThreads" comment block above
+    int maxThreads;
+
+    // avifs can have multiple sets of images in them. This specifies which to decode.
+    // Set this via avifDecoderSetSource().
+    avifDecoderSource requestedSource;
+
+    // If this is true and a progressive AVIF is decoded, avifDecoder will behave as if the AVIF is
+    // an image sequence, in that it will set imageCount to the number of progressive frames
+    // available, and avifDecoderNextImage()/avifDecoderNthImage() will allow for specific layers
+    // of a progressive image to be decoded. To distinguish between a progressive AVIF and an AVIF
+    // image sequence, inspect avifDecoder.progressiveState.
+    avifBool allowProgressive;
+
+    // If this is false, avifDecoderNextImage() will start decoding a frame only after there are
+    // enough input bytes to decode all of that frame. If this is true, avifDecoder will decode each
+    // subimage or grid cell as soon as possible. The benefits are: grid images may be partially
+    // displayed before being entirely available, and the overall decoding may finish earlier.
+    // Must be set before calling avifDecoderNextImage() or avifDecoderNthImage().
+    // WARNING: Experimental feature.
+    avifBool allowIncremental;
+
+    // Enable any of these to avoid reading and surfacing specific data to the decoded avifImage.
+    // These can be useful if your avifIO implementation heavily uses AVIF_RESULT_WAITING_ON_IO for
+    // streaming data, as some of these payloads are (unfortunately) packed at the end of the file,
+    // which will cause avifDecoderParse() to return AVIF_RESULT_WAITING_ON_IO until it finds them.
+    // If you don't actually leverage this data, it is best to ignore it here.
+    avifBool ignoreExif;
+    avifBool ignoreXMP;
+
+    // This represents the maximum size of an image (in pixel count) that libavif and the underlying
+    // AV1 decoder should attempt to decode. It defaults to AVIF_DEFAULT_IMAGE_SIZE_LIMIT, and can
+    // be set to a smaller value. The value 0 is reserved.
+    // Note: Only some underlying AV1 codecs support a configurable size limit (such as dav1d).
+    uint32_t imageSizeLimit;
+
+    // This represents the maximum dimension of an image (width or height) that libavif should
+    // attempt to decode. It defaults to AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT. Set it to 0 to ignore
+    // the limit.
+    uint32_t imageDimensionLimit;
+
+    // This provides an upper bound on how many images the decoder is willing to attempt to decode,
+    // to provide a bit of protection from malicious or malformed AVIFs citing millions upon
+    // millions of frames, only to be invalid later. The default is AVIF_DEFAULT_IMAGE_COUNT_LIMIT
+    // (see comment above), and setting this to 0 disables the limit.
+    uint32_t imageCountLimit;
+
+    // Strict flags. Defaults to AVIF_STRICT_ENABLED. See avifStrictFlag definitions above.
+    avifStrictFlags strictFlags;
+
+    // --------------------------------------------------------------------------------------------
+    // Outputs
+
+    // All decoded image data; owned by the decoder. All information in this image is incrementally
+    // added and updated as avifDecoder*() functions are called. After a successful call to
+    // avifDecoderParse(), all values in decoder->image (other than the planes/rowBytes themselves)
+    // will be pre-populated with all information found in the outer AVIF container, prior to any
+    // AV1 decoding. If the contents of the inner AV1 payload disagree with the outer container,
+    // these values may change after calls to avifDecoderRead*(),avifDecoderNextImage(), or
+    // avifDecoderNthImage().
+    //
+    // The YUV and A contents of this image are likely owned by the decoder, so be sure to copy any
+    // data inside of this image before advancing to the next image or reusing the decoder. It is
+    // legal to call avifImageYUVToRGB() on this in between calls to avifDecoderNextImage(), but use
+    // avifImageCopy() if you want to make a complete, permanent copy of this image's YUV content or
+    // metadata.
+    avifImage * image;
+
+    // Counts and timing for the current image in an image sequence. Uninteresting for single image files.
+    int imageIndex;                        // 0-based
+    int imageCount;                        // Always 1 for non-progressive, non-sequence AVIFs.
+    avifProgressiveState progressiveState; // See avifProgressiveState declaration
+    avifImageTiming imageTiming;           //
+    uint64_t timescale;                    // timescale of the media (Hz)
+    double duration;                       // duration of a single playback of the image sequence in seconds
+                                           // (durationInTimescales / timescale)
+    uint64_t durationInTimescales;         // duration of a single playback of the image sequence in "timescales"
+    int repetitionCount;                   // number of times the sequence has to be repeated. This can also be one of
+                                           // AVIF_REPETITION_COUNT_INFINITE or AVIF_REPETITION_COUNT_UNKNOWN. Essentially, if
+                                           // repetitionCount is a non-negative integer `n`, then the image sequence should be
+                                           // played back `n + 1` times.
+
+    // This is true when avifDecoderParse() detects an alpha plane. Use this to find out if alpha is
+    // present after a successful call to avifDecoderParse(), but prior to any call to
+    // avifDecoderNextImage() or avifDecoderNthImage(), as decoder->image->alphaPlane won't exist yet.
+    avifBool alphaPresent;
+
+    // stats from the most recent read, possibly 0s if reading an image sequence
+    avifIOStats ioStats;
+
+    // Additional diagnostics (such as detailed error state)
+    avifDiagnostics diag;
+
+    // --------------------------------------------------------------------------------------------
+    // Internals
+
+    // Use one of the avifDecoderSetIO*() functions to set this
+    avifIO * io;
+
+    // Internals used by the decoder
+    struct avifDecoderData * data;
+
+    // Version 1.0.0 ends here.
+
+    // This is true when avifDecoderParse() detects an image sequence track in the image. If this is true, the image can be
+    // decoded either as an animated image sequence or as a still image (the primary image item) by setting avifDecoderSetSource
+    // to the appropriate source.
+    avifBool imageSequenceTrackPresent;
+
+    // Version 1.1.0 ends here. Add any new members after this line.
+
+    // Image content to decode (if present). Defaults to AVIF_IMAGE_CONTENT_DECODE_DEFAULT.
+    avifImageContentTypeFlags imageContentToDecode;
+} avifDecoder;
+
+// Returns NULL in case of memory allocation failure.
+AVIF_API avifDecoder * avifDecoderCreate(void);
+AVIF_API void avifDecoderDestroy(avifDecoder * decoder);
+
+// Simple interfaces to decode a single image, independent of the decoder afterwards (decoder may be destroyed).
+AVIF_API avifResult avifDecoderRead(avifDecoder * decoder, avifImage * image); // call avifDecoderSetIO*() first
+AVIF_API avifResult avifDecoderReadMemory(avifDecoder * decoder, avifImage * image, const uint8_t * data, size_t size);
+AVIF_API avifResult avifDecoderReadFile(avifDecoder * decoder, avifImage * image, const char * filename);
+
+// Multi-function alternative to avifDecoderRead() for image sequences and gaining direct access
+// to the decoder's YUV buffers (for performance's sake). Data passed into avifDecoderParse() is NOT
+// copied, so it must continue to exist until the decoder is destroyed.
+//
+// Usage / function call order is:
+// * avifDecoderCreate()
+// * avifDecoderSetSource() - optional, the default (AVIF_DECODER_SOURCE_AUTO) is usually sufficient
+// * avifDecoderSetIO*()
+// * avifDecoderParse()
+// * avifDecoderNextImage() - in a loop, using decoder->image after each successful call
+// * avifDecoderDestroy()
+//
+// NOTE: Until avifDecoderParse() returns AVIF_RESULT_OK, no data in avifDecoder should
+//       be considered valid, and no queries (such as Keyframe/Timing/MaxExtent) should be made.
+//
+// You can use avifDecoderReset() any time after a successful call to avifDecoderParse()
+// to reset the internal decoder back to before the first frame. Calling either
+// avifDecoderSetSource() or avifDecoderParse() will automatically Reset the decoder.
+//
+// avifDecoderSetSource() allows you not only to choose whether to parse tracks or
+// items in a file containing both, but switch between sources without having to
+// Parse again. Normally AVIF_DECODER_SOURCE_AUTO is enough for the common path.
+AVIF_API avifResult avifDecoderSetSource(avifDecoder * decoder, avifDecoderSource source);
+// Note: When avifDecoderSetIO() is called, whether 'decoder' takes ownership of 'io' depends on
+// whether io->destroy is set. avifDecoderDestroy(decoder) calls avifIODestroy(io), which calls
+// io->destroy(io) if io->destroy is set. Therefore, if io->destroy is not set, then
+// avifDecoderDestroy(decoder) has no effects on 'io'.
+AVIF_API void avifDecoderSetIO(avifDecoder * decoder, avifIO * io);
+AVIF_API avifResult avifDecoderSetIOMemory(avifDecoder * decoder, const uint8_t * data, size_t size);
+AVIF_API avifResult avifDecoderSetIOFile(avifDecoder * decoder, const char * filename);
+AVIF_API avifResult avifDecoderParse(avifDecoder * decoder);
+AVIF_API avifResult avifDecoderNextImage(avifDecoder * decoder);
+AVIF_API avifResult avifDecoderNthImage(avifDecoder * decoder, uint32_t frameIndex);
+AVIF_API avifResult avifDecoderReset(avifDecoder * decoder);
+
+// Keyframe information
+// frameIndex - 0-based, matching avifDecoder->imageIndex, bound by avifDecoder->imageCount
+// "nearest" keyframe means the keyframe prior to this frame index (returns frameIndex if it is a keyframe)
+// These functions may be used after a successful call (AVIF_RESULT_OK) to avifDecoderParse().
+AVIF_NODISCARD AVIF_API avifBool avifDecoderIsKeyframe(const avifDecoder * decoder, uint32_t frameIndex);
+AVIF_API uint32_t avifDecoderNearestKeyframe(const avifDecoder * decoder, uint32_t frameIndex);
+
+// Timing helper - This does not change the current image or invoke the codec (safe to call repeatedly)
+// This function may be used after a successful call (AVIF_RESULT_OK) to avifDecoderParse().
+AVIF_API avifResult avifDecoderNthImageTiming(const avifDecoder * decoder, uint32_t frameIndex, avifImageTiming * outTiming);
+
+// When avifDecoderNextImage() or avifDecoderNthImage() returns AVIF_RESULT_WAITING_ON_IO, this
+// function can be called next to retrieve the number of top rows that can be immediately accessed
+// from the luma plane of decoder->image, and alpha if any. The corresponding rows from the chroma planes,
+// if any, can also be accessed (half rounded up if subsampled, same number of rows otherwise).
+// If a gain map is present and AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is on and
+// (imageContentToDecode & AVIF_IMAGE_CONTENT_GAIN_MAP) is nonzero, the gain map's planes can also be accessed
+// in the same way. If the gain map's height is different from the main image, then the number of
+// available gain map rows is at least:
+// roundf((float)decoded_row_count / decoder->image->height * decoder->image->gainMap.image->height)
+// When gain map scaling is needed, callers might choose to use a few less rows depending on how many rows
+// are needed by the scaling algorithm, to avoid the last row(s) changing when more data becomes available.
+// decoder->allowIncremental must be set to true before calling avifDecoderNextImage() or
+// avifDecoderNthImage(). Returns decoder->image->height when the last call to avifDecoderNextImage() or
+// avifDecoderNthImage() returned AVIF_RESULT_OK. Returns 0 in all other cases.
+// WARNING: Experimental feature.
+AVIF_API uint32_t avifDecoderDecodedRowCount(const avifDecoder * decoder);
+
+// ---------------------------------------------------------------------------
+// avifExtent
+
+typedef struct avifExtent
+{
+    uint64_t offset;
+    size_t size;
+} avifExtent;
+
+// Streaming data helper - Use this to calculate the maximal AVIF data extent encompassing all AV1
+// sample data needed to decode the Nth image. The offset will be the earliest offset of all
+// required AV1 extents for this frame, and the size will create a range including the last byte of
+// the last AV1 sample needed. Note that this extent may include non-sample data, as a frame's
+// sample data may be broken into multiple extents and interleaved with other data, or in
+// non-sequential order. This extent will also encompass all AV1 samples that this frame's sample
+// depends on to decode (such as samples for reference frames), from the nearest keyframe up to this
+// Nth frame.
+//
+// If avifDecoderNthImageMaxExtent() returns AVIF_RESULT_OK and the extent's size is 0 bytes, this
+// signals that libavif doesn't expect to call avifIO's Read for this frame's decode. This happens if
+// data for this frame was read as a part of avifDecoderParse() (typically in an idat box inside of
+// a meta box).
+//
+// This function may be used after a successful call (AVIF_RESULT_OK) to avifDecoderParse().
+AVIF_API avifResult avifDecoderNthImageMaxExtent(const avifDecoder * decoder, uint32_t frameIndex, avifExtent * outExtent);
+
+// ---------------------------------------------------------------------------
+// avifEncoder
+
+struct avifEncoderData;
+struct avifCodecSpecificOptions;
+
+typedef struct avifScalingMode
+{
+    avifFraction horizontal;
+    avifFraction vertical;
+} avifScalingMode;
+
+// Notes:
+// * The avifEncoder struct may be extended in a future release. Code outside the libavif library
+//   must allocate avifEncoder by calling the avifEncoderCreate() function.
+// * If avifEncoderWrite() returns AVIF_RESULT_OK, output must be freed with avifRWDataFree()
+// * If (maxThreads < 2), multithreading is disabled
+//   * NOTE: Please see the "Understanding maxThreads" comment block above
+// * Quality range: [AVIF_QUALITY_WORST - AVIF_QUALITY_BEST]
+// * Quantizer range: [AVIF_QUANTIZER_BEST_QUALITY - AVIF_QUANTIZER_WORST_QUALITY]
+// * In older versions of libavif, the avifEncoder struct doesn't have the quality and qualityAlpha
+//   fields. For backward compatibility, if the quality field is not set, the default value of
+//   quality is based on the average of minQuantizer and maxQuantizer. Similarly the default value
+//   of qualityAlpha is based on the average of minQuantizerAlpha and maxQuantizerAlpha. New code
+//   should set quality and qualityAlpha and leave minQuantizer, maxQuantizer, minQuantizerAlpha,
+//   and maxQuantizerAlpha initialized to their default values.
+// * To enable tiling, set tileRowsLog2 > 0 and/or tileColsLog2 > 0.
+//   Tiling values range [0-6], where the value indicates a request for 2^n tiles in that dimension.
+//   If autoTiling is set to AVIF_TRUE, libavif ignores tileRowsLog2 and tileColsLog2 and
+//   automatically chooses suitable tiling values.
+// * Speed range: [AVIF_SPEED_SLOWEST - AVIF_SPEED_FASTEST]. Slower should make for a better quality
+//   image in less bytes. AVIF_SPEED_DEFAULT means "Leave the AV1 codec to its default speed settings"./
+//   If avifEncoder uses rav1e, the speed value is directly passed through (0-10). If libaom is used,
+//   a combination of settings are tweaked to simulate this speed range.
+// * Extra layer count: [0 - (AVIF_MAX_AV1_LAYER_COUNT-1)]. Non-zero value indicates a layered
+//   (progressive) image.
+// * Some encoder settings can be changed after encoding starts. Changes will take effect in the next
+//   call to avifEncoderAddImage().
+typedef struct avifEncoder
+{
+    // Defaults to AVIF_CODEC_CHOICE_AUTO: Preference determined by order in availableCodecs table (avif.c)
+    avifCodecChoice codecChoice;
+
+    // settings (see Notes above)
+    int maxThreads;
+    int speed;
+    int keyframeInterval;     // Any set of |keyframeInterval| consecutive frames will have at least one keyframe. When it is 0,
+                              // there is no such restriction.
+    uint64_t timescale;       // timescale of the media (Hz)
+    int repetitionCount;      // Number of times the image sequence should be repeated. This can also be set to
+                              // AVIF_REPETITION_COUNT_INFINITE for infinite repetitions.  Only applicable for image sequences.
+                              // Essentially, if repetitionCount is a non-negative integer `n`, then the image sequence should be
+                              // played back `n + 1` times. Defaults to AVIF_REPETITION_COUNT_INFINITE.
+    uint32_t extraLayerCount; // EXPERIMENTAL: Non-zero value encodes layered image.
+
+    // changeable encoder settings
+    int quality;
+    int qualityAlpha;
+    int minQuantizer;
+    int maxQuantizer;
+    int minQuantizerAlpha;
+    int maxQuantizerAlpha;
+    int tileRowsLog2;
+    int tileColsLog2;
+    avifBool autoTiling;
+    avifScalingMode scalingMode;
+
+    // stats from the most recent write
+    avifIOStats ioStats;
+
+    // Additional diagnostics (such as detailed error state)
+    avifDiagnostics diag;
+
+    // Internals used by the encoder
+    struct avifEncoderData * data;
+    struct avifCodecSpecificOptions * csOptions;
+
+    // Version 1.0.0 ends here.
+
+    // Defaults to AVIF_HEADER_FULL
+    avifHeaderFormat headerFormat;
+
+    // Version 1.1.0 ends here. Add any new members after this line.
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    int qualityGainMap; // changeable encoder setting
+#endif
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    // Perform extra steps at encoding and decoding to extend AV1 features using bundled additional image items.
+    avifSampleTransformRecipe sampleTransformRecipe;
+#endif
+} avifEncoder;
+
+// avifEncoderCreate() returns NULL if a memory allocation failed.
+AVIF_NODISCARD AVIF_API avifEncoder * avifEncoderCreate(void);
+AVIF_API avifResult avifEncoderWrite(avifEncoder * encoder, const avifImage * image, avifRWData * output);
+AVIF_API void avifEncoderDestroy(avifEncoder * encoder);
+
+typedef enum avifAddImageFlag
+{
+    AVIF_ADD_IMAGE_FLAG_NONE = 0,
+
+    // Force this frame to be a keyframe (sync frame).
+    AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME = (1 << 0),
+
+    // Use this flag when encoding a single frame, single layer image.
+    // Signals "still_picture" to AV1 encoders, which tweaks various compression rules.
+    // This is enabled automatically when using the avifEncoderWrite() single-image encode path.
+    AVIF_ADD_IMAGE_FLAG_SINGLE = (1 << 1)
+} avifAddImageFlag;
+typedef uint32_t avifAddImageFlags;
+
+// Multi-function alternative to avifEncoderWrite() for advanced features.
+//
+// Usage / function call order is:
+// * avifEncoderCreate()
+// - Still image:
+//   * avifEncoderAddImage() [exactly once]
+// - Still image grid:
+//   * avifEncoderAddImageGrid() [exactly once, AVIF_ADD_IMAGE_FLAG_SINGLE is assumed]
+// - Image sequence:
+//   * Set encoder->timescale (Hz) correctly
+//   * avifEncoderAddImage() ... [repeatedly; at least once]
+// - Still layered image:
+//   * Set encoder->extraLayerCount correctly
+//   * avifEncoderAddImage() ... [exactly encoder->extraLayerCount+1 times]
+// - Still layered grid:
+//   * Set encoder->extraLayerCount correctly
+//   * avifEncoderAddImageGrid() ... [exactly encoder->extraLayerCount+1 times]
+// * avifEncoderFinish()
+// * avifEncoderDestroy()
+//
+// The image passed to avifEncoderAddImage() or avifEncoderAddImageGrid() is encoded during the
+// call (which may be slow) and can be freed after the function returns.
+
+// durationInTimescales is ignored if AVIF_ADD_IMAGE_FLAG_SINGLE is set in addImageFlags,
+// or if we are encoding a layered image.
+AVIF_API avifResult avifEncoderAddImage(avifEncoder * encoder, const avifImage * image, uint64_t durationInTimescales, avifAddImageFlags addImageFlags);
+AVIF_API avifResult avifEncoderAddImageGrid(avifEncoder * encoder,
+                                            uint32_t gridCols,
+                                            uint32_t gridRows,
+                                            const avifImage * const * cellImages,
+                                            avifAddImageFlags addImageFlags);
+AVIF_API avifResult avifEncoderFinish(avifEncoder * encoder, avifRWData * output);
+
+// Codec-specific, optional "advanced" tuning settings, in the form of string key/value pairs,
+// to be consumed by the codec in the next avifEncoderAddImage() call.
+// See the codec documentation to know if a setting is persistent or applied only to the next frame.
+// key must be non-NULL, but passing a NULL value will delete the pending key, if it exists.
+// Setting an incorrect or unknown option for the current codec will cause errors of type
+// AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION from avifEncoderWrite() or avifEncoderAddImage().
+AVIF_API avifResult avifEncoderSetCodecSpecificOption(avifEncoder * encoder, const char * key, const char * value);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+// Returns the size in bytes of the AV1 image item containing gain map samples, or 0 if no gain map was encoded.
+AVIF_API size_t avifEncoderGetGainMapSizeBytes(avifEncoder * encoder);
+#endif
+
+// Helpers
+AVIF_NODISCARD AVIF_API avifBool avifImageUsesU16(const avifImage * image);
+AVIF_NODISCARD AVIF_API avifBool avifImageIsOpaque(const avifImage * image);
+// channel can be an avifChannelIndex.
+AVIF_API uint8_t * avifImagePlane(const avifImage * image, int channel);
+AVIF_API uint32_t avifImagePlaneRowBytes(const avifImage * image, int channel);
+AVIF_API uint32_t avifImagePlaneWidth(const avifImage * image, int channel);
+AVIF_API uint32_t avifImagePlaneHeight(const avifImage * image, int channel);
+
+// Returns AVIF_TRUE if input begins with a valid FileTypeBox (ftyp) that supports
+// either the brand 'avif' or 'avis' (or both), without performing any allocations.
+AVIF_NODISCARD AVIF_API avifBool avifPeekCompatibleFileType(const avifROData * input);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+// ---------------------------------------------------------------------------
+// Gain Map utilities.
+// Gain Maps are a HIGHLY EXPERIMENTAL FEATURE, see comments in the avifGainMap
+// section above.
+
+// Performs tone mapping on a base image using the provided gain map.
+// The HDR headroom is log2 of the ratio of HDR to SDR white brightness of the display to tone map for.
+// 'toneMappedImage' should have the 'format', 'depth', and 'isFloat' fields set to the desired values.
+// If non NULL, 'clli' will be filled with the light level information of the tone mapped image.
+// NOTE: only used in tests for now, might be added to the public API at some point.
+AVIF_API avifResult avifImageApplyGainMap(const avifImage * baseImage,
+                                          const avifGainMap * gainMap,
+                                          float hdrHeadroom,
+                                          avifColorPrimaries outputColorPrimaries,
+                                          avifTransferCharacteristics outputTransferCharacteristics,
+                                          avifRGBImage * toneMappedImage,
+                                          avifContentLightLevelInformationBox * clli,
+                                          avifDiagnostics * diag);
+// Same as above but takes an avifRGBImage as input instead of avifImage.
+AVIF_API avifResult avifRGBImageApplyGainMap(const avifRGBImage * baseImage,
+                                             avifColorPrimaries baseColorPrimaries,
+                                             avifTransferCharacteristics baseTransferCharacteristics,
+                                             const avifGainMap * gainMap,
+                                             float hdrHeadroom,
+                                             avifColorPrimaries outputColorPrimaries,
+                                             avifTransferCharacteristics outputTransferCharacteristics,
+                                             avifRGBImage * toneMappedImage,
+                                             avifContentLightLevelInformationBox * clli,
+                                             avifDiagnostics * diag);
+
+// Computes a gain map between two images: a base image and an alternate image.
+// Both images should have the same width and height, and use the same color
+// primaries. TODO(maryla): allow different primaries.
+// gainMap->image should be initialized with avifImageCreate(), with the width,
+// height, depth and yuvFormat fields set to the desired output values for the
+// gain map. All of these fields may differ from the source images.
+AVIF_API avifResult avifRGBImageComputeGainMap(const avifRGBImage * baseRgbImage,
+                                               avifColorPrimaries baseColorPrimaries,
+                                               avifTransferCharacteristics baseTransferCharacteristics,
+                                               const avifRGBImage * altRgbImage,
+                                               avifColorPrimaries altColorPrimaries,
+                                               avifTransferCharacteristics altTransferCharacteristics,
+                                               avifGainMap * gainMap,
+                                               avifDiagnostics * diag);
+// Convenience function. Same as above but takes avifImage images as input
+// instead of avifRGBImage. Gain map computation is performed in RGB space so
+// the images are converted to RGB first.
+AVIF_API avifResult avifImageComputeGainMap(const avifImage * baseImage,
+                                            const avifImage * altImage,
+                                            avifGainMap * gainMap,
+                                            avifDiagnostics * diag);
+
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef AVIF_AVIF_H
diff --git a/third_party/libavif/src/include/avif/avif_cxx.h b/third_party/libavif/src/include/avif/avif_cxx.h
new file mode 100644
index 0000000000..176157c808
--- /dev/null
+++ b/third_party/libavif/src/include/avif/avif_cxx.h
@@ -0,0 +1,40 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef AVIF_AVIF_CXX_H
+#define AVIF_AVIF_CXX_H
+
+#if !defined(__cplusplus)
+#error "This a C++ only header. Use avif/avif.h for C."
+#endif
+
+#include <memory>
+
+#include "avif/avif.h"
+
+namespace avif
+{
+
+// Struct to call the destroy functions in a unique_ptr.
+struct UniquePtrDeleter
+{
+    void operator()(avifEncoder * encoder) const { avifEncoderDestroy(encoder); }
+    void operator()(avifDecoder * decoder) const { avifDecoderDestroy(decoder); }
+    void operator()(avifImage * image) const { avifImageDestroy(image); }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    void operator()(avifGainMap * gainMap) const { avifGainMapDestroy(gainMap); }
+#endif
+};
+
+// Use these unique_ptr to ensure the structs are automatically destroyed.
+using EncoderPtr = std::unique_ptr<avifEncoder, UniquePtrDeleter>;
+using DecoderPtr = std::unique_ptr<avifDecoder, UniquePtrDeleter>;
+using ImagePtr = std::unique_ptr<avifImage, UniquePtrDeleter>;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+using GainMapPtr = std::unique_ptr<avifGainMap, UniquePtrDeleter>;
+#endif
+
+} // namespace avif
+
+#endif // AVIF_AVIF_CXX_H
diff --git a/third_party/libavif/src/include/avif/internal.h b/third_party/libavif/src/include/avif/internal.h
new file mode 100644
index 0000000000..c044716ab6
--- /dev/null
+++ b/third_party/libavif/src/include/avif/internal.h
@@ -0,0 +1,793 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#ifndef AVIF_INTERNAL_H
+#define AVIF_INTERNAL_H
+
+#include "avif/avif.h" // IWYU pragma: export
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#if defined(AVIF_DLL) && defined(AVIF_USING_STATIC_LIBS)
+#error "Your target is linking against avif and avif_internal: only one should be chosen"
+#endif
+
+// Yes, clamp macros are nasty. Do not use them.
+#define AVIF_CLAMP(x, low, high) (((x) < (low)) ? (low) : (((high) < (x)) ? (high) : (x)))
+#define AVIF_MIN(a, b) (((a) < (b)) ? (a) : (b))
+#define AVIF_MAX(a, b) (((a) > (b)) ? (a) : (b))
+
+// Used for debugging. Define AVIF_BREAK_ON_ERROR to catch the earliest failure during encoding or decoding.
+#if defined(AVIF_BREAK_ON_ERROR)
+static inline void avifBreakOnError()
+{
+    // Same mechanism as OpenCV's error() function, or replace by a breakpoint.
+    int * p = NULL;
+    *p = 0;
+}
+#else
+#define avifBreakOnError()
+#endif
+
+// Used by stream related things.
+#define AVIF_CHECK(A)           \
+    do {                        \
+        if (!(A)) {             \
+            avifBreakOnError(); \
+            return AVIF_FALSE;  \
+        }                       \
+    } while (0)
+
+// Used instead of CHECK if needing to return a specific error on failure, instead of AVIF_FALSE
+#define AVIF_CHECKERR(A, ERR)   \
+    do {                        \
+        if (!(A)) {             \
+            avifBreakOnError(); \
+            return ERR;         \
+        }                       \
+    } while (0)
+
+// Forward any error to the caller now or continue execution.
+#define AVIF_CHECKRES(A)                  \
+    do {                                  \
+        const avifResult result__ = (A);  \
+        if (result__ != AVIF_RESULT_OK) { \
+            avifBreakOnError();           \
+            return result__;              \
+        }                                 \
+    } while (0)
+
+// AVIF_ASSERT_OR_RETURN() can be used instead of assert() for extra security in release builds.
+#ifdef NDEBUG
+#define AVIF_ASSERT_OR_RETURN(A) AVIF_CHECKERR((A), AVIF_RESULT_INTERNAL_ERROR)
+#else
+#define AVIF_ASSERT_OR_RETURN(A) assert(A)
+#endif
+
+// ---------------------------------------------------------------------------
+// URNs and Content-Types
+
+#define AVIF_URN_ALPHA0 "urn:mpeg:mpegB:cicp:systems:auxiliary:alpha"
+#define AVIF_URN_ALPHA1 "urn:mpeg:hevc:2015:auxid:1"
+
+#define AVIF_CONTENT_TYPE_XMP "application/rdf+xml"
+
+// ---------------------------------------------------------------------------
+// Utils
+
+float avifRoundf(float v);
+
+// H (host) is platform-dependent. Could be little- or big-endian.
+// N (network) is big-endian: most- to least-significant bytes.
+// C (custom) is little-endian: least- to most-significant bytes.
+// Never read N or C values; only access after casting to uint8_t*.
+uint16_t avifHTONS(uint16_t s);
+uint16_t avifNTOHS(uint16_t s);
+uint16_t avifCTOHS(uint16_t s);
+uint32_t avifHTONL(uint32_t l);
+uint32_t avifNTOHL(uint32_t l);
+uint32_t avifCTOHL(uint32_t l);
+uint64_t avifHTON64(uint64_t l);
+uint64_t avifNTOH64(uint64_t l);
+
+void avifCalcYUVCoefficients(const avifImage * image, float * outR, float * outG, float * outB);
+
+typedef float (*avifTransferFunction)(float);
+// Returns a function to map from gamma-encoded values in the [0.0, 1.0] range to linear extended SDR values.
+// Extended SDR values are in [0.0, 1.0] for SDR transfer chracteristics (all transfer characteristics except PQ and HLG)
+// and can go beyond 1.0 for HDR transfer characteristics:
+// - For AVIF_TRANSFER_CHARACTERISTICS_PQ, the linear range is [0.0, 10000/203]
+// - For AVIF_TRANSFER_CHARACTERISTICS_HLG, the linear range is [0.0, 1000/203]
+avifTransferFunction avifTransferCharacteristicsGetGammaToLinearFunction(avifTransferCharacteristics atc);
+// Same as above in the opposite direction. toGamma(toLinear(v)) ~= v.
+avifTransferFunction avifTransferCharacteristicsGetLinearToGammaFunction(avifTransferCharacteristics atc);
+
+// Computes the RGB->YUV conversion coefficients kr, kg, kb, such that Y=kr*R+kg*G+kb*B.
+void avifColorPrimariesComputeYCoeffs(avifColorPrimaries colorPrimaries, float coeffs[3]);
+
+// Computes a conversion matrix from RGB to XYZ with a D50 white point.
+AVIF_NODISCARD avifBool avifColorPrimariesComputeRGBToXYZD50Matrix(avifColorPrimaries colorPrimaries, double coeffs[3][3]);
+// Computes a conversion matrix from XYZ with a D50 white point to RGB.
+AVIF_NODISCARD avifBool avifColorPrimariesComputeXYZD50ToRGBMatrix(avifColorPrimaries colorPrimaries, double coeffs[3][3]);
+// Computes the RGB->RGB conversion matrix to convert from one set of RGB primaries to another.
+AVIF_NODISCARD avifBool avifColorPrimariesComputeRGBToRGBMatrix(avifColorPrimaries srcColorPrimaries,
+                                                                avifColorPrimaries dstColorPrimaries,
+                                                                double coeffs[3][3]);
+// Converts the given linear RGB pixel from one color space to another using the provided coefficients.
+// The coefficients can be obtained with avifColorPrimariesComputeRGBToRGBMatrix().
+// The output values are not clamped and may be < 0 or > 1.
+void avifLinearRGBConvertColorSpace(float rgb[4], double coeffs[3][3]);
+
+#define AVIF_ARRAY_DECLARE(TYPENAME, ITEMSTYPE, ITEMSNAME) \
+    typedef struct TYPENAME                                \
+    {                                                      \
+        ITEMSTYPE * ITEMSNAME;                             \
+        uint32_t elementSize;                              \
+        uint32_t count;                                    \
+        uint32_t capacity;                                 \
+    } TYPENAME
+AVIF_NODISCARD avifBool avifArrayCreate(void * arrayStruct, uint32_t elementSize, uint32_t initialCapacity);
+AVIF_NODISCARD void * avifArrayPush(void * arrayStruct);
+void avifArrayPop(void * arrayStruct);
+void avifArrayDestroy(void * arrayStruct);
+
+void avifFractionSimplify(avifFraction * f);
+// Makes the fractions have a common denominator.
+AVIF_NODISCARD avifBool avifFractionCD(avifFraction * a, avifFraction * b);
+AVIF_NODISCARD avifBool avifFractionAdd(avifFraction a, avifFraction b, avifFraction * result);
+AVIF_NODISCARD avifBool avifFractionSub(avifFraction a, avifFraction b, avifFraction * result);
+
+void avifImageSetDefaults(avifImage * image);
+// Copies all fields that do not need to be freed/allocated from srcImage to dstImage.
+void avifImageCopyNoAlloc(avifImage * dstImage, const avifImage * srcImage);
+
+// Copies the samples from srcImage to dstImage. dstImage must be allocated.
+// srcImage and dstImage must have the same width, height, and depth.
+// If the AVIF_PLANES_YUV bit is set in planes, then srcImage and dstImage must have the same yuvFormat.
+// Ignores the gainMap field (which exists only if AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP is defined).
+void avifImageCopySamples(avifImage * dstImage, const avifImage * srcImage, avifPlanesFlags planes);
+
+// ---------------------------------------------------------------------------
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+// Mapping used in the coding of Sample Transform metadata.
+typedef enum avifSampleTransformBitDepth
+{
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_8 = 0,  // Signed 8-bit.
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_16 = 1, // Signed 16-bit.
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32 = 2, // Signed 32-bit.
+    AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_64 = 3  // Signed 64-bit.
+} avifSampleTransformBitDepth;
+
+// Meaning of an operand or operator in Sample Transform metadata.
+typedef enum avifSampleTransformTokenType
+{
+    // Operands.
+    AVIF_SAMPLE_TRANSFORM_CONSTANT = 0,
+    AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX = 1,
+
+    // Operators. L is the left operand. R is the right operand if there are two operands.
+    AVIF_SAMPLE_TRANSFORM_NEGATE = 2,     // S = -L
+    AVIF_SAMPLE_TRANSFORM_ABSOLUTE = 3,   // S = |L|
+    AVIF_SAMPLE_TRANSFORM_SUM = 4,        // S = L + R
+    AVIF_SAMPLE_TRANSFORM_DIFFERENCE = 5, // S = L - R
+    AVIF_SAMPLE_TRANSFORM_PRODUCT = 6,    // S = L * R
+    AVIF_SAMPLE_TRANSFORM_DIVIDE = 7,     // S = R==0 ? L : floor(L / R)
+    AVIF_SAMPLE_TRANSFORM_AND = 8,        // S = L & R
+    AVIF_SAMPLE_TRANSFORM_OR = 9,         // S = L | R
+    AVIF_SAMPLE_TRANSFORM_XOR = 10,       // S = L ^ R
+    AVIF_SAMPLE_TRANSFORM_NOT = 11,       // S = ~L
+    AVIF_SAMPLE_TRANSFORM_MSB = 12,       // S = L<=0 ? 0 : floor(log2(L))
+    AVIF_SAMPLE_TRANSFORM_POW = 13,       // S = L==0 ? 0 : pow(L, R)
+    AVIF_SAMPLE_TRANSFORM_MIN = 14,       // S = L<=R ? L : R
+    AVIF_SAMPLE_TRANSFORM_MAX = 15,       // S = L<=R ? R : L
+    AVIF_SAMPLE_TRANSFORM_RESERVED
+} avifSampleTransformTokenType;
+
+typedef struct avifSampleTransformToken
+{
+    uint8_t type;                // avifSampleTransformTokenType
+    int32_t constant;            // If type is AVIF_SAMPLE_TRANSFORM_CONSTANT.
+                                 // Only 32-bit (bit_depth=2) constants are supported.
+    uint8_t inputImageItemIndex; // If type is AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX. 1-based.
+} avifSampleTransformToken;
+
+AVIF_ARRAY_DECLARE(avifSampleTransformExpression, avifSampleTransformToken, tokens);
+avifBool avifSampleTransformExpressionIsValid(const avifSampleTransformExpression * tokens, uint32_t numInputImageItems);
+avifBool avifSampleTransformExpressionIsEquivalentTo(const avifSampleTransformExpression * a, const avifSampleTransformExpression * b);
+
+avifResult avifSampleTransformRecipeToExpression(avifSampleTransformRecipe recipe, avifSampleTransformExpression * expression);
+avifResult avifSampleTransformExpressionToRecipe(const avifSampleTransformExpression * expression, avifSampleTransformRecipe * recipe);
+
+// Applies the expression to the samples of the inputImageItems in the selected planes and stores
+// the results in dstImage. dstImage can be part of the inputImageItems.
+// dstImage and inputImageItems must be allocated and have the same planes and dimensions.
+avifResult avifImageApplyExpression(avifImage * dstImage,
+                                    avifSampleTransformBitDepth bitDepth,
+                                    const avifSampleTransformExpression * expression,
+                                    uint8_t numInputImageItems,
+                                    const avifImage * inputImageItems[],
+                                    avifPlanesFlags planes);
+
+// Same as avifImageApplyExpression(). Convenience function.
+avifResult avifImageApplyOperations(avifImage * dstImage,
+                                    avifSampleTransformBitDepth bitDepth,
+                                    uint32_t numTokens,
+                                    const avifSampleTransformToken tokens[],
+                                    uint8_t numInputImageItems,
+                                    const avifImage * inputImageItems[],
+                                    avifPlanesFlags planes);
+
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+// ---------------------------------------------------------------------------
+// Alpha
+
+typedef struct avifAlphaParams
+{
+    uint32_t width;
+    uint32_t height;
+
+    uint32_t srcDepth;
+    const uint8_t * srcPlane;
+    uint32_t srcRowBytes;
+    uint32_t srcOffsetBytes;
+    uint32_t srcPixelBytes;
+
+    uint32_t dstDepth;
+    uint8_t * dstPlane;
+    uint32_t dstRowBytes;
+    uint32_t dstOffsetBytes;
+    uint32_t dstPixelBytes;
+
+} avifAlphaParams;
+
+void avifFillAlpha(const avifAlphaParams * params);
+void avifReformatAlpha(const avifAlphaParams * params);
+
+typedef enum avifReformatMode
+{
+    AVIF_REFORMAT_MODE_YUV_COEFFICIENTS = 0, // Normal YUV conversion using coefficients
+    AVIF_REFORMAT_MODE_IDENTITY,             // Pack GBR directly into YUV planes (AVIF_MATRIX_COEFFICIENTS_IDENTITY)
+    AVIF_REFORMAT_MODE_YCGCO,                // YUV conversion using AVIF_MATRIX_COEFFICIENTS_YCGCO
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    AVIF_REFORMAT_MODE_YCGCO_RE, // YUV conversion using AVIF_MATRIX_COEFFICIENTS_YCGCO_RE
+    AVIF_REFORMAT_MODE_YCGCO_RO, // YUV conversion using AVIF_MATRIX_COEFFICIENTS_YCGCO_RO
+#endif
+} avifReformatMode;
+
+typedef enum avifAlphaMultiplyMode
+{
+    AVIF_ALPHA_MULTIPLY_MODE_NO_OP = 0,
+    AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY,
+    AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY
+} avifAlphaMultiplyMode;
+
+// Information about an RGB color space.
+typedef struct avifRGBColorSpaceInfo
+{
+    uint32_t channelBytes; // Number of bytes per channel.
+    uint32_t pixelBytes;   // Number of bytes per pixel (= channelBytes * num channels).
+    uint32_t offsetBytesR; // Offset in bytes of the red channel in a pixel.
+    uint32_t offsetBytesG; // Offset in bytes of the green channel in a pixel.
+    uint32_t offsetBytesB; // Offset in bytes of the blue channel in a pixel.
+    uint32_t offsetBytesA; // Offset in bytes of the alpha channel in a pixel.
+
+    int maxChannel;    // Maximum value for a channel (e.g. 255 for 8 bit).
+    float maxChannelF; // Same as maxChannel but as a float.
+} avifRGBColorSpaceInfo;
+
+avifBool avifGetRGBColorSpaceInfo(const avifRGBImage * rgb, avifRGBColorSpaceInfo * info);
+
+// Information about a YUV color space.
+typedef struct avifYUVColorSpaceInfo
+{
+    // YUV coefficients. Y = kr*R + kg*G + kb*B.
+    float kr;
+    float kg;
+    float kb;
+
+    uint32_t channelBytes; // Number of bytes per channel.
+    uint32_t depth;        // Bit depth.
+    avifRange range;       // Full or limited range.
+    int maxChannel;        // Maximum value for a channel (e.g. 255 for 8 bit).
+    float biasY;           // Minimum Y value.
+    float biasUV;          // The value of 0.5 for the appropriate bit depth (128 for 8 bit, 512 for 10 bit, 2048 for 12 bit).
+    float rangeY;          // Difference between max and min Y.
+    float rangeUV;         // Difference between max and min UV.
+
+    avifPixelFormatInfo formatInfo; // Chroma subsampling information.
+    avifReformatMode mode;          // Appropriate RGB<->YUV conversion mode.
+} avifYUVColorSpaceInfo;
+
+avifBool avifGetYUVColorSpaceInfo(const avifImage * image, avifYUVColorSpaceInfo * info);
+
+typedef struct avifReformatState
+{
+    avifRGBColorSpaceInfo rgb;
+    avifYUVColorSpaceInfo yuv;
+} avifReformatState;
+
+// Retrieves the pixel value at position (x, y) expressed as floats in [0, 1]. If the image's format doesn't have alpha,
+// rgbaPixel[3] is set to 1.0f.
+void avifGetRGBAPixel(const avifRGBImage * src, uint32_t x, uint32_t y, const avifRGBColorSpaceInfo * info, float rgbaPixel[4]);
+// Sets the pixel value at position (i, j) from RGBA values expressed as floats in [0, 1]. If the image's format doesn't
+// support alpha, rgbaPixel[3] is ignored.
+void avifSetRGBAPixel(const avifRGBImage * dst, uint32_t x, uint32_t y, const avifRGBColorSpaceInfo * info, const float rgbaPixel[4]);
+
+// Returns:
+// * AVIF_RESULT_OK              - Converted successfully with libyuv
+// * AVIF_RESULT_NOT_IMPLEMENTED - The fast path for this combination is not implemented with libyuv, use built-in RGB conversion
+// * [any other error]           - Return error to caller
+avifResult avifImageRGBToYUVLibYUV(avifImage * image, const avifRGBImage * rgb);
+
+// Parameters:
+// * image - input YUV image
+// * rgb - output RGB image
+// * reformatAlpha - if set to AVIF_TRUE, the function will attempt to copy the alpha channel to the output RGB image using
+// libyuv.
+// * alphaReformattedWithLibYUV - Output parameter. If reformatAlpha is set to true and libyuv was able to copy over the alpha
+// channel, then this will be set to AVIF_TRUE. Otherwise, this will be set to AVIF_FALSE. The value in this parameter is valid
+// only if the return value of the function is AVIF_RESULT_OK or AVIF_RESULT_NOT_IMPLEMENTED.
+// Returns:
+// * AVIF_RESULT_OK              - Converted successfully with libyuv
+// * AVIF_RESULT_NOT_IMPLEMENTED - The fast path for this combination is not implemented with libyuv, use built-in YUV conversion
+// * [any other error]           - Return error to caller
+avifResult avifImageYUVToRGBLibYUV(const avifImage * image, avifRGBImage * rgb, avifBool reformatAlpha, avifBool * alphaReformattedWithLibYUV);
+
+// Returns:
+// * AVIF_RESULT_OK              - Converted successfully with libsharpyuv
+// * AVIF_RESULT_NOT_IMPLEMENTED - libsharpyuv is not compiled in, or doesn't support this type of input
+// * [any other error]           - Return error to caller
+avifResult avifImageRGBToYUVLibSharpYUV(avifImage * image, const avifRGBImage * rgb, const avifReformatState * state);
+
+// Returns:
+// * AVIF_RESULT_OK               - Converted successfully with libyuv.
+// * AVIF_RESULT_NOT_IMPLEMENTED  - The fast path for this conversion is not implemented with libyuv, use built-in conversion.
+// * AVIF_RESULT_INVALID_ARGUMENT - Return error to caller.
+avifResult avifRGBImageToF16LibYUV(avifRGBImage * rgb);
+
+// Returns:
+// * AVIF_RESULT_OK              - (Un)Premultiply successfully with libyuv
+// * AVIF_RESULT_NOT_IMPLEMENTED - The fast path for this combination is not implemented with libyuv, use built-in (Un)Premultiply
+// * [any other error]           - Return error to caller
+avifResult avifRGBImagePremultiplyAlphaLibYUV(avifRGBImage * rgb);
+avifResult avifRGBImageUnpremultiplyAlphaLibYUV(avifRGBImage * rgb);
+
+AVIF_NODISCARD avifBool avifDimensionsTooLarge(uint32_t width, uint32_t height, uint32_t imageSizeLimit, uint32_t imageDimensionLimit);
+
+// Given the number of encoding threads or decoding threads available and the image dimensions,
+// chooses suitable values of *tileRowsLog2 and *tileColsLog2.
+//
+// Note: Although avifSetTileConfiguration() is only used in src/write.c and could be a static
+// function in that file, it is defined as an internal global function so that it can be tested by
+// unit tests.
+void avifSetTileConfiguration(int threads, uint32_t width, uint32_t height, int * tileRowsLog2, int * tileColsLog2);
+
+// ---------------------------------------------------------------------------
+// Scaling
+
+// Scales the YUV/A planes in-place.
+avifResult avifImageScaleWithLimit(avifImage * image,
+                                   uint32_t dstWidth,
+                                   uint32_t dstHeight,
+                                   uint32_t imageSizeLimit,
+                                   uint32_t imageDimensionLimit,
+                                   avifDiagnostics * diag);
+
+// ---------------------------------------------------------------------------
+// AVIF item category
+
+typedef enum avifItemCategory
+{
+    AVIF_ITEM_COLOR,
+    AVIF_ITEM_ALPHA,
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    AVIF_ITEM_GAIN_MAP,
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    AVIF_ITEM_SAMPLE_TRANSFORM, // Sample Transform derived image item 'sato'.
+    // Extra input image items for AVIF_ITEM_SAMPLE_TRANSFORM. "Extra" because AVIF_ITEM_COLOR could be one too.
+    AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR,
+    AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_1_COLOR,
+    AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA,
+    AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_1_ALPHA,
+#endif
+    AVIF_ITEM_CATEGORY_COUNT
+} avifItemCategory;
+
+avifBool avifIsAlpha(avifItemCategory itemCategory);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+#define AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS \
+    (AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA - AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR)
+#define AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS \
+    (1 /* for AVIF_ITEM_COLOR */ + AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS)
+
+#define AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR
+#define AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY \
+    (AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA + AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS - 1)
+#endif
+
+// ---------------------------------------------------------------------------
+// Grid AVIF images
+
+// Returns false if the tiles in a grid image violate any standards.
+// The image contains imageW*imageH pixels. The tiles are of tileW*tileH pixels each.
+AVIF_NODISCARD avifBool avifAreGridDimensionsValid(avifPixelFormat yuvFormat,
+                                                   uint32_t imageW,
+                                                   uint32_t imageH,
+                                                   uint32_t tileW,
+                                                   uint32_t tileH,
+                                                   avifDiagnostics * diag);
+
+// ---------------------------------------------------------------------------
+// Metadata
+
+// Attempts to parse the image->exif payload for Exif orientation and sets image->transformFlags, image->irot and
+// image->imir on success. Returns AVIF_RESULT_INVALID_EXIF_PAYLOAD on failure.
+avifResult avifImageExtractExifOrientationToIrotImir(avifImage * image);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+// Returns the Exif orientation in [1-8] as defined in JEITA CP-3451C section 4.6.4.A Orientation
+// corresponding to image->irot and image->imir.
+uint8_t avifImageIrotImirToExifOrientation(const avifImage * image);
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+// ---------------------------------------------------------------------------
+// avifCodecDecodeInput
+
+// Legal spatial_id values are [0,1,2,3], so this serves as a sentinel value for "do not filter by spatial_id"
+#define AVIF_SPATIAL_ID_UNSET 0xff
+
+typedef struct avifDecodeSample
+{
+    avifROData data;
+    avifBool ownsData;
+    avifBool partialData; // if true, data exists but doesn't have all of the sample in it
+
+    uint32_t itemID;   // if non-zero, data comes from a mergedExtents buffer in an avifDecoderItem, not a file offset
+    uint64_t offset;   // additional offset into data. Can be used to offset into an itemID's payload as well.
+    size_t size;       //
+    uint8_t spatialID; // If set to a value other than AVIF_SPATIAL_ID_UNSET, output frames from this sample should be
+                       // skipped until the output frame's spatial_id matches this ID.
+    avifBool sync;     // is sync sample (keyframe)
+} avifDecodeSample;
+AVIF_ARRAY_DECLARE(avifDecodeSampleArray, avifDecodeSample, sample);
+
+typedef struct avifCodecDecodeInput
+{
+    avifDecodeSampleArray samples;
+    avifBool allLayers;            // if true, the underlying codec must decode all layers, not just the best layer
+    avifItemCategory itemCategory; // category of item being decoded
+} avifCodecDecodeInput;
+
+AVIF_NODISCARD avifCodecDecodeInput * avifCodecDecodeInputCreate(void);
+void avifCodecDecodeInputDestroy(avifCodecDecodeInput * decodeInput);
+
+// ---------------------------------------------------------------------------
+// avifCodecEncodeOutput
+
+typedef struct avifEncodeSample
+{
+    avifRWData data;
+    avifBool sync; // is sync sample (keyframe)
+} avifEncodeSample;
+AVIF_ARRAY_DECLARE(avifEncodeSampleArray, avifEncodeSample, sample);
+
+typedef struct avifCodecEncodeOutput
+{
+    avifEncodeSampleArray samples;
+} avifCodecEncodeOutput;
+
+AVIF_NODISCARD avifCodecEncodeOutput * avifCodecEncodeOutputCreate(void);
+avifResult avifCodecEncodeOutputAddSample(avifCodecEncodeOutput * encodeOutput, const uint8_t * data, size_t len, avifBool sync);
+void avifCodecEncodeOutputDestroy(avifCodecEncodeOutput * encodeOutput);
+
+// ---------------------------------------------------------------------------
+// avifCodecSpecificOptions (key/value string pairs for advanced tuning)
+
+typedef struct avifCodecSpecificOption
+{
+    char * key;   // Must be a simple lowercase alphanumeric string
+    char * value; // Free-form string to be interpreted by the codec
+} avifCodecSpecificOption;
+AVIF_ARRAY_DECLARE(avifCodecSpecificOptions, avifCodecSpecificOption, entries);
+
+// Returns NULL if a memory allocation failed.
+AVIF_NODISCARD avifCodecSpecificOptions * avifCodecSpecificOptionsCreate(void);
+void avifCodecSpecificOptionsClear(avifCodecSpecificOptions * csOptions);
+void avifCodecSpecificOptionsDestroy(avifCodecSpecificOptions * csOptions);
+avifResult avifCodecSpecificOptionsSet(avifCodecSpecificOptions * csOptions, const char * key, const char * value); // if(value==NULL), key is deleted
+
+// ---------------------------------------------------------------------------
+// avifCodecType (underlying video format)
+
+// Alliance for Open Media video formats that can be used in the AVIF image format.
+typedef enum avifCodecType
+{
+    AVIF_CODEC_TYPE_UNKNOWN,
+    AVIF_CODEC_TYPE_AV1,
+#if defined(AVIF_CODEC_AVM)
+    AVIF_CODEC_TYPE_AV2, // Experimental.
+#endif
+} avifCodecType;
+
+// Returns AVIF_CODEC_TYPE_UNKNOWN unless the chosen codec is available with the requiredFlags.
+avifCodecType avifCodecTypeFromChoice(avifCodecChoice choice, avifCodecFlags requiredFlags);
+
+// ---------------------------------------------------------------------------
+// avifCodec (abstraction layer to use different codec implementations)
+
+struct avifCodec;
+struct avifCodecInternal;
+
+typedef enum avifEncoderChange
+{
+    AVIF_ENCODER_CHANGE_MIN_QUANTIZER = (1 << 0),
+    AVIF_ENCODER_CHANGE_MAX_QUANTIZER = (1 << 1),
+    AVIF_ENCODER_CHANGE_MIN_QUANTIZER_ALPHA = (1 << 2),
+    AVIF_ENCODER_CHANGE_MAX_QUANTIZER_ALPHA = (1 << 3),
+    AVIF_ENCODER_CHANGE_TILE_ROWS_LOG2 = (1 << 4),
+    AVIF_ENCODER_CHANGE_TILE_COLS_LOG2 = (1 << 5),
+    AVIF_ENCODER_CHANGE_QUANTIZER = (1 << 6),
+    AVIF_ENCODER_CHANGE_QUANTIZER_ALPHA = (1 << 7),
+    AVIF_ENCODER_CHANGE_SCALING_MODE = (1 << 8),
+
+    AVIF_ENCODER_CHANGE_CODEC_SPECIFIC = (1 << 30)
+} avifEncoderChange;
+typedef int avifEncoderChanges;
+
+typedef avifBool (*avifCodecGetNextImageFunc)(struct avifCodec * codec,
+                                              const avifDecodeSample * sample,
+                                              avifBool alpha,
+                                              avifBool * isLimitedRangeAlpha,
+                                              avifImage * image);
+// EncodeImage and EncodeFinish are not required to always emit a sample, but when all images are
+// encoded and EncodeFinish is called, the number of samples emitted must match the number of submitted frames.
+// avifCodecEncodeImageFunc may return AVIF_RESULT_UNKNOWN_ERROR to automatically emit the appropriate
+// AVIF_RESULT_ENCODE_COLOR_FAILED or AVIF_RESULT_ENCODE_ALPHA_FAILED depending on the alpha argument.
+// avifCodecEncodeImageFunc should use tileRowsLog2 and tileColsLog2 instead of
+// encoder->tileRowsLog2, encoder->tileColsLog2, and encoder->autoTiling. The caller of
+// avifCodecEncodeImageFunc is responsible for automatic tiling if encoder->autoTiling is set to
+// AVIF_TRUE. The actual tiling values are passed to avifCodecEncodeImageFunc as parameters.
+// Similarly, avifCodecEncodeImageFunc should use the quantizer parameter instead of
+// encoder->quality and encoder->qualityAlpha. If disableLaggedOutput is AVIF_TRUE, then the encoder will emit the output frame
+// without any lag (if supported). Note that disableLaggedOutput is only used by the first call to this function (which
+// initializes the encoder) and is ignored by the subsequent calls.
+//
+// Note: The caller of avifCodecEncodeImageFunc always passes encoder->data->tileRowsLog2 and
+// encoder->data->tileColsLog2 as the tileRowsLog2 and tileColsLog2 arguments. Because
+// encoder->data is of a struct type defined in src/write.c, avifCodecEncodeImageFunc cannot
+// dereference encoder->data and has to receive encoder->data->tileRowsLog2 and
+// encoder->data->tileColsLog2 via function parameters.
+typedef avifResult (*avifCodecEncodeImageFunc)(struct avifCodec * codec,
+                                               avifEncoder * encoder,
+                                               const avifImage * image,
+                                               avifBool alpha,
+                                               int tileRowsLog2,
+                                               int tileColsLog2,
+                                               int quantizer,
+                                               avifEncoderChanges encoderChanges,
+                                               avifBool disableLaggedOutput,
+                                               avifAddImageFlags addImageFlags,
+                                               avifCodecEncodeOutput * output);
+typedef avifBool (*avifCodecEncodeFinishFunc)(struct avifCodec * codec, avifCodecEncodeOutput * output);
+typedef void (*avifCodecDestroyInternalFunc)(struct avifCodec * codec);
+
+typedef struct avifCodec
+{
+    avifCodecSpecificOptions * csOptions; // Contains codec-specific key/value pairs for advanced tuning.
+                                          // If a codec uses a value, it must mark it as used.
+                                          // This array is NOT owned by avifCodec.
+    struct avifCodecInternal * internal;  // up to each codec to use how it wants
+                                          //
+    avifDiagnostics * diag;               // Shallow copy; owned by avifEncoder or avifDecoder
+
+    // Decoder options (for getNextImage):
+    int maxThreads;          // See avifDecoder::maxThreads.
+    uint32_t imageSizeLimit; // See avifDecoder::imageSizeLimit.
+    uint8_t operatingPoint;  // Operating point, defaults to 0.
+    avifBool allLayers;      // if true, the underlying codec must decode all layers, not just the best layer
+
+    avifCodecGetNextImageFunc getNextImage;
+    avifCodecEncodeImageFunc encodeImage;
+    avifCodecEncodeFinishFunc encodeFinish;
+    avifCodecDestroyInternalFunc destroyInternal;
+} avifCodec;
+
+avifResult avifCodecCreate(avifCodecChoice choice, avifCodecFlags requiredFlags, avifCodec ** codec);
+void avifCodecDestroy(avifCodec * codec);
+
+AVIF_NODISCARD avifCodec * avifCodecCreateAOM(void);   // requires AVIF_CODEC_AOM (codec_aom.c)
+const char * avifCodecVersionAOM(void);                // requires AVIF_CODEC_AOM (codec_aom.c)
+AVIF_NODISCARD avifCodec * avifCodecCreateDav1d(void); // requires AVIF_CODEC_DAV1D (codec_dav1d.c)
+const char * avifCodecVersionDav1d(void);              // requires AVIF_CODEC_DAV1D (codec_dav1d.c)
+AVIF_NODISCARD avifCodec * avifCodecCreateGav1(void);  // requires AVIF_CODEC_LIBGAV1 (codec_libgav1.c)
+const char * avifCodecVersionGav1(void);               // requires AVIF_CODEC_LIBGAV1 (codec_libgav1.c)
+AVIF_NODISCARD avifCodec * avifCodecCreateRav1e(void); // requires AVIF_CODEC_RAV1E (codec_rav1e.c)
+const char * avifCodecVersionRav1e(void);              // requires AVIF_CODEC_RAV1E (codec_rav1e.c)
+AVIF_NODISCARD avifCodec * avifCodecCreateSvt(void);   // requires AVIF_CODEC_SVT (codec_svt.c)
+const char * avifCodecVersionSvt(void);                // requires AVIF_CODEC_SVT (codec_svt.c)
+AVIF_NODISCARD avifCodec * avifCodecCreateAVM(void);   // requires AVIF_CODEC_AVM (codec_avm.c)
+const char * avifCodecVersionAVM(void);                // requires AVIF_CODEC_AVM (codec_avm.c)
+
+// ---------------------------------------------------------------------------
+// avifDiagnostics
+
+#ifdef __clang__
+__attribute__((__format__(__printf__, 2, 3)))
+#endif
+void avifDiagnosticsPrintf(avifDiagnostics * diag, const char * format, ...);
+
+#if defined(AVIF_ENABLE_COMPLIANCE_WARDEN)
+avifResult avifIsCompliant(const uint8_t * data, size_t size);
+#endif
+
+// ---------------------------------------------------------------------------
+// avifStream
+//
+// In network byte order (big-endian) unless otherwise specified.
+
+typedef size_t avifBoxMarker;
+
+typedef struct avifBoxHeader
+{
+    // If set to AVIF_TRUE, it means that the box goes on until the end of the
+    // stream. So, |size| must be set to the number of bytes left in the input
+    // stream. If set to AVIF_FALSE, |size| indicates the size of the box in
+    // bytes, excluding the box header.
+    avifBool isSizeZeroBox;
+    // Size of the box in bytes, excluding the box header.
+    size_t size;
+
+    uint8_t type[4];
+} avifBoxHeader;
+
+typedef struct avifROStream
+{
+    avifROData * raw;
+
+    // Index of the next byte in the raw stream.
+    size_t offset;
+
+    // If 0, byte-aligned functions can be used (avifROStreamRead() etc.).
+    // Otherwise, it represents the number of bits already used in the last byte
+    // (located at offset-1).
+    size_t numUsedBitsInPartialByte;
+
+    // Error information, if any.
+    avifDiagnostics * diag;
+    const char * diagContext;
+} avifROStream;
+
+const uint8_t * avifROStreamCurrent(avifROStream * stream);
+void avifROStreamStart(avifROStream * stream, avifROData * raw, avifDiagnostics * diag, const char * diagContext);
+size_t avifROStreamOffset(const avifROStream * stream);
+void avifROStreamSetOffset(avifROStream * stream, size_t offset);
+
+AVIF_NODISCARD avifBool avifROStreamHasBytesLeft(const avifROStream * stream, size_t byteCount);
+size_t avifROStreamRemainingBytes(const avifROStream * stream);
+// The following functions require byte alignment.
+AVIF_NODISCARD avifBool avifROStreamSkip(avifROStream * stream, size_t byteCount);
+AVIF_NODISCARD avifBool avifROStreamRead(avifROStream * stream, uint8_t * data, size_t size);
+AVIF_NODISCARD avifBool avifROStreamReadU16(avifROStream * stream, uint16_t * v);
+AVIF_NODISCARD avifBool avifROStreamReadU16Endianness(avifROStream * stream, uint16_t * v, avifBool littleEndian);
+AVIF_NODISCARD avifBool avifROStreamReadU32(avifROStream * stream, uint32_t * v);
+AVIF_NODISCARD avifBool avifROStreamReadU32Endianness(avifROStream * stream, uint32_t * v, avifBool littleEndian);
+// Reads a factor*8 sized uint, saves in v. If factor is 0, reads nothing and saves 0 in v.
+AVIF_NODISCARD avifBool avifROStreamReadUX8(avifROStream * stream, uint64_t * v, uint64_t factor);
+AVIF_NODISCARD avifBool avifROStreamReadU64(avifROStream * stream, uint64_t * v);
+AVIF_NODISCARD avifBool avifROStreamReadString(avifROStream * stream, char * output, size_t outputSize);
+AVIF_NODISCARD avifBool avifROStreamReadBoxHeader(avifROStream * stream, avifBoxHeader * header); // This fails if the size reported by the header cannot fit in the stream
+AVIF_NODISCARD avifBool avifROStreamReadBoxHeaderPartial(avifROStream * stream, avifBoxHeader * header, avifBool topLevel); // This doesn't require that the full box can fit in the stream
+AVIF_NODISCARD avifBool avifROStreamReadVersionAndFlags(avifROStream * stream, uint8_t * version, uint32_t * flags); // version and flags ptrs are both optional
+AVIF_NODISCARD avifBool avifROStreamReadAndEnforceVersion(avifROStream * stream, uint8_t enforcedVersion); // currently discards flags
+// The following functions can read non-aligned bits.
+AVIF_NODISCARD avifBool avifROStreamSkipBits(avifROStream * stream, size_t bitCount);
+AVIF_NODISCARD avifBool avifROStreamReadBitsU8(avifROStream * stream, uint8_t * v, size_t bitCount);
+AVIF_NODISCARD avifBool avifROStreamReadBitsU16(avifROStream * stream, uint16_t * v, size_t bitCount);
+AVIF_NODISCARD avifBool avifROStreamReadBitsU32(avifROStream * stream, uint32_t * v, size_t bitCount);
+
+typedef struct avifRWStream
+{
+    avifRWData * raw;
+
+    // Index of the next byte in the raw stream.
+    size_t offset;
+
+    // If 0, byte-aligned functions can be used (avifRWStreamWrite() etc.).
+    // Otherwise, it represents the number of bits already used in the last byte
+    // (located at offset-1).
+    size_t numUsedBitsInPartialByte;
+} avifRWStream;
+
+void avifRWStreamStart(avifRWStream * stream, avifRWData * raw);
+size_t avifRWStreamOffset(const avifRWStream * stream);
+void avifRWStreamSetOffset(avifRWStream * stream, size_t offset);
+
+void avifRWStreamFinishWrite(avifRWStream * stream);
+// The following functions require byte alignment.
+avifResult avifRWStreamWrite(avifRWStream * stream, const void * data, size_t size);
+avifResult avifRWStreamWriteChars(avifRWStream * stream, const char * chars, size_t size);
+avifResult avifRWStreamWriteBox(avifRWStream * stream, const char * type, size_t contentSize, avifBoxMarker * marker);
+avifResult avifRWStreamWriteFullBox(avifRWStream * stream, const char * type, size_t contentSize, int version, uint32_t flags, avifBoxMarker * marker);
+void avifRWStreamFinishBox(avifRWStream * stream, avifBoxMarker marker);
+avifResult avifRWStreamWriteU8(avifRWStream * stream, uint8_t v);
+avifResult avifRWStreamWriteU16(avifRWStream * stream, uint16_t v);
+avifResult avifRWStreamWriteU32(avifRWStream * stream, uint32_t v);
+avifResult avifRWStreamWriteU64(avifRWStream * stream, uint64_t v);
+avifResult avifRWStreamWriteZeros(avifRWStream * stream, size_t byteCount);
+// The following functions can write non-aligned bits.
+avifResult avifRWStreamWriteBits(avifRWStream * stream, uint32_t v, size_t bitCount);
+
+// This is to make it clear that the box size is currently unknown, and will be determined later (with a call to avifRWStreamFinishBox)
+#define AVIF_BOX_SIZE_TBD 0
+
+// Used for both av1C and av2C.
+typedef struct avifCodecConfigurationBox
+{
+    // [skipped; is constant] unsigned int (1)marker = 1;
+    // [skipped; is constant] unsigned int (7)version = 1;
+
+    uint8_t seqProfile;           // unsigned int (3) seq_profile;
+    uint8_t seqLevelIdx0;         // unsigned int (5) seq_level_idx_0;
+    uint8_t seqTier0;             // unsigned int (1) seq_tier_0;
+    uint8_t highBitdepth;         // unsigned int (1) high_bitdepth;
+    uint8_t twelveBit;            // unsigned int (1) twelve_bit;
+    uint8_t monochrome;           // unsigned int (1) monochrome;
+    uint8_t chromaSubsamplingX;   // unsigned int (1) chroma_subsampling_x;
+    uint8_t chromaSubsamplingY;   // unsigned int (1) chroma_subsampling_y;
+    uint8_t chromaSamplePosition; // unsigned int (2) chroma_sample_position;
+
+    // unsigned int (3)reserved = 0;
+    // unsigned int (1)initial_presentation_delay_present;
+    // if (initial_presentation_delay_present) {
+    //     unsigned int (4)initial_presentation_delay_minus_one;
+    // } else {
+    //     unsigned int (4)reserved = 0;
+    // }
+} avifCodecConfigurationBox;
+
+typedef struct avifSequenceHeader
+{
+    uint8_t reduced_still_picture_header;
+    uint32_t maxWidth;
+    uint32_t maxHeight;
+    uint32_t bitDepth;
+    avifPixelFormat yuvFormat;
+    avifChromaSamplePosition chromaSamplePosition;
+    avifColorPrimaries colorPrimaries;
+    avifTransferCharacteristics transferCharacteristics;
+    avifMatrixCoefficients matrixCoefficients;
+    avifRange range;
+    avifCodecConfigurationBox av1C; // TODO(yguyon): Rename or add av2C
+} avifSequenceHeader;
+
+AVIF_NODISCARD avifBool avifSequenceHeaderParse(avifSequenceHeader * header, const avifROData * sample, avifCodecType codecType);
+
+// ---------------------------------------------------------------------------
+// gain maps
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+
+// Finds the approximate min/max values from the given gain map values, excluding outliers.
+// Uses a histogram, with outliers defined as having at least one empty bucket between them
+// and the rest of the distribution. Discards at most 0.1% of values.
+// Removing outliers helps with accuracy/compression.
+avifResult avifFindMinMaxWithoutOutliers(const float * gainMapF, int numPixels, float * rangeMin, float * rangeMax);
+
+avifResult avifGainMapValidateMetadata(const avifGainMap * gainMap, avifDiagnostics * diag);
+
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#define AVIF_INDEFINITE_DURATION64 UINT64_MAX
+#define AVIF_INDEFINITE_DURATION32 UINT32_MAX
+
+#ifdef __cplusplus
+} // extern "C"
+#endif
+
+#endif // ifndef AVIF_INTERNAL_H
diff --git a/third_party/libavif/src/libavif.pc.cmake b/third_party/libavif/src/libavif.pc.cmake
new file mode 100644
index 0000000000..1341c2b8f4
--- /dev/null
+++ b/third_party/libavif/src/libavif.pc.cmake
@@ -0,0 +1,13 @@
+prefix=@CMAKE_INSTALL_PREFIX@
+exec_prefix=${prefix}
+libdir=@PC_LIBDIR@
+includedir=@PC_INCLUDEDIR@
+
+Name: @PROJECT_NAME@
+Description: Library for encoding and decoding .avif files
+Version: @PROJECT_VERSION@
+Libs: -L${libdir} -lavif
+Libs.private:@AVIF_PKG_CONFIG_EXTRA_LIBS_PRIVATE@
+Cflags: -I${includedir}@AVIF_PKG_CONFIG_EXTRA_CFLAGS@
+Cflags.private: -UAVIF_DLL
+Requires.private:@AVIF_PKG_CONFIG_EXTRA_REQUIRES_PRIVATE@
diff --git a/third_party/libavif/src/src/alpha.c b/third_party/libavif/src/src/alpha.c
new file mode 100644
index 0000000000..f73400ae32
--- /dev/null
+++ b/third_party/libavif/src/src/alpha.c
@@ -0,0 +1,389 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <string.h>
+
+void avifFillAlpha(const avifAlphaParams * params)
+{
+    if (params->dstDepth > 8) {
+        const uint16_t maxChannel = (uint16_t)((1 << params->dstDepth) - 1);
+        uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+        for (uint32_t j = 0; j < params->height; ++j) {
+            uint8_t * dstPixel = dstRow;
+            for (uint32_t i = 0; i < params->width; ++i) {
+                *((uint16_t *)dstPixel) = maxChannel;
+                dstPixel += params->dstPixelBytes;
+            }
+            dstRow += params->dstRowBytes;
+        }
+    } else {
+        // In this case, (1 << params->dstDepth) - 1 is always equal to 255.
+        const uint8_t maxChannel = 255;
+        uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+        for (uint32_t j = 0; j < params->height; ++j) {
+            uint8_t * dstPixel = dstRow;
+            for (uint32_t i = 0; i < params->width; ++i) {
+                *dstPixel = maxChannel;
+                dstPixel += params->dstPixelBytes;
+            }
+            dstRow += params->dstRowBytes;
+        }
+    }
+}
+
+void avifReformatAlpha(const avifAlphaParams * params)
+{
+    const int srcMaxChannel = (1 << params->srcDepth) - 1;
+    const int dstMaxChannel = (1 << params->dstDepth) - 1;
+    const float srcMaxChannelF = (float)srcMaxChannel;
+    const float dstMaxChannelF = (float)dstMaxChannel;
+
+    if (params->srcDepth == params->dstDepth) {
+        // no depth rescale
+
+        if (params->srcDepth > 8) {
+            // no depth rescale, uint16_t -> uint16_t
+
+            const uint8_t * srcRow = &params->srcPlane[params->srcOffsetBytes];
+            uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+            for (uint32_t j = 0; j < params->height; ++j) {
+                const uint8_t * srcPixel = srcRow;
+                uint8_t * dstPixel = dstRow;
+                for (uint32_t i = 0; i < params->width; ++i) {
+                    *((uint16_t *)dstPixel) = *((const uint16_t *)srcPixel);
+                    srcPixel += params->srcPixelBytes;
+                    dstPixel += params->dstPixelBytes;
+                }
+                srcRow += params->srcRowBytes;
+                dstRow += params->dstRowBytes;
+            }
+        } else {
+            // no depth rescale, uint8_t -> uint8_t
+
+            const uint8_t * srcRow = &params->srcPlane[params->srcOffsetBytes];
+            uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+            for (uint32_t j = 0; j < params->height; ++j) {
+                const uint8_t * srcPixel = srcRow;
+                uint8_t * dstPixel = dstRow;
+                for (uint32_t i = 0; i < params->width; ++i) {
+                    *dstPixel = *srcPixel;
+                    srcPixel += params->srcPixelBytes;
+                    dstPixel += params->dstPixelBytes;
+                }
+                srcRow += params->srcRowBytes;
+                dstRow += params->dstRowBytes;
+            }
+        }
+    } else {
+        // depth rescale
+
+        if (params->srcDepth > 8) {
+            if (params->dstDepth > 8) {
+                // depth rescale, uint16_t -> uint16_t
+
+                const uint8_t * srcRow = &params->srcPlane[params->srcOffsetBytes];
+                uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+                for (uint32_t j = 0; j < params->height; ++j) {
+                    const uint8_t * srcPixel = srcRow;
+                    uint8_t * dstPixel = dstRow;
+                    for (uint32_t i = 0; i < params->width; ++i) {
+                        int srcAlpha = *((const uint16_t *)srcPixel);
+                        float alphaF = (float)srcAlpha / srcMaxChannelF;
+                        int dstAlpha = (int)(0.5f + (alphaF * dstMaxChannelF));
+                        dstAlpha = AVIF_CLAMP(dstAlpha, 0, dstMaxChannel);
+                        *((uint16_t *)dstPixel) = (uint16_t)dstAlpha;
+                        srcPixel += params->srcPixelBytes;
+                        dstPixel += params->dstPixelBytes;
+                    }
+                    srcRow += params->srcRowBytes;
+                    dstRow += params->dstRowBytes;
+                }
+            } else {
+                // depth rescale, uint16_t -> uint8_t
+
+                const uint8_t * srcRow = &params->srcPlane[params->srcOffsetBytes];
+                uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+                for (uint32_t j = 0; j < params->height; ++j) {
+                    const uint8_t * srcPixel = srcRow;
+                    uint8_t * dstPixel = dstRow;
+                    for (uint32_t i = 0; i < params->width; ++i) {
+                        int srcAlpha = *((const uint16_t *)srcPixel);
+                        float alphaF = (float)srcAlpha / srcMaxChannelF;
+                        int dstAlpha = (int)(0.5f + (alphaF * dstMaxChannelF));
+                        dstAlpha = AVIF_CLAMP(dstAlpha, 0, dstMaxChannel);
+                        *dstPixel = (uint8_t)dstAlpha;
+                        srcPixel += params->srcPixelBytes;
+                        dstPixel += params->dstPixelBytes;
+                    }
+                    srcRow += params->srcRowBytes;
+                    dstRow += params->dstRowBytes;
+                }
+            }
+        } else {
+            // If (srcDepth == 8), dstDepth must be >8 otherwise we'd be in the (params->srcDepth == params->dstDepth) block above.
+            assert(params->dstDepth > 8);
+
+            // depth rescale, uint8_t -> uint16_t
+            const uint8_t * srcRow = &params->srcPlane[params->srcOffsetBytes];
+            uint8_t * dstRow = &params->dstPlane[params->dstOffsetBytes];
+            for (uint32_t j = 0; j < params->height; ++j) {
+                const uint8_t * srcPixel = srcRow;
+                uint8_t * dstPixel = dstRow;
+                for (uint32_t i = 0; i < params->width; ++i) {
+                    int srcAlpha = *srcPixel;
+                    float alphaF = (float)srcAlpha / srcMaxChannelF;
+                    int dstAlpha = (int)(0.5f + (alphaF * dstMaxChannelF));
+                    dstAlpha = AVIF_CLAMP(dstAlpha, 0, dstMaxChannel);
+                    *((uint16_t *)dstPixel) = (uint16_t)dstAlpha;
+                    srcPixel += params->srcPixelBytes;
+                    dstPixel += params->dstPixelBytes;
+                }
+                srcRow += params->srcRowBytes;
+                dstRow += params->dstRowBytes;
+            }
+        }
+    }
+}
+
+avifResult avifRGBImagePremultiplyAlpha(avifRGBImage * rgb)
+{
+    // no data
+    if (!rgb->pixels || !rgb->rowBytes) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    // no alpha.
+    if (!avifRGBFormatHasAlpha(rgb->format)) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+
+    avifResult libyuvResult = avifRGBImagePremultiplyAlphaLibYUV(rgb);
+    if (libyuvResult != AVIF_RESULT_NOT_IMPLEMENTED) {
+        return libyuvResult;
+    }
+
+    assert(rgb->depth >= 8 && rgb->depth <= 16);
+
+    uint32_t max = (1 << rgb->depth) - 1;
+    float maxF = (float)max;
+
+    if (rgb->depth > 8) {
+        if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint16_t * pixel = (uint16_t *)row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint16_t a = pixel[3];
+                    if (a >= max) {
+                        // opaque is no-op
+                    } else if (a == 0) {
+                        // result must be zero
+                        pixel[0] = 0;
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                    } else {
+                        // a < maxF is always true now, so we don't need clamp here
+                        pixel[0] = (uint16_t)avifRoundf((float)pixel[0] * (float)a / maxF);
+                        pixel[1] = (uint16_t)avifRoundf((float)pixel[1] * (float)a / maxF);
+                        pixel[2] = (uint16_t)avifRoundf((float)pixel[2] * (float)a / maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        } else {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint16_t * pixel = (uint16_t *)row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint16_t a = pixel[0];
+                    if (a >= max) {
+                    } else if (a == 0) {
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                        pixel[3] = 0;
+                    } else {
+                        pixel[1] = (uint16_t)avifRoundf((float)pixel[1] * (float)a / maxF);
+                        pixel[2] = (uint16_t)avifRoundf((float)pixel[2] * (float)a / maxF);
+                        pixel[3] = (uint16_t)avifRoundf((float)pixel[3] * (float)a / maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        }
+    } else {
+        if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint8_t * pixel = row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint8_t a = pixel[3];
+                    // uint8_t can't exceed 255
+                    if (a == max) {
+                    } else if (a == 0) {
+                        pixel[0] = 0;
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                    } else {
+                        pixel[0] = (uint8_t)avifRoundf((float)pixel[0] * (float)a / maxF);
+                        pixel[1] = (uint8_t)avifRoundf((float)pixel[1] * (float)a / maxF);
+                        pixel[2] = (uint8_t)avifRoundf((float)pixel[2] * (float)a / maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        } else {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint8_t * pixel = row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint8_t a = pixel[0];
+                    if (a == max) {
+                    } else if (a == 0) {
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                        pixel[3] = 0;
+                    } else {
+                        pixel[1] = (uint8_t)avifRoundf((float)pixel[1] * (float)a / maxF);
+                        pixel[2] = (uint8_t)avifRoundf((float)pixel[2] * (float)a / maxF);
+                        pixel[3] = (uint8_t)avifRoundf((float)pixel[3] * (float)a / maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        }
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRGBImageUnpremultiplyAlpha(avifRGBImage * rgb)
+{
+    // no data
+    if (!rgb->pixels || !rgb->rowBytes) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    // no alpha.
+    if (!avifRGBFormatHasAlpha(rgb->format)) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    avifResult libyuvResult = avifRGBImageUnpremultiplyAlphaLibYUV(rgb);
+    if (libyuvResult != AVIF_RESULT_NOT_IMPLEMENTED) {
+        return libyuvResult;
+    }
+
+    assert(rgb->depth >= 8 && rgb->depth <= 16);
+
+    uint32_t max = (1 << rgb->depth) - 1;
+    float maxF = (float)max;
+
+    if (rgb->depth > 8) {
+        if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint16_t * pixel = (uint16_t *)row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint16_t a = pixel[3];
+                    if (a >= max) {
+                        // opaque is no-op
+                    } else if (a == 0) {
+                        // prevent division by zero
+                        pixel[0] = 0;
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                    } else {
+                        float c1 = avifRoundf((float)pixel[0] * maxF / (float)a);
+                        float c2 = avifRoundf((float)pixel[1] * maxF / (float)a);
+                        float c3 = avifRoundf((float)pixel[2] * maxF / (float)a);
+                        pixel[0] = (uint16_t)AVIF_MIN(c1, maxF);
+                        pixel[1] = (uint16_t)AVIF_MIN(c2, maxF);
+                        pixel[2] = (uint16_t)AVIF_MIN(c3, maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        } else {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint16_t * pixel = (uint16_t *)row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint16_t a = pixel[0];
+                    if (a >= max) {
+                    } else if (a == 0) {
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                        pixel[3] = 0;
+                    } else {
+                        float c1 = avifRoundf((float)pixel[1] * maxF / (float)a);
+                        float c2 = avifRoundf((float)pixel[2] * maxF / (float)a);
+                        float c3 = avifRoundf((float)pixel[3] * maxF / (float)a);
+                        pixel[1] = (uint16_t)AVIF_MIN(c1, maxF);
+                        pixel[2] = (uint16_t)AVIF_MIN(c2, maxF);
+                        pixel[3] = (uint16_t)AVIF_MIN(c3, maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        }
+    } else {
+        if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint8_t * pixel = row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint8_t a = pixel[3];
+                    if (a == max) {
+                    } else if (a == 0) {
+                        pixel[0] = 0;
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                    } else {
+                        float c1 = avifRoundf((float)pixel[0] * maxF / (float)a);
+                        float c2 = avifRoundf((float)pixel[1] * maxF / (float)a);
+                        float c3 = avifRoundf((float)pixel[2] * maxF / (float)a);
+                        pixel[0] = (uint8_t)AVIF_MIN(c1, maxF);
+                        pixel[1] = (uint8_t)AVIF_MIN(c2, maxF);
+                        pixel[2] = (uint8_t)AVIF_MIN(c3, maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        } else {
+            uint8_t * row = rgb->pixels;
+            for (uint32_t j = 0; j < rgb->height; ++j) {
+                uint8_t * pixel = row;
+                for (uint32_t i = 0; i < rgb->width; ++i) {
+                    uint8_t a = pixel[0];
+                    if (a == max) {
+                    } else if (a == 0) {
+                        pixel[1] = 0;
+                        pixel[2] = 0;
+                        pixel[3] = 0;
+                    } else {
+                        float c1 = avifRoundf((float)pixel[1] * maxF / (float)a);
+                        float c2 = avifRoundf((float)pixel[2] * maxF / (float)a);
+                        float c3 = avifRoundf((float)pixel[3] * maxF / (float)a);
+                        pixel[1] = (uint8_t)AVIF_MIN(c1, maxF);
+                        pixel[2] = (uint8_t)AVIF_MIN(c2, maxF);
+                        pixel[3] = (uint8_t)AVIF_MIN(c3, maxF);
+                    }
+                    pixel += 4;
+                }
+                row += rgb->rowBytes;
+            }
+        }
+    }
+
+    return AVIF_RESULT_OK;
+}
diff --git a/third_party/libavif/src/src/avif.c b/third_party/libavif/src/src/avif.c
new file mode 100644
index 0000000000..a81885800f
--- /dev/null
+++ b/third_party/libavif/src/src/avif.c
@@ -0,0 +1,1227 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <limits.h>
+#include <stdint.h>
+#include <string.h>
+
+#define STR_HELPER(x) #x
+#define STR(x) STR_HELPER(x)
+#define AVIF_VERSION_STRING (STR(AVIF_VERSION_MAJOR) "." STR(AVIF_VERSION_MINOR) "." STR(AVIF_VERSION_PATCH))
+
+const char * avifVersion(void)
+{
+    return AVIF_VERSION_STRING;
+}
+
+const char * avifPixelFormatToString(avifPixelFormat format)
+{
+    switch (format) {
+        case AVIF_PIXEL_FORMAT_YUV444:
+            return "YUV444";
+        case AVIF_PIXEL_FORMAT_YUV420:
+            return "YUV420";
+        case AVIF_PIXEL_FORMAT_YUV422:
+            return "YUV422";
+        case AVIF_PIXEL_FORMAT_YUV400:
+            return "YUV400";
+        case AVIF_PIXEL_FORMAT_NONE:
+        case AVIF_PIXEL_FORMAT_COUNT:
+        default:
+            break;
+    }
+    return "Unknown";
+}
+
+void avifGetPixelFormatInfo(avifPixelFormat format, avifPixelFormatInfo * info)
+{
+    memset(info, 0, sizeof(avifPixelFormatInfo));
+
+    switch (format) {
+        case AVIF_PIXEL_FORMAT_YUV444:
+            info->chromaShiftX = 0;
+            info->chromaShiftY = 0;
+            break;
+
+        case AVIF_PIXEL_FORMAT_YUV422:
+            info->chromaShiftX = 1;
+            info->chromaShiftY = 0;
+            break;
+
+        case AVIF_PIXEL_FORMAT_YUV420:
+            info->chromaShiftX = 1;
+            info->chromaShiftY = 1;
+            break;
+
+        case AVIF_PIXEL_FORMAT_YUV400:
+            info->monochrome = AVIF_TRUE;
+            // The nonexistent chroma is considered as subsampled in each dimension
+            // according to the AV1 specification. See sections 5.5.2 and 6.4.2.
+            info->chromaShiftX = 1;
+            info->chromaShiftY = 1;
+            break;
+
+        case AVIF_PIXEL_FORMAT_NONE:
+        case AVIF_PIXEL_FORMAT_COUNT:
+        default:
+            break;
+    }
+}
+
+const char * avifResultToString(avifResult result)
+{
+    // clang-format off
+    switch (result) {
+        case AVIF_RESULT_OK:                            return "OK";
+        case AVIF_RESULT_INVALID_FTYP:                  return "Invalid ftyp";
+        case AVIF_RESULT_NO_CONTENT:                    return "No content";
+        case AVIF_RESULT_NO_YUV_FORMAT_SELECTED:        return "No YUV format selected";
+        case AVIF_RESULT_REFORMAT_FAILED:               return "Reformat failed";
+        case AVIF_RESULT_UNSUPPORTED_DEPTH:             return "Unsupported depth";
+        case AVIF_RESULT_ENCODE_COLOR_FAILED:           return "Encoding of color planes failed";
+        case AVIF_RESULT_ENCODE_ALPHA_FAILED:           return "Encoding of alpha plane failed";
+        case AVIF_RESULT_BMFF_PARSE_FAILED:             return "BMFF parsing failed";
+        case AVIF_RESULT_MISSING_IMAGE_ITEM:            return "Missing or empty image item";
+        case AVIF_RESULT_DECODE_COLOR_FAILED:           return "Decoding of color planes failed";
+        case AVIF_RESULT_DECODE_ALPHA_FAILED:           return "Decoding of alpha plane failed";
+        case AVIF_RESULT_COLOR_ALPHA_SIZE_MISMATCH:     return "Color and alpha planes size mismatch";
+        case AVIF_RESULT_ISPE_SIZE_MISMATCH:            return "Plane sizes don't match ispe values";
+        case AVIF_RESULT_NO_CODEC_AVAILABLE:            return "No codec available";
+        case AVIF_RESULT_NO_IMAGES_REMAINING:           return "No images remaining";
+        case AVIF_RESULT_INVALID_EXIF_PAYLOAD:          return "Invalid Exif payload";
+        case AVIF_RESULT_INVALID_IMAGE_GRID:            return "Invalid image grid";
+        case AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION: return "Invalid codec-specific option";
+        case AVIF_RESULT_TRUNCATED_DATA:                return "Truncated data";
+        case AVIF_RESULT_IO_NOT_SET:                    return "IO not set";
+        case AVIF_RESULT_IO_ERROR:                      return "IO Error";
+        case AVIF_RESULT_WAITING_ON_IO:                 return "Waiting on IO";
+        case AVIF_RESULT_INVALID_ARGUMENT:              return "Invalid argument";
+        case AVIF_RESULT_NOT_IMPLEMENTED:               return "Not implemented";
+        case AVIF_RESULT_OUT_OF_MEMORY:                 return "Out of memory";
+        case AVIF_RESULT_CANNOT_CHANGE_SETTING:         return "Cannot change some setting during encoding";
+        case AVIF_RESULT_INCOMPATIBLE_IMAGE:            return "The image is incompatible with already encoded images";
+        case AVIF_RESULT_INTERNAL_ERROR:                return "Internal error";
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        case AVIF_RESULT_ENCODE_GAIN_MAP_FAILED:        return "Encoding of gain map planes failed";
+        case AVIF_RESULT_DECODE_GAIN_MAP_FAILED:        return "Decoding of gain map planes failed";
+        case AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE:     return "Invalid tone mapped image item";
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        case AVIF_RESULT_ENCODE_SAMPLE_TRANSFORM_FAILED: return "Encoding of sample transformed image failed";
+        case AVIF_RESULT_DECODE_SAMPLE_TRANSFORM_FAILED: return "Decoding of sample transformed image failed";
+#endif
+        case AVIF_RESULT_UNKNOWN_ERROR:
+        default:
+            break;
+    }
+    // clang-format on
+    return "Unknown Error";
+}
+
+const char * avifProgressiveStateToString(avifProgressiveState progressiveState)
+{
+    // clang-format off
+    switch (progressiveState) {
+        case AVIF_PROGRESSIVE_STATE_UNAVAILABLE: return "Unavailable";
+        case AVIF_PROGRESSIVE_STATE_AVAILABLE:   return "Available";
+        case AVIF_PROGRESSIVE_STATE_ACTIVE:      return "Active";
+        default:
+            break;
+    }
+    // clang-format on
+    return "Unknown";
+}
+
+void avifImageSetDefaults(avifImage * image)
+{
+    memset(image, 0, sizeof(avifImage));
+    image->yuvRange = AVIF_RANGE_FULL;
+    image->colorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;
+    image->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED;
+    image->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED;
+}
+
+avifImage * avifImageCreate(uint32_t width, uint32_t height, uint32_t depth, avifPixelFormat yuvFormat)
+{
+    // width and height are checked when actually used, for example by avifImageAllocatePlanes().
+    AVIF_CHECKERR(depth <= 16, NULL); // avifImage only supports up to 16 bits per sample. See avifImageUsesU16().
+    // Cast to silence "comparison of unsigned expression is always true" warning.
+    AVIF_CHECKERR((int)yuvFormat >= AVIF_PIXEL_FORMAT_NONE && yuvFormat < AVIF_PIXEL_FORMAT_COUNT, NULL);
+
+    avifImage * image = (avifImage *)avifAlloc(sizeof(avifImage));
+    AVIF_CHECKERR(image, NULL);
+    avifImageSetDefaults(image);
+    image->width = width;
+    image->height = height;
+    image->depth = depth;
+    image->yuvFormat = yuvFormat;
+    return image;
+}
+
+avifImage * avifImageCreateEmpty(void)
+{
+    return avifImageCreate(0, 0, 0, AVIF_PIXEL_FORMAT_NONE);
+}
+
+void avifImageCopyNoAlloc(avifImage * dstImage, const avifImage * srcImage)
+{
+    dstImage->width = srcImage->width;
+    dstImage->height = srcImage->height;
+    dstImage->depth = srcImage->depth;
+    dstImage->yuvFormat = srcImage->yuvFormat;
+    dstImage->yuvRange = srcImage->yuvRange;
+    dstImage->yuvChromaSamplePosition = srcImage->yuvChromaSamplePosition;
+    dstImage->alphaPremultiplied = srcImage->alphaPremultiplied;
+
+    dstImage->colorPrimaries = srcImage->colorPrimaries;
+    dstImage->transferCharacteristics = srcImage->transferCharacteristics;
+    dstImage->matrixCoefficients = srcImage->matrixCoefficients;
+    dstImage->clli = srcImage->clli;
+
+    dstImage->transformFlags = srcImage->transformFlags;
+    dstImage->pasp = srcImage->pasp;
+    dstImage->clap = srcImage->clap;
+    dstImage->irot = srcImage->irot;
+    dstImage->imir = srcImage->imir;
+}
+
+void avifImageCopySamples(avifImage * dstImage, const avifImage * srcImage, avifPlanesFlags planes)
+{
+    assert(srcImage->depth == dstImage->depth);
+    if (planes & AVIF_PLANES_YUV) {
+        assert(srcImage->yuvFormat == dstImage->yuvFormat);
+        // Note that there may be a mismatch between srcImage->yuvRange and dstImage->yuvRange
+        // because libavif allows for 'colr' and AV1 OBU video range values to differ.
+    }
+    const size_t bytesPerPixel = avifImageUsesU16(srcImage) ? 2 : 1;
+
+    const avifBool skipColor = !(planes & AVIF_PLANES_YUV);
+    const avifBool skipAlpha = !(planes & AVIF_PLANES_A);
+    for (int c = AVIF_CHAN_Y; c <= AVIF_CHAN_A; ++c) {
+        const avifBool alpha = c == AVIF_CHAN_A;
+        if ((skipColor && !alpha) || (skipAlpha && alpha)) {
+            continue;
+        }
+
+        const uint32_t planeWidth = avifImagePlaneWidth(srcImage, c);
+        const uint32_t planeHeight = avifImagePlaneHeight(srcImage, c);
+        const uint8_t * srcRow = avifImagePlane(srcImage, c);
+        uint8_t * dstRow = avifImagePlane(dstImage, c);
+        const uint32_t srcRowBytes = avifImagePlaneRowBytes(srcImage, c);
+        const uint32_t dstRowBytes = avifImagePlaneRowBytes(dstImage, c);
+        assert(!srcRow == !dstRow);
+        if (!srcRow) {
+            continue;
+        }
+        assert(planeWidth == avifImagePlaneWidth(dstImage, c));
+        assert(planeHeight == avifImagePlaneHeight(dstImage, c));
+
+        const size_t planeWidthBytes = planeWidth * bytesPerPixel;
+        for (uint32_t y = 0; y < planeHeight; ++y) {
+            memcpy(dstRow, srcRow, planeWidthBytes);
+            srcRow += srcRowBytes;
+            dstRow += dstRowBytes;
+        }
+    }
+}
+
+avifResult avifImageCopy(avifImage * dstImage, const avifImage * srcImage, avifPlanesFlags planes)
+{
+    avifImageFreePlanes(dstImage, AVIF_PLANES_ALL);
+    avifImageCopyNoAlloc(dstImage, srcImage);
+
+    AVIF_CHECKRES(avifImageSetProfileICC(dstImage, srcImage->icc.data, srcImage->icc.size));
+
+    AVIF_CHECKRES(avifRWDataSet(&dstImage->exif, srcImage->exif.data, srcImage->exif.size));
+    AVIF_CHECKRES(avifImageSetMetadataXMP(dstImage, srcImage->xmp.data, srcImage->xmp.size));
+
+    if ((planes & AVIF_PLANES_YUV) && srcImage->yuvPlanes[AVIF_CHAN_Y]) {
+        if ((srcImage->yuvFormat != AVIF_PIXEL_FORMAT_YUV400) &&
+            (!srcImage->yuvPlanes[AVIF_CHAN_U] || !srcImage->yuvPlanes[AVIF_CHAN_V])) {
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+        const avifResult allocationResult = avifImageAllocatePlanes(dstImage, AVIF_PLANES_YUV);
+        if (allocationResult != AVIF_RESULT_OK) {
+            return allocationResult;
+        }
+    }
+    if ((planes & AVIF_PLANES_A) && srcImage->alphaPlane) {
+        const avifResult allocationResult = avifImageAllocatePlanes(dstImage, AVIF_PLANES_A);
+        if (allocationResult != AVIF_RESULT_OK) {
+            return allocationResult;
+        }
+    }
+    avifImageCopySamples(dstImage, srcImage, planes);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (srcImage->gainMap) {
+        if (!dstImage->gainMap) {
+            dstImage->gainMap = avifGainMapCreate();
+            AVIF_CHECKERR(dstImage->gainMap, AVIF_RESULT_OUT_OF_MEMORY);
+        }
+        for (int c = 0; c < 3; ++c) {
+            dstImage->gainMap->gainMapMin[c] = srcImage->gainMap->gainMapMin[c];
+            dstImage->gainMap->gainMapMax[c] = srcImage->gainMap->gainMapMax[c];
+            dstImage->gainMap->gainMapGamma[c] = srcImage->gainMap->gainMapGamma[c];
+            dstImage->gainMap->baseOffset[c] = srcImage->gainMap->baseOffset[c];
+            dstImage->gainMap->alternateOffset[c] = srcImage->gainMap->alternateOffset[c];
+        }
+        dstImage->gainMap->baseHdrHeadroom = srcImage->gainMap->baseHdrHeadroom;
+        dstImage->gainMap->alternateHdrHeadroom = srcImage->gainMap->alternateHdrHeadroom;
+        dstImage->gainMap->useBaseColorSpace = srcImage->gainMap->useBaseColorSpace;
+        AVIF_CHECKRES(avifRWDataSet(&dstImage->gainMap->altICC, srcImage->gainMap->altICC.data, srcImage->gainMap->altICC.size));
+        dstImage->gainMap->altColorPrimaries = srcImage->gainMap->altColorPrimaries;
+        dstImage->gainMap->altTransferCharacteristics = srcImage->gainMap->altTransferCharacteristics;
+        dstImage->gainMap->altMatrixCoefficients = srcImage->gainMap->altMatrixCoefficients;
+        dstImage->gainMap->altDepth = srcImage->gainMap->altDepth;
+        dstImage->gainMap->altPlaneCount = srcImage->gainMap->altPlaneCount;
+        dstImage->gainMap->altCLLI = srcImage->gainMap->altCLLI;
+
+        if (srcImage->gainMap->image) {
+            if (!dstImage->gainMap->image) {
+                dstImage->gainMap->image = avifImageCreateEmpty();
+            }
+            AVIF_CHECKRES(avifImageCopy(dstImage->gainMap->image, srcImage->gainMap->image, planes));
+        } else if (dstImage->gainMap->image) {
+            avifImageDestroy(dstImage->gainMap->image);
+            dstImage->gainMap->image = NULL;
+        }
+    } else if (dstImage->gainMap) {
+        avifGainMapDestroy(dstImage->gainMap);
+        dstImage->gainMap = NULL;
+    }
+#endif // defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifImageSetViewRect(avifImage * dstImage, const avifImage * srcImage, const avifCropRect * rect)
+{
+    avifPixelFormatInfo formatInfo;
+    avifGetPixelFormatInfo(srcImage->yuvFormat, &formatInfo);
+    if ((rect->width > srcImage->width) || (rect->height > srcImage->height) || (rect->x > (srcImage->width - rect->width)) ||
+        (rect->y > (srcImage->height - rect->height))) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (!formatInfo.monochrome && ((rect->x & formatInfo.chromaShiftX) || (rect->y & formatInfo.chromaShiftY))) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    avifImageFreePlanes(dstImage, AVIF_PLANES_ALL); // dstImage->imageOwnsYUVPlanes and dstImage->imageOwnsAlphaPlane set to AVIF_FALSE.
+    avifImageCopyNoAlloc(dstImage, srcImage);
+    dstImage->width = rect->width;
+    dstImage->height = rect->height;
+    const uint32_t pixelBytes = (srcImage->depth > 8) ? 2 : 1;
+    if (srcImage->yuvPlanes[AVIF_CHAN_Y]) {
+        for (int yuvPlane = AVIF_CHAN_Y; yuvPlane <= AVIF_CHAN_V; ++yuvPlane) {
+            if (srcImage->yuvRowBytes[yuvPlane]) {
+                const size_t planeX = (yuvPlane == AVIF_CHAN_Y) ? rect->x : (rect->x >> formatInfo.chromaShiftX);
+                const size_t planeY = (yuvPlane == AVIF_CHAN_Y) ? rect->y : (rect->y >> formatInfo.chromaShiftY);
+                dstImage->yuvPlanes[yuvPlane] =
+                    srcImage->yuvPlanes[yuvPlane] + planeY * srcImage->yuvRowBytes[yuvPlane] + planeX * pixelBytes;
+                dstImage->yuvRowBytes[yuvPlane] = srcImage->yuvRowBytes[yuvPlane];
+            }
+        }
+    }
+    if (srcImage->alphaPlane) {
+        dstImage->alphaPlane = srcImage->alphaPlane + (size_t)rect->y * srcImage->alphaRowBytes + (size_t)rect->x * pixelBytes;
+        dstImage->alphaRowBytes = srcImage->alphaRowBytes;
+    }
+    return AVIF_RESULT_OK;
+}
+
+void avifImageDestroy(avifImage * image)
+{
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (image->gainMap) {
+        avifGainMapDestroy(image->gainMap);
+    }
+#endif
+    avifImageFreePlanes(image, AVIF_PLANES_ALL);
+    avifRWDataFree(&image->icc);
+    avifRWDataFree(&image->exif);
+    avifRWDataFree(&image->xmp);
+    avifFree(image);
+}
+
+avifResult avifImageSetProfileICC(avifImage * image, const uint8_t * icc, size_t iccSize)
+{
+    return avifRWDataSet(&image->icc, icc, iccSize);
+}
+
+avifResult avifImageSetMetadataXMP(avifImage * image, const uint8_t * xmp, size_t xmpSize)
+{
+    return avifRWDataSet(&image->xmp, xmp, xmpSize);
+}
+
+avifResult avifImageAllocatePlanes(avifImage * image, avifPlanesFlags planes)
+{
+    if (image->width == 0 || image->height == 0) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    const uint32_t channelSize = avifImageUsesU16(image) ? 2 : 1;
+    if (image->width > UINT32_MAX / channelSize) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    const uint32_t fullRowBytes = channelSize * image->width;
+    if (image->height > PTRDIFF_MAX / fullRowBytes) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    const size_t fullSize = (size_t)fullRowBytes * image->height;
+
+    if ((planes & AVIF_PLANES_YUV) && (image->yuvFormat != AVIF_PIXEL_FORMAT_NONE)) {
+        avifPixelFormatInfo info;
+        avifGetPixelFormatInfo(image->yuvFormat, &info);
+
+        image->imageOwnsYUVPlanes = AVIF_TRUE;
+        if (!image->yuvPlanes[AVIF_CHAN_Y]) {
+            image->yuvPlanes[AVIF_CHAN_Y] = (uint8_t *)avifAlloc(fullSize);
+            if (!image->yuvPlanes[AVIF_CHAN_Y]) {
+                return AVIF_RESULT_OUT_OF_MEMORY;
+            }
+            image->yuvRowBytes[AVIF_CHAN_Y] = fullRowBytes;
+        }
+
+        if (!info.monochrome) {
+            // Intermediary computation as 64 bits in case width or height is exactly UINT32_MAX.
+            const uint32_t shiftedW = (uint32_t)(((uint64_t)image->width + info.chromaShiftX) >> info.chromaShiftX);
+            const uint32_t shiftedH = (uint32_t)(((uint64_t)image->height + info.chromaShiftY) >> info.chromaShiftY);
+
+            // These are less than or equal to fullRowBytes/fullSize. No need to check overflows.
+            const uint32_t uvRowBytes = channelSize * shiftedW;
+            const size_t uvSize = (size_t)uvRowBytes * shiftedH;
+
+            for (int uvPlane = AVIF_CHAN_U; uvPlane <= AVIF_CHAN_V; ++uvPlane) {
+                if (!image->yuvPlanes[uvPlane]) {
+                    image->yuvPlanes[uvPlane] = (uint8_t *)avifAlloc(uvSize);
+                    if (!image->yuvPlanes[uvPlane]) {
+                        return AVIF_RESULT_OUT_OF_MEMORY;
+                    }
+                    image->yuvRowBytes[uvPlane] = uvRowBytes;
+                }
+            }
+        }
+    }
+    if (planes & AVIF_PLANES_A) {
+        image->imageOwnsAlphaPlane = AVIF_TRUE;
+        if (!image->alphaPlane) {
+            image->alphaPlane = (uint8_t *)avifAlloc(fullSize);
+            if (!image->alphaPlane) {
+                return AVIF_RESULT_OUT_OF_MEMORY;
+            }
+            image->alphaRowBytes = fullRowBytes;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+void avifImageFreePlanes(avifImage * image, avifPlanesFlags planes)
+{
+    if ((planes & AVIF_PLANES_YUV) && (image->yuvFormat != AVIF_PIXEL_FORMAT_NONE)) {
+        if (image->imageOwnsYUVPlanes) {
+            avifFree(image->yuvPlanes[AVIF_CHAN_Y]);
+            avifFree(image->yuvPlanes[AVIF_CHAN_U]);
+            avifFree(image->yuvPlanes[AVIF_CHAN_V]);
+        }
+        image->yuvPlanes[AVIF_CHAN_Y] = NULL;
+        image->yuvRowBytes[AVIF_CHAN_Y] = 0;
+        image->yuvPlanes[AVIF_CHAN_U] = NULL;
+        image->yuvRowBytes[AVIF_CHAN_U] = 0;
+        image->yuvPlanes[AVIF_CHAN_V] = NULL;
+        image->yuvRowBytes[AVIF_CHAN_V] = 0;
+        image->imageOwnsYUVPlanes = AVIF_FALSE;
+    }
+    if (planes & AVIF_PLANES_A) {
+        if (image->imageOwnsAlphaPlane) {
+            avifFree(image->alphaPlane);
+        }
+        image->alphaPlane = NULL;
+        image->alphaRowBytes = 0;
+        image->imageOwnsAlphaPlane = AVIF_FALSE;
+    }
+}
+
+void avifImageStealPlanes(avifImage * dstImage, avifImage * srcImage, avifPlanesFlags planes)
+{
+    avifImageFreePlanes(dstImage, planes);
+
+    if (planes & AVIF_PLANES_YUV) {
+        dstImage->yuvPlanes[AVIF_CHAN_Y] = srcImage->yuvPlanes[AVIF_CHAN_Y];
+        dstImage->yuvRowBytes[AVIF_CHAN_Y] = srcImage->yuvRowBytes[AVIF_CHAN_Y];
+        dstImage->yuvPlanes[AVIF_CHAN_U] = srcImage->yuvPlanes[AVIF_CHAN_U];
+        dstImage->yuvRowBytes[AVIF_CHAN_U] = srcImage->yuvRowBytes[AVIF_CHAN_U];
+        dstImage->yuvPlanes[AVIF_CHAN_V] = srcImage->yuvPlanes[AVIF_CHAN_V];
+        dstImage->yuvRowBytes[AVIF_CHAN_V] = srcImage->yuvRowBytes[AVIF_CHAN_V];
+
+        srcImage->yuvPlanes[AVIF_CHAN_Y] = NULL;
+        srcImage->yuvRowBytes[AVIF_CHAN_Y] = 0;
+        srcImage->yuvPlanes[AVIF_CHAN_U] = NULL;
+        srcImage->yuvRowBytes[AVIF_CHAN_U] = 0;
+        srcImage->yuvPlanes[AVIF_CHAN_V] = NULL;
+        srcImage->yuvRowBytes[AVIF_CHAN_V] = 0;
+
+        dstImage->yuvFormat = srcImage->yuvFormat;
+        dstImage->imageOwnsYUVPlanes = srcImage->imageOwnsYUVPlanes;
+        srcImage->imageOwnsYUVPlanes = AVIF_FALSE;
+    }
+    if (planes & AVIF_PLANES_A) {
+        dstImage->alphaPlane = srcImage->alphaPlane;
+        dstImage->alphaRowBytes = srcImage->alphaRowBytes;
+
+        srcImage->alphaPlane = NULL;
+        srcImage->alphaRowBytes = 0;
+
+        dstImage->imageOwnsAlphaPlane = srcImage->imageOwnsAlphaPlane;
+        srcImage->imageOwnsAlphaPlane = AVIF_FALSE;
+    }
+}
+
+avifBool avifImageUsesU16(const avifImage * image)
+{
+    return (image->depth > 8);
+}
+
+avifBool avifImageIsOpaque(const avifImage * image)
+{
+    if (!image->alphaPlane) {
+        return AVIF_TRUE;
+    }
+
+    const uint32_t opaqueValue = (1u << image->depth) - 1u;
+    const uint8_t * row = image->alphaPlane;
+    for (uint32_t y = 0; y < image->height; ++y) {
+        if (avifImageUsesU16(image)) {
+            const uint16_t * row16 = (const uint16_t *)row;
+            for (uint32_t x = 0; x < image->width; ++x) {
+                if (row16[x] != opaqueValue) {
+                    return AVIF_FALSE;
+                }
+            }
+        } else {
+            for (uint32_t x = 0; x < image->width; ++x) {
+                if (row[x] != opaqueValue) {
+                    return AVIF_FALSE;
+                }
+            }
+        }
+        row += image->alphaRowBytes;
+    }
+    return AVIF_TRUE;
+}
+
+uint8_t * avifImagePlane(const avifImage * image, int channel)
+{
+    if ((channel == AVIF_CHAN_Y) || (channel == AVIF_CHAN_U) || (channel == AVIF_CHAN_V)) {
+        return image->yuvPlanes[channel];
+    }
+    if (channel == AVIF_CHAN_A) {
+        return image->alphaPlane;
+    }
+    return NULL;
+}
+
+uint32_t avifImagePlaneRowBytes(const avifImage * image, int channel)
+{
+    if ((channel == AVIF_CHAN_Y) || (channel == AVIF_CHAN_U) || (channel == AVIF_CHAN_V)) {
+        return image->yuvRowBytes[channel];
+    }
+    if (channel == AVIF_CHAN_A) {
+        return image->alphaRowBytes;
+    }
+    return 0;
+}
+
+uint32_t avifImagePlaneWidth(const avifImage * image, int channel)
+{
+    if (channel == AVIF_CHAN_Y) {
+        return image->width;
+    }
+    if ((channel == AVIF_CHAN_U) || (channel == AVIF_CHAN_V)) {
+        avifPixelFormatInfo formatInfo;
+        avifGetPixelFormatInfo(image->yuvFormat, &formatInfo);
+        if (formatInfo.monochrome) {
+            return 0;
+        }
+        return (image->width + formatInfo.chromaShiftX) >> formatInfo.chromaShiftX;
+    }
+    if ((channel == AVIF_CHAN_A) && image->alphaPlane) {
+        return image->width;
+    }
+    return 0;
+}
+
+uint32_t avifImagePlaneHeight(const avifImage * image, int channel)
+{
+    if (channel == AVIF_CHAN_Y) {
+        return image->height;
+    }
+    if ((channel == AVIF_CHAN_U) || (channel == AVIF_CHAN_V)) {
+        avifPixelFormatInfo formatInfo;
+        avifGetPixelFormatInfo(image->yuvFormat, &formatInfo);
+        if (formatInfo.monochrome) {
+            return 0;
+        }
+        return (image->height + formatInfo.chromaShiftY) >> formatInfo.chromaShiftY;
+    }
+    if ((channel == AVIF_CHAN_A) && image->alphaPlane) {
+        return image->height;
+    }
+    return 0;
+}
+
+avifBool avifDimensionsTooLarge(uint32_t width, uint32_t height, uint32_t imageSizeLimit, uint32_t imageDimensionLimit)
+{
+    if (width > (imageSizeLimit / height)) {
+        return AVIF_TRUE;
+    }
+    if ((imageDimensionLimit != 0) && ((width > imageDimensionLimit) || (height > imageDimensionLimit))) {
+        return AVIF_TRUE;
+    }
+    return AVIF_FALSE;
+}
+
+// avifCodecCreate*() functions are in their respective codec_*.c files
+
+void avifCodecDestroy(avifCodec * codec)
+{
+    if (codec && codec->destroyInternal) {
+        codec->destroyInternal(codec);
+    }
+    avifFree(codec);
+}
+
+// ---------------------------------------------------------------------------
+// avifRGBImage
+
+avifBool avifRGBFormatHasAlpha(avifRGBFormat format)
+{
+    return (format != AVIF_RGB_FORMAT_RGB) && (format != AVIF_RGB_FORMAT_BGR) && (format != AVIF_RGB_FORMAT_RGB_565);
+}
+
+uint32_t avifRGBFormatChannelCount(avifRGBFormat format)
+{
+    return avifRGBFormatHasAlpha(format) ? 4 : 3;
+}
+
+uint32_t avifRGBImagePixelSize(const avifRGBImage * rgb)
+{
+    if (rgb->format == AVIF_RGB_FORMAT_RGB_565) {
+        return 2;
+    }
+    return avifRGBFormatChannelCount(rgb->format) * ((rgb->depth > 8) ? 2 : 1);
+}
+
+void avifRGBImageSetDefaults(avifRGBImage * rgb, const avifImage * image)
+{
+    rgb->width = image->width;
+    rgb->height = image->height;
+    rgb->depth = image->depth;
+    rgb->format = AVIF_RGB_FORMAT_RGBA;
+    rgb->chromaUpsampling = AVIF_CHROMA_UPSAMPLING_AUTOMATIC;
+    rgb->chromaDownsampling = AVIF_CHROMA_DOWNSAMPLING_AUTOMATIC;
+    rgb->avoidLibYUV = AVIF_FALSE;
+    rgb->ignoreAlpha = AVIF_FALSE;
+    rgb->pixels = NULL;
+    rgb->rowBytes = 0;
+    rgb->alphaPremultiplied = AVIF_FALSE; // Most expect RGBA output to *not* be premultiplied. Those that do can opt-in by
+                                          // setting this to match image->alphaPremultiplied or forcing this to true
+                                          // after calling avifRGBImageSetDefaults(),
+    rgb->isFloat = AVIF_FALSE;
+    rgb->maxThreads = 1;
+}
+
+avifResult avifRGBImageAllocatePixels(avifRGBImage * rgb)
+{
+    avifRGBImageFreePixels(rgb);
+    const uint32_t pixelSize = avifRGBImagePixelSize(rgb);
+    if (rgb->width > UINT32_MAX / pixelSize) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    const uint32_t rowBytes = rgb->width * pixelSize;
+    if (rgb->height > PTRDIFF_MAX / rowBytes) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    rgb->pixels = (uint8_t *)avifAlloc((size_t)rowBytes * rgb->height);
+    AVIF_CHECKERR(rgb->pixels, AVIF_RESULT_OUT_OF_MEMORY);
+    rgb->rowBytes = rowBytes;
+    return AVIF_RESULT_OK;
+}
+
+void avifRGBImageFreePixels(avifRGBImage * rgb)
+{
+    if (rgb->pixels) {
+        avifFree(rgb->pixels);
+    }
+
+    rgb->pixels = NULL;
+    rgb->rowBytes = 0;
+}
+
+// ---------------------------------------------------------------------------
+// avifCropRect
+
+static avifFraction calcCenter(int32_t dim)
+{
+    avifFraction f;
+    f.n = dim >> 1;
+    f.d = 1;
+    if ((dim % 2) != 0) {
+        f.n = dim;
+        f.d = 2;
+    }
+    return f;
+}
+
+static avifBool overflowsInt32(int64_t x)
+{
+    return (x < INT32_MIN) || (x > INT32_MAX);
+}
+
+static avifBool avifCropRectIsValid(const avifCropRect * cropRect, uint32_t imageW, uint32_t imageH, avifPixelFormat yuvFormat, avifDiagnostics * diag)
+
+{
+    // ISO/IEC 23000-22:2019/Amd. 2:2021, Section 7.3.6.7:
+    //   The clean aperture property is restricted according to the chroma
+    //   sampling format of the input image (4:4:4, 4:2:2:, 4:2:0, or 4:0:0) as
+    //   follows:
+    //   ...
+    //   - If chroma is subsampled horizontally (i.e., 4:2:2 and 4:2:0), the
+    //     leftmost pixel of the clean aperture shall be even numbers;
+    //   - If chroma is subsampled vertically (i.e., 4:2:0), the topmost line
+    //     of the clean aperture shall be even numbers.
+
+    if ((cropRect->width == 0) || (cropRect->height == 0)) {
+        avifDiagnosticsPrintf(diag, "[Strict] crop rect width and height must be nonzero");
+        return AVIF_FALSE;
+    }
+    if ((cropRect->x > (UINT32_MAX - cropRect->width)) || ((cropRect->x + cropRect->width) > imageW) ||
+        (cropRect->y > (UINT32_MAX - cropRect->height)) || ((cropRect->y + cropRect->height) > imageH)) {
+        avifDiagnosticsPrintf(diag, "[Strict] crop rect is out of the image's bounds");
+        return AVIF_FALSE;
+    }
+
+    if ((yuvFormat == AVIF_PIXEL_FORMAT_YUV420) || (yuvFormat == AVIF_PIXEL_FORMAT_YUV422)) {
+        if ((cropRect->x % 2) != 0) {
+            avifDiagnosticsPrintf(diag, "[Strict] crop rect X offset must be even due to this image's YUV subsampling");
+            return AVIF_FALSE;
+        }
+    }
+    if (yuvFormat == AVIF_PIXEL_FORMAT_YUV420) {
+        if ((cropRect->y % 2) != 0) {
+            avifDiagnosticsPrintf(diag, "[Strict] crop rect Y offset must be even due to this image's YUV subsampling");
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifCropRectConvertCleanApertureBox(avifCropRect * cropRect,
+                                             const avifCleanApertureBox * clap,
+                                             uint32_t imageW,
+                                             uint32_t imageH,
+                                             avifPixelFormat yuvFormat,
+                                             avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    // ISO/IEC 14496-12:2022, Section 12.1.4.1:
+    //   For horizOff and vertOff, D shall be strictly positive and N may be
+    //   positive or negative. For cleanApertureWidth and cleanApertureHeight,
+    //   N shall be positive and D shall be strictly positive.
+
+    const int32_t widthN = (int32_t)clap->widthN;
+    const int32_t widthD = (int32_t)clap->widthD;
+    const int32_t heightN = (int32_t)clap->heightN;
+    const int32_t heightD = (int32_t)clap->heightD;
+    const int32_t horizOffN = (int32_t)clap->horizOffN;
+    const int32_t horizOffD = (int32_t)clap->horizOffD;
+    const int32_t vertOffN = (int32_t)clap->vertOffN;
+    const int32_t vertOffD = (int32_t)clap->vertOffD;
+    if ((widthD <= 0) || (heightD <= 0) || (horizOffD <= 0) || (vertOffD <= 0)) {
+        avifDiagnosticsPrintf(diag, "[Strict] clap contains a denominator that is not strictly positive");
+        return AVIF_FALSE;
+    }
+    if ((widthN < 0) || (heightN < 0)) {
+        avifDiagnosticsPrintf(diag, "[Strict] clap width or height is negative");
+        return AVIF_FALSE;
+    }
+
+    // ISO/IEC 23000-22:2019/Amd. 2:2021, Section 7.3.6.7:
+    //   The clean aperture property is restricted according to the chroma
+    //   sampling format of the input image (4:4:4, 4:2:2:, 4:2:0, or 4:0:0) as
+    //   follows:
+    //   - cleanApertureWidth and cleanApertureHeight shall be integers;
+    //   - The leftmost pixel and the topmost line of the clean aperture as
+    //     defined in ISO/IEC 14496-12:2020, Section 12.1.4.1 shall be integers;
+    //   ...
+
+    if ((widthN % widthD) != 0) {
+        avifDiagnosticsPrintf(diag, "[Strict] clap width %d/%d is not an integer", widthN, widthD);
+        return AVIF_FALSE;
+    }
+    if ((heightN % heightD) != 0) {
+        avifDiagnosticsPrintf(diag, "[Strict] clap height %d/%d is not an integer", heightN, heightD);
+        return AVIF_FALSE;
+    }
+    const int32_t clapW = widthN / widthD;
+    const int32_t clapH = heightN / heightD;
+
+    if ((imageW > INT32_MAX) || (imageH > INT32_MAX)) {
+        avifDiagnosticsPrintf(diag, "[Strict] image width %u or height %u is greater than INT32_MAX", imageW, imageH);
+        return AVIF_FALSE;
+    }
+    avifFraction uncroppedCenterX = calcCenter((int32_t)imageW);
+    avifFraction uncroppedCenterY = calcCenter((int32_t)imageH);
+
+    avifFraction horizOff;
+    horizOff.n = horizOffN;
+    horizOff.d = horizOffD;
+    avifFraction croppedCenterX;
+    if (!avifFractionAdd(uncroppedCenterX, horizOff, &croppedCenterX)) {
+        avifDiagnosticsPrintf(diag, "[Strict] croppedCenterX overflowed");
+        return AVIF_FALSE;
+    }
+
+    avifFraction vertOff;
+    vertOff.n = vertOffN;
+    vertOff.d = vertOffD;
+    avifFraction croppedCenterY;
+    if (!avifFractionAdd(uncroppedCenterY, vertOff, &croppedCenterY)) {
+        avifDiagnosticsPrintf(diag, "[Strict] croppedCenterY overflowed");
+        return AVIF_FALSE;
+    }
+
+    avifFraction halfW;
+    halfW.n = clapW;
+    halfW.d = 2;
+    avifFraction cropX;
+    if (!avifFractionSub(croppedCenterX, halfW, &cropX)) {
+        avifDiagnosticsPrintf(diag, "[Strict] cropX overflowed");
+        return AVIF_FALSE;
+    }
+    if ((cropX.n % cropX.d) != 0) {
+        avifDiagnosticsPrintf(diag, "[Strict] calculated crop X offset %d/%d is not an integer", cropX.n, cropX.d);
+        return AVIF_FALSE;
+    }
+
+    avifFraction halfH;
+    halfH.n = clapH;
+    halfH.d = 2;
+    avifFraction cropY;
+    if (!avifFractionSub(croppedCenterY, halfH, &cropY)) {
+        avifDiagnosticsPrintf(diag, "[Strict] cropY overflowed");
+        return AVIF_FALSE;
+    }
+    if ((cropY.n % cropY.d) != 0) {
+        avifDiagnosticsPrintf(diag, "[Strict] calculated crop Y offset %d/%d is not an integer", cropY.n, cropY.d);
+        return AVIF_FALSE;
+    }
+
+    if ((cropX.n < 0) || (cropY.n < 0)) {
+        avifDiagnosticsPrintf(diag, "[Strict] at least one crop offset is not positive");
+        return AVIF_FALSE;
+    }
+
+    cropRect->x = (uint32_t)(cropX.n / cropX.d);
+    cropRect->y = (uint32_t)(cropY.n / cropY.d);
+    cropRect->width = (uint32_t)clapW;
+    cropRect->height = (uint32_t)clapH;
+    return avifCropRectIsValid(cropRect, imageW, imageH, yuvFormat, diag);
+}
+
+avifBool avifCleanApertureBoxConvertCropRect(avifCleanApertureBox * clap,
+                                             const avifCropRect * cropRect,
+                                             uint32_t imageW,
+                                             uint32_t imageH,
+                                             avifPixelFormat yuvFormat,
+                                             avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    if (!avifCropRectIsValid(cropRect, imageW, imageH, yuvFormat, diag)) {
+        return AVIF_FALSE;
+    }
+
+    if ((imageW > INT32_MAX) || (imageH > INT32_MAX)) {
+        avifDiagnosticsPrintf(diag, "[Strict] image width %u or height %u is greater than INT32_MAX", imageW, imageH);
+        return AVIF_FALSE;
+    }
+    avifFraction uncroppedCenterX = calcCenter((int32_t)imageW);
+    avifFraction uncroppedCenterY = calcCenter((int32_t)imageH);
+
+    if ((cropRect->width > INT32_MAX) || (cropRect->height > INT32_MAX)) {
+        avifDiagnosticsPrintf(diag,
+                              "[Strict] crop rect width %u or height %u is greater than INT32_MAX",
+                              cropRect->width,
+                              cropRect->height);
+        return AVIF_FALSE;
+    }
+    avifFraction croppedCenterX = calcCenter((int32_t)cropRect->width);
+    const int64_t croppedCenterXN = croppedCenterX.n + (int64_t)cropRect->x * croppedCenterX.d;
+    if (overflowsInt32(croppedCenterXN)) {
+        avifDiagnosticsPrintf(diag, "[Strict] croppedCenterX overflowed");
+        return AVIF_FALSE;
+    }
+    croppedCenterX.n = (int32_t)croppedCenterXN;
+    avifFraction croppedCenterY = calcCenter((int32_t)cropRect->height);
+    const int64_t croppedCenterYN = croppedCenterY.n + (int64_t)cropRect->y * croppedCenterY.d;
+    if (overflowsInt32(croppedCenterYN)) {
+        avifDiagnosticsPrintf(diag, "[Strict] croppedCenterY overflowed");
+        return AVIF_FALSE;
+    }
+    croppedCenterY.n = (int32_t)croppedCenterYN;
+
+    avifFraction horizOff;
+    if (!avifFractionSub(croppedCenterX, uncroppedCenterX, &horizOff)) {
+        avifDiagnosticsPrintf(diag, "[Strict] horizOff overflowed");
+        return AVIF_FALSE;
+    }
+    avifFraction vertOff;
+    if (!avifFractionSub(croppedCenterY, uncroppedCenterY, &vertOff)) {
+        avifDiagnosticsPrintf(diag, "[Strict] vertOff overflowed");
+        return AVIF_FALSE;
+    }
+
+    clap->widthN = cropRect->width;
+    clap->widthD = 1;
+    clap->heightN = cropRect->height;
+    clap->heightD = 1;
+    clap->horizOffN = horizOff.n;
+    clap->horizOffD = horizOff.d;
+    clap->vertOffN = vertOff.n;
+    clap->vertOffD = vertOff.d;
+    return AVIF_TRUE;
+}
+
+// ---------------------------------------------------------------------------
+
+avifBool avifIsAlpha(avifItemCategory itemCategory)
+{
+    if (itemCategory == AVIF_ITEM_ALPHA) {
+        return AVIF_TRUE;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (itemCategory >= AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA &&
+        itemCategory < AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA + AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS) {
+        return AVIF_TRUE;
+    }
+#endif
+    return AVIF_FALSE;
+}
+
+// ---------------------------------------------------------------------------
+
+avifBool avifAreGridDimensionsValid(avifPixelFormat yuvFormat, uint32_t imageW, uint32_t imageH, uint32_t tileW, uint32_t tileH, avifDiagnostics * diag)
+{
+    // ISO/IEC 23000-22:2019, Section 7.3.11.4.2:
+    //   - the tile_width shall be greater than or equal to 64, and should be a multiple of 64
+    //   - the tile_height shall be greater than or equal to 64, and should be a multiple of 64
+    // The "should" part is ignored here.
+    if ((tileW < 64) || (tileH < 64)) {
+        avifDiagnosticsPrintf(diag,
+                              "Grid image tile width (%u) or height (%u) cannot be smaller than 64. "
+                              "See MIAF (ISO/IEC 23000-22:2019), Section 7.3.11.4.2",
+                              tileW,
+                              tileH);
+        return AVIF_FALSE;
+    }
+
+    // ISO/IEC 23000-22:2019, Section 7.3.11.4.2:
+    //   - when the images are in the 4:2:2 chroma sampling format the horizontal tile offsets and widths,
+    //     and the output width, shall be even numbers;
+    //   - when the images are in the 4:2:0 chroma sampling format both the horizontal and vertical tile
+    //     offsets and widths, and the output width and height, shall be even numbers.
+    // If the rules above were not respected, the following problematic situation may happen:
+    //   Some 4:2:0 image is 650 pixels wide and has 10 cell columns, each being 65 pixels wide.
+    //   The chroma plane of the whole image is 325 pixels wide. The chroma plane of each cell is 33 pixels wide.
+    //   33*10 - 325 gives 5 extra pixels with no specified destination in the reconstructed image.
+
+    // Tile offsets are not enforced since they depend on tile size (ISO/IEC 23008-12:2017, Section 6.6.2.3.1):
+    //   The reconstructed image is formed by tiling the input images into a grid [...] without gap or overlap
+    if ((((yuvFormat == AVIF_PIXEL_FORMAT_YUV420) || (yuvFormat == AVIF_PIXEL_FORMAT_YUV422)) &&
+         (((imageW % 2) != 0) || ((tileW % 2) != 0))) ||
+        ((yuvFormat == AVIF_PIXEL_FORMAT_YUV420) && (((imageH % 2) != 0) || ((tileH % 2) != 0)))) {
+        avifDiagnosticsPrintf(diag,
+                              "Grid image width (%u) or height (%u) or tile width (%u) or height (%u) "
+                              "shall be even if chroma is subsampled in that dimension. "
+                              "See MIAF (ISO/IEC 23000-22:2019), Section 7.3.11.4.2",
+                              imageW,
+                              imageH,
+                              tileW,
+                              tileH);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+// ---------------------------------------------------------------------------
+// avifCodecSpecificOption
+
+// Returns NULL if a memory allocation failed.
+static char * avifStrdup(const char * str)
+{
+    size_t len = strlen(str);
+    char * dup = (char *)avifAlloc(len + 1);
+    if (!dup) {
+        return NULL;
+    }
+    memcpy(dup, str, len + 1);
+    return dup;
+}
+
+avifCodecSpecificOptions * avifCodecSpecificOptionsCreate(void)
+{
+    avifCodecSpecificOptions * ava = (avifCodecSpecificOptions *)avifAlloc(sizeof(avifCodecSpecificOptions));
+    if (!ava || !avifArrayCreate(ava, sizeof(avifCodecSpecificOption), 4)) {
+        goto error;
+    }
+    return ava;
+
+error:
+    avifFree(ava);
+    return NULL;
+}
+
+void avifCodecSpecificOptionsClear(avifCodecSpecificOptions * csOptions)
+{
+    for (uint32_t i = 0; i < csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &csOptions->entries[i];
+        avifFree(entry->key);
+        avifFree(entry->value);
+    }
+
+    csOptions->count = 0;
+}
+
+void avifCodecSpecificOptionsDestroy(avifCodecSpecificOptions * csOptions)
+{
+    avifCodecSpecificOptionsClear(csOptions);
+    avifArrayDestroy(csOptions);
+    avifFree(csOptions);
+}
+
+avifResult avifCodecSpecificOptionsSet(avifCodecSpecificOptions * csOptions, const char * key, const char * value)
+{
+    // Check to see if a key must be replaced
+    for (uint32_t i = 0; i < csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &csOptions->entries[i];
+        if (!strcmp(entry->key, key)) {
+            if (value) {
+                // Update the value
+                avifFree(entry->value);
+                entry->value = avifStrdup(value);
+                AVIF_CHECKERR(entry->value, AVIF_RESULT_OUT_OF_MEMORY);
+            } else {
+                // Delete the value
+                avifFree(entry->key);
+                avifFree(entry->value);
+                --csOptions->count;
+                if (csOptions->count > 0) {
+                    memmove(&csOptions->entries[i], &csOptions->entries[i + 1], (csOptions->count - i) * (size_t)csOptions->elementSize);
+                }
+            }
+            return AVIF_RESULT_OK;
+        }
+    }
+
+    if (value) {
+        // Add a new key
+        avifCodecSpecificOption * entry = (avifCodecSpecificOption *)avifArrayPush(csOptions);
+        AVIF_CHECKERR(entry, AVIF_RESULT_OUT_OF_MEMORY);
+        entry->key = avifStrdup(key);
+        AVIF_CHECKERR(entry->key, AVIF_RESULT_OUT_OF_MEMORY);
+        entry->value = avifStrdup(value);
+        AVIF_CHECKERR(entry->value, AVIF_RESULT_OUT_OF_MEMORY);
+    }
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+// Codec availability and versions
+
+typedef const char * (*versionFunc)(void);
+typedef avifCodec * (*avifCodecCreateFunc)(void);
+
+struct AvailableCodec
+{
+    avifCodecChoice choice;
+    avifCodecType type;
+    const char * name;
+    versionFunc version;
+    avifCodecCreateFunc create;
+    uint32_t flags;
+};
+
+// This is the main codec table; it determines all usage/availability in libavif.
+
+static struct AvailableCodec availableCodecs[] = {
+// Ordered by preference (for AUTO)
+
+#if defined(AVIF_CODEC_DAV1D)
+    { AVIF_CODEC_CHOICE_DAV1D, AVIF_CODEC_TYPE_AV1, "dav1d", avifCodecVersionDav1d, avifCodecCreateDav1d, AVIF_CODEC_FLAG_CAN_DECODE },
+#endif
+#if defined(AVIF_CODEC_LIBGAV1)
+    { AVIF_CODEC_CHOICE_LIBGAV1, AVIF_CODEC_TYPE_AV1, "libgav1", avifCodecVersionGav1, avifCodecCreateGav1, AVIF_CODEC_FLAG_CAN_DECODE },
+#endif
+#if defined(AVIF_CODEC_AOM)
+    { AVIF_CODEC_CHOICE_AOM,
+      AVIF_CODEC_TYPE_AV1,
+      "aom",
+      avifCodecVersionAOM,
+      avifCodecCreateAOM,
+#if defined(AVIF_CODEC_AOM_DECODE) && defined(AVIF_CODEC_AOM_ENCODE)
+      AVIF_CODEC_FLAG_CAN_DECODE | AVIF_CODEC_FLAG_CAN_ENCODE
+#elif defined(AVIF_CODEC_AOM_DECODE)
+      AVIF_CODEC_FLAG_CAN_DECODE
+#elif defined(AVIF_CODEC_AOM_ENCODE)
+      AVIF_CODEC_FLAG_CAN_ENCODE
+#else
+#error AVIF_CODEC_AOM_DECODE or AVIF_CODEC_AOM_ENCODE must be defined
+#endif
+    },
+#endif
+#if defined(AVIF_CODEC_RAV1E)
+    { AVIF_CODEC_CHOICE_RAV1E, AVIF_CODEC_TYPE_AV1, "rav1e", avifCodecVersionRav1e, avifCodecCreateRav1e, AVIF_CODEC_FLAG_CAN_ENCODE },
+#endif
+#if defined(AVIF_CODEC_SVT)
+    { AVIF_CODEC_CHOICE_SVT, AVIF_CODEC_TYPE_AV1, "svt", avifCodecVersionSvt, avifCodecCreateSvt, AVIF_CODEC_FLAG_CAN_ENCODE },
+#endif
+#if defined(AVIF_CODEC_AVM)
+    { AVIF_CODEC_CHOICE_AVM, AVIF_CODEC_TYPE_AV2, "avm", avifCodecVersionAVM, avifCodecCreateAVM, AVIF_CODEC_FLAG_CAN_DECODE | AVIF_CODEC_FLAG_CAN_ENCODE },
+#endif
+    { AVIF_CODEC_CHOICE_AUTO, AVIF_CODEC_TYPE_UNKNOWN, NULL, NULL, NULL, 0 }
+};
+
+static const int availableCodecsCount = (sizeof(availableCodecs) / sizeof(availableCodecs[0])) - 1;
+
+static struct AvailableCodec * findAvailableCodec(avifCodecChoice choice, avifCodecFlags requiredFlags)
+{
+    for (int i = 0; i < availableCodecsCount; ++i) {
+        if ((choice != AVIF_CODEC_CHOICE_AUTO) && (availableCodecs[i].choice != choice)) {
+            continue;
+        }
+        if (requiredFlags && ((availableCodecs[i].flags & requiredFlags) != requiredFlags)) {
+            continue;
+        }
+        if ((choice == AVIF_CODEC_CHOICE_AUTO) && (availableCodecs[i].choice == AVIF_CODEC_CHOICE_AVM)) {
+            // AV2 is experimental and cannot be the default, it must be explicitly selected.
+            continue;
+        }
+        return &availableCodecs[i];
+    }
+    return NULL;
+}
+
+const char * avifCodecName(avifCodecChoice choice, avifCodecFlags requiredFlags)
+{
+    struct AvailableCodec * availableCodec = findAvailableCodec(choice, requiredFlags);
+    if (availableCodec) {
+        return availableCodec->name;
+    }
+    return NULL;
+}
+
+avifCodecType avifCodecTypeFromChoice(avifCodecChoice choice, avifCodecFlags requiredFlags)
+{
+    struct AvailableCodec * availableCodec = findAvailableCodec(choice, requiredFlags);
+    if (availableCodec) {
+        return availableCodec->type;
+    }
+    return AVIF_CODEC_TYPE_UNKNOWN;
+}
+
+avifCodecChoice avifCodecChoiceFromName(const char * name)
+{
+    for (int i = 0; i < availableCodecsCount; ++i) {
+        if (!strcmp(availableCodecs[i].name, name)) {
+            return availableCodecs[i].choice;
+        }
+    }
+    return AVIF_CODEC_CHOICE_AUTO;
+}
+
+avifResult avifCodecCreate(avifCodecChoice choice, avifCodecFlags requiredFlags, avifCodec ** codec)
+{
+    *codec = NULL;
+    struct AvailableCodec * availableCodec = findAvailableCodec(choice, requiredFlags);
+    AVIF_CHECKERR(availableCodec != NULL, AVIF_RESULT_NO_CODEC_AVAILABLE);
+    *codec = availableCodec->create();
+    AVIF_CHECKERR(*codec != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    return AVIF_RESULT_OK;
+}
+
+static void append(char ** writePos, size_t * remainingLen, const char * appendStr)
+{
+    size_t appendLen = strlen(appendStr);
+    if (appendLen > *remainingLen) {
+        appendLen = *remainingLen;
+    }
+
+    memcpy(*writePos, appendStr, appendLen);
+    *remainingLen -= appendLen;
+    *writePos += appendLen;
+    *(*writePos) = 0;
+}
+
+void avifCodecVersions(char outBuffer[256])
+{
+    size_t remainingLen = 255;
+    char * writePos = outBuffer;
+    *writePos = 0;
+
+    for (int i = 0; i < availableCodecsCount; ++i) {
+        if (i > 0) {
+            append(&writePos, &remainingLen, ", ");
+        }
+        append(&writePos, &remainingLen, availableCodecs[i].name);
+        if ((availableCodecs[i].flags & (AVIF_CODEC_FLAG_CAN_ENCODE | AVIF_CODEC_FLAG_CAN_DECODE)) ==
+            (AVIF_CODEC_FLAG_CAN_ENCODE | AVIF_CODEC_FLAG_CAN_DECODE)) {
+            append(&writePos, &remainingLen, " [enc/dec]");
+        } else if (availableCodecs[i].flags & AVIF_CODEC_FLAG_CAN_ENCODE) {
+            append(&writePos, &remainingLen, " [enc]");
+        } else if (availableCodecs[i].flags & AVIF_CODEC_FLAG_CAN_DECODE) {
+            append(&writePos, &remainingLen, " [dec]");
+        }
+        append(&writePos, &remainingLen, ":");
+        append(&writePos, &remainingLen, availableCodecs[i].version());
+    }
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+avifGainMap * avifGainMapCreate(void)
+{
+    avifGainMap * gainMap = (avifGainMap *)avifAlloc(sizeof(avifGainMap));
+    if (!gainMap) {
+        return NULL;
+    }
+    memset(gainMap, 0, sizeof(avifGainMap));
+    gainMap->altColorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;
+    gainMap->altTransferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED;
+    gainMap->altMatrixCoefficients = AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED;
+    gainMap->altYUVRange = AVIF_RANGE_FULL;
+    gainMap->useBaseColorSpace = AVIF_TRUE;
+    // Set all denominators to valid values (1).
+    for (int i = 0; i < 3; ++i) {
+        gainMap->gainMapMin[i].d = 1;
+        gainMap->gainMapMax[i].d = 1;
+        gainMap->gainMapGamma[i].n = 1;
+        gainMap->gainMapGamma[i].d = 1;
+        gainMap->baseOffset[i].d = 1;
+        gainMap->alternateOffset[i].d = 1;
+    }
+    gainMap->baseHdrHeadroom.d = 1;
+    gainMap->alternateHdrHeadroom.d = 1;
+    return gainMap;
+}
+
+void avifGainMapDestroy(avifGainMap * gainMap)
+{
+    if (gainMap->image) {
+        avifImageDestroy(gainMap->image);
+    }
+    avifRWDataFree(&gainMap->altICC);
+    avifFree(gainMap);
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
diff --git a/third_party/libavif/src/src/codec_aom.c b/third_party/libavif/src/src/codec_aom.c
new file mode 100644
index 0000000000..396c32f40a
--- /dev/null
+++ b/third_party/libavif/src/src/codec_aom.c
@@ -0,0 +1,1247 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+// These are for libaom to deal with
+#ifdef __clang__
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wduplicate-enum"
+#pragma clang diagnostic ignored "-Wextra-semi"
+#pragma clang diagnostic ignored "-Wused-but-marked-unused"
+#endif
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+#include "aom/aom_encoder.h"
+#include "aom/aomcx.h"
+#endif
+
+#if defined(AVIF_CODEC_AOM_DECODE)
+#include "aom/aom_decoder.h"
+#include "aom/aomdx.h"
+#endif
+
+#ifdef __clang__
+#pragma clang diagnostic pop
+
+// This fixes complaints with aom_codec_control() and aom_img_fmt that are from libaom
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wused-but-marked-unused"
+#pragma clang diagnostic ignored "-Wassign-enum"
+#endif
+
+#include <assert.h>
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+// Detect whether the aom_codec_set_option() function is available. See aom/aom_codec.h
+// in https://aomedia-review.googlesource.com/c/aom/+/126302.
+#if AOM_CODEC_ABI_VERSION >= (6 + AOM_IMAGE_ABI_VERSION)
+#define HAVE_AOM_CODEC_SET_OPTION 1
+#endif
+
+// Speeds 7-9 were added to all intra mode in https://aomedia-review.googlesource.com/c/aom/+/140624.
+#if AOM_ENCODER_ABI_VERSION >= (10 + AOM_CODEC_ABI_VERSION + /*AOM_EXT_PART_ABI_VERSION=*/1)
+#define ALL_INTRA_HAS_SPEEDS_7_TO_9 1
+#endif
+#endif
+
+struct avifCodecInternal
+{
+#if defined(AVIF_CODEC_AOM_DECODE)
+    avifBool decoderInitialized;
+    aom_codec_ctx_t decoder;
+    aom_codec_iter_t iter;
+    aom_image_t * image;
+#endif
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+    avifBool encoderInitialized;
+    aom_codec_ctx_t encoder;
+    struct aom_codec_enc_cfg cfg;
+    avifPixelFormatInfo formatInfo;
+    aom_img_fmt_t aomFormat;
+    avifBool monochromeEnabled;
+    // Whether 'tuning' (of the specified distortion metric) was set with an
+    // avifEncoderSetCodecSpecificOption(encoder, "tune", value) call.
+    avifBool tuningSet;
+    uint32_t currentLayer;
+#endif
+};
+
+static void aomCodecDestroyInternal(avifCodec * codec)
+{
+#if defined(AVIF_CODEC_AOM_DECODE)
+    if (codec->internal->decoderInitialized) {
+        aom_codec_destroy(&codec->internal->decoder);
+    }
+#endif
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+    if (codec->internal->encoderInitialized) {
+        aom_codec_destroy(&codec->internal->encoder);
+    }
+#endif
+
+    avifFree(codec->internal);
+}
+
+#if defined(AVIF_CODEC_AOM_DECODE)
+
+static avifBool aomCodecGetNextImage(struct avifCodec * codec,
+                                     const avifDecodeSample * sample,
+                                     avifBool alpha,
+                                     avifBool * isLimitedRangeAlpha,
+                                     avifImage * image)
+{
+    if (!codec->internal->decoderInitialized) {
+        aom_codec_dec_cfg_t cfg;
+        memset(&cfg, 0, sizeof(aom_codec_dec_cfg_t));
+        cfg.threads = codec->maxThreads;
+        cfg.allow_lowbitdepth = 1;
+
+        aom_codec_iface_t * decoder_interface = aom_codec_av1_dx();
+        if (aom_codec_dec_init(&codec->internal->decoder, decoder_interface, &cfg, 0)) {
+            return AVIF_FALSE;
+        }
+        codec->internal->decoderInitialized = AVIF_TRUE;
+
+        if (aom_codec_control(&codec->internal->decoder, AV1D_SET_OUTPUT_ALL_LAYERS, codec->allLayers)) {
+            return AVIF_FALSE;
+        }
+        if (aom_codec_control(&codec->internal->decoder, AV1D_SET_OPERATING_POINT, codec->operatingPoint)) {
+            return AVIF_FALSE;
+        }
+
+        codec->internal->iter = NULL;
+    }
+
+    aom_image_t * nextFrame = NULL;
+    uint8_t spatialID = AVIF_SPATIAL_ID_UNSET;
+    for (;;) {
+        nextFrame = aom_codec_get_frame(&codec->internal->decoder, &codec->internal->iter);
+        if (nextFrame) {
+            if (spatialID != AVIF_SPATIAL_ID_UNSET) {
+                // This requires libaom v3.1.2 or later, which has the fix for
+                // https://crbug.com/aomedia/2993.
+                if (spatialID == nextFrame->spatial_id) {
+                    // Found the correct spatial_id.
+                    break;
+                }
+            } else {
+                // Got an image!
+                break;
+            }
+        } else if (sample) {
+            codec->internal->iter = NULL;
+            if (aom_codec_decode(&codec->internal->decoder, sample->data.data, sample->data.size, NULL)) {
+                return AVIF_FALSE;
+            }
+            spatialID = sample->spatialID;
+            sample = NULL;
+        } else {
+            break;
+        }
+    }
+
+    if (nextFrame) {
+        codec->internal->image = nextFrame;
+    } else {
+        if (alpha && codec->internal->image) {
+            // Special case: reuse last alpha frame
+        } else {
+            return AVIF_FALSE;
+        }
+    }
+
+    avifBool isColor = !alpha;
+    if (isColor) {
+        // Color (YUV) planes - set image to correct size / format, fill color
+
+        avifPixelFormat yuvFormat = AVIF_PIXEL_FORMAT_NONE;
+        switch (codec->internal->image->fmt) {
+            case AOM_IMG_FMT_I420:
+            case AOM_IMG_FMT_AOMI420:
+            case AOM_IMG_FMT_I42016:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+                break;
+            case AOM_IMG_FMT_I422:
+            case AOM_IMG_FMT_I42216:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV422;
+                break;
+            case AOM_IMG_FMT_I444:
+            case AOM_IMG_FMT_I44416:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                break;
+            case AOM_IMG_FMT_NONE:
+#if defined(AOM_HAVE_IMG_FMT_NV12)
+            // Although the libaom encoder supports the NV12 image format as an input format, the
+            // libaom decoder does not support NV12 as an output format.
+            case AOM_IMG_FMT_NV12:
+#endif
+            case AOM_IMG_FMT_YV12:
+            case AOM_IMG_FMT_AOMYV12:
+            case AOM_IMG_FMT_YV1216:
+            default:
+                return AVIF_FALSE;
+        }
+        if (codec->internal->image->monochrome) {
+            yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+        }
+
+        if (image->width && image->height) {
+            if ((image->width != codec->internal->image->d_w) || (image->height != codec->internal->image->d_h) ||
+                (image->depth != codec->internal->image->bit_depth) || (image->yuvFormat != yuvFormat)) {
+                // Throw it all out
+                avifImageFreePlanes(image, AVIF_PLANES_ALL);
+            }
+        }
+        image->width = codec->internal->image->d_w;
+        image->height = codec->internal->image->d_h;
+        image->depth = codec->internal->image->bit_depth;
+
+        image->yuvFormat = yuvFormat;
+        image->yuvRange = (codec->internal->image->range == AOM_CR_STUDIO_RANGE) ? AVIF_RANGE_LIMITED : AVIF_RANGE_FULL;
+        image->yuvChromaSamplePosition = (avifChromaSamplePosition)codec->internal->image->csp;
+
+        image->colorPrimaries = (avifColorPrimaries)codec->internal->image->cp;
+        image->transferCharacteristics = (avifTransferCharacteristics)codec->internal->image->tc;
+        image->matrixCoefficients = (avifMatrixCoefficients)codec->internal->image->mc;
+
+        // Steal the pointers from the decoder's image directly
+        avifImageFreePlanes(image, AVIF_PLANES_YUV);
+        int yuvPlaneCount = (yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+        for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+            image->yuvPlanes[yuvPlane] = codec->internal->image->planes[yuvPlane];
+            image->yuvRowBytes[yuvPlane] = codec->internal->image->stride[yuvPlane];
+        }
+        image->imageOwnsYUVPlanes = AVIF_FALSE;
+    } else {
+        // Alpha plane - ensure image is correct size, fill color
+
+        if (image->width && image->height) {
+            if ((image->width != codec->internal->image->d_w) || (image->height != codec->internal->image->d_h) ||
+                (image->depth != codec->internal->image->bit_depth)) {
+                // Alpha plane doesn't match previous alpha plane decode, bail out
+                return AVIF_FALSE;
+            }
+        }
+        image->width = codec->internal->image->d_w;
+        image->height = codec->internal->image->d_h;
+        image->depth = codec->internal->image->bit_depth;
+
+        avifImageFreePlanes(image, AVIF_PLANES_A);
+        image->alphaPlane = codec->internal->image->planes[0];
+        image->alphaRowBytes = codec->internal->image->stride[0];
+        *isLimitedRangeAlpha = (codec->internal->image->range == AOM_CR_STUDIO_RANGE);
+        image->imageOwnsAlphaPlane = AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
+#endif // defined(AVIF_CODEC_AOM_DECODE)
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+
+static aom_img_fmt_t avifImageCalcAOMFmt(const avifImage * image, avifBool alpha)
+{
+    aom_img_fmt_t fmt;
+    if (alpha) {
+        // We're going monochrome, who cares about chroma quality
+        fmt = AOM_IMG_FMT_I420;
+    } else {
+        switch (image->yuvFormat) {
+            case AVIF_PIXEL_FORMAT_YUV444:
+                fmt = AOM_IMG_FMT_I444;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV422:
+                fmt = AOM_IMG_FMT_I422;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV420:
+            case AVIF_PIXEL_FORMAT_YUV400:
+                fmt = AOM_IMG_FMT_I420;
+                break;
+            case AVIF_PIXEL_FORMAT_NONE:
+            case AVIF_PIXEL_FORMAT_COUNT:
+            default:
+                return AOM_IMG_FMT_NONE;
+        }
+    }
+
+    if (image->depth > 8) {
+        fmt |= AOM_IMG_FMT_HIGHBITDEPTH;
+    }
+
+    return fmt;
+}
+
+#if !defined(HAVE_AOM_CODEC_SET_OPTION)
+static avifBool aomOptionParseInt(const char * str, int * val)
+{
+    char * endptr;
+    const long rawval = strtol(str, &endptr, 10);
+
+    if (str[0] != '\0' && endptr[0] == '\0' && rawval >= INT_MIN && rawval <= INT_MAX) {
+        *val = (int)rawval;
+        return AVIF_TRUE;
+    }
+
+    return AVIF_FALSE;
+}
+
+static avifBool aomOptionParseUInt(const char * str, unsigned int * val)
+{
+    char * endptr;
+    const unsigned long rawval = strtoul(str, &endptr, 10);
+
+    if (str[0] != '\0' && endptr[0] == '\0' && rawval <= UINT_MAX) {
+        *val = (unsigned int)rawval;
+        return AVIF_TRUE;
+    }
+
+    return AVIF_FALSE;
+}
+#endif // !defined(HAVE_AOM_CODEC_SET_OPTION)
+
+struct aomOptionEnumList
+{
+    const char * name;
+    int val;
+};
+
+static avifBool aomOptionParseEnum(const char * str, const struct aomOptionEnumList * enums, int * val)
+{
+    const struct aomOptionEnumList * listptr;
+    long int rawval;
+    char * endptr;
+
+    // First see if the value can be parsed as a raw value.
+    rawval = strtol(str, &endptr, 10);
+    if (str[0] != '\0' && endptr[0] == '\0') {
+        // Got a raw value, make sure it's valid.
+        for (listptr = enums; listptr->name; listptr++)
+            if (listptr->val == rawval) {
+                *val = (int)rawval;
+                return AVIF_TRUE;
+            }
+    }
+
+    // Next see if it can be parsed as a string.
+    for (listptr = enums; listptr->name; listptr++) {
+        if (!strcmp(str, listptr->name)) {
+            *val = listptr->val;
+            return AVIF_TRUE;
+        }
+    }
+
+    return AVIF_FALSE;
+}
+
+static const struct aomOptionEnumList endUsageEnum[] = { //
+    { "vbr", AOM_VBR },                                  // Variable Bit Rate (VBR) mode
+    { "cbr", AOM_CBR },                                  // Constant Bit Rate (CBR) mode
+    { "cq", AOM_CQ },                                    // Constrained Quality (CQ) mode
+    { "q", AOM_Q },                                      // Constant Quality (Q) mode
+    { NULL, 0 }
+};
+
+// Returns true if <key> equals <name> or <prefix><name>, where <prefix> is "color:" or "alpha:"
+// or the abbreviated form "c:" or "a:".
+static avifBool avifKeyEqualsName(const char * key, const char * name, avifBool alpha)
+{
+    const char * prefix = alpha ? "alpha:" : "color:";
+    size_t prefixLen = 6;
+    const char * shortPrefix = alpha ? "a:" : "c:";
+    size_t shortPrefixLen = 2;
+    return !strcmp(key, name) || (!strncmp(key, prefix, prefixLen) && !strcmp(key + prefixLen, name)) ||
+           (!strncmp(key, shortPrefix, shortPrefixLen) && !strcmp(key + shortPrefixLen, name));
+}
+
+static avifBool avifProcessAOMOptionsPreInit(avifCodec * codec, avifBool alpha, struct aom_codec_enc_cfg * cfg)
+{
+    for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+        int val;
+        if (avifKeyEqualsName(entry->key, "end-usage", alpha)) { // Rate control mode
+            if (!aomOptionParseEnum(entry->value, endUsageEnum, &val)) {
+                avifDiagnosticsPrintf(codec->diag, "Invalid value for end-usage: %s", entry->value);
+                return AVIF_FALSE;
+            }
+            cfg->rc_end_usage = val;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+#if !defined(HAVE_AOM_CODEC_SET_OPTION)
+typedef enum
+{
+    AVIF_AOM_OPTION_NUL = 0,
+    AVIF_AOM_OPTION_STR,
+    AVIF_AOM_OPTION_INT,
+    AVIF_AOM_OPTION_UINT,
+    AVIF_AOM_OPTION_ENUM,
+} aomOptionType;
+
+struct aomOptionDef
+{
+    const char * name;
+    int controlId;
+    aomOptionType type;
+    // If type is AVIF_AOM_OPTION_ENUM, this must be set. Otherwise should be NULL.
+    const struct aomOptionEnumList * enums;
+};
+
+static const struct aomOptionEnumList tuningEnum[] = { //
+    { "psnr", AOM_TUNE_PSNR },                         //
+    { "ssim", AOM_TUNE_SSIM },                         //
+    { NULL, 0 }
+};
+
+static const struct aomOptionDef aomOptionDefs[] = {
+    // Adaptive quantization mode
+    { "aq-mode", AV1E_SET_AQ_MODE, AVIF_AOM_OPTION_UINT, NULL },
+    // Constant/Constrained Quality level
+    { "cq-level", AOME_SET_CQ_LEVEL, AVIF_AOM_OPTION_UINT, NULL },
+    // Enable delta quantization in chroma planes
+    { "enable-chroma-deltaq", AV1E_SET_ENABLE_CHROMA_DELTAQ, AVIF_AOM_OPTION_INT, NULL },
+    // Bias towards block sharpness in rate-distortion optimization of transform coefficients
+    { "sharpness", AOME_SET_SHARPNESS, AVIF_AOM_OPTION_UINT, NULL },
+    // Tune distortion metric
+    { "tune", AOME_SET_TUNING, AVIF_AOM_OPTION_ENUM, tuningEnum },
+    // Film grain test vector
+    { "film-grain-test", AV1E_SET_FILM_GRAIN_TEST_VECTOR, AVIF_AOM_OPTION_INT, NULL },
+    // Film grain table file
+    { "film-grain-table", AV1E_SET_FILM_GRAIN_TABLE, AVIF_AOM_OPTION_STR, NULL },
+
+    // Sentinel
+    { NULL, 0, AVIF_AOM_OPTION_NUL, NULL }
+};
+#endif // !defined(HAVE_AOM_CODEC_SET_OPTION)
+
+static avifBool avifProcessAOMOptionsPostInit(avifCodec * codec, avifBool alpha)
+{
+    for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+        // Skip options for the other kind of plane.
+        const char * otherPrefix = alpha ? "color:" : "alpha:";
+        size_t otherPrefixLen = 6;
+        const char * otherShortPrefix = alpha ? "c:" : "a:";
+        size_t otherShortPrefixLen = 2;
+        if (!strncmp(entry->key, otherPrefix, otherPrefixLen) || !strncmp(entry->key, otherShortPrefix, otherShortPrefixLen)) {
+            continue;
+        }
+
+        // Skip options processed by avifProcessAOMOptionsPreInit.
+        if (avifKeyEqualsName(entry->key, "end-usage", alpha)) {
+            continue;
+        }
+
+#if defined(HAVE_AOM_CODEC_SET_OPTION)
+        const char * prefix = alpha ? "alpha:" : "color:";
+        size_t prefixLen = 6;
+        const char * shortPrefix = alpha ? "a:" : "c:";
+        size_t shortPrefixLen = 2;
+        const char * key = entry->key;
+        if (!strncmp(key, prefix, prefixLen)) {
+            key += prefixLen;
+        } else if (!strncmp(key, shortPrefix, shortPrefixLen)) {
+            key += shortPrefixLen;
+        }
+        if (aom_codec_set_option(&codec->internal->encoder, key, entry->value) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_set_option(\"%s\", \"%s\") failed: %s: %s",
+                                  key,
+                                  entry->value,
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_FALSE;
+        }
+        if (!strcmp(key, "tune")) {
+            codec->internal->tuningSet = AVIF_TRUE;
+        }
+#else  // !defined(HAVE_AOM_CODEC_SET_OPTION)
+        avifBool match = AVIF_FALSE;
+        for (int j = 0; aomOptionDefs[j].name; ++j) {
+            if (avifKeyEqualsName(entry->key, aomOptionDefs[j].name, alpha)) {
+                match = AVIF_TRUE;
+                avifBool success = AVIF_FALSE;
+                int valInt;
+                unsigned int valUInt;
+                switch (aomOptionDefs[j].type) {
+                    case AVIF_AOM_OPTION_NUL:
+                        success = AVIF_FALSE;
+                        break;
+                    case AVIF_AOM_OPTION_STR:
+                        success = aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, entry->value) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_INT:
+                        success = aomOptionParseInt(entry->value, &valInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valInt) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_UINT:
+                        success = aomOptionParseUInt(entry->value, &valUInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valUInt) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_ENUM:
+                        success = aomOptionParseEnum(entry->value, aomOptionDefs[j].enums, &valInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valInt) == AOM_CODEC_OK;
+                        break;
+                }
+                if (!success) {
+                    return AVIF_FALSE;
+                }
+                if (aomOptionDefs[j].controlId == AOME_SET_TUNING) {
+                    codec->internal->tuningSet = AVIF_TRUE;
+                }
+                break;
+            }
+        }
+        if (!match) {
+            return AVIF_FALSE;
+        }
+#endif // defined(HAVE_AOM_CODEC_SET_OPTION)
+    }
+    return AVIF_TRUE;
+}
+
+struct aomScalingModeMapList
+{
+    avifFraction avifMode;
+    AOM_SCALING_MODE aomMode;
+};
+
+static const struct aomScalingModeMapList scalingModeMap[] = {
+    { { 1, 1 }, AOME_NORMAL },    { { 1, 2 }, AOME_ONETWO },    { { 1, 4 }, AOME_ONEFOUR },  { { 1, 8 }, AOME_ONEEIGHT },
+    { { 3, 4 }, AOME_THREEFOUR }, { { 3, 5 }, AOME_THREEFIVE }, { { 4, 5 }, AOME_FOURFIVE },
+};
+
+static const int scalingModeMapSize = sizeof(scalingModeMap) / sizeof(scalingModeMap[0]);
+
+static avifBool avifFindAOMScalingMode(const avifFraction * avifMode, AOM_SCALING_MODE * aomMode)
+{
+    avifFraction simplifiedFraction = *avifMode;
+    avifFractionSimplify(&simplifiedFraction);
+    for (int i = 0; i < scalingModeMapSize; ++i) {
+        if (scalingModeMap[i].avifMode.n == simplifiedFraction.n && scalingModeMap[i].avifMode.d == simplifiedFraction.d) {
+            *aomMode = scalingModeMap[i].aomMode;
+            return AVIF_TRUE;
+        }
+    }
+
+    return AVIF_FALSE;
+}
+
+static avifBool doesLevelMatch(int width, int height, int levelWidth, int levelHeight, int levelDimMult)
+{
+    const int64_t levelLumaPels = (int64_t)levelWidth * levelHeight;
+    const int64_t lumaPels = (int64_t)width * height;
+    return lumaPels <= levelLumaPels && width <= levelWidth * levelDimMult && height <= levelHeight * levelDimMult;
+}
+
+static avifBool aomCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output);
+
+static avifResult aomCodecEncodeImage(avifCodec * codec,
+                                      avifEncoder * encoder,
+                                      const avifImage * image,
+                                      avifBool alpha,
+                                      int tileRowsLog2,
+                                      int tileColsLog2,
+                                      int quantizer,
+                                      avifEncoderChanges encoderChanges,
+                                      avifBool disableLaggedOutput,
+                                      avifAddImageFlags addImageFlags,
+                                      avifCodecEncodeOutput * output)
+{
+    struct aom_codec_enc_cfg * cfg = &codec->internal->cfg;
+    avifBool quantizerUpdated = AVIF_FALSE;
+
+    // For encoder->scalingMode.horizontal and encoder->scalingMode.vertical to take effect in AOM
+    // encoder, config should be applied for each frame, so we don't care about changes on these
+    // two fields.
+    encoderChanges &= ~AVIF_ENCODER_CHANGE_SCALING_MODE;
+
+    if (!codec->internal->encoderInitialized) {
+        // Map encoder speed to AOM usage + CpuUsed:
+        // Speed  0: GoodQuality CpuUsed 0
+        // Speed  1: GoodQuality CpuUsed 1
+        // Speed  2: GoodQuality CpuUsed 2
+        // Speed  3: GoodQuality CpuUsed 3
+        // Speed  4: GoodQuality CpuUsed 4
+        // Speed  5: GoodQuality CpuUsed 5
+        // Speed  6: GoodQuality CpuUsed 6
+        // Speed  7: RealTime    CpuUsed 7
+        // Speed  8: RealTime    CpuUsed 8
+        // Speed  9: RealTime    CpuUsed 9
+        // Speed 10: RealTime    CpuUsed 9
+        unsigned int aomUsage = AOM_USAGE_GOOD_QUALITY;
+        // Use the new AOM_USAGE_ALL_INTRA (added in https://crbug.com/aomedia/2959) for still
+        // image encoding if it is available.
+#if defined(AOM_USAGE_ALL_INTRA)
+        if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+            aomUsage = AOM_USAGE_ALL_INTRA;
+        }
+#endif
+        int aomCpuUsed = -1;
+        if (encoder->speed != AVIF_SPEED_DEFAULT) {
+            aomCpuUsed = AVIF_CLAMP(encoder->speed, 0, 9);
+            if (aomCpuUsed >= 7) {
+#if defined(AOM_USAGE_ALL_INTRA) && defined(ALL_INTRA_HAS_SPEEDS_7_TO_9)
+                if (!(addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE)) {
+                    aomUsage = AOM_USAGE_REALTIME;
+                }
+#else
+                aomUsage = AOM_USAGE_REALTIME;
+#endif
+            }
+        }
+
+        // aom_codec.h says: aom_codec_version() == (major<<16 | minor<<8 | patch)
+        static const int aomVersion_2_0_0 = (2 << 16);
+        const int aomVersion = aom_codec_version();
+        if ((aomVersion < aomVersion_2_0_0) && (image->depth > 8)) {
+            // Due to a known issue with libaom v1.0.0-errata1-avif, 10bpc and
+            // 12bpc image encodes will call the wrong variant of
+            // aom_subtract_block when cpu-used is 7 or 8, and crash. Until we get
+            // a new tagged release from libaom with the fix and can verify we're
+            // running with that version of libaom, we must avoid using
+            // cpu-used=7/8 on any >8bpc image encodes.
+            //
+            // Context:
+            //   * https://github.com/AOMediaCodec/libavif/issues/49
+            //   * https://bugs.chromium.org/p/aomedia/issues/detail?id=2587
+            //
+            // Continued bug tracking here:
+            //   * https://github.com/AOMediaCodec/libavif/issues/56
+
+            if (aomCpuUsed > 6) {
+                aomCpuUsed = 6;
+            }
+        }
+
+        codec->internal->aomFormat = avifImageCalcAOMFmt(image, alpha);
+        if (codec->internal->aomFormat == AOM_IMG_FMT_NONE) {
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+
+        avifGetPixelFormatInfo(image->yuvFormat, &codec->internal->formatInfo);
+
+        aom_codec_iface_t * encoderInterface = aom_codec_av1_cx();
+        aom_codec_err_t err = aom_codec_enc_config_default(encoderInterface, cfg, aomUsage);
+        if (err != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag, "aom_codec_enc_config_default() failed: %s", aom_codec_err_to_string(err));
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+
+        // Set our own default cfg->rc_end_usage value, which may differ from libaom's default.
+        switch (aomUsage) {
+            case AOM_USAGE_GOOD_QUALITY:
+                // libaom's default is AOM_VBR. Change the default to AOM_Q since we don't need to
+                // hit a certain target bit rate. It's easier to control the worst quality in Q
+                // mode.
+                cfg->rc_end_usage = AOM_Q;
+                break;
+            case AOM_USAGE_REALTIME:
+                // For real-time mode we need to use CBR rate control mode. AOM_Q doesn't fit the
+                // rate control requirements for real-time mode. CBR does.
+                cfg->rc_end_usage = AOM_CBR;
+                break;
+#if defined(AOM_USAGE_ALL_INTRA)
+            case AOM_USAGE_ALL_INTRA:
+                cfg->rc_end_usage = AOM_Q;
+                break;
+#endif
+        }
+
+        // Profile 0.  8-bit and 10-bit 4:2:0 and 4:0:0 only.
+        // Profile 1.  8-bit and 10-bit 4:4:4
+        // Profile 2.  8-bit and 10-bit 4:2:2
+        //            12-bit 4:0:0, 4:2:0, 4:2:2 and 4:4:4
+        uint8_t seqProfile = 0;
+        if (image->depth == 12) {
+            // Only seqProfile 2 can handle 12 bit
+            seqProfile = 2;
+        } else {
+            // 8-bit or 10-bit
+
+            if (alpha) {
+                seqProfile = 0;
+            } else {
+                switch (image->yuvFormat) {
+                    case AVIF_PIXEL_FORMAT_YUV444:
+                        seqProfile = 1;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV422:
+                        seqProfile = 2;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV420:
+                        seqProfile = 0;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV400:
+                        seqProfile = 0;
+                        break;
+                    case AVIF_PIXEL_FORMAT_NONE:
+                    case AVIF_PIXEL_FORMAT_COUNT:
+                    default:
+                        break;
+                }
+            }
+        }
+
+        cfg->g_profile = seqProfile;
+        cfg->g_bit_depth = image->depth;
+        cfg->g_input_bit_depth = image->depth;
+        cfg->g_w = image->width;
+        cfg->g_h = image->height;
+
+        // Detect the libaom v3.6.0 bug described in
+        // https://crbug.com/aomedia/2871#c12. See the changes to
+        // av1/encoder/encoder.c in
+        // https://aomedia-review.googlesource.com/c/aom/+/174421.
+        static const int aomVersion_3_6_0 = (3 << 16) | (6 << 8);
+        if (aomVersion == aomVersion_3_6_0) {
+            // Detect the use of levels 7.x and 8.x, which use a larger max
+            // tile area (4096 * 4608) than MAX_TILE_AREA (4096 * 2304). The
+            // larger max tile area may not result in a different bitstream
+            // (see the tile_info() function in the AV1 spec, Section 5.9.15),
+            // so this is just a necessary condition for the bug.
+            if (!doesLevelMatch(image->width, image->height, 8192, 4352, 2) &&
+                (doesLevelMatch(image->width, image->height, 16384, 8704, 2) ||
+                 doesLevelMatch(image->width, image->height, 32768, 17408, 2))) {
+                avifDiagnosticsPrintf(codec->diag, "Detected libaom v3.6.0 bug with large images. Upgrade to libaom v3.6.1 or later.");
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+
+        if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+            // Set the maximum number of frames to encode to 1. This instructs
+            // libaom to set still_picture and reduced_still_picture_header to
+            // 1 in AV1 sequence headers.
+            cfg->g_limit = 1;
+
+            // Use the default settings of the new AOM_USAGE_ALL_INTRA (added in
+            // https://crbug.com/aomedia/2959).
+            //
+            // Set g_lag_in_frames to 0 to reduce the number of frame buffers
+            // (from 20 to 2) in libaom's lookahead structure. This reduces
+            // memory consumption when encoding a single image.
+            cfg->g_lag_in_frames = 0;
+            // Disable automatic placement of key frames by the encoder.
+            cfg->kf_mode = AOM_KF_DISABLED;
+            // Tell libaom that all frames will be key frames.
+            cfg->kf_max_dist = 0;
+        } else {
+            if (encoder->keyframeInterval > 0) {
+                cfg->kf_max_dist = encoder->keyframeInterval;
+            }
+        }
+        if (encoder->extraLayerCount > 0) {
+            cfg->g_limit = encoder->extraLayerCount + 1;
+            // For layered image, disable lagged encoding to always get output
+            // frame for each input frame.
+            cfg->g_lag_in_frames = 0;
+        }
+        if (disableLaggedOutput) {
+            cfg->g_lag_in_frames = 0;
+        }
+        if (encoder->maxThreads > 1) {
+            // libaom fails if cfg->g_threads is greater than 64 threads. See MAX_NUM_THREADS in
+            // aom/aom_util/aom_thread.h.
+            cfg->g_threads = AVIF_MIN(encoder->maxThreads, 64);
+        }
+
+        codec->internal->monochromeEnabled = AVIF_FALSE;
+        if (aomVersion > aomVersion_2_0_0) {
+            // There exists a bug in libaom's chroma_check() function where it will attempt to
+            // access nonexistent UV planes when encoding monochrome at faster libavif "speeds". It
+            // was fixed shortly after the 2.0.0 libaom release, and the fix exists in both the
+            // master and applejack branches. This ensures that the next version *after* 2.0.0 will
+            // have the fix, and we must avoid cfg->monochrome until then.
+            //
+            // Bugfix Change-Id: https://aomedia-review.googlesource.com/q/I26a39791f820b4d4e1d63ff7141f594c3c7181f5
+
+            if (alpha || (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400)) {
+                codec->internal->monochromeEnabled = AVIF_TRUE;
+                cfg->monochrome = 1;
+            }
+        }
+
+        if (!avifProcessAOMOptionsPreInit(codec, alpha, cfg)) {
+            return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+        }
+
+        int minQuantizer;
+        int maxQuantizer;
+        if (alpha) {
+            minQuantizer = encoder->minQuantizerAlpha;
+            maxQuantizer = encoder->maxQuantizerAlpha;
+        } else {
+            minQuantizer = encoder->minQuantizer;
+            maxQuantizer = encoder->maxQuantizer;
+        }
+        minQuantizer = AVIF_CLAMP(minQuantizer, 0, 63);
+        maxQuantizer = AVIF_CLAMP(maxQuantizer, 0, 63);
+        if ((cfg->rc_end_usage == AOM_VBR) || (cfg->rc_end_usage == AOM_CBR)) {
+            // cq-level is ignored in these two end-usage modes, so adjust minQuantizer and
+            // maxQuantizer to the target quantizer.
+            if (quantizer == AVIF_QUANTIZER_LOSSLESS) {
+                minQuantizer = AVIF_QUANTIZER_LOSSLESS;
+                maxQuantizer = AVIF_QUANTIZER_LOSSLESS;
+            } else {
+                minQuantizer = AVIF_MAX(quantizer - 4, minQuantizer);
+                maxQuantizer = AVIF_MIN(quantizer + 4, maxQuantizer);
+            }
+        }
+        cfg->rc_min_quantizer = minQuantizer;
+        cfg->rc_max_quantizer = maxQuantizer;
+        quantizerUpdated = AVIF_TRUE;
+
+        aom_codec_flags_t encoderFlags = 0;
+        if (image->depth > 8) {
+            encoderFlags |= AOM_CODEC_USE_HIGHBITDEPTH;
+        }
+        if (aom_codec_enc_init(&codec->internal->encoder, encoderInterface, cfg, encoderFlags) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_enc_init() failed: %s: %s",
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+        codec->internal->encoderInitialized = AVIF_TRUE;
+
+        if ((cfg->rc_end_usage == AOM_CQ) || (cfg->rc_end_usage == AOM_Q)) {
+            aom_codec_control(&codec->internal->encoder, AOME_SET_CQ_LEVEL, quantizer);
+        }
+        avifBool lossless = (quantizer == AVIF_QUANTIZER_LOSSLESS);
+        if (lossless) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_LOSSLESS, 1);
+        }
+        if (tileRowsLog2 != 0) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_ROWS, tileRowsLog2);
+        }
+        if (tileColsLog2 != 0) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_COLUMNS, tileColsLog2);
+        }
+        if (encoder->extraLayerCount > 0) {
+            int layerCount = encoder->extraLayerCount + 1;
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_NUMBER_SPATIAL_LAYERS, layerCount) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+        if (aomCpuUsed != -1) {
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_CPUUSED, aomCpuUsed) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+
+        // Set color_config() in the sequence header OBU.
+        if (alpha) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_RANGE, AOM_CR_FULL_RANGE);
+        } else {
+            // libaom's defaults are AOM_CICP_CP_UNSPECIFIED, AOM_CICP_TC_UNSPECIFIED,
+            // AOM_CICP_MC_UNSPECIFIED, AOM_CSP_UNKNOWN, and 0 (studio/limited range). Call
+            // aom_codec_control() only if the values are not the defaults.
+            if (image->colorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_PRIMARIES, (int)image->colorPrimaries);
+            }
+            if (image->transferCharacteristics != AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_TRANSFER_CHARACTERISTICS, (int)image->transferCharacteristics);
+            }
+            if (image->matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_MATRIX_COEFFICIENTS, (int)image->matrixCoefficients);
+            }
+            if (image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_CHROMA_SAMPLE_POSITION, (int)image->yuvChromaSamplePosition);
+            }
+            if (image->yuvRange != AVIF_RANGE_LIMITED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_RANGE, (int)image->yuvRange);
+            }
+        }
+
+#if defined(AOM_CTRL_AV1E_SET_SKIP_POSTPROC_FILTERING)
+        if (cfg->g_usage == AOM_USAGE_ALL_INTRA) {
+            // Enable AV1E_SET_SKIP_POSTPROC_FILTERING for still-picture encoding, which is
+            // disabled by default.
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_SKIP_POSTPROC_FILTERING, 1);
+        }
+#endif
+
+        if (!avifProcessAOMOptionsPostInit(codec, alpha)) {
+            return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+        }
+        if (!codec->internal->tuningSet) {
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_TUNING, AOM_TUNE_SSIM) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+    } else {
+        avifBool dimensionsChanged = AVIF_FALSE;
+        if ((cfg->g_w != image->width) || (cfg->g_h != image->height)) {
+            // We are not ready for dimension change for now.
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+        if (alpha) {
+            if (encoderChanges & (AVIF_ENCODER_CHANGE_MIN_QUANTIZER_ALPHA | AVIF_ENCODER_CHANGE_MAX_QUANTIZER_ALPHA)) {
+                cfg->rc_min_quantizer = AVIF_CLAMP(encoder->minQuantizerAlpha, 0, 63);
+                cfg->rc_max_quantizer = AVIF_CLAMP(encoder->maxQuantizerAlpha, 0, 63);
+                quantizerUpdated = AVIF_TRUE;
+            }
+        } else {
+            if (encoderChanges & (AVIF_ENCODER_CHANGE_MIN_QUANTIZER | AVIF_ENCODER_CHANGE_MAX_QUANTIZER)) {
+                cfg->rc_min_quantizer = AVIF_CLAMP(encoder->minQuantizer, 0, 63);
+                cfg->rc_max_quantizer = AVIF_CLAMP(encoder->maxQuantizer, 0, 63);
+                quantizerUpdated = AVIF_TRUE;
+            }
+        }
+        const int quantizerChangedBit = alpha ? AVIF_ENCODER_CHANGE_QUANTIZER_ALPHA : AVIF_ENCODER_CHANGE_QUANTIZER;
+        if (encoderChanges & quantizerChangedBit) {
+            if ((cfg->rc_end_usage == AOM_VBR) || (cfg->rc_end_usage == AOM_CBR)) {
+                // cq-level is ignored in these two end-usage modes, so adjust minQuantizer and
+                // maxQuantizer to the target quantizer.
+                if (quantizer == AVIF_QUANTIZER_LOSSLESS) {
+                    cfg->rc_min_quantizer = AVIF_QUANTIZER_LOSSLESS;
+                    cfg->rc_max_quantizer = AVIF_QUANTIZER_LOSSLESS;
+                } else {
+                    int minQuantizer;
+                    int maxQuantizer;
+                    if (alpha) {
+                        minQuantizer = encoder->minQuantizerAlpha;
+                        maxQuantizer = encoder->maxQuantizerAlpha;
+                    } else {
+                        minQuantizer = encoder->minQuantizer;
+                        maxQuantizer = encoder->maxQuantizer;
+                    }
+                    minQuantizer = AVIF_CLAMP(minQuantizer, 0, 63);
+                    maxQuantizer = AVIF_CLAMP(maxQuantizer, 0, 63);
+                    cfg->rc_min_quantizer = AVIF_MAX(quantizer - 4, minQuantizer);
+                    cfg->rc_max_quantizer = AVIF_MIN(quantizer + 4, maxQuantizer);
+                }
+                quantizerUpdated = AVIF_TRUE;
+            }
+        }
+        if (quantizerUpdated || dimensionsChanged) {
+            aom_codec_err_t err = aom_codec_enc_config_set(&codec->internal->encoder, cfg);
+            if (err != AOM_CODEC_OK) {
+                avifDiagnosticsPrintf(codec->diag,
+                                      "aom_codec_enc_config_set() failed: %s: %s",
+                                      aom_codec_error(&codec->internal->encoder),
+                                      aom_codec_error_detail(&codec->internal->encoder));
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_TILE_ROWS_LOG2) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_ROWS, tileRowsLog2);
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_TILE_COLS_LOG2) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_COLUMNS, tileColsLog2);
+        }
+        if (encoderChanges & quantizerChangedBit) {
+            if ((cfg->rc_end_usage == AOM_CQ) || (cfg->rc_end_usage == AOM_Q)) {
+                aom_codec_control(&codec->internal->encoder, AOME_SET_CQ_LEVEL, quantizer);
+            }
+            avifBool lossless = (quantizer == AVIF_QUANTIZER_LOSSLESS);
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_LOSSLESS, lossless);
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_CODEC_SPECIFIC) {
+            if (!avifProcessAOMOptionsPostInit(codec, alpha)) {
+                return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+            }
+        }
+    }
+
+    if (codec->internal->currentLayer > encoder->extraLayerCount) {
+        avifDiagnosticsPrintf(codec->diag,
+                              "Too many layers sent. Expected %u layers, but got %u layers.",
+                              encoder->extraLayerCount + 1,
+                              codec->internal->currentLayer + 1);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (encoder->extraLayerCount > 0) {
+        aom_codec_control(&codec->internal->encoder, AOME_SET_SPATIAL_LAYER_ID, codec->internal->currentLayer);
+    }
+
+    aom_scaling_mode_t aomScalingMode;
+    if (!avifFindAOMScalingMode(&encoder->scalingMode.horizontal, &aomScalingMode.h_scaling_mode)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (!avifFindAOMScalingMode(&encoder->scalingMode.vertical, &aomScalingMode.v_scaling_mode)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if ((aomScalingMode.h_scaling_mode != AOME_NORMAL) || (aomScalingMode.v_scaling_mode != AOME_NORMAL)) {
+        // AOME_SET_SCALEMODE only applies to next frame (layer), so we have to set it every time.
+        aom_codec_control(&codec->internal->encoder, AOME_SET_SCALEMODE, &aomScalingMode);
+    }
+
+    aom_image_t aomImage;
+    // We prefer to simply set the aomImage.planes[] pointers to the plane buffers in 'image'. When
+    // doing this, we set aomImage.w equal to aomImage.d_w and aomImage.h equal to aomImage.d_h and
+    // do not "align" aomImage.w and aomImage.h. Unfortunately this exposes a bug in libaom
+    // (https://crbug.com/aomedia/3113) if chroma is subsampled and image->width or image->height is
+    // equal to 1. To work around this libaom bug, we allocate the aomImage.planes[] buffers and
+    // copy the image YUV data if image->width or image->height is equal to 1. This bug has been
+    // fixed in libaom v3.1.3.
+    //
+    // Note: The exact condition for the bug is
+    //   ((image->width == 1) && (chroma is subsampled horizontally)) ||
+    //   ((image->height == 1) && (chroma is subsampled vertically))
+    // Since an image width or height of 1 is uncommon in practice, we test an inexact but simpler
+    // condition.
+    avifBool aomImageAllocated = (image->width == 1) || (image->height == 1);
+    if (aomImageAllocated) {
+        aom_img_alloc(&aomImage, codec->internal->aomFormat, image->width, image->height, 16);
+    } else {
+        memset(&aomImage, 0, sizeof(aomImage));
+        aomImage.fmt = codec->internal->aomFormat;
+        aomImage.bit_depth = (image->depth > 8) ? 16 : 8;
+        aomImage.w = image->width;
+        aomImage.h = image->height;
+        aomImage.d_w = image->width;
+        aomImage.d_h = image->height;
+        // Get sample size for this format.
+        unsigned int bps;
+        if (codec->internal->aomFormat == AOM_IMG_FMT_I420) {
+            bps = 12;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I422) {
+            bps = 16;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I444) {
+            bps = 24;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I42016) {
+            bps = 24;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I42216) {
+            bps = 32;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I44416) {
+            bps = 48;
+        } else {
+            bps = 16;
+        }
+        aomImage.bps = bps;
+        // See avifImageCalcAOMFmt(). libaom doesn't have AOM_IMG_FMT_I400, so we use AOM_IMG_FMT_I420 as a substitute for monochrome.
+        aomImage.x_chroma_shift = (alpha || codec->internal->formatInfo.monochrome) ? 1 : codec->internal->formatInfo.chromaShiftX;
+        aomImage.y_chroma_shift = (alpha || codec->internal->formatInfo.monochrome) ? 1 : codec->internal->formatInfo.chromaShiftY;
+    }
+
+    avifBool monochromeRequested = AVIF_FALSE;
+
+    if (alpha) {
+        aomImage.range = AOM_CR_FULL_RANGE;
+        monochromeRequested = AVIF_TRUE;
+        if (aomImageAllocated) {
+            const uint32_t bytesPerRow = ((image->depth > 8) ? 2 : 1) * image->width;
+            for (uint32_t j = 0; j < image->height; ++j) {
+                const uint8_t * srcAlphaRow = &image->alphaPlane[j * image->alphaRowBytes];
+                uint8_t * dstAlphaRow = &aomImage.planes[0][j * aomImage.stride[0]];
+                memcpy(dstAlphaRow, srcAlphaRow, bytesPerRow);
+            }
+        } else {
+            aomImage.planes[0] = image->alphaPlane;
+            aomImage.stride[0] = image->alphaRowBytes;
+        }
+
+        // Ignore UV planes when monochrome
+    } else {
+        int yuvPlaneCount = 3;
+        if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+            yuvPlaneCount = 1; // Ignore UV planes when monochrome
+            monochromeRequested = AVIF_TRUE;
+        }
+        if (aomImageAllocated) {
+            uint32_t bytesPerPixel = (image->depth > 8) ? 2 : 1;
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                uint32_t planeWidth = avifImagePlaneWidth(image, yuvPlane);
+                uint32_t planeHeight = avifImagePlaneHeight(image, yuvPlane);
+                uint32_t bytesPerRow = bytesPerPixel * planeWidth;
+
+                for (uint32_t j = 0; j < planeHeight; ++j) {
+                    const uint8_t * srcRow = &image->yuvPlanes[yuvPlane][j * image->yuvRowBytes[yuvPlane]];
+                    uint8_t * dstRow = &aomImage.planes[yuvPlane][j * aomImage.stride[yuvPlane]];
+                    memcpy(dstRow, srcRow, bytesPerRow);
+                }
+            }
+        } else {
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                aomImage.planes[yuvPlane] = image->yuvPlanes[yuvPlane];
+                aomImage.stride[yuvPlane] = image->yuvRowBytes[yuvPlane];
+            }
+        }
+
+        aomImage.cp = (aom_color_primaries_t)image->colorPrimaries;
+        aomImage.tc = (aom_transfer_characteristics_t)image->transferCharacteristics;
+        aomImage.mc = (aom_matrix_coefficients_t)image->matrixCoefficients;
+        aomImage.csp = (aom_chroma_sample_position_t)image->yuvChromaSamplePosition;
+        aomImage.range = (aom_color_range_t)image->yuvRange;
+    }
+
+    unsigned char * monoUVPlane = NULL;
+    if (monochromeRequested) {
+        if (codec->internal->monochromeEnabled) {
+            aomImage.monochrome = 1;
+        } else {
+            // The user requested monochrome (via alpha or YUV400) but libaom cannot currently support
+            // monochrome (see chroma_check comment above). Manually set UV planes to 0.5.
+
+            // aomImage is always 420 when we're monochrome
+            uint32_t monoUVWidth = (image->width + 1) >> 1;
+            uint32_t monoUVHeight = (image->height + 1) >> 1;
+
+            // Allocate the U plane if necessary.
+            if (!aomImageAllocated) {
+                uint32_t channelSize = avifImageUsesU16(image) ? 2 : 1;
+                uint32_t monoUVRowBytes = channelSize * monoUVWidth;
+                size_t monoUVSize = (size_t)monoUVHeight * monoUVRowBytes;
+
+                monoUVPlane = avifAlloc(monoUVSize);
+                AVIF_CHECKERR(monoUVPlane != NULL, AVIF_RESULT_OUT_OF_MEMORY); // No need for aom_img_free() because !aomImageAllocated
+                aomImage.planes[1] = monoUVPlane;
+                aomImage.stride[1] = monoUVRowBytes;
+            }
+            // Set the U plane to 0.5.
+            if (image->depth > 8) {
+                const uint16_t half = (uint16_t)(1 << (image->depth - 1));
+                for (uint32_t j = 0; j < monoUVHeight; ++j) {
+                    uint16_t * dstRow = (uint16_t *)&aomImage.planes[1][(size_t)j * aomImage.stride[1]];
+                    for (uint32_t i = 0; i < monoUVWidth; ++i) {
+                        dstRow[i] = half;
+                    }
+                }
+            } else {
+                const uint8_t half = 128;
+                size_t planeSize = (size_t)monoUVHeight * aomImage.stride[1];
+                memset(aomImage.planes[1], half, planeSize);
+            }
+            // Make the V plane the same as the U plane.
+            aomImage.planes[2] = aomImage.planes[1];
+            aomImage.stride[2] = aomImage.stride[1];
+        }
+    }
+
+    aom_enc_frame_flags_t encodeFlags = 0;
+    if (addImageFlags & AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME) {
+        encodeFlags |= AOM_EFLAG_FORCE_KF;
+    }
+    if (codec->internal->currentLayer > 0) {
+        encodeFlags |= AOM_EFLAG_NO_REF_GF | AOM_EFLAG_NO_REF_ARF | AOM_EFLAG_NO_REF_BWD | AOM_EFLAG_NO_REF_ARF2 |
+                       AOM_EFLAG_NO_UPD_GF | AOM_EFLAG_NO_UPD_ARF;
+    }
+    aom_codec_err_t encodeErr = aom_codec_encode(&codec->internal->encoder, &aomImage, 0, 1, encodeFlags);
+    avifFree(monoUVPlane);
+    if (aomImageAllocated) {
+        aom_img_free(&aomImage);
+    }
+    if (encodeErr != AOM_CODEC_OK) {
+        avifDiagnosticsPrintf(codec->diag,
+                              "aom_codec_encode() failed: %s: %s",
+                              aom_codec_error(&codec->internal->encoder),
+                              aom_codec_error_detail(&codec->internal->encoder));
+        return AVIF_RESULT_UNKNOWN_ERROR;
+    }
+
+    aom_codec_iter_t iter = NULL;
+    for (;;) {
+        const aom_codec_cx_pkt_t * pkt = aom_codec_get_cx_data(&codec->internal->encoder, &iter);
+        if (pkt == NULL) {
+            break;
+        }
+        if (pkt->kind == AOM_CODEC_CX_FRAME_PKT) {
+            AVIF_CHECKRES(
+                avifCodecEncodeOutputAddSample(output, pkt->data.frame.buf, pkt->data.frame.sz, (pkt->data.frame.flags & AOM_FRAME_IS_KEY)));
+        }
+    }
+
+    if ((addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) ||
+        ((encoder->extraLayerCount > 0) && (encoder->extraLayerCount == codec->internal->currentLayer))) {
+        // Flush and clean up encoder resources early to save on overhead when encoding alpha or grid images,
+        // as encoding is finished now. For layered image, encoding finishes when the last layer is encoded.
+
+        if (!aomCodecEncodeFinish(codec, output)) {
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+        aom_codec_destroy(&codec->internal->encoder);
+        codec->internal->encoderInitialized = AVIF_FALSE;
+    }
+    if (encoder->extraLayerCount > 0) {
+        ++codec->internal->currentLayer;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool aomCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output)
+{
+    if (!codec->internal->encoderInitialized) {
+        return AVIF_TRUE;
+    }
+    for (;;) {
+        // flush encoder
+        if (aom_codec_encode(&codec->internal->encoder, NULL, 0, 1, 0) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_encode() with img=NULL failed: %s: %s",
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_FALSE;
+        }
+
+        avifBool gotPacket = AVIF_FALSE;
+        aom_codec_iter_t iter = NULL;
+        for (;;) {
+            const aom_codec_cx_pkt_t * pkt = aom_codec_get_cx_data(&codec->internal->encoder, &iter);
+            if (pkt == NULL) {
+                break;
+            }
+            if (pkt->kind == AOM_CODEC_CX_FRAME_PKT) {
+                gotPacket = AVIF_TRUE;
+                const avifResult result = avifCodecEncodeOutputAddSample(output,
+                                                                         pkt->data.frame.buf,
+                                                                         pkt->data.frame.sz,
+                                                                         (pkt->data.frame.flags & AOM_FRAME_IS_KEY));
+                if (result != AVIF_RESULT_OK) {
+                    avifDiagnosticsPrintf(codec->diag, "avifCodecEncodeOutputAddSample() failed: %s", avifResultToString(result));
+                    return AVIF_FALSE;
+                }
+            }
+        }
+
+        if (!gotPacket) {
+            break;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+#endif // defined(AVIF_CODEC_AOM_ENCODE)
+
+const char * avifCodecVersionAOM(void)
+{
+    return aom_codec_version_str();
+}
+
+avifCodec * avifCodecCreateAOM(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+
+#if defined(AVIF_CODEC_AOM_DECODE)
+    codec->getNextImage = aomCodecGetNextImage;
+#endif
+
+#if defined(AVIF_CODEC_AOM_ENCODE)
+    codec->encodeImage = aomCodecEncodeImage;
+    codec->encodeFinish = aomCodecEncodeFinish;
+#endif
+
+    codec->destroyInternal = aomCodecDestroyInternal;
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(struct avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    return codec;
+}
+
+#ifdef __clang__
+#pragma clang diagnostic pop
+#endif
diff --git a/third_party/libavif/src/src/codec_avm.c b/third_party/libavif/src/src/codec_avm.c
new file mode 100644
index 0000000000..c7a29a0bf2
--- /dev/null
+++ b/third_party/libavif/src/src/codec_avm.c
@@ -0,0 +1,1111 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include "aom/aom_decoder.h"
+#include "aom/aom_encoder.h"
+#include "aom/aomcx.h"
+#include "aom/aomdx.h"
+
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+
+struct avifCodecInternal
+{
+    avifBool decoderInitialized;
+    aom_codec_ctx_t decoder;
+    aom_codec_iter_t iter;
+    aom_image_t * image;
+
+    avifBool encoderInitialized;
+    aom_codec_ctx_t encoder;
+    struct aom_codec_enc_cfg cfg;
+    avifPixelFormatInfo formatInfo;
+    aom_img_fmt_t aomFormat;
+    avifBool monochromeEnabled;
+    // Whether 'tuning' (of the specified distortion metric) was set with an
+    // avifEncoderSetCodecSpecificOption(encoder, "tune", value) call.
+    avifBool tuningSet;
+    uint32_t currentLayer;
+};
+
+static void avmCodecDestroyInternal(avifCodec * codec)
+{
+    if (codec->internal->decoderInitialized) {
+        aom_codec_destroy(&codec->internal->decoder);
+    }
+
+    if (codec->internal->encoderInitialized) {
+        aom_codec_destroy(&codec->internal->encoder);
+    }
+
+    avifFree(codec->internal);
+}
+
+static avifResult avifCheckCodecVersionAVM()
+{
+    // The minimum supported version of avm is the anchor 4.0.0.
+    // aom_codec.h says: aom_codec_version() == (major<<16 | minor<<8 | patch)
+    AVIF_CHECKERR((aom_codec_version() >> 16) >= 4, AVIF_RESULT_NO_CODEC_AVAILABLE);
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avmCodecGetNextImage(struct avifCodec * codec,
+                                     const avifDecodeSample * sample,
+                                     avifBool alpha,
+                                     avifBool * isLimitedRangeAlpha,
+                                     avifImage * image)
+{
+    if (!codec->internal->decoderInitialized) {
+        AVIF_CHECKRES(avifCheckCodecVersionAVM());
+
+        aom_codec_dec_cfg_t cfg;
+        memset(&cfg, 0, sizeof(aom_codec_dec_cfg_t));
+        cfg.threads = codec->maxThreads;
+
+        aom_codec_iface_t * decoder_interface = aom_codec_av1_dx();
+        if (aom_codec_dec_init(&codec->internal->decoder, decoder_interface, &cfg, 0)) {
+            return AVIF_FALSE;
+        }
+        codec->internal->decoderInitialized = AVIF_TRUE;
+
+        if (aom_codec_control(&codec->internal->decoder, AV1D_SET_OUTPUT_ALL_LAYERS, codec->allLayers)) {
+            return AVIF_FALSE;
+        }
+        if (aom_codec_control(&codec->internal->decoder, AV1D_SET_OPERATING_POINT, codec->operatingPoint)) {
+            return AVIF_FALSE;
+        }
+
+        codec->internal->iter = NULL;
+    }
+
+    aom_image_t * nextFrame = NULL;
+    uint8_t spatialID = AVIF_SPATIAL_ID_UNSET;
+    for (;;) {
+        nextFrame = aom_codec_get_frame(&codec->internal->decoder, &codec->internal->iter);
+        if (nextFrame) {
+            if (spatialID != AVIF_SPATIAL_ID_UNSET) {
+                if (spatialID == nextFrame->spatial_id) {
+                    // Found the correct spatial_id.
+                    break;
+                }
+            } else {
+                // Got an image!
+                break;
+            }
+        } else if (sample) {
+            codec->internal->iter = NULL;
+            if (aom_codec_decode(&codec->internal->decoder, sample->data.data, sample->data.size, NULL)) {
+                return AVIF_FALSE;
+            }
+            spatialID = sample->spatialID;
+            sample = NULL;
+        } else {
+            break;
+        }
+    }
+
+    if (nextFrame) {
+        codec->internal->image = nextFrame;
+    } else {
+        if (alpha && codec->internal->image) {
+            // Special case: reuse last alpha frame
+        } else {
+            return AVIF_FALSE;
+        }
+    }
+
+    avifBool isColor = !alpha;
+    if (isColor) {
+        // Color (YUV) planes - set image to correct size / format, fill color
+
+        avifPixelFormat yuvFormat = AVIF_PIXEL_FORMAT_NONE;
+        switch (codec->internal->image->fmt) {
+            case AOM_IMG_FMT_I420:
+            case AOM_IMG_FMT_AOMI420:
+            case AOM_IMG_FMT_I42016:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+                break;
+            case AOM_IMG_FMT_I422:
+            case AOM_IMG_FMT_I42216:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV422;
+                break;
+            case AOM_IMG_FMT_I444:
+            case AOM_IMG_FMT_I44416:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                break;
+            case AOM_IMG_FMT_NONE:
+            case AOM_IMG_FMT_YV12:
+            case AOM_IMG_FMT_AOMYV12:
+            case AOM_IMG_FMT_YV1216:
+            default:
+                return AVIF_FALSE;
+        }
+        if (codec->internal->image->monochrome) {
+            // avm does not handle monochrome as of research-v8.0.0.
+            // This should not happen.
+            yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+        }
+
+        if (image->width && image->height) {
+            if ((image->width != codec->internal->image->d_w) || (image->height != codec->internal->image->d_h) ||
+                (image->depth != codec->internal->image->bit_depth) || (image->yuvFormat != yuvFormat)) {
+                // Throw it all out
+                avifImageFreePlanes(image, AVIF_PLANES_ALL);
+            }
+        }
+        image->width = codec->internal->image->d_w;
+        image->height = codec->internal->image->d_h;
+        image->depth = codec->internal->image->bit_depth;
+
+        image->yuvFormat = yuvFormat;
+        image->yuvRange = (codec->internal->image->range == AOM_CR_STUDIO_RANGE) ? AVIF_RANGE_LIMITED : AVIF_RANGE_FULL;
+        image->yuvChromaSamplePosition = (avifChromaSamplePosition)codec->internal->image->csp;
+
+        image->colorPrimaries = (avifColorPrimaries)codec->internal->image->cp;
+        image->transferCharacteristics = (avifTransferCharacteristics)codec->internal->image->tc;
+        image->matrixCoefficients = (avifMatrixCoefficients)codec->internal->image->mc;
+
+        avifImageFreePlanes(image, AVIF_PLANES_YUV);
+        int yuvPlaneCount = (yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+
+        // avifImage assumes that a depth of 8 bits means an 8-bit buffer.
+        // aom_image does not. The buffer depth depends on fmt|AOM_IMG_FMT_HIGHBITDEPTH, even for 8-bit values.
+        if (!avifImageUsesU16(image) && (codec->internal->image->fmt & AOM_IMG_FMT_HIGHBITDEPTH)) {
+            AVIF_CHECK(avifImageAllocatePlanes(image, AVIF_PLANES_YUV) == AVIF_RESULT_OK);
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                const uint32_t planeWidth = avifImagePlaneWidth(image, yuvPlane);
+                const uint32_t planeHeight = avifImagePlaneHeight(image, yuvPlane);
+                const uint8_t * srcRow = codec->internal->image->planes[yuvPlane];
+                uint8_t * dstRow = avifImagePlane(image, yuvPlane);
+                const uint32_t dstRowBytes = avifImagePlaneRowBytes(image, yuvPlane);
+                for (uint32_t y = 0; y < planeHeight; ++y) {
+                    const uint16_t * srcRow16 = (const uint16_t *)srcRow;
+                    for (uint32_t x = 0; x < planeWidth; ++x) {
+                        dstRow[x] = (uint8_t)srcRow16[x];
+                    }
+                    srcRow += codec->internal->image->stride[yuvPlane];
+                    dstRow += dstRowBytes;
+                }
+            }
+        } else {
+            // Steal the pointers from the decoder's image directly
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                image->yuvPlanes[yuvPlane] = codec->internal->image->planes[yuvPlane];
+                image->yuvRowBytes[yuvPlane] = codec->internal->image->stride[yuvPlane];
+            }
+            image->imageOwnsYUVPlanes = AVIF_FALSE;
+        }
+    } else {
+        // Alpha plane - ensure image is correct size, fill color
+
+        if (image->width && image->height) {
+            if ((image->width != codec->internal->image->d_w) || (image->height != codec->internal->image->d_h) ||
+                (image->depth != codec->internal->image->bit_depth)) {
+                // Alpha plane doesn't match previous alpha plane decode, bail out
+                return AVIF_FALSE;
+            }
+        }
+        image->width = codec->internal->image->d_w;
+        image->height = codec->internal->image->d_h;
+        image->depth = codec->internal->image->bit_depth;
+
+        avifImageFreePlanes(image, AVIF_PLANES_A);
+
+        if (!avifImageUsesU16(image) && (codec->internal->image->fmt & AOM_IMG_FMT_HIGHBITDEPTH)) {
+            AVIF_CHECK(avifImageAllocatePlanes(image, AVIF_PLANES_A) == AVIF_RESULT_OK);
+            const uint8_t * srcRow = codec->internal->image->planes[0];
+            uint8_t * dstRow = image->alphaPlane;
+            for (uint32_t y = 0; y < image->height; ++y) {
+                const uint16_t * srcRow16 = (const uint16_t *)srcRow;
+                for (uint32_t x = 0; x < image->width; ++x) {
+                    dstRow[x] = (uint8_t)srcRow16[x];
+                }
+                srcRow += codec->internal->image->stride[0];
+                dstRow += image->alphaRowBytes;
+            }
+        } else {
+            image->alphaPlane = codec->internal->image->planes[0];
+            image->alphaRowBytes = codec->internal->image->stride[0];
+            image->imageOwnsAlphaPlane = AVIF_FALSE;
+        }
+        *isLimitedRangeAlpha = (codec->internal->image->range == AOM_CR_STUDIO_RANGE);
+    }
+
+    return AVIF_TRUE;
+}
+
+static aom_img_fmt_t avifImageCalcAOMFmt(const avifImage * image, avifBool alpha)
+{
+    aom_img_fmt_t fmt;
+    if (alpha) {
+        // We're going monochrome, who cares about chroma quality
+        fmt = AOM_IMG_FMT_I420;
+    } else {
+        switch (image->yuvFormat) {
+            case AVIF_PIXEL_FORMAT_YUV444:
+                fmt = AOM_IMG_FMT_I444;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV422:
+                fmt = AOM_IMG_FMT_I422;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV420:
+            case AVIF_PIXEL_FORMAT_YUV400:
+                fmt = AOM_IMG_FMT_I420;
+                break;
+            case AVIF_PIXEL_FORMAT_NONE:
+            case AVIF_PIXEL_FORMAT_COUNT:
+            default:
+                return AOM_IMG_FMT_NONE;
+        }
+    }
+
+    if (image->depth > 8) {
+        fmt |= AOM_IMG_FMT_HIGHBITDEPTH;
+    }
+
+    return fmt;
+}
+
+static avifBool aomOptionParseInt(const char * str, int * val)
+{
+    char * endptr;
+    const long rawval = strtol(str, &endptr, 10);
+
+    if (str[0] != '\0' && endptr[0] == '\0' && rawval >= INT_MIN && rawval <= INT_MAX) {
+        *val = (int)rawval;
+        return AVIF_TRUE;
+    }
+
+    return AVIF_FALSE;
+}
+
+static avifBool aomOptionParseUInt(const char * str, unsigned int * val)
+{
+    char * endptr;
+    const unsigned long rawval = strtoul(str, &endptr, 10);
+
+    if (str[0] != '\0' && endptr[0] == '\0' && rawval <= UINT_MAX) {
+        *val = (unsigned int)rawval;
+        return AVIF_TRUE;
+    }
+
+    return AVIF_FALSE;
+}
+
+struct aomOptionEnumList
+{
+    const char * name;
+    int val;
+};
+
+static avifBool aomOptionParseEnum(const char * str, const struct aomOptionEnumList * enums, int * val)
+{
+    const struct aomOptionEnumList * listptr;
+    long int rawval;
+    char * endptr;
+
+    // First see if the value can be parsed as a raw value.
+    rawval = strtol(str, &endptr, 10);
+    if (str[0] != '\0' && endptr[0] == '\0') {
+        // Got a raw value, make sure it's valid.
+        for (listptr = enums; listptr->name; listptr++)
+            if (listptr->val == rawval) {
+                *val = (int)rawval;
+                return AVIF_TRUE;
+            }
+    }
+
+    // Next see if it can be parsed as a string.
+    for (listptr = enums; listptr->name; listptr++) {
+        if (!strcmp(str, listptr->name)) {
+            *val = listptr->val;
+            return AVIF_TRUE;
+        }
+    }
+
+    return AVIF_FALSE;
+}
+
+static const struct aomOptionEnumList endUsageEnum[] = { //
+    { "vbr", AOM_VBR },                                  // Variable Bit Rate (VBR) mode
+    { "cbr", AOM_CBR },                                  // Constant Bit Rate (CBR) mode
+    { "cq", AOM_CQ },                                    // Constrained Quality (CQ) mode
+    { "q", AOM_Q },                                      // Constant Quality (Q) mode
+    { NULL, 0 }
+};
+
+// Returns true if <key> equals <name> or <prefix><name>, where <prefix> is "color:" or "alpha:"
+// or the abbreviated form "c:" or "a:".
+static avifBool avifKeyEqualsName(const char * key, const char * name, avifBool alpha)
+{
+    const char * prefix = alpha ? "alpha:" : "color:";
+    size_t prefixLen = 6;
+    const char * shortPrefix = alpha ? "a:" : "c:";
+    size_t shortPrefixLen = 2;
+    return !strcmp(key, name) || (!strncmp(key, prefix, prefixLen) && !strcmp(key + prefixLen, name)) ||
+           (!strncmp(key, shortPrefix, shortPrefixLen) && !strcmp(key + shortPrefixLen, name));
+}
+
+static avifBool avifProcessAOMOptionsPreInit(avifCodec * codec, avifBool alpha, struct aom_codec_enc_cfg * cfg)
+{
+    for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+        int val;
+        if (avifKeyEqualsName(entry->key, "end-usage", alpha)) { // Rate control mode
+            if (!aomOptionParseEnum(entry->value, endUsageEnum, &val)) {
+                avifDiagnosticsPrintf(codec->diag, "Invalid value for end-usage: %s", entry->value);
+                return AVIF_FALSE;
+            }
+            cfg->rc_end_usage = val;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+typedef enum
+{
+    AVIF_AOM_OPTION_NUL = 0,
+    AVIF_AOM_OPTION_STR,
+    AVIF_AOM_OPTION_INT,
+    AVIF_AOM_OPTION_UINT,
+    AVIF_AOM_OPTION_ENUM,
+} aomOptionType;
+
+struct aomOptionDef
+{
+    const char * name;
+    int controlId;
+    aomOptionType type;
+    // If type is AVIF_AOM_OPTION_ENUM, this must be set. Otherwise should be NULL.
+    const struct aomOptionEnumList * enums;
+};
+
+static const struct aomOptionEnumList tuningEnum[] = { //
+    { "psnr", AOM_TUNE_PSNR },                         //
+    { "ssim", AOM_TUNE_SSIM },                         //
+    { NULL, 0 }
+};
+
+static const struct aomOptionDef aomOptionDefs[] = {
+    // Adaptive quantization mode
+    { "aq-mode", AV1E_SET_AQ_MODE, AVIF_AOM_OPTION_UINT, NULL },
+    // Constant/Constrained Quality level
+    { "qp-level", AOME_SET_QP, AVIF_AOM_OPTION_UINT, NULL },
+    // Enable delta quantization in chroma planes
+    { "enable-chroma-deltaq", AV1E_SET_ENABLE_CHROMA_DELTAQ, AVIF_AOM_OPTION_INT, NULL },
+    // Bias towards block sharpness in rate-distortion optimization of transform coefficients
+    { "sharpness", AOME_SET_SHARPNESS, AVIF_AOM_OPTION_UINT, NULL },
+    // Tune distortion metric
+    { "tune", AOME_SET_TUNING, AVIF_AOM_OPTION_ENUM, tuningEnum },
+    // Film grain test vector
+    { "film-grain-test", AV1E_SET_FILM_GRAIN_TEST_VECTOR, AVIF_AOM_OPTION_INT, NULL },
+    // Film grain table file
+    { "film-grain-table", AV1E_SET_FILM_GRAIN_TABLE, AVIF_AOM_OPTION_STR, NULL },
+
+    // Sentinel
+    { NULL, 0, AVIF_AOM_OPTION_NUL, NULL }
+};
+
+static avifBool avifProcessAOMOptionsPostInit(avifCodec * codec, avifBool alpha)
+{
+    for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+        avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+        // Skip options for the other kind of plane.
+        const char * otherPrefix = alpha ? "color:" : "alpha:";
+        size_t otherPrefixLen = 6;
+        const char * otherShortPrefix = alpha ? "c:" : "a:";
+        size_t otherShortPrefixLen = 2;
+        if (!strncmp(entry->key, otherPrefix, otherPrefixLen) || !strncmp(entry->key, otherShortPrefix, otherShortPrefixLen)) {
+            continue;
+        }
+
+        // Skip options processed by avifProcessAOMOptionsPreInit.
+        if (avifKeyEqualsName(entry->key, "end-usage", alpha)) {
+            continue;
+        }
+
+        const char * prefix = alpha ? "alpha:" : "color:";
+        size_t prefixLen = 6;
+        const char * shortPrefix = alpha ? "a:" : "c:";
+        size_t shortPrefixLen = 2;
+        const char * key = entry->key;
+        if (!strncmp(key, prefix, prefixLen)) {
+            key += prefixLen;
+        } else if (!strncmp(key, shortPrefix, shortPrefixLen)) {
+            key += shortPrefixLen;
+        }
+        if (aom_codec_set_option(&codec->internal->encoder, key, entry->value) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_set_option(\"%s\", \"%s\") failed: %s: %s",
+                                  key,
+                                  entry->value,
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_FALSE;
+        }
+        if (!strcmp(key, "tune")) {
+            codec->internal->tuningSet = AVIF_TRUE;
+        }
+
+        avifBool match = AVIF_FALSE;
+        for (int j = 0; aomOptionDefs[j].name; ++j) {
+            if (avifKeyEqualsName(entry->key, aomOptionDefs[j].name, alpha)) {
+                match = AVIF_TRUE;
+                avifBool success = AVIF_FALSE;
+                int valInt;
+                unsigned int valUInt;
+                switch (aomOptionDefs[j].type) {
+                    case AVIF_AOM_OPTION_NUL:
+                        success = AVIF_FALSE;
+                        break;
+                    case AVIF_AOM_OPTION_STR:
+                        success = aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, entry->value) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_INT:
+                        success = aomOptionParseInt(entry->value, &valInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valInt) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_UINT:
+                        success = aomOptionParseUInt(entry->value, &valUInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valUInt) == AOM_CODEC_OK;
+                        break;
+                    case AVIF_AOM_OPTION_ENUM:
+                        success = aomOptionParseEnum(entry->value, aomOptionDefs[j].enums, &valInt) &&
+                                  aom_codec_control(&codec->internal->encoder, aomOptionDefs[j].controlId, valInt) == AOM_CODEC_OK;
+                        break;
+                }
+                if (!success) {
+                    return AVIF_FALSE;
+                }
+                if (aomOptionDefs[j].controlId == AOME_SET_TUNING) {
+                    codec->internal->tuningSet = AVIF_TRUE;
+                }
+                break;
+            }
+        }
+        if (!match) {
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+struct aomScalingModeMapList
+{
+    avifFraction avifMode;
+    AOM_SCALING_MODE aomMode;
+};
+
+static const struct aomScalingModeMapList scalingModeMap[] = {
+    { { 1, 1 }, AOME_NORMAL },    { { 1, 2 }, AOME_ONETWO },    { { 1, 4 }, AOME_ONEFOUR },  { { 1, 8 }, AOME_ONEEIGHT },
+    { { 3, 4 }, AOME_THREEFOUR }, { { 3, 5 }, AOME_THREEFIVE }, { { 4, 5 }, AOME_FOURFIVE },
+};
+
+static const int scalingModeMapSize = sizeof(scalingModeMap) / sizeof(scalingModeMap[0]);
+
+static avifBool avifFindAOMScalingMode(const avifFraction * avifMode, AOM_SCALING_MODE * aomMode)
+{
+    avifFraction simplifiedFraction = *avifMode;
+    avifFractionSimplify(&simplifiedFraction);
+    for (int i = 0; i < scalingModeMapSize; ++i) {
+        if (scalingModeMap[i].avifMode.n == simplifiedFraction.n && scalingModeMap[i].avifMode.d == simplifiedFraction.d) {
+            *aomMode = scalingModeMap[i].aomMode;
+            return AVIF_TRUE;
+        }
+    }
+
+    return AVIF_FALSE;
+}
+
+// Scales from aom's [0:63] to avm's [0:255]. TODO(yguyon): Accept [0:255] directly in avifEncoder.
+static int avmScaleQuantizer(int quantizer)
+{
+    return AVIF_CLAMP((quantizer * 255 + 31) / 63, 0, 255);
+}
+
+static avifBool avmCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output);
+
+static avifResult avmCodecEncodeImage(avifCodec * codec,
+                                      avifEncoder * encoder,
+                                      const avifImage * image,
+                                      avifBool alpha,
+                                      int tileRowsLog2,
+                                      int tileColsLog2,
+                                      int quantizer,
+                                      avifEncoderChanges encoderChanges,
+                                      avifBool disableLaggedOutput,
+                                      avifAddImageFlags addImageFlags,
+                                      avifCodecEncodeOutput * output)
+{
+    struct aom_codec_enc_cfg * cfg = &codec->internal->cfg;
+    avifBool quantizerUpdated = AVIF_FALSE;
+
+    // For encoder->scalingMode.horizontal and encoder->scalingMode.vertical to take effect in AV2
+    // encoder, config should be applied for each frame, so we don't care about changes on these
+    // two fields.
+    encoderChanges &= ~AVIF_ENCODER_CHANGE_SCALING_MODE;
+
+    if (!codec->internal->encoderInitialized) {
+        AVIF_CHECKRES(avifCheckCodecVersionAVM());
+
+        int aomCpuUsed = -1;
+        if (encoder->speed != AVIF_SPEED_DEFAULT) {
+            aomCpuUsed = AVIF_CLAMP(encoder->speed, 0, 9);
+        }
+
+        codec->internal->aomFormat = avifImageCalcAOMFmt(image, alpha);
+        if (codec->internal->aomFormat == AOM_IMG_FMT_NONE) {
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+
+        avifGetPixelFormatInfo(image->yuvFormat, &codec->internal->formatInfo);
+
+        aom_codec_iface_t * encoderInterface = aom_codec_av1_cx();
+        aom_codec_err_t err = aom_codec_enc_config_default(encoderInterface, cfg, AOM_USAGE_GOOD_QUALITY);
+        if (err != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag, "aom_codec_enc_config_default() failed: %s", aom_codec_err_to_string(err));
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+
+        // avm's default is AOM_VBR. Change the default to AOM_Q since we don't need to hit a certain target bit rate.
+        // It's easier to control the worst quality in Q mode.
+        cfg->rc_end_usage = AOM_Q;
+
+        // Profile 0.  8-bit and 10-bit 4:2:0 and 4:0:0 only.
+        // Profile 1.  8-bit and 10-bit 4:4:4
+        // Profile 2.  8-bit and 10-bit 4:2:2
+        //            12-bit 4:0:0, 4:2:0, 4:2:2 and 4:4:4
+        uint8_t seqProfile = 0;
+        if (image->depth == 12) {
+            // Only seqProfile 2 can handle 12 bit
+            seqProfile = 2;
+        } else {
+            // 8-bit or 10-bit
+
+            if (alpha) {
+                seqProfile = 0;
+            } else {
+                switch (image->yuvFormat) {
+                    case AVIF_PIXEL_FORMAT_YUV444:
+                        seqProfile = 1;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV422:
+                        seqProfile = 2;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV420:
+                        seqProfile = 0;
+                        break;
+                    case AVIF_PIXEL_FORMAT_YUV400:
+                        seqProfile = 0;
+                        break;
+                    case AVIF_PIXEL_FORMAT_NONE:
+                    case AVIF_PIXEL_FORMAT_COUNT:
+                    default:
+                        break;
+                }
+            }
+        }
+
+        cfg->g_profile = seqProfile;
+        cfg->g_bit_depth = image->depth;
+        cfg->g_input_bit_depth = image->depth;
+        cfg->g_w = image->width;
+        cfg->g_h = image->height;
+        if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+            // Set the maximum number of frames to encode to 1. This instructs
+            // libavm to set still_picture and reduced_still_picture_header to
+            // 1 in AV1 sequence headers.
+            cfg->g_limit = 1;
+
+            // Use the default settings of the new AOM_USAGE_ALL_INTRA (added in
+            // https://crbug.com/aomedia/2959).
+            //
+            // Set g_lag_in_frames to 0 to reduce the number of frame buffers
+            // (from 20 to 2) in libavm's lookahead structure. This reduces
+            // memory consumption when encoding a single image.
+            cfg->g_lag_in_frames = 0;
+            // Disable automatic placement of key frames by the encoder.
+            cfg->kf_mode = AOM_KF_DISABLED;
+            // Tell libavm that all frames will be key frames.
+            cfg->kf_max_dist = 0;
+        }
+        if (encoder->extraLayerCount > 0) {
+            cfg->g_limit = encoder->extraLayerCount + 1;
+            // For layered image, disable lagged encoding to always get output
+            // frame for each input frame.
+            cfg->g_lag_in_frames = 0;
+        }
+        if (disableLaggedOutput) {
+            cfg->g_lag_in_frames = 0;
+        }
+        if (encoder->maxThreads > 1) {
+            // libavm fails if cfg->g_threads is greater than 64 threads. See MAX_NUM_THREADS in
+            // avm/aom_util/aom_thread.h.
+            cfg->g_threads = AVIF_MIN(encoder->maxThreads, 64);
+        }
+
+        // avm does not handle monochrome as of research-v8.0.0.
+        // TODO(yguyon): Enable when fixed upstream
+        codec->internal->monochromeEnabled = AVIF_FALSE;
+
+        if (!avifProcessAOMOptionsPreInit(codec, alpha, cfg)) {
+            return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+        }
+
+        int minQuantizer;
+        int maxQuantizer;
+        if (alpha) {
+            minQuantizer = encoder->minQuantizerAlpha;
+            maxQuantizer = encoder->maxQuantizerAlpha;
+        } else {
+            minQuantizer = encoder->minQuantizer;
+            maxQuantizer = encoder->maxQuantizer;
+        }
+        // Scale from aom's [0:63] to avm's [0:255]. TODO(yguyon): Accept [0:255] directly in avifEncoder.
+        minQuantizer = avmScaleQuantizer(minQuantizer);
+        maxQuantizer = avmScaleQuantizer(maxQuantizer);
+        if ((cfg->rc_end_usage == AOM_VBR) || (cfg->rc_end_usage == AOM_CBR)) {
+            // cq-level is ignored in these two end-usage modes, so adjust minQuantizer and
+            // maxQuantizer to the target quantizer.
+            if (quantizer == AVIF_QUANTIZER_LOSSLESS) {
+                minQuantizer = AVIF_QUANTIZER_LOSSLESS;
+                maxQuantizer = AVIF_QUANTIZER_LOSSLESS;
+            } else {
+                minQuantizer = AVIF_MAX(quantizer - 4, minQuantizer);
+                maxQuantizer = AVIF_MIN(quantizer + 4, maxQuantizer);
+            }
+        }
+        cfg->rc_min_quantizer = minQuantizer;
+        cfg->rc_max_quantizer = maxQuantizer;
+        quantizerUpdated = AVIF_TRUE;
+
+        if (aom_codec_enc_init(&codec->internal->encoder, encoderInterface, cfg, /*flags=*/0) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_enc_init() failed: %s: %s",
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+        codec->internal->encoderInitialized = AVIF_TRUE;
+
+        if ((cfg->rc_end_usage == AOM_CQ) || (cfg->rc_end_usage == AOM_Q)) {
+            aom_codec_control(&codec->internal->encoder, AOME_SET_QP, quantizer);
+        }
+        avifBool lossless = (quantizer == AVIF_QUANTIZER_LOSSLESS);
+        if (lossless) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_LOSSLESS, 1);
+        }
+        if (encoder->maxThreads > 1) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_ROW_MT, 1);
+        }
+        if (tileRowsLog2 != 0) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_ROWS, tileRowsLog2);
+        }
+        if (tileColsLog2 != 0) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_COLUMNS, tileColsLog2);
+        }
+        if (encoder->extraLayerCount > 0) {
+            int layerCount = encoder->extraLayerCount + 1;
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_NUMBER_SPATIAL_LAYERS, layerCount) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+        if (aomCpuUsed != -1) {
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_CPUUSED, aomCpuUsed) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+
+        // Set color_config() in the sequence header OBU.
+        if (alpha) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_RANGE, AOM_CR_FULL_RANGE);
+        } else {
+            // libavm's defaults are AOM_CICP_CP_UNSPECIFIED, AOM_CICP_TC_UNSPECIFIED,
+            // AOM_CICP_MC_UNSPECIFIED, AOM_CSP_UNKNOWN, and 0 (studio/limited range). Call
+            // aom_codec_control() only if the values are not the defaults.
+            if (image->colorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_PRIMARIES, (int)image->colorPrimaries);
+            }
+            if (image->transferCharacteristics != AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_TRANSFER_CHARACTERISTICS, (int)image->transferCharacteristics);
+            }
+            if (image->matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_MATRIX_COEFFICIENTS, (int)image->matrixCoefficients);
+            }
+            if (image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_CHROMA_SAMPLE_POSITION, (int)image->yuvChromaSamplePosition);
+            }
+            if (image->yuvRange != AVIF_RANGE_LIMITED) {
+                aom_codec_control(&codec->internal->encoder, AV1E_SET_COLOR_RANGE, (int)image->yuvRange);
+            }
+        }
+
+        if (!avifProcessAOMOptionsPostInit(codec, alpha)) {
+            return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+        }
+        if (!codec->internal->tuningSet) {
+            if (aom_codec_control(&codec->internal->encoder, AOME_SET_TUNING, AOM_TUNE_SSIM) != AOM_CODEC_OK) {
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+    } else {
+        avifBool dimensionsChanged = AVIF_FALSE;
+        if ((cfg->g_w != image->width) || (cfg->g_h != image->height)) {
+            // We are not ready for dimension change for now.
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+        if (alpha) {
+            if (encoderChanges & (AVIF_ENCODER_CHANGE_MIN_QUANTIZER_ALPHA | AVIF_ENCODER_CHANGE_MAX_QUANTIZER_ALPHA)) {
+                cfg->rc_min_quantizer = avmScaleQuantizer(encoder->minQuantizerAlpha);
+                cfg->rc_max_quantizer = avmScaleQuantizer(encoder->maxQuantizerAlpha);
+                quantizerUpdated = AVIF_TRUE;
+            }
+        } else {
+            if (encoderChanges & (AVIF_ENCODER_CHANGE_MIN_QUANTIZER | AVIF_ENCODER_CHANGE_MAX_QUANTIZER)) {
+                cfg->rc_min_quantizer = avmScaleQuantizer(encoder->minQuantizer);
+                cfg->rc_max_quantizer = avmScaleQuantizer(encoder->maxQuantizer);
+                quantizerUpdated = AVIF_TRUE;
+            }
+        }
+        const int quantizerChangedBit = alpha ? AVIF_ENCODER_CHANGE_QUANTIZER_ALPHA : AVIF_ENCODER_CHANGE_QUANTIZER;
+        if (encoderChanges & quantizerChangedBit) {
+            if ((cfg->rc_end_usage == AOM_VBR) || (cfg->rc_end_usage == AOM_CBR)) {
+                // cq-level is ignored in these two end-usage modes, so adjust minQuantizer and
+                // maxQuantizer to the target quantizer.
+                if (quantizer == AVIF_QUANTIZER_LOSSLESS) {
+                    cfg->rc_min_quantizer = AVIF_QUANTIZER_LOSSLESS;
+                    cfg->rc_max_quantizer = AVIF_QUANTIZER_LOSSLESS;
+                } else {
+                    int minQuantizer;
+                    int maxQuantizer;
+                    if (alpha) {
+                        minQuantizer = encoder->minQuantizerAlpha;
+                        maxQuantizer = encoder->maxQuantizerAlpha;
+                    } else {
+                        minQuantizer = encoder->minQuantizer;
+                        maxQuantizer = encoder->maxQuantizer;
+                    }
+                    minQuantizer = avmScaleQuantizer(minQuantizer);
+                    maxQuantizer = avmScaleQuantizer(maxQuantizer);
+                    cfg->rc_min_quantizer = AVIF_MAX(quantizer - 4, minQuantizer);
+                    cfg->rc_max_quantizer = AVIF_MIN(quantizer + 4, maxQuantizer);
+                }
+                quantizerUpdated = AVIF_TRUE;
+            }
+        }
+        if (quantizerUpdated || dimensionsChanged) {
+            aom_codec_err_t err = aom_codec_enc_config_set(&codec->internal->encoder, cfg);
+            if (err != AOM_CODEC_OK) {
+                avifDiagnosticsPrintf(codec->diag,
+                                      "aom_codec_enc_config_set() failed: %s: %s",
+                                      aom_codec_error(&codec->internal->encoder),
+                                      aom_codec_error_detail(&codec->internal->encoder));
+                return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_TILE_ROWS_LOG2) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_ROWS, tileRowsLog2);
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_TILE_COLS_LOG2) {
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_TILE_COLUMNS, tileColsLog2);
+        }
+        if (encoderChanges & quantizerChangedBit) {
+            if ((cfg->rc_end_usage == AOM_CQ) || (cfg->rc_end_usage == AOM_Q)) {
+                aom_codec_control(&codec->internal->encoder, AOME_SET_QP, quantizer);
+            }
+            avifBool lossless = (quantizer == AVIF_QUANTIZER_LOSSLESS);
+            aom_codec_control(&codec->internal->encoder, AV1E_SET_LOSSLESS, lossless);
+        }
+        if (encoderChanges & AVIF_ENCODER_CHANGE_CODEC_SPECIFIC) {
+            if (!avifProcessAOMOptionsPostInit(codec, alpha)) {
+                return AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+            }
+        }
+    }
+
+    if (codec->internal->currentLayer > encoder->extraLayerCount) {
+        avifDiagnosticsPrintf(codec->diag,
+                              "Too many layers sent. Expected %u layers, but got %u layers.",
+                              encoder->extraLayerCount + 1,
+                              codec->internal->currentLayer + 1);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (encoder->extraLayerCount > 0) {
+        aom_codec_control(&codec->internal->encoder, AOME_SET_SPATIAL_LAYER_ID, codec->internal->currentLayer);
+    }
+
+    aom_scaling_mode_t aomScalingMode;
+    if (!avifFindAOMScalingMode(&encoder->scalingMode.horizontal, &aomScalingMode.h_scaling_mode)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (!avifFindAOMScalingMode(&encoder->scalingMode.vertical, &aomScalingMode.v_scaling_mode)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if ((aomScalingMode.h_scaling_mode != AOME_NORMAL) || (aomScalingMode.v_scaling_mode != AOME_NORMAL)) {
+        // AOME_SET_SCALEMODE only applies to next frame (layer), so we have to set it every time.
+        aom_codec_control(&codec->internal->encoder, AOME_SET_SCALEMODE, &aomScalingMode);
+    }
+
+    aom_image_t aomImage;
+    // We prefer to simply set the aomImage.planes[] pointers to the plane buffers in 'image'. When
+    // doing this, we set aomImage.w equal to aomImage.d_w and aomImage.h equal to aomImage.d_h and
+    // do not "align" aomImage.w and aomImage.h. Unfortunately this exposes a libaom bug in libavm
+    // (https://crbug.com/aomedia/3113) if chroma is subsampled and image->width or image->height is
+    // equal to 1. To work around this libavm bug, we allocate the aomImage.planes[] buffers and
+    // copy the image YUV data if image->width or image->height is equal to 1. This bug has been
+    // fixed in libaom v3.1.3 but not in libavm.
+    //
+    // Note: The exact condition for the bug is
+    //   ((image->width == 1) && (chroma is subsampled horizontally)) ||
+    //   ((image->height == 1) && (chroma is subsampled vertically))
+    // Since an image width or height of 1 is uncommon in practice, we test an inexact but simpler
+    // condition.
+    avifBool aomImageAllocated = (image->width == 1) || (image->height == 1);
+    if (aomImageAllocated) {
+        aom_img_alloc(&aomImage, codec->internal->aomFormat, image->width, image->height, 16);
+    } else {
+        memset(&aomImage, 0, sizeof(aomImage));
+        aomImage.fmt = codec->internal->aomFormat;
+        aomImage.bit_depth = (image->depth > 8) ? 16 : 8;
+        aomImage.w = image->width;
+        aomImage.h = image->height;
+        aomImage.d_w = image->width;
+        aomImage.d_h = image->height;
+        // Get sample size for this format.
+        unsigned int bps;
+        if (codec->internal->aomFormat == AOM_IMG_FMT_I420) {
+            bps = 12;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I422) {
+            bps = 16;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I444) {
+            bps = 24;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I42016) {
+            bps = 24;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I42216) {
+            bps = 32;
+        } else if (codec->internal->aomFormat == AOM_IMG_FMT_I44416) {
+            bps = 48;
+        } else {
+            bps = 16;
+        }
+        aomImage.bps = bps;
+        // See avifImageCalcAOMFmt(). libavm doesn't have AOM_IMG_FMT_I400, so we use AOM_IMG_FMT_I420 as a substitute for monochrome.
+        aomImage.x_chroma_shift = (alpha || codec->internal->formatInfo.monochrome) ? 1 : codec->internal->formatInfo.chromaShiftX;
+        aomImage.y_chroma_shift = (alpha || codec->internal->formatInfo.monochrome) ? 1 : codec->internal->formatInfo.chromaShiftY;
+    }
+
+    avifBool monochromeRequested = AVIF_FALSE;
+
+    if (alpha) {
+        aomImage.range = AOM_CR_FULL_RANGE;
+        monochromeRequested = AVIF_TRUE;
+        if (aomImageAllocated) {
+            const uint32_t bytesPerRow = ((image->depth > 8) ? 2 : 1) * image->width;
+            for (uint32_t j = 0; j < image->height; ++j) {
+                const uint8_t * srcAlphaRow = &image->alphaPlane[j * image->alphaRowBytes];
+                uint8_t * dstAlphaRow = &aomImage.planes[0][j * aomImage.stride[0]];
+                memcpy(dstAlphaRow, srcAlphaRow, bytesPerRow);
+            }
+        } else {
+            aomImage.planes[0] = image->alphaPlane;
+            aomImage.stride[0] = image->alphaRowBytes;
+        }
+
+        // Ignore UV planes when monochrome
+    } else {
+        int yuvPlaneCount = 3;
+        if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+            yuvPlaneCount = 1; // Ignore UV planes when monochrome
+            monochromeRequested = AVIF_TRUE;
+        }
+        if (aomImageAllocated) {
+            uint32_t bytesPerPixel = (image->depth > 8) ? 2 : 1;
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                uint32_t planeWidth = avifImagePlaneWidth(image, yuvPlane);
+                uint32_t planeHeight = avifImagePlaneHeight(image, yuvPlane);
+                uint32_t bytesPerRow = bytesPerPixel * planeWidth;
+
+                for (uint32_t j = 0; j < planeHeight; ++j) {
+                    const uint8_t * srcRow = &image->yuvPlanes[yuvPlane][j * image->yuvRowBytes[yuvPlane]];
+                    uint8_t * dstRow = &aomImage.planes[yuvPlane][j * aomImage.stride[yuvPlane]];
+                    memcpy(dstRow, srcRow, bytesPerRow);
+                }
+            }
+        } else {
+            for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+                aomImage.planes[yuvPlane] = image->yuvPlanes[yuvPlane];
+                aomImage.stride[yuvPlane] = image->yuvRowBytes[yuvPlane];
+            }
+        }
+
+        aomImage.cp = (aom_color_primaries_t)image->colorPrimaries;
+        aomImage.tc = (aom_transfer_characteristics_t)image->transferCharacteristics;
+        aomImage.mc = (aom_matrix_coefficients_t)image->matrixCoefficients;
+        aomImage.csp = (aom_chroma_sample_position_t)image->yuvChromaSamplePosition;
+        aomImage.range = (aom_color_range_t)image->yuvRange;
+    }
+
+    unsigned char * monoUVPlane = NULL;
+    if (monochromeRequested) {
+        if (codec->internal->monochromeEnabled) {
+            aomImage.monochrome = 1;
+        } else {
+            // The user requested monochrome (via alpha or YUV400) but libavm does not support
+            // monochrome. Manually set UV planes to 0.5.
+
+            // aomImage is always 420 when we're monochrome
+            uint32_t monoUVWidth = (image->width + 1) >> 1;
+            uint32_t monoUVHeight = (image->height + 1) >> 1;
+
+            // Allocate the U plane if necessary.
+            if (!aomImageAllocated) {
+                uint32_t channelSize = avifImageUsesU16(image) ? 2 : 1;
+                uint32_t monoUVRowBytes = channelSize * monoUVWidth;
+                size_t monoUVSize = (size_t)monoUVHeight * monoUVRowBytes;
+
+                monoUVPlane = avifAlloc(monoUVSize);
+                AVIF_CHECKERR(monoUVPlane != NULL, AVIF_RESULT_OUT_OF_MEMORY); // No need for aom_img_free() because !aomImageAllocated
+                aomImage.planes[1] = monoUVPlane;
+                aomImage.stride[1] = monoUVRowBytes;
+            }
+            // Set the U plane to 0.5.
+            if (image->depth > 8) {
+                const uint16_t half = 1 << (image->depth - 1);
+                for (uint32_t j = 0; j < monoUVHeight; ++j) {
+                    uint16_t * dstRow = (uint16_t *)&aomImage.planes[1][(size_t)j * aomImage.stride[1]];
+                    for (uint32_t i = 0; i < monoUVWidth; ++i) {
+                        dstRow[i] = half;
+                    }
+                }
+            } else {
+                const uint8_t half = 128;
+                size_t planeSize = (size_t)monoUVHeight * aomImage.stride[1];
+                memset(aomImage.planes[1], half, planeSize);
+            }
+            // Make the V plane the same as the U plane.
+            aomImage.planes[2] = aomImage.planes[1];
+            aomImage.stride[2] = aomImage.stride[1];
+        }
+    }
+
+    aom_enc_frame_flags_t encodeFlags = 0;
+    if (addImageFlags & AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME) {
+        encodeFlags |= AOM_EFLAG_FORCE_KF;
+    }
+    if (codec->internal->currentLayer > 0) {
+        encodeFlags |= AOM_EFLAG_NO_REF_GF | AOM_EFLAG_NO_REF_ARF | AOM_EFLAG_NO_REF_BWD | AOM_EFLAG_NO_REF_ARF2 | AOM_EFLAG_NO_UPD_ALL;
+    }
+    aom_codec_err_t encodeErr = aom_codec_encode(&codec->internal->encoder, &aomImage, 0, 1, encodeFlags);
+    avifFree(monoUVPlane);
+    if (aomImageAllocated) {
+        aom_img_free(&aomImage);
+    }
+    if (encodeErr != AOM_CODEC_OK) {
+        avifDiagnosticsPrintf(codec->diag,
+                              "aom_codec_encode() failed: %s: %s",
+                              aom_codec_error(&codec->internal->encoder),
+                              aom_codec_error_detail(&codec->internal->encoder));
+        return AVIF_RESULT_UNKNOWN_ERROR;
+    }
+
+    aom_codec_iter_t iter = NULL;
+    for (;;) {
+        const aom_codec_cx_pkt_t * pkt = aom_codec_get_cx_data(&codec->internal->encoder, &iter);
+        if (pkt == NULL) {
+            break;
+        }
+        if (pkt->kind == AOM_CODEC_CX_FRAME_PKT) {
+            AVIF_CHECKRES(
+                avifCodecEncodeOutputAddSample(output, pkt->data.frame.buf, pkt->data.frame.sz, (pkt->data.frame.flags & AOM_FRAME_IS_KEY)));
+        }
+    }
+
+    if ((addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) ||
+        ((encoder->extraLayerCount > 0) && (encoder->extraLayerCount == codec->internal->currentLayer))) {
+        // Flush and clean up encoder resources early to save on overhead when encoding alpha or grid images,
+        // as encoding is finished now. For layered image, encoding finishes when the last layer is encoded.
+
+        if (!avmCodecEncodeFinish(codec, output)) {
+            return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+        aom_codec_destroy(&codec->internal->encoder);
+        codec->internal->encoderInitialized = AVIF_FALSE;
+    }
+    if (encoder->extraLayerCount > 0) {
+        ++codec->internal->currentLayer;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avmCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output)
+{
+    if (!codec->internal->encoderInitialized) {
+        return AVIF_TRUE;
+    }
+    for (;;) {
+        // flush encoder
+        if (aom_codec_encode(&codec->internal->encoder, NULL, 0, 1, 0) != AOM_CODEC_OK) {
+            avifDiagnosticsPrintf(codec->diag,
+                                  "aom_codec_encode() with img=NULL failed: %s: %s",
+                                  aom_codec_error(&codec->internal->encoder),
+                                  aom_codec_error_detail(&codec->internal->encoder));
+            return AVIF_FALSE;
+        }
+
+        avifBool gotPacket = AVIF_FALSE;
+        aom_codec_iter_t iter = NULL;
+        for (;;) {
+            const aom_codec_cx_pkt_t * pkt = aom_codec_get_cx_data(&codec->internal->encoder, &iter);
+            if (pkt == NULL) {
+                break;
+            }
+            if (pkt->kind == AOM_CODEC_CX_FRAME_PKT) {
+                gotPacket = AVIF_TRUE;
+                const avifResult result = avifCodecEncodeOutputAddSample(output,
+                                                                         pkt->data.frame.buf,
+                                                                         pkt->data.frame.sz,
+                                                                         (pkt->data.frame.flags & AOM_FRAME_IS_KEY));
+                if (result != AVIF_RESULT_OK) {
+                    avifDiagnosticsPrintf(codec->diag, "avifCodecEncodeOutputAddSample() failed: %s", avifResultToString(result));
+                    return AVIF_FALSE;
+                }
+            }
+        }
+
+        if (!gotPacket) {
+            break;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+const char * avifCodecVersionAVM(void)
+{
+    return aom_codec_version_str();
+}
+
+avifCodec * avifCodecCreateAVM(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+
+    codec->getNextImage = avmCodecGetNextImage;
+
+    codec->encodeImage = avmCodecEncodeImage;
+    codec->encodeFinish = avmCodecEncodeFinish;
+
+    codec->destroyInternal = avmCodecDestroyInternal;
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(struct avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    return codec;
+}
diff --git a/third_party/libavif/src/src/codec_dav1d.c b/third_party/libavif/src/src/codec_dav1d.c
new file mode 100644
index 0000000000..5aff5a1262
--- /dev/null
+++ b/third_party/libavif/src/src/codec_dav1d.c
@@ -0,0 +1,255 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#if defined(_MSC_VER)
+#pragma warning(disable : 4201) // nonstandard extension used: nameless struct/union
+#endif
+#if defined(__clang__)
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wc11-extensions" // C11 extension used: nameless struct/union
+#endif
+#include "dav1d/dav1d.h"
+#if defined(__clang__)
+#pragma clang diagnostic pop
+#endif
+
+#include <string.h>
+
+// For those building with an older version of dav1d (not recommended).
+#ifndef DAV1D_ERR
+#define DAV1D_ERR(e) (-(e))
+#endif
+
+struct avifCodecInternal
+{
+    Dav1dContext * dav1dContext;
+    Dav1dPicture dav1dPicture;
+    avifBool hasPicture;
+    avifRange colorRange;
+};
+
+static void avifDav1dFreeCallback(const uint8_t * buf, void * cookie)
+{
+    // This data is owned by the decoder; nothing to free here
+    (void)buf;
+    (void)cookie;
+}
+
+static void dav1dCodecDestroyInternal(avifCodec * codec)
+{
+    if (codec->internal->hasPicture) {
+        dav1d_picture_unref(&codec->internal->dav1dPicture);
+    }
+    if (codec->internal->dav1dContext) {
+        dav1d_close(&codec->internal->dav1dContext);
+    }
+    avifFree(codec->internal);
+}
+
+static avifBool dav1dCodecGetNextImage(struct avifCodec * codec,
+                                       const avifDecodeSample * sample,
+                                       avifBool alpha,
+                                       avifBool * isLimitedRangeAlpha,
+                                       avifImage * image)
+{
+    if (codec->internal->dav1dContext == NULL) {
+        Dav1dSettings dav1dSettings;
+        dav1d_default_settings(&dav1dSettings);
+        // Give all available threads to decode a single frame as fast as possible
+#if DAV1D_API_VERSION_MAJOR >= 6
+        dav1dSettings.max_frame_delay = 1;
+        dav1dSettings.n_threads = AVIF_CLAMP(codec->maxThreads, 1, DAV1D_MAX_THREADS);
+#else
+        dav1dSettings.n_frame_threads = 1;
+        dav1dSettings.n_tile_threads = AVIF_CLAMP(codec->maxThreads, 1, DAV1D_MAX_TILE_THREADS);
+#endif // DAV1D_API_VERSION_MAJOR >= 6
+        // Set a maximum frame size limit to avoid OOM'ing fuzzers. In 32-bit builds, if
+        // frame_size_limit > 8192 * 8192, dav1d reduces frame_size_limit to 8192 * 8192 and logs
+        // a message, so we set frame_size_limit to at most 8192 * 8192 to avoid the dav1d_log
+        // message.
+        dav1dSettings.frame_size_limit = (sizeof(size_t) < 8) ? AVIF_MIN(codec->imageSizeLimit, 8192 * 8192) : codec->imageSizeLimit;
+        dav1dSettings.operating_point = codec->operatingPoint;
+        dav1dSettings.all_layers = codec->allLayers;
+
+        if (dav1d_open(&codec->internal->dav1dContext, &dav1dSettings) != 0) {
+            return AVIF_FALSE;
+        }
+    }
+
+    avifBool gotPicture = AVIF_FALSE;
+    Dav1dPicture nextFrame;
+    memset(&nextFrame, 0, sizeof(Dav1dPicture));
+
+    Dav1dData dav1dData;
+    if (dav1d_data_wrap(&dav1dData, sample->data.data, sample->data.size, avifDav1dFreeCallback, NULL) != 0) {
+        return AVIF_FALSE;
+    }
+
+    int res;
+    for (;;) {
+        if (dav1dData.data) {
+            res = dav1d_send_data(codec->internal->dav1dContext, &dav1dData);
+            if ((res < 0) && (res != DAV1D_ERR(EAGAIN))) {
+                dav1d_data_unref(&dav1dData);
+                return AVIF_FALSE;
+            }
+        }
+
+        res = dav1d_get_picture(codec->internal->dav1dContext, &nextFrame);
+        if (res == DAV1D_ERR(EAGAIN)) {
+            if (dav1dData.data) {
+                // send more data
+                continue;
+            }
+            return AVIF_FALSE;
+        } else if (res < 0) {
+            // No more frames
+            if (dav1dData.data) {
+                dav1d_data_unref(&dav1dData);
+            }
+            return AVIF_FALSE;
+        } else {
+            // Got a picture!
+            if ((sample->spatialID != AVIF_SPATIAL_ID_UNSET) && (sample->spatialID != nextFrame.frame_hdr->spatial_id)) {
+                // Layer selection: skip this unwanted layer
+                dav1d_picture_unref(&nextFrame);
+            } else {
+                gotPicture = AVIF_TRUE;
+                break;
+            }
+        }
+    }
+    if (dav1dData.data) {
+        dav1d_data_unref(&dav1dData);
+    }
+
+    // Drain all buffered frames in the decoder.
+    //
+    // The sample should have only one frame of the desired layer. If there are more frames after
+    // that frame, we need to discard them so that they won't be mistakenly output when the decoder
+    // is used to decode another sample.
+    Dav1dPicture bufferedFrame;
+    memset(&bufferedFrame, 0, sizeof(Dav1dPicture));
+    do {
+        res = dav1d_get_picture(codec->internal->dav1dContext, &bufferedFrame);
+        if (res < 0) {
+            if (res != DAV1D_ERR(EAGAIN)) {
+                if (gotPicture) {
+                    dav1d_picture_unref(&nextFrame);
+                }
+                return AVIF_FALSE;
+            }
+        } else {
+            dav1d_picture_unref(&bufferedFrame);
+        }
+    } while (res == 0);
+
+    if (gotPicture) {
+        dav1d_picture_unref(&codec->internal->dav1dPicture);
+        codec->internal->dav1dPicture = nextFrame;
+        codec->internal->colorRange = codec->internal->dav1dPicture.seq_hdr->color_range ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED;
+        codec->internal->hasPicture = AVIF_TRUE;
+    } else {
+        if (alpha && codec->internal->hasPicture) {
+            // Special case: reuse last alpha frame
+        } else {
+            return AVIF_FALSE;
+        }
+    }
+
+    Dav1dPicture * dav1dImage = &codec->internal->dav1dPicture;
+    avifBool isColor = !alpha;
+    if (isColor) {
+        // Color (YUV) planes - set image to correct size / format, fill color
+
+        avifPixelFormat yuvFormat = AVIF_PIXEL_FORMAT_NONE;
+        switch (dav1dImage->p.layout) {
+            case DAV1D_PIXEL_LAYOUT_I400:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+                break;
+            case DAV1D_PIXEL_LAYOUT_I420:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+                break;
+            case DAV1D_PIXEL_LAYOUT_I422:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV422;
+                break;
+            case DAV1D_PIXEL_LAYOUT_I444:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                break;
+        }
+
+        if (image->width && image->height) {
+            if ((image->width != (uint32_t)dav1dImage->p.w) || (image->height != (uint32_t)dav1dImage->p.h) ||
+                (image->depth != (uint32_t)dav1dImage->p.bpc) || (image->yuvFormat != yuvFormat)) {
+                // Throw it all out
+                avifImageFreePlanes(image, AVIF_PLANES_ALL);
+            }
+        }
+        image->width = dav1dImage->p.w;
+        image->height = dav1dImage->p.h;
+        image->depth = dav1dImage->p.bpc;
+
+        image->yuvFormat = yuvFormat;
+        image->yuvRange = codec->internal->colorRange;
+        image->yuvChromaSamplePosition = (avifChromaSamplePosition)dav1dImage->seq_hdr->chr;
+
+        image->colorPrimaries = (avifColorPrimaries)dav1dImage->seq_hdr->pri;
+        image->transferCharacteristics = (avifTransferCharacteristics)dav1dImage->seq_hdr->trc;
+        image->matrixCoefficients = (avifMatrixCoefficients)dav1dImage->seq_hdr->mtrx;
+
+        // Steal the pointers from the decoder's image directly
+        avifImageFreePlanes(image, AVIF_PLANES_YUV);
+        int yuvPlaneCount = (yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+        for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+            image->yuvPlanes[yuvPlane] = dav1dImage->data[yuvPlane];
+            image->yuvRowBytes[yuvPlane] = (uint32_t)dav1dImage->stride[(yuvPlane == AVIF_CHAN_Y) ? 0 : 1];
+        }
+        image->imageOwnsYUVPlanes = AVIF_FALSE;
+    } else {
+        // Alpha plane - ensure image is correct size, fill color
+
+        if (image->width && image->height) {
+            if ((image->width != (uint32_t)dav1dImage->p.w) || (image->height != (uint32_t)dav1dImage->p.h) ||
+                (image->depth != (uint32_t)dav1dImage->p.bpc)) {
+                // Alpha plane doesn't match previous alpha plane decode, bail out
+                return AVIF_FALSE;
+            }
+        }
+        image->width = dav1dImage->p.w;
+        image->height = dav1dImage->p.h;
+        image->depth = dav1dImage->p.bpc;
+
+        avifImageFreePlanes(image, AVIF_PLANES_A);
+        image->alphaPlane = dav1dImage->data[0];
+        image->alphaRowBytes = (uint32_t)dav1dImage->stride[0];
+        *isLimitedRangeAlpha = (codec->internal->colorRange == AVIF_RANGE_LIMITED);
+        image->imageOwnsAlphaPlane = AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+const char * avifCodecVersionDav1d(void)
+{
+    return dav1d_version();
+}
+
+avifCodec * avifCodecCreateDav1d(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+    codec->getNextImage = dav1dCodecGetNextImage;
+    codec->destroyInternal = dav1dCodecDestroyInternal;
+
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(struct avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    return codec;
+}
diff --git a/third_party/libavif/src/src/codec_libgav1.c b/third_party/libavif/src/src/codec_libgav1.c
new file mode 100644
index 0000000000..43cb81f099
--- /dev/null
+++ b/third_party/libavif/src/src/codec_libgav1.c
@@ -0,0 +1,174 @@
+// Copyright 2020 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include "gav1/decoder.h"
+
+#include <string.h>
+
+struct avifCodecInternal
+{
+    Libgav1DecoderSettings gav1Settings;
+    Libgav1Decoder * gav1Decoder;
+    const Libgav1DecoderBuffer * gav1Image;
+    avifRange colorRange;
+};
+
+static void gav1CodecDestroyInternal(avifCodec * codec)
+{
+    if (codec->internal->gav1Decoder != NULL) {
+        Libgav1DecoderDestroy(codec->internal->gav1Decoder);
+    }
+    avifFree(codec->internal);
+}
+
+static avifBool gav1CodecGetNextImage(struct avifCodec * codec,
+                                      const avifDecodeSample * sample,
+                                      avifBool alpha,
+                                      avifBool * isLimitedRangeAlpha,
+                                      avifImage * image)
+{
+    if (codec->internal->gav1Decoder == NULL) {
+        codec->internal->gav1Settings.threads = codec->maxThreads;
+        codec->internal->gav1Settings.operating_point = codec->operatingPoint;
+        codec->internal->gav1Settings.output_all_layers = codec->allLayers;
+
+        if (Libgav1DecoderCreate(&codec->internal->gav1Settings, &codec->internal->gav1Decoder) != kLibgav1StatusOk) {
+            return AVIF_FALSE;
+        }
+    }
+
+    if (Libgav1DecoderEnqueueFrame(codec->internal->gav1Decoder,
+                                   sample->data.data,
+                                   sample->data.size,
+                                   /*user_private_data=*/0,
+                                   /*buffer_private_data=*/NULL) != kLibgav1StatusOk) {
+        return AVIF_FALSE;
+    }
+    // Each Libgav1DecoderDequeueFrame() call invalidates the output frame
+    // returned by the previous Libgav1DecoderDequeueFrame() call. Clear
+    // our pointer to the previous output frame.
+    codec->internal->gav1Image = NULL;
+
+    const Libgav1DecoderBuffer * nextFrame = NULL;
+    for (;;) {
+        if (Libgav1DecoderDequeueFrame(codec->internal->gav1Decoder, &nextFrame) != kLibgav1StatusOk) {
+            return AVIF_FALSE;
+        }
+        if (nextFrame && (sample->spatialID != AVIF_SPATIAL_ID_UNSET) && (nextFrame->spatial_id != sample->spatialID)) {
+            nextFrame = NULL;
+        } else {
+            break;
+        }
+    }
+    // Got an image!
+
+    if (nextFrame) {
+        codec->internal->gav1Image = nextFrame;
+        codec->internal->colorRange = (nextFrame->color_range == kLibgav1ColorRangeStudio) ? AVIF_RANGE_LIMITED : AVIF_RANGE_FULL;
+    } else {
+        if (alpha && codec->internal->gav1Image) {
+            // Special case: reuse last alpha frame
+        } else {
+            return AVIF_FALSE;
+        }
+    }
+
+    const Libgav1DecoderBuffer * gav1Image = codec->internal->gav1Image;
+    avifBool isColor = !alpha;
+    if (isColor) {
+        // Color (YUV) planes - set image to correct size / format, fill color
+
+        avifPixelFormat yuvFormat = AVIF_PIXEL_FORMAT_NONE;
+        switch (gav1Image->image_format) {
+            case kLibgav1ImageFormatMonochrome400:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+                break;
+            case kLibgav1ImageFormatYuv420:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+                break;
+            case kLibgav1ImageFormatYuv422:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV422;
+                break;
+            case kLibgav1ImageFormatYuv444:
+                yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                break;
+        }
+
+        if (image->width && image->height) {
+            if ((image->width != (uint32_t)gav1Image->displayed_width[0]) ||
+                (image->height != (uint32_t)gav1Image->displayed_height[0]) || (image->depth != (uint32_t)gav1Image->bitdepth) ||
+                (image->yuvFormat != yuvFormat)) {
+                // Throw it all out
+                avifImageFreePlanes(image, AVIF_PLANES_ALL);
+            }
+        }
+        image->width = gav1Image->displayed_width[0];
+        image->height = gav1Image->displayed_height[0];
+        image->depth = gav1Image->bitdepth;
+
+        image->yuvFormat = yuvFormat;
+        image->yuvRange = codec->internal->colorRange;
+        image->yuvChromaSamplePosition = (avifChromaSamplePosition)gav1Image->chroma_sample_position;
+
+        image->colorPrimaries = (avifColorPrimaries)gav1Image->color_primary;
+        image->transferCharacteristics = (avifTransferCharacteristics)gav1Image->transfer_characteristics;
+        image->matrixCoefficients = (avifMatrixCoefficients)gav1Image->matrix_coefficients;
+
+        // Steal the pointers from the decoder's image directly
+        avifImageFreePlanes(image, AVIF_PLANES_YUV);
+        int yuvPlaneCount = (yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+        for (int yuvPlane = 0; yuvPlane < yuvPlaneCount; ++yuvPlane) {
+            image->yuvPlanes[yuvPlane] = gav1Image->plane[yuvPlane];
+            image->yuvRowBytes[yuvPlane] = gav1Image->stride[yuvPlane];
+        }
+        image->imageOwnsYUVPlanes = AVIF_FALSE;
+    } else {
+        // Alpha plane - ensure image is correct size, fill color
+
+        if (image->width && image->height) {
+            if ((image->width != (uint32_t)gav1Image->displayed_width[0]) ||
+                (image->height != (uint32_t)gav1Image->displayed_height[0]) || (image->depth != (uint32_t)gav1Image->bitdepth)) {
+                // Alpha plane doesn't match previous alpha plane decode, bail out
+                return AVIF_FALSE;
+            }
+        }
+        image->width = gav1Image->displayed_width[0];
+        image->height = gav1Image->displayed_height[0];
+        image->depth = gav1Image->bitdepth;
+
+        avifImageFreePlanes(image, AVIF_PLANES_A);
+        image->alphaPlane = gav1Image->plane[0];
+        image->alphaRowBytes = gav1Image->stride[0];
+        *isLimitedRangeAlpha = (codec->internal->colorRange == AVIF_RANGE_LIMITED);
+        image->imageOwnsAlphaPlane = AVIF_FALSE;
+    }
+
+    return AVIF_TRUE;
+}
+
+const char * avifCodecVersionGav1(void)
+{
+    return Libgav1GetVersionString();
+}
+
+avifCodec * avifCodecCreateGav1(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+    codec->getNextImage = gav1CodecGetNextImage;
+    codec->destroyInternal = gav1CodecDestroyInternal;
+
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(struct avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    Libgav1DecoderSettingsInitDefault(&codec->internal->gav1Settings);
+    return codec;
+}
diff --git a/third_party/libavif/src/src/codec_rav1e.c b/third_party/libavif/src/src/codec_rav1e.c
new file mode 100644
index 0000000000..c39c9a6754
--- /dev/null
+++ b/third_party/libavif/src/src/codec_rav1e.c
@@ -0,0 +1,322 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include "rav1e.h"
+
+#include <string.h>
+
+struct avifCodecInternal
+{
+    RaContext * rav1eContext;
+    RaChromaSampling chromaSampling;
+    int yShift;
+    uint32_t encodeWidth;
+    uint32_t encodeHeight;
+};
+
+static void rav1eCodecDestroyInternal(avifCodec * codec)
+{
+    if (codec->internal->rav1eContext) {
+        rav1e_context_unref(codec->internal->rav1eContext);
+        codec->internal->rav1eContext = NULL;
+    }
+    avifFree(codec->internal);
+}
+
+// Official support wasn't added until v0.4.0
+static avifBool rav1eSupports400(void)
+{
+    const char * rav1eVersionString = rav1e_version_short();
+
+    // Check major version > 0
+    int majorVersion = atoi(rav1eVersionString);
+    if (majorVersion > 0) {
+        return AVIF_TRUE;
+    }
+
+    // Check minor version >= 4
+    const char * minorVersionString = strchr(rav1eVersionString, '.');
+    if (!minorVersionString) {
+        return AVIF_FALSE;
+    }
+    ++minorVersionString;
+    if (!(*minorVersionString)) {
+        return AVIF_FALSE;
+    }
+    int minorVersion = atoi(minorVersionString);
+    return minorVersion >= 4;
+}
+
+static avifResult rav1eCodecEncodeImage(avifCodec * codec,
+                                        avifEncoder * encoder,
+                                        const avifImage * image,
+                                        avifBool alpha,
+                                        int tileRowsLog2,
+                                        int tileColsLog2,
+                                        int quantizer,
+                                        avifEncoderChanges encoderChanges,
+                                        avifBool disableLaggedOutput,
+                                        uint32_t addImageFlags,
+                                        avifCodecEncodeOutput * output)
+{
+    // rav1e does not support changing encoder settings.
+    if (encoderChanges) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // rav1e does not support changing image dimensions.
+    if (!codec->internal->rav1eContext) {
+        codec->internal->encodeWidth = image->width;
+        codec->internal->encodeHeight = image->height;
+    } else if ((codec->internal->encodeWidth != image->width) || (codec->internal->encodeHeight != image->height)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // rav1e does not support encoding layered image.
+    if (encoder->extraLayerCount > 0) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // rav1e does not support disabling lagged output. See https://github.com/xiph/rav1e/issues/2267. Ignore this setting.
+    (void)disableLaggedOutput;
+
+    avifResult result = AVIF_RESULT_UNKNOWN_ERROR;
+
+    RaConfig * rav1eConfig = NULL;
+    RaFrame * rav1eFrame = NULL;
+
+    if (!codec->internal->rav1eContext) {
+        const avifBool supports400 = rav1eSupports400();
+        RaPixelRange rav1eRange;
+        if (alpha) {
+            rav1eRange = RA_PIXEL_RANGE_FULL;
+            codec->internal->chromaSampling = supports400 ? RA_CHROMA_SAMPLING_CS400 : RA_CHROMA_SAMPLING_CS420;
+            codec->internal->yShift = 1;
+        } else {
+            rav1eRange = (image->yuvRange == AVIF_RANGE_FULL) ? RA_PIXEL_RANGE_FULL : RA_PIXEL_RANGE_LIMITED;
+            codec->internal->yShift = 0;
+            switch (image->yuvFormat) {
+                case AVIF_PIXEL_FORMAT_YUV444:
+                    codec->internal->chromaSampling = RA_CHROMA_SAMPLING_CS444;
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV422:
+                    codec->internal->chromaSampling = RA_CHROMA_SAMPLING_CS422;
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV420:
+                    codec->internal->chromaSampling = RA_CHROMA_SAMPLING_CS420;
+                    codec->internal->yShift = 1;
+                    break;
+                case AVIF_PIXEL_FORMAT_YUV400:
+                    codec->internal->chromaSampling = supports400 ? RA_CHROMA_SAMPLING_CS400 : RA_CHROMA_SAMPLING_CS420;
+                    codec->internal->yShift = 1;
+                    break;
+                case AVIF_PIXEL_FORMAT_NONE:
+                case AVIF_PIXEL_FORMAT_COUNT:
+                default:
+                    return AVIF_RESULT_UNKNOWN_ERROR;
+            }
+        }
+
+        rav1eConfig = rav1e_config_default();
+        if (rav1e_config_set_pixel_format(rav1eConfig,
+                                          (uint8_t)image->depth,
+                                          codec->internal->chromaSampling,
+                                          (RaChromaSamplePosition)image->yuvChromaSamplePosition,
+                                          rav1eRange) < 0) {
+            goto cleanup;
+        }
+
+        if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+            if (rav1e_config_parse(rav1eConfig, "still_picture", "true") == -1) {
+                goto cleanup;
+            }
+        }
+        if (rav1e_config_parse_int(rav1eConfig, "width", image->width) == -1) {
+            goto cleanup;
+        }
+        if (rav1e_config_parse_int(rav1eConfig, "height", image->height) == -1) {
+            goto cleanup;
+        }
+        if (rav1e_config_parse_int(rav1eConfig, "threads", encoder->maxThreads) == -1) {
+            goto cleanup;
+        }
+
+        int minQuantizer = AVIF_CLAMP(encoder->minQuantizer, 0, 63);
+        if (alpha) {
+            minQuantizer = AVIF_CLAMP(encoder->minQuantizerAlpha, 0, 63);
+        }
+        minQuantizer = (minQuantizer * 255) / 63; // Rescale quantizer values as rav1e's QP range is [0,255]
+        quantizer = (quantizer * 255) / 63;
+        if (rav1e_config_parse_int(rav1eConfig, "min_quantizer", minQuantizer) == -1) {
+            goto cleanup;
+        }
+        if (rav1e_config_parse_int(rav1eConfig, "quantizer", quantizer) == -1) {
+            goto cleanup;
+        }
+        if (tileRowsLog2 != 0) {
+            if (rav1e_config_parse_int(rav1eConfig, "tile_rows", 1 << tileRowsLog2) == -1) {
+                goto cleanup;
+            }
+        }
+        if (tileColsLog2 != 0) {
+            if (rav1e_config_parse_int(rav1eConfig, "tile_cols", 1 << tileColsLog2) == -1) {
+                goto cleanup;
+            }
+        }
+        if (encoder->speed != AVIF_SPEED_DEFAULT) {
+            int speed = AVIF_CLAMP(encoder->speed, 0, 10);
+            if (rav1e_config_parse_int(rav1eConfig, "speed", speed) == -1) {
+                goto cleanup;
+            }
+        }
+        if (encoder->keyframeInterval > 0) {
+            // "key_frame_interval" is the maximum interval between two keyframes.
+            if (rav1e_config_parse_int(rav1eConfig, "key_frame_interval", encoder->keyframeInterval) == -1) {
+                goto cleanup;
+            }
+        }
+        for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+            avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+            if (rav1e_config_parse(rav1eConfig, entry->key, entry->value) < 0) {
+                avifDiagnosticsPrintf(codec->diag, "Invalid value for %s: %s.", entry->key, entry->value);
+                result = AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+                goto cleanup;
+            }
+        }
+
+        rav1e_config_set_color_description(rav1eConfig,
+                                           (RaMatrixCoefficients)image->matrixCoefficients,
+                                           (RaColorPrimaries)image->colorPrimaries,
+                                           (RaTransferCharacteristics)image->transferCharacteristics);
+
+        codec->internal->rav1eContext = rav1e_context_new(rav1eConfig);
+        if (!codec->internal->rav1eContext) {
+            goto cleanup;
+        }
+    }
+
+    rav1eFrame = rav1e_frame_new(codec->internal->rav1eContext);
+
+    int byteWidth = (image->depth > 8) ? 2 : 1;
+    if (alpha) {
+        rav1e_frame_fill_plane(rav1eFrame, 0, image->alphaPlane, (size_t)image->alphaRowBytes * image->height, image->alphaRowBytes, byteWidth);
+    } else {
+        rav1e_frame_fill_plane(rav1eFrame, 0, image->yuvPlanes[0], (size_t)image->yuvRowBytes[0] * image->height, image->yuvRowBytes[0], byteWidth);
+        if (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV400) {
+            uint32_t uvHeight = (image->height + codec->internal->yShift) >> codec->internal->yShift;
+            rav1e_frame_fill_plane(rav1eFrame, 1, image->yuvPlanes[1], (size_t)image->yuvRowBytes[1] * uvHeight, image->yuvRowBytes[1], byteWidth);
+            rav1e_frame_fill_plane(rav1eFrame, 2, image->yuvPlanes[2], (size_t)image->yuvRowBytes[2] * uvHeight, image->yuvRowBytes[2], byteWidth);
+        }
+    }
+
+    RaFrameTypeOverride frameType = RA_FRAME_TYPE_OVERRIDE_NO;
+    if (addImageFlags & AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME) {
+        frameType = RA_FRAME_TYPE_OVERRIDE_KEY;
+    }
+    rav1e_frame_set_type(rav1eFrame, frameType);
+
+    RaEncoderStatus encoderStatus = rav1e_send_frame(codec->internal->rav1eContext, rav1eFrame);
+    if (encoderStatus != RA_ENCODER_STATUS_SUCCESS) {
+        goto cleanup;
+    }
+
+    RaPacket * pkt = NULL;
+    for (;;) {
+        encoderStatus = rav1e_receive_packet(codec->internal->rav1eContext, &pkt);
+        if (encoderStatus == RA_ENCODER_STATUS_ENCODED) {
+            continue;
+        }
+        if ((encoderStatus != RA_ENCODER_STATUS_SUCCESS) && (encoderStatus != RA_ENCODER_STATUS_NEED_MORE_DATA)) {
+            goto cleanup;
+        } else if (pkt) {
+            if (pkt->data && (pkt->len > 0)) {
+                result = avifCodecEncodeOutputAddSample(output, pkt->data, pkt->len, (pkt->frame_type == RA_FRAME_TYPE_KEY));
+                if (result != AVIF_RESULT_OK) {
+                    goto cleanup;
+                }
+            }
+            rav1e_packet_unref(pkt);
+            pkt = NULL;
+        } else {
+            break;
+        }
+    }
+    result = AVIF_RESULT_OK;
+cleanup:
+    if (rav1eFrame) {
+        rav1e_frame_unref(rav1eFrame);
+        rav1eFrame = NULL;
+    }
+    if (rav1eConfig) {
+        rav1e_config_unref(rav1eConfig);
+        rav1eConfig = NULL;
+    }
+    return result;
+}
+
+static avifBool rav1eCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output)
+{
+    for (;;) {
+        RaEncoderStatus encoderStatus = rav1e_send_frame(codec->internal->rav1eContext, NULL); // flush
+        if (encoderStatus != RA_ENCODER_STATUS_SUCCESS) {
+            return AVIF_FALSE;
+        }
+
+        avifBool gotPacket = AVIF_FALSE;
+        RaPacket * pkt = NULL;
+        for (;;) {
+            encoderStatus = rav1e_receive_packet(codec->internal->rav1eContext, &pkt);
+            if (encoderStatus == RA_ENCODER_STATUS_ENCODED) {
+                continue;
+            }
+            if ((encoderStatus != RA_ENCODER_STATUS_SUCCESS) && (encoderStatus != RA_ENCODER_STATUS_LIMIT_REACHED)) {
+                return AVIF_FALSE;
+            }
+            if (pkt) {
+                gotPacket = AVIF_TRUE;
+                if (pkt->data && (pkt->len > 0)) {
+                    if (avifCodecEncodeOutputAddSample(output, pkt->data, pkt->len, (pkt->frame_type == RA_FRAME_TYPE_KEY)) !=
+                        AVIF_RESULT_OK) {
+                        return AVIF_FALSE;
+                    }
+                }
+                rav1e_packet_unref(pkt);
+                pkt = NULL;
+            } else {
+                break;
+            }
+        }
+
+        if (!gotPacket) {
+            break;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+const char * avifCodecVersionRav1e(void)
+{
+    return rav1e_version_full();
+}
+
+avifCodec * avifCodecCreateRav1e(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+    codec->encodeImage = rav1eCodecEncodeImage;
+    codec->encodeFinish = rav1eCodecEncodeFinish;
+    codec->destroyInternal = rav1eCodecDestroyInternal;
+
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(struct avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    return codec;
+}
diff --git a/third_party/libavif/src/src/codec_svt.c b/third_party/libavif/src/src/codec_svt.c
new file mode 100644
index 0000000000..193f244a1e
--- /dev/null
+++ b/third_party/libavif/src/src/codec_svt.c
@@ -0,0 +1,397 @@
+// Copyright 2020 Cloudinary. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include "svt-av1/EbSvtAv1.h"
+
+#include "svt-av1/EbSvtAv1Enc.h"
+
+#include <stdint.h>
+#include <string.h>
+
+// The SVT_AV1_VERSION_MAJOR, SVT_AV1_VERSION_MINOR, SVT_AV1_VERSION_PATCHLEVEL, and
+// SVT_AV1_CHECK_VERSION macros were added in SVT-AV1 v0.9.0. Define these macros for older
+// versions of SVT-AV1.
+#ifndef SVT_AV1_VERSION_MAJOR
+#define SVT_AV1_VERSION_MAJOR SVT_VERSION_MAJOR
+#define SVT_AV1_VERSION_MINOR SVT_VERSION_MINOR
+#define SVT_AV1_VERSION_PATCHLEVEL SVT_VERSION_PATCHLEVEL
+// clang-format off
+#define SVT_AV1_CHECK_VERSION(major, minor, patch)                            \
+    (SVT_AV1_VERSION_MAJOR > (major) ||                                       \
+     (SVT_AV1_VERSION_MAJOR == (major) && SVT_AV1_VERSION_MINOR > (minor)) || \
+     (SVT_AV1_VERSION_MAJOR == (major) && SVT_AV1_VERSION_MINOR == (minor) && \
+      SVT_AV1_VERSION_PATCHLEVEL >= (patch)))
+// clang-format on
+#endif
+
+#if !SVT_AV1_CHECK_VERSION(0, 9, 0)
+#define STR_HELPER(x) #x
+#define STR(x) STR_HELPER(x)
+#define SVT_FULL_VERSION "v" STR(SVT_AV1_VERSION_MAJOR) "." STR(SVT_AV1_VERSION_MINOR) "." STR(SVT_AV1_VERSION_PATCHLEVEL)
+#endif
+
+typedef struct avifCodecInternal
+{
+    /* SVT-AV1 Encoder Handle */
+    EbComponentType * svt_encoder;
+
+    EbSvtAv1EncConfiguration svt_config;
+} avifCodecInternal;
+
+static avifBool allocate_svt_buffers(EbBufferHeaderType ** input_buf);
+static avifResult dequeue_frame(avifCodec * codec, avifCodecEncodeOutput * output, avifBool done_sending_pics);
+
+static avifResult svtCodecEncodeImage(avifCodec * codec,
+                                      avifEncoder * encoder,
+                                      const avifImage * image,
+                                      avifBool alpha,
+                                      int tileRowsLog2,
+                                      int tileColsLog2,
+                                      int quantizer,
+                                      avifEncoderChanges encoderChanges,
+                                      avifBool disableLaggedOutput,
+                                      uint32_t addImageFlags,
+                                      avifCodecEncodeOutput * output)
+{
+    // SVT-AV1 does not support changing encoder settings.
+    if (encoderChanges) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // SVT-AV1 does not support changing image dimensions.
+    if (codec->internal->svt_encoder != NULL) {
+        if ((codec->internal->svt_config.source_width != image->width) || (codec->internal->svt_config.source_height != image->height)) {
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+    }
+
+    // SVT-AV1 does not support encoding layered image.
+    if (encoder->extraLayerCount > 0) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // SVT-AV1 does not support disabling lagged output. Ignore this setting.
+    (void)disableLaggedOutput;
+
+    avifResult result = AVIF_RESULT_UNKNOWN_ERROR;
+    EbColorFormat color_format = EB_YUV420;
+    uint8_t * uvPlanes = NULL; // 4:2:0 U and V placeholder for alpha because SVT-AV1 does not support 4:0:0.
+    EbBufferHeaderType * input_buffer = NULL;
+    EbErrorType res = EB_ErrorNone;
+
+    int y_shift = 0;
+    EbColorRange svt_range;
+    if (alpha) {
+        svt_range = EB_CR_FULL_RANGE;
+        y_shift = 1;
+    } else {
+        svt_range = (image->yuvRange == AVIF_RANGE_FULL) ? EB_CR_FULL_RANGE : EB_CR_STUDIO_RANGE;
+        switch (image->yuvFormat) {
+            case AVIF_PIXEL_FORMAT_YUV444:
+                color_format = EB_YUV444;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV422:
+                color_format = EB_YUV422;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV420:
+                color_format = EB_YUV420;
+                y_shift = 1;
+                break;
+            case AVIF_PIXEL_FORMAT_YUV400:
+                // Setting color_format = EB_YUV400; results in "Svt[error]: Instance 1: Only support 420 now".
+            case AVIF_PIXEL_FORMAT_NONE:
+            case AVIF_PIXEL_FORMAT_COUNT:
+            default:
+                return AVIF_RESULT_UNKNOWN_ERROR;
+        }
+    }
+
+    if (codec->internal->svt_encoder == NULL) {
+        EbSvtAv1EncConfiguration * svt_config = &codec->internal->svt_config;
+        // Zero-initialize svt_config because svt_av1_enc_init_handle() does not set many fields of svt_config.
+        // See https://gitlab.com/AOMediaCodec/SVT-AV1/-/issues/1697.
+        memset(svt_config, 0, sizeof(EbSvtAv1EncConfiguration));
+
+        res = svt_av1_enc_init_handle(&codec->internal->svt_encoder, NULL, svt_config);
+        if (res != EB_ErrorNone) {
+            goto cleanup;
+        }
+        svt_config->encoder_color_format = color_format;
+        svt_config->encoder_bit_depth = (uint8_t)image->depth;
+        svt_config->color_range = svt_range;
+#if !SVT_AV1_CHECK_VERSION(0, 9, 0)
+        svt_config->is_16bit_pipeline = image->depth > 8;
+#endif
+
+        // Follow comment in svt header: set if input is HDR10 BT2020 using SMPTE ST2084 (PQ).
+        svt_config->high_dynamic_range_input = (image->depth == 10 && image->colorPrimaries == AVIF_COLOR_PRIMARIES_BT2020 &&
+                                                image->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_SMPTE2084 &&
+                                                image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_BT2020_NCL);
+
+        svt_config->source_width = image->width;
+        svt_config->source_height = image->height;
+        svt_config->logical_processors = encoder->maxThreads;
+        svt_config->enable_adaptive_quantization = 2;
+        // disable 2-pass
+#if SVT_AV1_CHECK_VERSION(0, 9, 0)
+        svt_config->rc_stats_buffer = (SvtAv1FixedBuf) { NULL, 0 };
+#else
+        svt_config->rc_firstpass_stats_out = AVIF_FALSE;
+        svt_config->rc_twopass_stats_in = (SvtAv1FixedBuf) { NULL, 0 };
+#endif
+
+        svt_config->rate_control_mode = 0; // CRF because enable_adaptive_quantization is 2
+        if (alpha) {
+            svt_config->min_qp_allowed = AVIF_CLAMP(encoder->minQuantizerAlpha, 0, 63);
+            svt_config->max_qp_allowed = AVIF_CLAMP(encoder->maxQuantizerAlpha, 0, 63);
+        } else {
+            svt_config->min_qp_allowed = AVIF_CLAMP(encoder->minQuantizer, 0, 63);
+            svt_config->max_qp_allowed = AVIF_CLAMP(encoder->maxQuantizer, 0, 63);
+        }
+        svt_config->qp = quantizer;
+
+        if (tileRowsLog2 != 0) {
+            svt_config->tile_rows = tileRowsLog2;
+        }
+        if (tileColsLog2 != 0) {
+            svt_config->tile_columns = tileColsLog2;
+        }
+        if (encoder->speed != AVIF_SPEED_DEFAULT) {
+#if SVT_AV1_CHECK_VERSION(0, 9, 0)
+            svt_config->enc_mode = (int8_t)encoder->speed;
+#else
+            int speed = AVIF_CLAMP(encoder->speed, 0, 8);
+            svt_config->enc_mode = (int8_t)speed;
+#endif
+        }
+
+        if (color_format == EB_YUV422 || image->depth > 10) {
+            svt_config->profile = PROFESSIONAL_PROFILE;
+        } else if (color_format == EB_YUV444) {
+            svt_config->profile = HIGH_PROFILE;
+        }
+
+        // In order for SVT-AV1 to force keyframes by setting pic_type to
+        // EB_AV1_KEY_PICTURE on any frame, force_key_frames has to be set.
+        svt_config->force_key_frames = TRUE;
+
+        // keyframeInterval == 1 case is handled when encoding each frame by
+        // setting pic_type to EB_AV1_KEY_PICTURE. For keyframeInterval > 1,
+        // set the intra_period_length. Even though setting intra_period_length
+        // to 0 should work in this case, it does not.
+        if (encoder->keyframeInterval > 1) {
+            svt_config->intra_period_length = encoder->keyframeInterval - 1;
+        }
+
+#if SVT_AV1_CHECK_VERSION(0, 9, 1)
+        for (uint32_t i = 0; i < codec->csOptions->count; ++i) {
+            avifCodecSpecificOption * entry = &codec->csOptions->entries[i];
+            if (svt_av1_enc_parse_parameter(svt_config, entry->key, entry->value) < 0) {
+                avifDiagnosticsPrintf(codec->diag, "Invalid value for %s: %s.", entry->key, entry->value);
+                result = AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+                goto cleanup;
+            }
+        }
+#else
+        if (codec->csOptions->count > 0) {
+            avifDiagnosticsPrintf(codec->diag, "SVT-AV1 does not support setting options");
+            result = AVIF_RESULT_INVALID_CODEC_SPECIFIC_OPTION;
+            goto cleanup;
+        }
+#endif
+
+        res = svt_av1_enc_set_parameter(codec->internal->svt_encoder, svt_config);
+        if (res == EB_ErrorBadParameter) {
+            goto cleanup;
+        }
+
+        res = svt_av1_enc_init(codec->internal->svt_encoder);
+        if (res != EB_ErrorNone) {
+            goto cleanup;
+        }
+    }
+
+    if (!allocate_svt_buffers(&input_buffer)) {
+        goto cleanup;
+    }
+    EbSvtIOFormat * input_picture_buffer = (EbSvtIOFormat *)input_buffer->p_buffer;
+
+    const uint32_t bytesPerPixel = image->depth > 8 ? 2 : 1;
+    const uint32_t uvHeight = (image->height + y_shift) >> y_shift;
+    if (alpha) {
+        input_picture_buffer->y_stride = image->alphaRowBytes / bytesPerPixel;
+        input_picture_buffer->luma = image->alphaPlane;
+        input_buffer->n_filled_len = image->alphaRowBytes * image->height;
+
+#if SVT_AV1_CHECK_VERSION(1, 8, 0)
+        // Simulate 4:2:0 UV planes. SVT-AV1 does not support 4:0:0 samples.
+        const uint32_t uvWidth = (image->width + y_shift) >> y_shift;
+        const uint32_t uvRowBytes = uvWidth * bytesPerPixel;
+        const uint32_t uvSize = uvRowBytes * uvHeight;
+        uvPlanes = avifAlloc(uvSize);
+        if (uvPlanes == NULL) {
+            goto cleanup;
+        }
+        memset(uvPlanes, 0, uvSize);
+        input_picture_buffer->cb = uvPlanes;
+        input_buffer->n_filled_len += uvSize;
+        input_picture_buffer->cr = uvPlanes;
+        input_buffer->n_filled_len += uvSize;
+        input_picture_buffer->cb_stride = uvWidth;
+        input_picture_buffer->cr_stride = uvWidth;
+#else
+        // This workaround was not needed before SVT-AV1 1.8.0.
+        // See https://github.com/AOMediaCodec/libavif/issues/1992.
+        (void)uvPlanes;
+#endif
+    } else {
+        input_picture_buffer->y_stride = image->yuvRowBytes[0] / bytesPerPixel;
+        input_picture_buffer->luma = image->yuvPlanes[0];
+        input_buffer->n_filled_len = image->yuvRowBytes[0] * image->height;
+        input_picture_buffer->cb = image->yuvPlanes[1];
+        input_buffer->n_filled_len += image->yuvRowBytes[1] * uvHeight;
+        input_picture_buffer->cr = image->yuvPlanes[2];
+        input_buffer->n_filled_len += image->yuvRowBytes[2] * uvHeight;
+        input_picture_buffer->cb_stride = image->yuvRowBytes[1] / bytesPerPixel;
+        input_picture_buffer->cr_stride = image->yuvRowBytes[2] / bytesPerPixel;
+    }
+
+    input_buffer->flags = 0;
+    input_buffer->pts = 0;
+
+    EbAv1PictureType frame_type = EB_AV1_INVALID_PICTURE;
+    if ((addImageFlags & AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME) || (encoder->keyframeInterval == 1)) {
+        frame_type = EB_AV1_KEY_PICTURE;
+    }
+    input_buffer->pic_type = frame_type;
+
+    res = svt_av1_enc_send_picture(codec->internal->svt_encoder, input_buffer);
+    if (res != EB_ErrorNone) {
+        goto cleanup;
+    }
+
+    result = dequeue_frame(codec, output, AVIF_FALSE);
+cleanup:
+    if (uvPlanes) {
+        avifFree(uvPlanes);
+    }
+    if (input_buffer) {
+        if (input_buffer->p_buffer) {
+            avifFree(input_buffer->p_buffer);
+        }
+        avifFree(input_buffer);
+    }
+    return result;
+}
+
+static avifBool svtCodecEncodeFinish(avifCodec * codec, avifCodecEncodeOutput * output)
+{
+    EbErrorType ret = EB_ErrorNone;
+
+    EbBufferHeaderType input_buffer;
+    input_buffer.n_alloc_len = 0;
+    input_buffer.n_filled_len = 0;
+    input_buffer.n_tick_count = 0;
+    input_buffer.p_app_private = NULL;
+    input_buffer.flags = EB_BUFFERFLAG_EOS;
+    input_buffer.p_buffer = NULL;
+    input_buffer.metadata = NULL;
+
+    // flush
+    ret = svt_av1_enc_send_picture(codec->internal->svt_encoder, &input_buffer);
+
+    if (ret != EB_ErrorNone)
+        return AVIF_FALSE;
+
+    return (dequeue_frame(codec, output, AVIF_TRUE) == AVIF_RESULT_OK);
+}
+
+const char * avifCodecVersionSvt(void)
+{
+#if SVT_AV1_CHECK_VERSION(0, 9, 0)
+    return svt_av1_get_version();
+#else
+    return SVT_FULL_VERSION;
+#endif
+}
+
+static void svtCodecDestroyInternal(avifCodec * codec)
+{
+    if (codec->internal->svt_encoder) {
+        svt_av1_enc_deinit(codec->internal->svt_encoder);
+        svt_av1_enc_deinit_handle(codec->internal->svt_encoder);
+        codec->internal->svt_encoder = NULL;
+    }
+    avifFree(codec->internal);
+}
+
+avifCodec * avifCodecCreateSvt(void)
+{
+    avifCodec * codec = (avifCodec *)avifAlloc(sizeof(avifCodec));
+    if (codec == NULL) {
+        return NULL;
+    }
+    memset(codec, 0, sizeof(struct avifCodec));
+    codec->encodeImage = svtCodecEncodeImage;
+    codec->encodeFinish = svtCodecEncodeFinish;
+    codec->destroyInternal = svtCodecDestroyInternal;
+
+    codec->internal = (struct avifCodecInternal *)avifAlloc(sizeof(avifCodecInternal));
+    if (codec->internal == NULL) {
+        avifFree(codec);
+        return NULL;
+    }
+    memset(codec->internal, 0, sizeof(struct avifCodecInternal));
+    return codec;
+}
+
+static avifBool allocate_svt_buffers(EbBufferHeaderType ** input_buf)
+{
+    *input_buf = avifAlloc(sizeof(EbBufferHeaderType));
+    if (!(*input_buf)) {
+        return AVIF_FALSE;
+    }
+    (*input_buf)->p_buffer = avifAlloc(sizeof(EbSvtIOFormat));
+    if (!(*input_buf)->p_buffer) {
+        return AVIF_FALSE;
+    }
+    memset((*input_buf)->p_buffer, 0, sizeof(EbSvtIOFormat));
+    (*input_buf)->size = sizeof(EbBufferHeaderType);
+    (*input_buf)->p_app_private = NULL;
+    (*input_buf)->pic_type = EB_AV1_INVALID_PICTURE;
+    (*input_buf)->metadata = NULL;
+
+    return AVIF_TRUE;
+}
+
+static avifResult dequeue_frame(avifCodec * codec, avifCodecEncodeOutput * output, avifBool done_sending_pics)
+{
+    EbErrorType res;
+    int encode_at_eos = 0;
+
+    do {
+        EbBufferHeaderType * output_buf = NULL;
+
+        res = svt_av1_enc_get_packet(codec->internal->svt_encoder, &output_buf, (uint8_t)done_sending_pics);
+        if (output_buf != NULL) {
+            encode_at_eos = ((output_buf->flags & EB_BUFFERFLAG_EOS) == EB_BUFFERFLAG_EOS);
+            if (output_buf->p_buffer && (output_buf->n_filled_len > 0)) {
+                const avifResult result = avifCodecEncodeOutputAddSample(output,
+                                                                         output_buf->p_buffer,
+                                                                         output_buf->n_filled_len,
+                                                                         (output_buf->pic_type == EB_AV1_KEY_PICTURE));
+                if (result != AVIF_RESULT_OK) {
+                    svt_av1_enc_release_out_buffer(&output_buf);
+                    return result;
+                }
+            }
+            svt_av1_enc_release_out_buffer(&output_buf);
+        }
+        output_buf = NULL;
+    } while (res == EB_ErrorNone && !encode_at_eos);
+    if (!done_sending_pics && ((res == EB_ErrorNone) || (res == EB_NoErrorEmptyQueue)))
+        return AVIF_RESULT_OK;
+    return (res == EB_ErrorNone ? AVIF_RESULT_OK : AVIF_RESULT_UNKNOWN_ERROR);
+}
diff --git a/third_party/libavif/src/src/colr.c b/third_party/libavif/src/src/colr.c
new file mode 100644
index 0000000000..71d66915f1
--- /dev/null
+++ b/third_party/libavif/src/src/colr.c
@@ -0,0 +1,534 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <float.h>
+#include <math.h>
+#include <string.h>
+
+struct avifColorPrimariesTable
+{
+    avifColorPrimaries colorPrimariesEnum;
+    const char * name;
+    float primaries[8]; // rX, rY, gX, gY, bX, bY, wX, wY
+};
+static const struct avifColorPrimariesTable avifColorPrimariesTables[] = {
+    { AVIF_COLOR_PRIMARIES_BT709, "BT.709", { 0.64f, 0.33f, 0.3f, 0.6f, 0.15f, 0.06f, 0.3127f, 0.329f } },
+    { AVIF_COLOR_PRIMARIES_BT470M, "BT.470-6 System M", { 0.67f, 0.33f, 0.21f, 0.71f, 0.14f, 0.08f, 0.310f, 0.316f } },
+    { AVIF_COLOR_PRIMARIES_BT470BG, "BT.470-6 System BG", { 0.64f, 0.33f, 0.29f, 0.60f, 0.15f, 0.06f, 0.3127f, 0.3290f } },
+    { AVIF_COLOR_PRIMARIES_BT601, "BT.601", { 0.630f, 0.340f, 0.310f, 0.595f, 0.155f, 0.070f, 0.3127f, 0.3290f } },
+    { AVIF_COLOR_PRIMARIES_SMPTE240, "SMPTE 240M", { 0.630f, 0.340f, 0.310f, 0.595f, 0.155f, 0.070f, 0.3127f, 0.3290f } },
+    { AVIF_COLOR_PRIMARIES_GENERIC_FILM, "Generic film", { 0.681f, 0.319f, 0.243f, 0.692f, 0.145f, 0.049f, 0.310f, 0.316f } },
+    { AVIF_COLOR_PRIMARIES_BT2020, "BT.2020", { 0.708f, 0.292f, 0.170f, 0.797f, 0.131f, 0.046f, 0.3127f, 0.3290f } },
+    { AVIF_COLOR_PRIMARIES_XYZ, "XYZ", { 1.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.3333f, 0.3333f } },
+    { AVIF_COLOR_PRIMARIES_SMPTE431, "SMPTE RP 431-2", { 0.680f, 0.320f, 0.265f, 0.690f, 0.150f, 0.060f, 0.314f, 0.351f } },
+    { AVIF_COLOR_PRIMARIES_SMPTE432, "SMPTE EG 432-1 (DCI P3)", { 0.680f, 0.320f, 0.265f, 0.690f, 0.150f, 0.060f, 0.3127f, 0.3290f } },
+    { AVIF_COLOR_PRIMARIES_EBU3213, "EBU Tech. 3213-E", { 0.630f, 0.340f, 0.295f, 0.605f, 0.155f, 0.077f, 0.3127f, 0.3290f } }
+};
+static const int avifColorPrimariesTableSize = sizeof(avifColorPrimariesTables) / sizeof(avifColorPrimariesTables[0]);
+
+void avifColorPrimariesGetValues(avifColorPrimaries acp, float outPrimaries[8])
+{
+    for (int i = 0; i < avifColorPrimariesTableSize; ++i) {
+        if (avifColorPrimariesTables[i].colorPrimariesEnum == acp) {
+            memcpy(outPrimaries, avifColorPrimariesTables[i].primaries, sizeof(avifColorPrimariesTables[i].primaries));
+            return;
+        }
+    }
+
+    // if we get here, the color primaries are unknown. Just return a reasonable default.
+    memcpy(outPrimaries, avifColorPrimariesTables[0].primaries, sizeof(avifColorPrimariesTables[0].primaries));
+}
+
+static avifBool matchesTo3RoundedPlaces(float a, float b)
+{
+    return (fabsf(a - b) < 0.001f);
+}
+
+static avifBool primariesMatch(const float p1[8], const float p2[8])
+{
+    return matchesTo3RoundedPlaces(p1[0], p2[0]) && matchesTo3RoundedPlaces(p1[1], p2[1]) &&
+           matchesTo3RoundedPlaces(p1[2], p2[2]) && matchesTo3RoundedPlaces(p1[3], p2[3]) && matchesTo3RoundedPlaces(p1[4], p2[4]) &&
+           matchesTo3RoundedPlaces(p1[5], p2[5]) && matchesTo3RoundedPlaces(p1[6], p2[6]) && matchesTo3RoundedPlaces(p1[7], p2[7]);
+}
+
+avifColorPrimaries avifColorPrimariesFind(const float inPrimaries[8], const char ** outName)
+{
+    if (outName) {
+        *outName = NULL;
+    }
+
+    for (int i = 0; i < avifColorPrimariesTableSize; ++i) {
+        if (primariesMatch(inPrimaries, avifColorPrimariesTables[i].primaries)) {
+            if (outName) {
+                *outName = avifColorPrimariesTables[i].name;
+            }
+            return avifColorPrimariesTables[i].colorPrimariesEnum;
+        }
+    }
+    return AVIF_COLOR_PRIMARIES_UNKNOWN;
+}
+
+avifResult avifTransferCharacteristicsGetGamma(avifTransferCharacteristics atc, float * gamma)
+{
+    switch (atc) {
+        case AVIF_TRANSFER_CHARACTERISTICS_BT470M:
+            *gamma = 2.2f;
+            return AVIF_RESULT_OK;
+        case AVIF_TRANSFER_CHARACTERISTICS_BT470BG:
+            *gamma = 2.8f;
+            return AVIF_RESULT_OK;
+        case AVIF_TRANSFER_CHARACTERISTICS_LINEAR:
+            *gamma = 1.0f;
+            return AVIF_RESULT_OK;
+        default:
+            return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+}
+
+avifTransferCharacteristics avifTransferCharacteristicsFindByGamma(float gamma)
+{
+    if (matchesTo3RoundedPlaces(gamma, 2.2f)) {
+        return AVIF_TRANSFER_CHARACTERISTICS_BT470M;
+    } else if (matchesTo3RoundedPlaces(gamma, 1.0f)) {
+        return AVIF_TRANSFER_CHARACTERISTICS_LINEAR;
+    } else if (matchesTo3RoundedPlaces(gamma, 2.8f)) {
+        return AVIF_TRANSFER_CHARACTERISTICS_BT470BG;
+    }
+
+    return AVIF_TRANSFER_CHARACTERISTICS_UNKNOWN;
+}
+
+struct avifMatrixCoefficientsTable
+{
+    avifMatrixCoefficients matrixCoefficientsEnum;
+    const char * name;
+    const float kr;
+    const float kb;
+};
+
+// https://www.itu.int/rec/T-REC-H.273-201612-S
+static const struct avifMatrixCoefficientsTable matrixCoefficientsTables[] = {
+    //{ AVIF_MATRIX_COEFFICIENTS_IDENTITY, "Identity", 0.0f, 0.0f, }, // Handled elsewhere
+    { AVIF_MATRIX_COEFFICIENTS_BT709, "BT.709", 0.2126f, 0.0722f },
+    { AVIF_MATRIX_COEFFICIENTS_FCC, "FCC USFC 73.682", 0.30f, 0.11f },
+    { AVIF_MATRIX_COEFFICIENTS_BT470BG, "BT.470-6 System BG", 0.299f, 0.114f },
+    { AVIF_MATRIX_COEFFICIENTS_BT601, "BT.601", 0.299f, 0.114f },
+    { AVIF_MATRIX_COEFFICIENTS_SMPTE240, "SMPTE ST 240", 0.212f, 0.087f },
+    //{ AVIF_MATRIX_COEFFICIENTS_YCGCO, "YCgCo", 0.0f, 0.0f, }, // Handled elsewhere
+    { AVIF_MATRIX_COEFFICIENTS_BT2020_NCL, "BT.2020 (non-constant luminance)", 0.2627f, 0.0593f },
+    //{ AVIF_MATRIX_COEFFICIENTS_BT2020_CL, "BT.2020 (constant luminance)", 0.2627f, 0.0593f }, // FIXME: It is not an linear transformation.
+    //{ AVIF_MATRIX_COEFFICIENTS_SMPTE2085, "ST 2085", 0.0f, 0.0f }, // FIXME: ST2085 can't represent using Kr and Kb.
+    //{ AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL, "Chromaticity-derived constant luminance system", 0.0f, 0.0f } // FIXME: It is not an linear transformation.
+    //{ AVIF_MATRIX_COEFFICIENTS_ICTCP, "BT.2100-0 ICtCp", 0.0f, 0.0f }, // FIXME: This can't represent using Kr and Kb.
+};
+
+static const int avifMatrixCoefficientsTableSize = sizeof(matrixCoefficientsTables) / sizeof(matrixCoefficientsTables[0]);
+
+static avifBool calcYUVInfoFromCICP(const avifImage * image, float coeffs[3])
+{
+    if (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_NCL) {
+        avifColorPrimariesComputeYCoeffs(image->colorPrimaries, coeffs);
+        return AVIF_TRUE;
+    } else {
+        for (int i = 0; i < avifMatrixCoefficientsTableSize; ++i) {
+            const struct avifMatrixCoefficientsTable * const table = &matrixCoefficientsTables[i];
+            if (table->matrixCoefficientsEnum == image->matrixCoefficients) {
+                coeffs[0] = table->kr;
+                coeffs[2] = table->kb;
+                coeffs[1] = 1.0f - coeffs[0] - coeffs[2];
+                return AVIF_TRUE;
+            }
+        }
+    }
+    return AVIF_FALSE;
+}
+
+void avifCalcYUVCoefficients(const avifImage * image, float * outR, float * outG, float * outB)
+{
+    // (As of ISO/IEC 23000-22:2019 Amendment 2)
+    // MIAF Section 7.3.6.4 "Colour information property":
+    //
+    // If a coded image has no associated colour property, the default property is defined as having
+    // colour_type equal to 'nclx' with properties as follows:
+    // -   colour_primaries equal to 1,
+    // -   transfer_characteristics equal to 13,
+    // -   matrix_coefficients equal to 5 or 6 (which are functionally identical), and
+    // -   full_range_flag equal to 1.
+    // Only if the colour information property of the image matches these default values, the colour
+    // property may be omitted; all other images shall have an explicitly declared colour space via
+    // association with a property of this type.
+    //
+    // See here for the discussion: https://github.com/AOMediaCodec/av1-avif/issues/77#issuecomment-676526097
+
+    // matrix_coefficients of [5,6] == BT.601:
+    float kr = 0.299f;
+    float kb = 0.114f;
+    float kg = 1.0f - kr - kb;
+
+    float coeffs[3];
+    if (calcYUVInfoFromCICP(image, coeffs)) {
+        kr = coeffs[0];
+        kg = coeffs[1];
+        kb = coeffs[2];
+    }
+
+    *outR = kr;
+    *outG = kg;
+    *outB = kb;
+}
+
+// ---------------------------------------------------------------------------
+// Transfer characteristics
+//
+// Transfer characteristics are defined in ITU-T H.273 https://www.itu.int/rec/T-REC-H.273-201612-S/en
+// with formulas for linear to gamma conversion in Table 3.
+// This is based on tongyuantongyu's implementation in https://github.com/AOMediaCodec/libavif/pull/444
+// with some fixes/changes in the first commit:
+// - Fixed 5 transfer curves where toLinear and toGamma functions were swapped (470M, 470BG, Log100,
+//   Log100Sqrt10 and SMPTE428)
+// - 'avifToLinearLog100' and 'avifToLinearLog100Sqrt10' were modified to return the middle of the
+//   range of linear values that are gamma-encoded to 0.0 in order to reduce the max round trip error,
+//   based on vrabaud's change in
+//   https://chromium.googlesource.com/webm/libwebp/+/25d94f473b10882b8bee9288d00539001b692042
+// - In this file, PQ and HLG return "extended SDR" linear values in [0.0, 10000/203] and
+//   [0.0, 1000/203] respectively, where a value of 1.0 means SDR white brightness (203 nits), and any
+//   value above 1.0 is brigther.
+// See git history for further changes.
+
+struct avifTransferCharacteristicsTable
+{
+    avifTransferCharacteristics transferCharacteristicsEnum;
+    const char * name;
+    avifTransferFunction toLinear;
+    avifTransferFunction toGamma;
+};
+
+static float avifToLinear709(float gamma)
+{
+    if (gamma < 0.0f) {
+        return 0.0f;
+    } else if (gamma < 4.5f * 0.018053968510807f) {
+        return gamma / 4.5f;
+    } else if (gamma < 1.0f) {
+        return powf((gamma + 0.09929682680944f) / 1.09929682680944f, 1.0f / 0.45f);
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToGamma709(float linear)
+{
+    if (linear < 0.0f) {
+        return 0.0f;
+    } else if (linear < 0.018053968510807f) {
+        return linear * 4.5f;
+    } else if (linear < 1.0f) {
+        return 1.09929682680944f * powf(linear, 0.45f) - 0.09929682680944f;
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToLinear470M(float gamma)
+{
+    return powf(AVIF_CLAMP(gamma, 0.0f, 1.0f), 2.2f);
+}
+
+static float avifToGamma470M(float linear)
+{
+    return powf(AVIF_CLAMP(linear, 0.0f, 1.0f), 1.0f / 2.2f);
+}
+
+static float avifToLinear470BG(float gamma)
+{
+    return powf(AVIF_CLAMP(gamma, 0.0f, 1.0f), 2.8f);
+}
+
+static float avifToGamma470BG(float linear)
+{
+    return powf(AVIF_CLAMP(linear, 0.0f, 1.0f), 1.0f / 2.8f);
+}
+
+static float avifToLinearSMPTE240(float gamma)
+{
+    if (gamma < 0.0f) {
+        return 0.0f;
+    } else if (gamma < 4.0f * 0.022821585529445f) {
+        return gamma / 4.0f;
+    } else if (gamma < 1.0f) {
+        return powf((gamma + 0.111572195921731f) / 1.111572195921731f, 1.0f / 0.45f);
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToGammaSMPTE240(float linear)
+{
+    if (linear < 0.0f) {
+        return 0.0f;
+    } else if (linear < 0.022821585529445f) {
+        return linear * 4.0f;
+    } else if (linear < 1.0f) {
+        return 1.111572195921731f * powf(linear, 0.45f) - 0.111572195921731f;
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToGammaLinear(float gamma)
+{
+    return AVIF_CLAMP(gamma, 0.0f, 1.0f);
+}
+
+static float avifToLinearLog100(float gamma)
+{
+    // The function is non-bijective so choose the middle of [0, 0.01].
+    const float mid_interval = 0.01f / 2.f;
+    return (gamma <= 0.0f) ? mid_interval : powf(10.0f, 2.f * (AVIF_MIN(gamma, 1.f) - 1.0f));
+}
+
+static float avifToGammaLog100(float linear)
+{
+    return linear <= 0.01f ? 0.0f : 1.0f + log10f(AVIF_MIN(linear, 1.0f)) / 2.0f;
+}
+
+static float avifToLinearLog100Sqrt10(float gamma)
+{
+    // The function is non-bijective so choose the middle of [0, 0.00316227766f].
+    const float mid_interval = 0.00316227766f / 2.f;
+    return (gamma <= 0.0f) ? mid_interval : powf(10.0f, 2.5f * (AVIF_MIN(gamma, 1.f) - 1.0f));
+}
+
+static float avifToGammaLog100Sqrt10(float linear)
+{
+    return linear <= 0.00316227766f ? 0.0f : 1.0f + log10f(AVIF_MIN(linear, 1.0f)) / 2.5f;
+}
+
+static float avifToLinearIEC61966(float gamma)
+{
+    if (gamma < -4.5f * 0.018053968510807f) {
+        return powf((-gamma + 0.09929682680944f) / -1.09929682680944f, 1.0f / 0.45f);
+    } else if (gamma < 4.5f * 0.018053968510807f) {
+        return gamma / 4.5f;
+    } else {
+        return powf((gamma + 0.09929682680944f) / 1.09929682680944f, 1.0f / 0.45f);
+    }
+}
+
+static float avifToGammaIEC61966(float linear)
+{
+    if (linear < -0.018053968510807f) {
+        return -1.09929682680944f * powf(-linear, 0.45f) + 0.09929682680944f;
+    } else if (linear < 0.018053968510807f) {
+        return linear * 4.5f;
+    } else {
+        return 1.09929682680944f * powf(linear, 0.45f) - 0.09929682680944f;
+    }
+}
+
+static float avifToLinearBT1361(float gamma)
+{
+    if (gamma < -0.25f) {
+        return -0.25f;
+    } else if (gamma < 0.0f) {
+        return powf((gamma - 0.02482420670236f) / -0.27482420670236f, 1.0f / 0.45f) / -4.0f;
+    } else if (gamma < 4.5f * 0.018053968510807f) {
+        return gamma / 4.5f;
+    } else if (gamma < 1.0f) {
+        return powf((gamma + 0.09929682680944f) / 1.09929682680944f, 1.0f / 0.45f);
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToGammaBT1361(float linear)
+{
+    if (linear < -0.25f) {
+        return -0.25f;
+    } else if (linear < 0.0f) {
+        return -0.27482420670236f * powf(-4.0f * linear, 0.45f) + 0.02482420670236f;
+    } else if (linear < 0.018053968510807f) {
+        return linear * 4.5f;
+    } else if (linear < 1.0f) {
+        return 1.09929682680944f * powf(linear, 0.45f) - 0.09929682680944f;
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToLinearSRGB(float gamma)
+{
+    if (gamma < 0.0f) {
+        return 0.0f;
+    } else if (gamma < 12.92f * 0.0030412825601275209f) {
+        return gamma / 12.92f;
+    } else if (gamma < 1.0f) {
+        return powf((gamma + 0.0550107189475866f) / 1.0550107189475866f, 2.4f);
+    } else {
+        return 1.0f;
+    }
+}
+
+static float avifToGammaSRGB(float linear)
+{
+    if (linear < 0.0f) {
+        return 0.0f;
+    } else if (linear < 0.0030412825601275209f) {
+        return linear * 12.92f;
+    } else if (linear < 1.0f) {
+        return 1.0550107189475866f * powf(linear, 1.0f / 2.4f) - 0.0550107189475866f;
+    } else {
+        return 1.0f;
+    }
+}
+
+#define PQ_MAX_NITS 10000.0f
+#define HLG_PEAK_LUMINANCE_NITS 1000.0f
+#define SDR_WHITE_NITS 203.0f
+
+static float avifToLinearPQ(float gamma)
+{
+    if (gamma > 0.0f) {
+        const float powGamma = powf(gamma, 1.0f / 78.84375f);
+        const float num = AVIF_MAX(powGamma - 0.8359375f, 0.0f);
+        const float den = AVIF_MAX(18.8515625f - 18.6875f * powGamma, FLT_MIN);
+        const float linear = powf(num / den, 1.0f / 0.1593017578125f);
+        // Scale so that SDR white is 1.0 (extended SDR).
+        return linear * PQ_MAX_NITS / SDR_WHITE_NITS;
+    } else {
+        return 0.0f;
+    }
+}
+
+static float avifToGammaPQ(float linear)
+{
+    if (linear > 0.0f) {
+        // Scale from extended SDR range to [0.0, 1.0].
+        linear = AVIF_CLAMP(linear * SDR_WHITE_NITS / PQ_MAX_NITS, 0.0f, 1.0f);
+        const float powLinear = powf(linear, 0.1593017578125f);
+        const float num = 0.1640625f * powLinear - 0.1640625f;
+        const float den = 1.0f + 18.6875f * powLinear;
+        return powf(1.0f + num / den, 78.84375f);
+    } else {
+        return 0.0f;
+    }
+}
+
+static float avifToLinearSMPTE428(float gamma)
+{
+    return powf(AVIF_MAX(gamma, 0.0f), 2.6f) / 0.91655527974030934f;
+}
+
+static float avifToGammaSMPTE428(float linear)
+{
+    return powf(0.91655527974030934f * AVIF_MAX(linear, 0.0f), 1.0f / 2.6f);
+}
+
+// Formula from ITU-R BT.2100-2
+// Assumes Lw=1000 (max display luminance in nits).
+// For simplicity, approximates Ys (which should be 0.2627*r+0.6780*g+0.0593*b)
+// to the input value (r, g, or b depending on the current channel).
+static float avifToLinearHLG(float gamma)
+{
+    // Inverse OETF followed by the OOTF, see Table 5 in ITU-R BT.2100-2 page 7.
+    // Note that this differs slightly from  ITU-T H.273 which doesn't use the OOTF.
+    if (gamma < 0.0f) {
+        return 0.0f;
+    }
+    float linear = 0.0f;
+    if (gamma <= 0.5f) {
+        linear = powf((gamma * gamma) * (1.0f / 3.0f), 1.2f);
+    } else {
+        linear = powf((expf((gamma - 0.55991073f) / 0.17883277f) + 0.28466892f) / 12.0f, 1.2f);
+    }
+    // Scale so that SDR white is 1.0 (extended SDR).
+    return linear * HLG_PEAK_LUMINANCE_NITS / SDR_WHITE_NITS;
+}
+
+static float avifToGammaHLG(float linear)
+{
+    // Scale from extended SDR range to [0.0, 1.0].
+    linear = AVIF_CLAMP(linear * SDR_WHITE_NITS / HLG_PEAK_LUMINANCE_NITS, 0.0f, 1.0f);
+    // Inverse OOTF followed by OETF see Table 5 and Note 5i in ITU-R BT.2100-2 page 7-8.
+    linear = powf(linear, 1.0f / 1.2f);
+    if (linear < 0.0f) {
+        return 0.0f;
+    } else if (linear <= (1.0f / 12.0f)) {
+        return sqrtf(3.0f * linear);
+    } else {
+        return 0.17883277f * logf(12.0f * linear - 0.28466892f) + 0.55991073f;
+    }
+}
+
+static const struct avifTransferCharacteristicsTable transferCharacteristicsTables[] = {
+    { AVIF_TRANSFER_CHARACTERISTICS_BT709, "BT.709", avifToLinear709, avifToGamma709 },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT470M, "BT.470-6 System M", avifToLinear470M, avifToGamma470M },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT470BG, "BT.470-6 System BG", avifToLinear470BG, avifToGamma470BG },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT601, "BT.601", avifToLinear709, avifToGamma709 },
+    { AVIF_TRANSFER_CHARACTERISTICS_SMPTE240, "SMPTE 240M", avifToLinearSMPTE240, avifToGammaSMPTE240 },
+    { AVIF_TRANSFER_CHARACTERISTICS_LINEAR, "Linear", avifToGammaLinear, avifToGammaLinear },
+    { AVIF_TRANSFER_CHARACTERISTICS_LOG100, "100:1 Log", avifToLinearLog100, avifToGammaLog100 },
+    { AVIF_TRANSFER_CHARACTERISTICS_LOG100_SQRT10, "100sqrt(10):1 Log", avifToLinearLog100Sqrt10, avifToGammaLog100Sqrt10 },
+    { AVIF_TRANSFER_CHARACTERISTICS_IEC61966, "IEC 61966-2-4", avifToLinearIEC61966, avifToGammaIEC61966 },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT1361, "BT.1361", avifToLinearBT1361, avifToGammaBT1361 },
+    { AVIF_TRANSFER_CHARACTERISTICS_SRGB, "sRGB", avifToLinearSRGB, avifToGammaSRGB },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT2020_10BIT, "10bit BT.2020", avifToLinear709, avifToGamma709 },
+    { AVIF_TRANSFER_CHARACTERISTICS_BT2020_12BIT, "12bit BT.2020", avifToLinear709, avifToGamma709 },
+    { AVIF_TRANSFER_CHARACTERISTICS_SMPTE2084, "SMPTE ST 2084 (PQ)", avifToLinearPQ, avifToGammaPQ },
+    { AVIF_TRANSFER_CHARACTERISTICS_SMPTE428, "SMPTE ST 428-1", avifToLinearSMPTE428, avifToGammaSMPTE428 },
+    { AVIF_TRANSFER_CHARACTERISTICS_HLG, "ARIB STD-B67 (HLG)", avifToLinearHLG, avifToGammaHLG }
+};
+
+static const int avifTransferCharacteristicsTableSize =
+    sizeof(transferCharacteristicsTables) / sizeof(transferCharacteristicsTables[0]);
+
+avifTransferFunction avifTransferCharacteristicsGetGammaToLinearFunction(avifTransferCharacteristics atc)
+{
+    for (int i = 0; i < avifTransferCharacteristicsTableSize; ++i) {
+        const struct avifTransferCharacteristicsTable * const table = &transferCharacteristicsTables[i];
+        if (table->transferCharacteristicsEnum == atc) {
+            return table->toLinear;
+        }
+    }
+    return avifToLinear709; // Provide a reasonable default.
+}
+
+avifTransferFunction avifTransferCharacteristicsGetLinearToGammaFunction(avifTransferCharacteristics atc)
+{
+    for (int i = 0; i < avifTransferCharacteristicsTableSize; ++i) {
+        const struct avifTransferCharacteristicsTable * const table = &transferCharacteristicsTables[i];
+        if (table->transferCharacteristicsEnum == atc) {
+            return table->toGamma;
+        }
+    }
+    return avifToGamma709; // Provide a reasonable default.
+}
+
+void avifColorPrimariesComputeYCoeffs(avifColorPrimaries colorPrimaries, float coeffs[3])
+{
+    float primaries[8];
+    avifColorPrimariesGetValues(colorPrimaries, primaries);
+    float const rX = primaries[0];
+    float const rY = primaries[1];
+    float const gX = primaries[2];
+    float const gY = primaries[3];
+    float const bX = primaries[4];
+    float const bY = primaries[5];
+    float const wX = primaries[6];
+    float const wY = primaries[7];
+    float const rZ = 1.0f - (rX + rY); // (Eq. 34)
+    float const gZ = 1.0f - (gX + gY); // (Eq. 35)
+    float const bZ = 1.0f - (bX + bY); // (Eq. 36)
+    float const wZ = 1.0f - (wX + wY); // (Eq. 37)
+    float const kr = (rY * (wX * (gY * bZ - bY * gZ) + wY * (bX * gZ - gX * bZ) + wZ * (gX * bY - bX * gY))) /
+                     (wY * (rX * (gY * bZ - bY * gZ) + gX * (bY * rZ - rY * bZ) + bX * (rY * gZ - gY * rZ)));
+    // (Eq. 32)
+    float const kb = (bY * (wX * (rY * gZ - gY * rZ) + wY * (gX * rZ - rX * gZ) + wZ * (rX * gY - gX * rY))) /
+                     (wY * (rX * (gY * bZ - bY * gZ) + gX * (bY * rZ - rY * bZ) + bX * (rY * gZ - gY * rZ)));
+    // (Eq. 33)
+    coeffs[0] = kr;
+    coeffs[2] = kb;
+    coeffs[1] = 1.0f - coeffs[0] - coeffs[2];
+}
diff --git a/third_party/libavif/src/src/colrconvert.c b/third_party/libavif/src/src/colrconvert.c
new file mode 100644
index 0000000000..a58f5e94e6
--- /dev/null
+++ b/third_party/libavif/src/src/colrconvert.c
@@ -0,0 +1,186 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <math.h>
+
+static const double epsilon = 1e-12;
+
+static avifBool avifXyToXYZ(const float xy[2], double XYZ[3])
+{
+    if (fabsf(xy[1]) < epsilon) {
+        return AVIF_FALSE;
+    }
+
+    const double factor = 1.0 / xy[1];
+    XYZ[0] = xy[0] * factor;
+    XYZ[1] = 1;
+    XYZ[2] = (1 - xy[0] - xy[1]) * factor;
+
+    return AVIF_TRUE;
+}
+
+// Computes I = M^-1. Returns false if M seems to be singular.
+static avifBool avifMatInv(double M[3][3], double I[3][3])
+{
+    double det = M[0][0] * (M[1][1] * M[2][2] - M[2][1] * M[1][2]) - M[0][1] * (M[1][0] * M[2][2] - M[1][2] * M[2][0]) +
+                 M[0][2] * (M[1][0] * M[2][1] - M[1][1] * M[2][0]);
+    if (fabs(det) < epsilon) {
+        return AVIF_FALSE;
+    }
+    det = 1.0 / det;
+
+    I[0][0] = (M[1][1] * M[2][2] - M[2][1] * M[1][2]) * det;
+    I[0][1] = (M[0][2] * M[2][1] - M[0][1] * M[2][2]) * det;
+    I[0][2] = (M[0][1] * M[1][2] - M[0][2] * M[1][1]) * det;
+    I[1][0] = (M[1][2] * M[2][0] - M[1][0] * M[2][2]) * det;
+    I[1][1] = (M[0][0] * M[2][2] - M[0][2] * M[2][0]) * det;
+    I[1][2] = (M[1][0] * M[0][2] - M[0][0] * M[1][2]) * det;
+    I[2][0] = (M[1][0] * M[2][1] - M[2][0] * M[1][1]) * det;
+    I[2][1] = (M[2][0] * M[0][1] - M[0][0] * M[2][1]) * det;
+    I[2][2] = (M[0][0] * M[1][1] - M[1][0] * M[0][1]) * det;
+
+    return AVIF_TRUE;
+}
+
+// Computes C = A*B
+static void avifMatMul(double A[3][3], double B[3][3], double C[3][3])
+{
+    C[0][0] = A[0][0] * B[0][0] + A[0][1] * B[1][0] + A[0][2] * B[2][0];
+    C[0][1] = A[0][0] * B[0][1] + A[0][1] * B[1][1] + A[0][2] * B[2][1];
+    C[0][2] = A[0][0] * B[0][2] + A[0][1] * B[1][2] + A[0][2] * B[2][2];
+    C[1][0] = A[1][0] * B[0][0] + A[1][1] * B[1][0] + A[1][2] * B[2][0];
+    C[1][1] = A[1][0] * B[0][1] + A[1][1] * B[1][1] + A[1][2] * B[2][1];
+    C[1][2] = A[1][0] * B[0][2] + A[1][1] * B[1][2] + A[1][2] * B[2][2];
+    C[2][0] = A[2][0] * B[0][0] + A[2][1] * B[1][0] + A[2][2] * B[2][0];
+    C[2][1] = A[2][0] * B[0][1] + A[2][1] * B[1][1] + A[2][2] * B[2][1];
+    C[2][2] = A[2][0] * B[0][2] + A[2][1] * B[1][2] + A[2][2] * B[2][2];
+}
+
+// Set M to have values of d on the leading diagonal, and zero elsewhere.
+static void avifMatDiag(const double d[3], double M[3][3])
+{
+    M[0][0] = d[0];
+    M[0][1] = 0;
+    M[0][2] = 0;
+    M[1][0] = 0;
+    M[1][1] = d[1];
+    M[1][2] = 0;
+    M[2][0] = 0;
+    M[2][1] = 0;
+    M[2][2] = d[2];
+}
+
+// Computes y = M.x
+static void avifVecMul(double M[3][3], const double x[3], double y[3])
+{
+    y[0] = M[0][0] * x[0] + M[0][1] * x[1] + M[0][2] * x[2];
+    y[1] = M[1][0] * x[0] + M[1][1] * x[1] + M[1][2] * x[2];
+    y[2] = M[2][0] * x[0] + M[2][1] * x[1] + M[2][2] * x[2];
+}
+
+// Bradford chromatic adaptation matrix
+// from https://www.researchgate.net/publication/253799640_A_uniform_colour_space_based_upon_CIECAM97s
+static double avifBradford[3][3] = {
+    { 0.8951, 0.2664, -0.1614 },
+    { -0.7502, 1.7135, 0.0367 },
+    { 0.0389, -0.0685, 1.0296 },
+};
+
+// LMS values for D50 whitepoint
+static const double avifLmsD50[3] = { 0.996284, 1.02043, 0.818644 };
+
+avifBool avifColorPrimariesComputeRGBToXYZD50Matrix(avifColorPrimaries colorPrimaries, double coeffs[3][3])
+{
+    float primaries[8];
+    avifColorPrimariesGetValues(colorPrimaries, primaries);
+
+    double whitePointXYZ[3];
+    AVIF_CHECK(avifXyToXYZ(&primaries[6], whitePointXYZ));
+
+    double rgbPrimaries[3][3] = {
+        { primaries[0], primaries[2], primaries[4] },
+        { primaries[1], primaries[3], primaries[5] },
+        { 1.0 - primaries[0] - primaries[1], 1.0 - primaries[2] - primaries[3], 1.0 - primaries[4] - primaries[5] }
+    };
+
+    double rgbPrimariesInv[3][3];
+    AVIF_CHECK(avifMatInv(rgbPrimaries, rgbPrimariesInv));
+
+    double rgbCoefficients[3];
+    avifVecMul(rgbPrimariesInv, whitePointXYZ, rgbCoefficients);
+
+    double rgbCoefficientsMat[3][3];
+    avifMatDiag(rgbCoefficients, rgbCoefficientsMat);
+
+    double rgbXYZ[3][3];
+    avifMatMul(rgbPrimaries, rgbCoefficientsMat, rgbXYZ);
+
+    // ICC stores primaries XYZ under PCS.
+    // Adapt using linear bradford transform
+    // from https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119021780.app3
+    double lms[3];
+    avifVecMul(avifBradford, whitePointXYZ, lms);
+    for (int i = 0; i < 3; ++i) {
+        if (fabs(lms[i]) < epsilon) {
+            return AVIF_FALSE;
+        }
+        lms[i] = avifLmsD50[i] / lms[i];
+    }
+
+    double adaptation[3][3];
+    avifMatDiag(lms, adaptation);
+
+    double tmp[3][3];
+    avifMatMul(adaptation, avifBradford, tmp);
+
+    double bradfordInv[3][3];
+    if (!avifMatInv(avifBradford, bradfordInv)) {
+        return AVIF_FALSE;
+    }
+    avifMatMul(bradfordInv, tmp, adaptation);
+
+    avifMatMul(adaptation, rgbXYZ, coeffs);
+
+    return AVIF_TRUE;
+}
+
+avifBool avifColorPrimariesComputeXYZD50ToRGBMatrix(avifColorPrimaries colorPrimaries, double coeffs[3][3])
+{
+    double rgbToXyz[3][3];
+    AVIF_CHECK(avifColorPrimariesComputeRGBToXYZD50Matrix(colorPrimaries, rgbToXyz));
+    AVIF_CHECK(avifMatInv(rgbToXyz, coeffs));
+    return AVIF_TRUE;
+}
+
+avifBool avifColorPrimariesComputeRGBToRGBMatrix(avifColorPrimaries srcColorPrimaries,
+                                                 avifColorPrimaries dstColorPrimaries,
+                                                 double coeffs[3][3])
+{
+    // Note: no special casing for srcColorPrimaries == dstColorPrimaries to allow
+    // testing that the computation actually produces the identity matrix.
+    double srcRGBToXYZ[3][3];
+    AVIF_CHECK(avifColorPrimariesComputeRGBToXYZD50Matrix(srcColorPrimaries, srcRGBToXYZ));
+    double xyzToDstRGB[3][3];
+    AVIF_CHECK(avifColorPrimariesComputeXYZD50ToRGBMatrix(dstColorPrimaries, xyzToDstRGB));
+    // coeffs = xyzToDstRGB * srcRGBToXYZ
+    // i.e. srcRGB -> XYZ -> dstRGB
+    avifMatMul(xyzToDstRGB, srcRGBToXYZ, coeffs);
+    return AVIF_TRUE;
+}
+
+// Converts a linear RGBA pixel to a different color space. This function actually works for gamma encoded
+// RGB as well but linear gives better results. Also, for gamma encoded values, it would be
+// better to clamp the output to [0, 1]. Linear values don't need clamping because values
+// > 1.0 are valid for HDR transfer curves, and the gamma compression function will do the
+// clamping as necessary.
+void avifLinearRGBConvertColorSpace(float rgb[4], double coeffs[3][3])
+{
+    const double rgbDouble[3] = { rgb[0], rgb[1], rgb[2] };
+    double converted[3];
+    avifVecMul(coeffs, rgbDouble, converted);
+    rgb[0] = (float)converted[0];
+    rgb[1] = (float)converted[1];
+    rgb[2] = (float)converted[2];
+}
diff --git a/third_party/libavif/src/src/compliance.cc b/third_party/libavif/src/src/compliance.cc
new file mode 100644
index 0000000000..28ab270be1
--- /dev/null
+++ b/third_party/libavif/src/src/compliance.cc
@@ -0,0 +1,54 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include <cstddef>
+#include <cstdint>
+#include <limits>
+
+#include "avif/internal.h"
+
+// From ../ext/ComplianceWarden/src/utils/
+#include "box_reader_impl.h"
+#include "spec.h"
+
+bool checkComplianceStd(Box const & file, SpecDesc const * spec);
+
+SpecDesc const * specFind(const char * name);
+std::vector<SpecDesc const *> & g_allSpecs();
+extern const SpecDesc * const globalSpecAvif;
+extern const SpecDesc * const globalSpecAv1Hdr10plus;
+extern const SpecDesc * const globalSpecHeif;
+extern const SpecDesc * const globalSpecIsobmff;
+extern const SpecDesc * const globalSpecMiaf;
+
+extern "C" avifResult avifIsCompliant(const uint8_t * data, size_t size)
+{
+    // See compliance_warden.sh.
+    if (g_allSpecs().empty()) {
+        registerSpec(globalSpecAvif);
+        registerSpec(globalSpecAv1Hdr10plus);
+        registerSpec(globalSpecHeif);
+        registerSpec(globalSpecIsobmff);
+        registerSpec(globalSpecMiaf);
+    }
+
+    // Inspired from ext/ComplianceWarden/src/app/cw.cpp
+    BoxReader topReader;
+    for (char sym : { 'f', 'i', 'l', 'e', '.', 'a', 'v', 'i', 'f' }) {
+        // Setting made-up file name (letter by letter).
+        topReader.myBox.syms.push_back({ "filename", static_cast<int64_t>(sym), 8 });
+    }
+    AVIF_CHECKERR(size <= std::numeric_limits<int>::max(), AVIF_RESULT_INVALID_ARGUMENT);
+    topReader.br = { const_cast<uint8_t *>(data), static_cast<int>(size) };
+    topReader.myBox.original = const_cast<uint8_t *>(data);
+    topReader.myBox.position = 0;
+    topReader.myBox.size = size;
+    topReader.myBox.fourcc = FOURCC("root");
+    topReader.specs = { specFind("avif") };
+    AVIF_CHECKERR(topReader.specs[0] != nullptr, AVIF_RESULT_UNKNOWN_ERROR);
+    auto parseFunc = getParseFunction(topReader.myBox.fourcc);
+    parseFunc(&topReader);
+    // gpac/ComplianceWarden will print the formatted result page to stdout, warnings and errors inclusive.
+    AVIF_CHECKERR(!checkComplianceStd(topReader.myBox, topReader.specs[0]), AVIF_RESULT_BMFF_PARSE_FAILED);
+    return AVIF_RESULT_OK;
+}
diff --git a/third_party/libavif/src/src/diag.c b/third_party/libavif/src/src/diag.c
new file mode 100644
index 0000000000..85370188cd
--- /dev/null
+++ b/third_party/libavif/src/src/diag.c
@@ -0,0 +1,34 @@
+// Copyright 2021 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <stdarg.h>
+#include <stdio.h>
+#include <string.h>
+
+void avifDiagnosticsClearError(avifDiagnostics * diag)
+{
+    *diag->error = '\0';
+}
+
+#ifdef __clang__
+__attribute__((__format__(__printf__, 2, 3)))
+#endif
+void avifDiagnosticsPrintf(avifDiagnostics * diag, const char * format, ...)
+{
+    if (!diag) {
+        // It is possible this is NULL (e.g. calls to avifPeekCompatibleFileType())
+        return;
+    }
+    if (*diag->error) {
+        // There is already a detailed error set.
+        return;
+    }
+
+    va_list args;
+    va_start(args, format);
+    vsnprintf(diag->error, AVIF_DIAGNOSTICS_ERROR_BUFFER_SIZE, format, args);
+    diag->error[AVIF_DIAGNOSTICS_ERROR_BUFFER_SIZE - 1] = '\0';
+    va_end(args);
+}
diff --git a/third_party/libavif/src/src/exif.c b/third_party/libavif/src/src/exif.c
new file mode 100644
index 0000000000..dc890602f4
--- /dev/null
+++ b/third_party/libavif/src/src/exif.c
@@ -0,0 +1,200 @@
+// Copyright 2022 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <stdint.h>
+#include <string.h>
+
+avifResult avifGetExifTiffHeaderOffset(const uint8_t * exif, size_t exifSize, size_t * offset)
+{
+    const uint8_t tiffHeaderBE[4] = { 'M', 'M', 0, 42 };
+    const uint8_t tiffHeaderLE[4] = { 'I', 'I', 42, 0 };
+    exifSize = AVIF_MIN(exifSize, UINT32_MAX);
+    for (*offset = 0; *offset + 4 < exifSize; ++*offset) {
+        if (!memcmp(&exif[*offset], tiffHeaderBE, 4) || !memcmp(&exif[*offset], tiffHeaderLE, 4)) {
+            return AVIF_RESULT_OK;
+        }
+    }
+    // Couldn't find the TIFF header
+    return AVIF_RESULT_INVALID_EXIF_PAYLOAD;
+}
+
+// Returns the offset to the Exif 8-bit orientation value and AVIF_RESULT_OK, or an error.
+// If the offset is set to exifSize, there was no parsing error but no orientation tag was found.
+avifResult avifGetExifOrientationOffset(const uint8_t * exif, size_t exifSize, size_t * offset)
+{
+    const avifResult result = avifGetExifTiffHeaderOffset(exif, exifSize, offset);
+    if (result != AVIF_RESULT_OK) {
+        // Couldn't find the TIFF header
+        return result;
+    }
+
+    avifROData raw = { exif + *offset, exifSize - *offset };
+    const avifBool littleEndian = (raw.data[0] == 'I');
+    avifROStream stream;
+    avifROStreamStart(&stream, &raw, NULL, NULL);
+
+    // TIFF Header
+    uint32_t offsetTo0thIfd;
+    if (!avifROStreamSkip(&stream, 4) || // Skip tiffHeaderBE or tiffHeaderLE.
+        !avifROStreamReadU32Endianness(&stream, &offsetTo0thIfd, littleEndian)) {
+        return AVIF_RESULT_INVALID_EXIF_PAYLOAD;
+    }
+
+    avifROStreamSetOffset(&stream, offsetTo0thIfd);
+    uint16_t fieldCount;
+    if (!avifROStreamReadU16Endianness(&stream, &fieldCount, littleEndian)) {
+        return AVIF_RESULT_INVALID_EXIF_PAYLOAD;
+    }
+    for (uint16_t field = 0; field < fieldCount; ++field) { // for each field interoperability array
+        uint16_t tag;
+        uint16_t type;
+        uint32_t count;
+        uint16_t firstHalfOfValueOffset;
+        if (!avifROStreamReadU16Endianness(&stream, &tag, littleEndian) || !avifROStreamReadU16Endianness(&stream, &type, littleEndian) ||
+            !avifROStreamReadU32Endianness(&stream, &count, littleEndian) ||
+            !avifROStreamReadU16Endianness(&stream, &firstHalfOfValueOffset, littleEndian) || !avifROStreamSkip(&stream, 2)) {
+            return AVIF_RESULT_INVALID_EXIF_PAYLOAD;
+        }
+        // Orientation attribute according to JEITA CP-3451C section 4.6.4 (TIFF Rev. 6.0 Attribute Information):
+        const uint16_t shortType = 0x03;
+        if (tag == 0x0112 && type == shortType && count == 0x01) {
+            // Only consider non-reserved orientation values, so that it is known that
+            // the most meaningful byte of firstHalfOfValueOffset is 0.
+            if (firstHalfOfValueOffset >= 1 && firstHalfOfValueOffset <= 8) {
+                // Offset to the least meaningful byte of firstHalfOfValueOffset.
+                *offset += avifROStreamOffset(&stream) - (littleEndian ? 4 : 3);
+                return AVIF_RESULT_OK;
+            }
+        }
+    }
+    // Orientation is in the 0th IFD, so no need to parse the following ones.
+
+    *offset = exifSize; // Signal missing orientation tag in valid Exif payload.
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifImageExtractExifOrientationToIrotImir(avifImage * image)
+{
+    const avifTransformFlags otherFlags = image->transformFlags & ~(AVIF_TRANSFORM_IROT | AVIF_TRANSFORM_IMIR);
+    size_t offset;
+    const avifResult result = avifGetExifOrientationOffset(image->exif.data, image->exif.size, &offset);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    if (offset < image->exif.size) {
+        const uint8_t orientation = image->exif.data[offset];
+        // Mapping from Exif orientation as defined in JEITA CP-3451C section 4.6.4.A Orientation
+        // to irot and imir boxes as defined in HEIF ISO/IEC 28002-12:2021 sections 6.5.10 and 6.5.12.
+        switch (orientation) {
+            case 1: // The 0th row is at the visual top of the image, and the 0th column is the visual left-hand side.
+                image->transformFlags = otherFlags;
+                image->irot.angle = 0; // ignored
+                image->imir.axis = 0;  // ignored
+                return AVIF_RESULT_OK;
+            case 2: // The 0th row is at the visual top of the image, and the 0th column is the visual right-hand side.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IMIR;
+                image->irot.angle = 0; // ignored
+                image->imir.axis = 1;
+                return AVIF_RESULT_OK;
+            case 3: // The 0th row is at the visual bottom of the image, and the 0th column is the visual right-hand side.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IROT;
+                image->irot.angle = 2;
+                image->imir.axis = 0; // ignored
+                return AVIF_RESULT_OK;
+            case 4: // The 0th row is at the visual bottom of the image, and the 0th column is the visual left-hand side.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IMIR;
+                image->irot.angle = 0; // ignored
+                image->imir.axis = 0;
+                return AVIF_RESULT_OK;
+            case 5: // The 0th row is the visual left-hand side of the image, and the 0th column is the visual top.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IROT | AVIF_TRANSFORM_IMIR;
+                image->irot.angle = 1; // applied before imir according to MIAF spec ISO/IEC 28002-12:2021 - section 7.3.6.7
+                image->imir.axis = 0;
+                return AVIF_RESULT_OK;
+            case 6: // The 0th row is the visual right-hand side of the image, and the 0th column is the visual top.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IROT;
+                image->irot.angle = 3;
+                image->imir.axis = 0; // ignored
+                return AVIF_RESULT_OK;
+            case 7: // The 0th row is the visual right-hand side of the image, and the 0th column is the visual bottom.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IROT | AVIF_TRANSFORM_IMIR;
+                image->irot.angle = 3; // applied before imir according to MIAF spec ISO/IEC 28002-12:2021 - section 7.3.6.7
+                image->imir.axis = 0;
+                return AVIF_RESULT_OK;
+            case 8: // The 0th row is the visual left-hand side of the image, and the 0th column is the visual bottom.
+                image->transformFlags = otherFlags | AVIF_TRANSFORM_IROT;
+                image->irot.angle = 1;
+                image->imir.axis = 0; // ignored
+                return AVIF_RESULT_OK;
+            default: // reserved
+                break;
+        }
+    }
+
+    // The orientation tag is not mandatory (only recommended) according to JEITA CP-3451C section 4.6.8.A.
+    // The default value is 1 if the orientation tag is missing, meaning:
+    //   The 0th row is at the visual top of the image, and the 0th column is the visual left-hand side.
+    image->transformFlags = otherFlags;
+    image->irot.angle = 0; // ignored
+    image->imir.axis = 0;  // ignored
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+uint8_t avifImageIrotImirToExifOrientation(const avifImage * image)
+{
+    if (!(image->transformFlags & AVIF_TRANSFORM_IROT) || image->irot.angle == 0) {
+        if (!(image->transformFlags & AVIF_TRANSFORM_IMIR)) {
+            return 1; // The 0th row is at the visual top of the image, and the 0th column is the visual left-hand side.
+        }
+        if (image->imir.axis == 0) {
+            return 4; // The 0th row is at the visual bottom of the image, and the 0th column is the visual left-hand side.
+        }
+        // image->imir.axis == 1
+        return 2; // The 0th row is at the visual top of the image, and the 0th column is the visual right-hand side.
+    }
+
+    if (image->irot.angle == 1) {
+        if (!(image->transformFlags & AVIF_TRANSFORM_IMIR)) {
+            return 8; // The 0th row is the visual left-hand side of the image, and the 0th column is the visual bottom.
+        }
+        if (image->imir.axis == 0) {
+            return 5; // The 0th row is the visual left-hand side of the image, and the 0th column is the visual top.
+        }
+        // image->imir.axis == 1
+        return 7; // The 0th row is the visual right-hand side of the image, and the 0th column is the visual bottom.
+    }
+
+    if (image->irot.angle == 2) {
+        if (!(image->transformFlags & AVIF_TRANSFORM_IMIR)) {
+            return 3; // The 0th row is at the visual bottom of the image, and the 0th column is the visual right-hand side.
+        }
+        if (image->imir.axis == 0) {
+            return 2; // The 0th row is at the visual top of the image, and the 0th column is the visual right-hand side.
+        }
+        // image->imir.axis == 1
+        return 4; // The 0th row is at the visual bottom of the image, and the 0th column is the visual left-hand side.
+    }
+
+    // image->irot.angle == 3
+    if (!(image->transformFlags & AVIF_TRANSFORM_IMIR)) {
+        return 6; // The 0th row is the visual right-hand side of the image, and the 0th column is the visual top.
+    }
+    if (image->imir.axis == 0) {
+        return 7; // The 0th row is the visual right-hand side of the image, and the 0th column is the visual bottom.
+    }
+    // image->imir.axis == 1
+    return 5; // The 0th row is the visual left-hand side of the image, and the 0th column is the visual top.
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+avifResult avifImageSetMetadataExif(avifImage * image, const uint8_t * exif, size_t exifSize)
+{
+    AVIF_CHECKRES(avifRWDataSet(&image->exif, exif, exifSize));
+    // Ignore any Exif parsing failure.
+    // TODO(wtc): Decide whether to ignore or return Exif parsing failures.
+    (void)avifImageExtractExifOrientationToIrotImir(image);
+    return AVIF_RESULT_OK;
+}
diff --git a/third_party/libavif/src/src/gainmap.c b/third_party/libavif/src/src/gainmap.c
new file mode 100644
index 0000000000..318a86d385
--- /dev/null
+++ b/third_party/libavif/src/src/gainmap.c
@@ -0,0 +1,852 @@
+// Copyright 2023 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+#include <assert.h>
+#include <float.h>
+#include <math.h>
+#include <string.h>
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+
+static void avifGainMapSetDefaults(avifGainMap * gainMap)
+{
+    for (int i = 0; i < 3; ++i) {
+        gainMap->gainMapMin[i] = (avifSignedFraction) { 1, 1 };
+        gainMap->gainMapMax[i] = (avifSignedFraction) { 1, 1 };
+        gainMap->baseOffset[i] = (avifSignedFraction) { 1, 64 };
+        gainMap->alternateOffset[i] = (avifSignedFraction) { 1, 64 };
+        gainMap->gainMapGamma[i] = (avifUnsignedFraction) { 1, 1 };
+    }
+    gainMap->baseHdrHeadroom = (avifUnsignedFraction) { 0, 1 };
+    gainMap->alternateHdrHeadroom = (avifUnsignedFraction) { 1, 1 };
+    gainMap->useBaseColorSpace = AVIF_TRUE;
+}
+
+static float avifSignedFractionToFloat(avifSignedFraction f)
+{
+    if (f.d == 0) {
+        return 0.0f;
+    }
+    return (float)f.n / f.d;
+}
+
+static float avifUnsignedFractionToFloat(avifUnsignedFraction f)
+{
+    if (f.d == 0) {
+        return 0.0f;
+    }
+    return (float)f.n / f.d;
+}
+
+// ---------------------------------------------------------------------------
+// Apply a gain map.
+
+// Returns a weight in [-1.0, 1.0] that represents how much the gain map should be applied.
+static float avifGetGainMapWeight(float hdrHeadroom, const avifGainMap * gainMap)
+{
+    const float baseHdrHeadroom = avifUnsignedFractionToFloat(gainMap->baseHdrHeadroom);
+    const float alternateHdrHeadroom = avifUnsignedFractionToFloat(gainMap->alternateHdrHeadroom);
+    if (baseHdrHeadroom == alternateHdrHeadroom) {
+        // Do not apply the gain map if the HDR headroom is the same.
+        // This case is not handled in the specification and does not make practical sense.
+        return 0.0f;
+    }
+    const float w = AVIF_CLAMP((hdrHeadroom - baseHdrHeadroom) / (alternateHdrHeadroom - baseHdrHeadroom), 0.0f, 1.0f);
+    return (alternateHdrHeadroom < baseHdrHeadroom) ? -w : w;
+}
+
+// Linear interpolation between 'a' and 'b' (returns 'a' if w == 0.0f, returns 'b' if w == 1.0f).
+static inline float lerp(float a, float b, float w)
+{
+    return (1.0f - w) * a + w * b;
+}
+
+#define SDR_WHITE_NITS 203.0f
+
+avifResult avifRGBImageApplyGainMap(const avifRGBImage * baseImage,
+                                    avifColorPrimaries baseColorPrimaries,
+                                    avifTransferCharacteristics baseTransferCharacteristics,
+                                    const avifGainMap * gainMap,
+                                    float hdrHeadroom,
+                                    avifColorPrimaries outputColorPrimaries,
+                                    avifTransferCharacteristics outputTransferCharacteristics,
+                                    avifRGBImage * toneMappedImage,
+                                    avifContentLightLevelInformationBox * clli,
+                                    avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    if (hdrHeadroom < 0.0f) {
+        avifDiagnosticsPrintf(diag, "hdrHeadroom should be >= 0, got %f", hdrHeadroom);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (baseImage == NULL || gainMap == NULL || toneMappedImage == NULL) {
+        avifDiagnosticsPrintf(diag, "NULL input image");
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    AVIF_CHECKRES(avifGainMapValidateMetadata(gainMap, diag));
+
+    const uint32_t width = baseImage->width;
+    const uint32_t height = baseImage->height;
+
+    const avifBool useBaseColorSpace = gainMap->useBaseColorSpace;
+    const avifColorPrimaries gainMapMathPrimaries =
+        (useBaseColorSpace || (gainMap->altColorPrimaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED)) ? baseColorPrimaries
+                                                                                                : gainMap->altColorPrimaries;
+    const avifBool needsInputColorConversion = (baseColorPrimaries != gainMapMathPrimaries);
+    const avifBool needsOutputColorConversion = (gainMapMathPrimaries != outputColorPrimaries);
+
+    avifImage * rescaledGainMap = NULL;
+    avifRGBImage rgbGainMap;
+    // Basic zero-initialization for now, avifRGBImageSetDefaults() is called later on.
+    memset(&rgbGainMap, 0, sizeof(rgbGainMap));
+
+    avifResult res = AVIF_RESULT_OK;
+    toneMappedImage->width = width;
+    toneMappedImage->height = height;
+    AVIF_CHECKRES(avifRGBImageAllocatePixels(toneMappedImage));
+
+    // --- After this point, the function should exit with 'goto cleanup' to free allocated pixels.
+
+    const float weight = avifGetGainMapWeight(hdrHeadroom, gainMap);
+
+    // Early exit if the gain map does not need to be applied and the pixel format is the same.
+    if (weight == 0.0f && outputTransferCharacteristics == baseTransferCharacteristics &&
+        outputColorPrimaries == baseColorPrimaries && baseImage->format == toneMappedImage->format &&
+        baseImage->depth == toneMappedImage->depth && baseImage->isFloat == toneMappedImage->isFloat) {
+        assert(baseImage->rowBytes == toneMappedImage->rowBytes);
+        assert(baseImage->height == toneMappedImage->height);
+        // Copy the base image.
+        memcpy(toneMappedImage->pixels, baseImage->pixels, baseImage->rowBytes * baseImage->height);
+        goto cleanup;
+    }
+
+    avifRGBColorSpaceInfo baseRGBInfo;
+    avifRGBColorSpaceInfo toneMappedPixelRGBInfo;
+    if (!avifGetRGBColorSpaceInfo(baseImage, &baseRGBInfo) || !avifGetRGBColorSpaceInfo(toneMappedImage, &toneMappedPixelRGBInfo)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space");
+        res = AVIF_RESULT_NOT_IMPLEMENTED;
+        goto cleanup;
+    }
+
+    const avifTransferFunction gammaToLinear = avifTransferCharacteristicsGetGammaToLinearFunction(baseTransferCharacteristics);
+    const avifTransferFunction linearToGamma = avifTransferCharacteristicsGetLinearToGammaFunction(outputTransferCharacteristics);
+
+    // Early exit if the gain map does not need to be applied.
+    if (weight == 0.0f) {
+        const avifBool primariesDiffer = (baseColorPrimaries != outputColorPrimaries);
+        double conversionCoeffs[3][3];
+        if (primariesDiffer && !avifColorPrimariesComputeRGBToRGBMatrix(baseColorPrimaries, outputColorPrimaries, conversionCoeffs)) {
+            avifDiagnosticsPrintf(diag, "Unsupported RGB color space conversion");
+            res = AVIF_RESULT_NOT_IMPLEMENTED;
+            goto cleanup;
+        }
+        // Just convert from one rgb format to another.
+        for (uint32_t j = 0; j < height; ++j) {
+            for (uint32_t i = 0; i < width; ++i) {
+                float basePixelRGBA[4];
+                avifGetRGBAPixel(baseImage, i, j, &baseRGBInfo, basePixelRGBA);
+                if (outputTransferCharacteristics != baseTransferCharacteristics || primariesDiffer) {
+                    for (int c = 0; c < 3; ++c) {
+                        basePixelRGBA[c] = gammaToLinear(basePixelRGBA[c]);
+                    }
+                    if (primariesDiffer) {
+                        avifLinearRGBConvertColorSpace(basePixelRGBA, conversionCoeffs);
+                    }
+                    for (int c = 0; c < 3; ++c) {
+                        basePixelRGBA[c] = AVIF_CLAMP(linearToGamma(basePixelRGBA[c]), 0.0f, 1.0f);
+                    }
+                }
+                avifSetRGBAPixel(toneMappedImage, i, j, &toneMappedPixelRGBInfo, basePixelRGBA);
+            }
+        }
+        goto cleanup;
+    }
+
+    double inputConversionCoeffs[3][3];
+    double outputConversionCoeffs[3][3];
+    if (needsInputColorConversion &&
+        !avifColorPrimariesComputeRGBToRGBMatrix(baseColorPrimaries, gainMapMathPrimaries, inputConversionCoeffs)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space conversion");
+        res = AVIF_RESULT_NOT_IMPLEMENTED;
+        goto cleanup;
+    }
+    if (needsOutputColorConversion &&
+        !avifColorPrimariesComputeRGBToRGBMatrix(gainMapMathPrimaries, outputColorPrimaries, outputConversionCoeffs)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space conversion");
+        res = AVIF_RESULT_NOT_IMPLEMENTED;
+        goto cleanup;
+    }
+
+    if (gainMap->image->width != width || gainMap->image->height != height) {
+        rescaledGainMap = avifImageCreateEmpty();
+        const avifCropRect rect = { 0, 0, gainMap->image->width, gainMap->image->height };
+        res = avifImageSetViewRect(rescaledGainMap, gainMap->image, &rect);
+        if (res != AVIF_RESULT_OK) {
+            goto cleanup;
+        }
+        res = avifImageScale(rescaledGainMap, width, height, diag);
+        if (res != AVIF_RESULT_OK) {
+            goto cleanup;
+        }
+    }
+    const avifImage * const gainMapImage = (rescaledGainMap != NULL) ? rescaledGainMap : gainMap->image;
+
+    avifRGBImageSetDefaults(&rgbGainMap, gainMapImage);
+    res = avifRGBImageAllocatePixels(&rgbGainMap);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+    res = avifImageYUVToRGB(gainMapImage, &rgbGainMap);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    avifRGBColorSpaceInfo gainMapRGBInfo;
+    if (!avifGetRGBColorSpaceInfo(&rgbGainMap, &gainMapRGBInfo)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space");
+        res = AVIF_RESULT_NOT_IMPLEMENTED;
+        goto cleanup;
+    }
+
+    float rgbMaxLinear = 0; // Max tone mapped pixel value across R, G and B channels.
+    float rgbSumLinear = 0; // Sum of max(r, g, b) for mapped pixels.
+    // The gain map metadata contains the encoding gamma, and 1/gamma should be used for decoding.
+    const float gammaInv[3] = { 1.0f / avifUnsignedFractionToFloat(gainMap->gainMapGamma[0]),
+                                1.0f / avifUnsignedFractionToFloat(gainMap->gainMapGamma[1]),
+                                1.0f / avifUnsignedFractionToFloat(gainMap->gainMapGamma[2]) };
+    const float gainMapMin[3] = { avifSignedFractionToFloat(gainMap->gainMapMin[0]),
+                                  avifSignedFractionToFloat(gainMap->gainMapMin[1]),
+                                  avifSignedFractionToFloat(gainMap->gainMapMin[2]) };
+    const float gainMapMax[3] = { avifSignedFractionToFloat(gainMap->gainMapMax[0]),
+                                  avifSignedFractionToFloat(gainMap->gainMapMax[1]),
+                                  avifSignedFractionToFloat(gainMap->gainMapMax[2]) };
+    const float baseOffset[3] = { avifSignedFractionToFloat(gainMap->baseOffset[0]),
+                                  avifSignedFractionToFloat(gainMap->baseOffset[1]),
+                                  avifSignedFractionToFloat(gainMap->baseOffset[2]) };
+    const float alternateOffset[3] = { avifSignedFractionToFloat(gainMap->alternateOffset[0]),
+                                       avifSignedFractionToFloat(gainMap->alternateOffset[1]),
+                                       avifSignedFractionToFloat(gainMap->alternateOffset[2]) };
+    for (uint32_t j = 0; j < height; ++j) {
+        for (uint32_t i = 0; i < width; ++i) {
+            float basePixelRGBA[4];
+            avifGetRGBAPixel(baseImage, i, j, &baseRGBInfo, basePixelRGBA);
+            float gainMapRGBA[4];
+            avifGetRGBAPixel(&rgbGainMap, i, j, &gainMapRGBInfo, gainMapRGBA);
+
+            // Apply gain map.
+            float toneMappedPixelRGBA[4];
+            float pixelRgbMaxLinear = 0.0f; //  = max(r, g, b) for this pixel
+
+            for (int c = 0; c < 3; ++c) {
+                basePixelRGBA[c] = gammaToLinear(basePixelRGBA[c]);
+            }
+
+            if (needsInputColorConversion) {
+                // Convert basePixelRGBA to gainMapMathPrimaries.
+                avifLinearRGBConvertColorSpace(basePixelRGBA, inputConversionCoeffs);
+            }
+
+            for (int c = 0; c < 3; ++c) {
+                const float baseLinear = basePixelRGBA[c];
+                const float gainMapValue = gainMapRGBA[c];
+
+                // Undo gamma & affine transform; the result is in log2 space.
+                const float gainMapLog2 = lerp(gainMapMin[c], gainMapMax[c], powf(gainMapValue, gammaInv[c]));
+                const float toneMappedLinear = (baseLinear + baseOffset[c]) * exp2f(gainMapLog2 * weight) - alternateOffset[c];
+
+                if (toneMappedLinear > rgbMaxLinear) {
+                    rgbMaxLinear = toneMappedLinear;
+                }
+                if (toneMappedLinear > pixelRgbMaxLinear) {
+                    pixelRgbMaxLinear = toneMappedLinear;
+                }
+
+                toneMappedPixelRGBA[c] = toneMappedLinear;
+            }
+
+            if (needsOutputColorConversion) {
+                // Convert toneMappedPixelRGBA to outputColorPrimaries.
+                avifLinearRGBConvertColorSpace(toneMappedPixelRGBA, outputConversionCoeffs);
+            }
+
+            for (int c = 0; c < 3; ++c) {
+                toneMappedPixelRGBA[c] = AVIF_CLAMP(linearToGamma(toneMappedPixelRGBA[c]), 0.0f, 1.0f);
+            }
+
+            toneMappedPixelRGBA[3] = basePixelRGBA[3]; // Alpha is unaffected by tone mapping.
+            rgbSumLinear += pixelRgbMaxLinear;
+            avifSetRGBAPixel(toneMappedImage, i, j, &toneMappedPixelRGBInfo, toneMappedPixelRGBA);
+        }
+    }
+    if (clli != NULL) {
+        // For exact CLLI value definitions, see ISO/IEC 23008-2 section D.3.35
+        // at https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html
+        // See also discussion in https://github.com/AOMediaCodec/libavif/issues/1727
+
+        // Convert extended SDR (where 1.0 is SDR white) to nits.
+        clli->maxCLL = (uint16_t)AVIF_CLAMP(avifRoundf(rgbMaxLinear * SDR_WHITE_NITS), 0.0f, (float)UINT16_MAX);
+        const float rgbAverageLinear = rgbSumLinear / (width * height);
+        clli->maxPALL = (uint16_t)AVIF_CLAMP(avifRoundf(rgbAverageLinear * SDR_WHITE_NITS), 0.0f, (float)UINT16_MAX);
+    }
+
+cleanup:
+    avifRGBImageFreePixels(&rgbGainMap);
+    if (rescaledGainMap != NULL) {
+        avifImageDestroy(rescaledGainMap);
+    }
+
+    return res;
+}
+
+avifResult avifImageApplyGainMap(const avifImage * baseImage,
+                                 const avifGainMap * gainMap,
+                                 float hdrHeadroom,
+                                 avifColorPrimaries outputColorPrimaries,
+                                 avifTransferCharacteristics outputTransferCharacteristics,
+                                 avifRGBImage * toneMappedImage,
+                                 avifContentLightLevelInformationBox * clli,
+                                 avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    if (baseImage->icc.size > 0 || gainMap->altICC.size > 0) {
+        avifDiagnosticsPrintf(diag, "Tone mapping for images with ICC profiles is not supported");
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    avifRGBImage baseImageRgb;
+    avifRGBImageSetDefaults(&baseImageRgb, baseImage);
+    AVIF_CHECKRES(avifRGBImageAllocatePixels(&baseImageRgb));
+    avifResult res = avifImageYUVToRGB(baseImage, &baseImageRgb);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    res = avifRGBImageApplyGainMap(&baseImageRgb,
+                                   baseImage->colorPrimaries,
+                                   baseImage->transferCharacteristics,
+                                   gainMap,
+                                   hdrHeadroom,
+                                   outputColorPrimaries,
+                                   outputTransferCharacteristics,
+                                   toneMappedImage,
+                                   clli,
+                                   diag);
+
+cleanup:
+    avifRGBImageFreePixels(&baseImageRgb);
+
+    return res;
+}
+
+// ---------------------------------------------------------------------------
+// Create a gain map.
+
+// Returns the index of the histogram bucket for a given value, for a histogram with 'numBuckets' buckets,
+// and values ranging in [bucketMin, bucketMax](values outside of the range are added to the first/last buckets).
+static int avifValueToBucketIdx(float v, float bucketMin, float bucketMax, int numBuckets)
+{
+    v = AVIF_CLAMP(v, bucketMin, bucketMax);
+    return AVIF_MIN((int)avifRoundf((v - bucketMin) / (bucketMax - bucketMin) * numBuckets), numBuckets - 1);
+}
+// Returns the lower end of the value range belonging to the given histogram bucket.
+static float avifBucketIdxToValue(int idx, float bucketMin, float bucketMax, int numBuckets)
+{
+    return idx * (bucketMax - bucketMin) / numBuckets + bucketMin;
+}
+
+avifResult avifFindMinMaxWithoutOutliers(const float * gainMapF, int numPixels, float * rangeMin, float * rangeMax)
+{
+    const float bucketSize = 0.01f;        // Size of one bucket. Empirical value.
+    const float maxOutliersRatio = 0.001f; // 0.1%
+    const int maxOutliersOnEachSide = (int)avifRoundf(numPixels * maxOutliersRatio / 2.0f);
+
+    float min = gainMapF[0];
+    float max = gainMapF[0];
+    for (int i = 0; i < numPixels; ++i) {
+        min = AVIF_MIN(min, gainMapF[i]);
+        max = AVIF_MAX(max, gainMapF[i]);
+    }
+
+    *rangeMin = min;
+    *rangeMax = max;
+    if ((max - min) <= (bucketSize * 2) || maxOutliersOnEachSide == 0) {
+        return AVIF_RESULT_OK;
+    }
+
+    const int maxNumBuckets = 10000;
+    const int numBuckets = AVIF_MIN((int)ceilf((max - min) / bucketSize), maxNumBuckets);
+    int * histogram = avifAlloc(sizeof(int) * numBuckets);
+    if (histogram == NULL) {
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    memset(histogram, 0, sizeof(int) * numBuckets);
+    for (int i = 0; i < numPixels; ++i) {
+        ++(histogram[avifValueToBucketIdx(gainMapF[i], min, max, numBuckets)]);
+    }
+
+    int leftOutliers = 0;
+    for (int i = 0; i < numBuckets; ++i) {
+        leftOutliers += histogram[i];
+        if (leftOutliers > maxOutliersOnEachSide) {
+            break;
+        }
+        if (histogram[i] == 0) {
+            // +1 to get the higher end of the bucket.
+            *rangeMin = avifBucketIdxToValue(i + 1, min, max, numBuckets);
+        }
+    }
+
+    int rightOutliers = 0;
+    for (int i = numBuckets - 1; i >= 0; --i) {
+        rightOutliers += histogram[i];
+        if (rightOutliers > maxOutliersOnEachSide) {
+            break;
+        }
+        if (histogram[i] == 0) {
+            *rangeMax = avifBucketIdxToValue(i, min, max, numBuckets);
+        }
+    }
+
+    avifFree(histogram);
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifGainMapValidateMetadata(const avifGainMap * gainMap, avifDiagnostics * diag)
+{
+    for (int i = 0; i < 3; ++i) {
+        if (gainMap->gainMapMin[i].d == 0 || gainMap->gainMapMax[i].d == 0 || gainMap->gainMapGamma[i].d == 0 ||
+            gainMap->baseOffset[i].d == 0 || gainMap->alternateOffset[i].d == 0) {
+            avifDiagnosticsPrintf(diag, "Per-channel denominator is 0 in gain map metadata");
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+        if (gainMap->gainMapGamma[i].n == 0) {
+            avifDiagnosticsPrintf(diag, "Per-channel gamma is 0 in gain map metadata");
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+    }
+    if (gainMap->baseHdrHeadroom.d == 0 || gainMap->alternateHdrHeadroom.d == 0) {
+        avifDiagnosticsPrintf(diag, "Headroom denominator is 0 in gain map metadata");
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (gainMap->useBaseColorSpace != 0 && gainMap->useBaseColorSpace != 1) {
+        avifDiagnosticsPrintf(diag, "useBaseColorSpace is %d in gain map metadata", gainMap->useBaseColorSpace);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static const float kEpsilon = 1e-10f;
+
+// Decides which of 'basePrimaries' or 'altPrimaries' should be used for doing gain map math when creating a gain map.
+// The other image (base or alternate) will be converted to this color space before computing
+// the ratio between the two images.
+// If a pixel color is outside of the target color space, some of the converted channel values will be negative.
+// This should be avoided, as the negative values must either be clamped or offset before computing the log2()
+// (since log2 only works on > 0 values). But a large offset causes artefacts when partially applying the gain map.
+// Therefore we want to do gain map math in the larger of the two color spaces.
+static avifResult avifChooseColorSpaceForGainMapMath(avifColorPrimaries basePrimaries,
+                                                     avifColorPrimaries altPrimaries,
+                                                     avifColorPrimaries * gainMapMathColorSpace)
+{
+    if (basePrimaries == altPrimaries) {
+        *gainMapMathColorSpace = basePrimaries;
+        return AVIF_RESULT_OK;
+    }
+    // Color convert pure red, pure green and pure blue in turn and see if they result in negative values.
+    float rgba[4] = { 0 };
+    double baseToAltCoeffs[3][3];
+    double altToBaseCoeffs[3][3];
+    if (!avifColorPrimariesComputeRGBToRGBMatrix(basePrimaries, altPrimaries, baseToAltCoeffs) ||
+        !avifColorPrimariesComputeRGBToRGBMatrix(altPrimaries, basePrimaries, altToBaseCoeffs)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    float baseColorspaceChannelMin = 0;
+    float altColorspaceChannelMin = 0;
+    for (int c = 0; c < 3; ++c) {
+        rgba[0] = rgba[1] = rgba[2] = 0;
+        rgba[c] = 1.0f;
+        avifLinearRGBConvertColorSpace(rgba, altToBaseCoeffs);
+        for (int i = 0; i < 3; ++i) {
+            baseColorspaceChannelMin = AVIF_MIN(baseColorspaceChannelMin, rgba[i]);
+        }
+        rgba[0] = rgba[1] = rgba[2] = 0;
+        rgba[c] = 1.0f;
+        avifLinearRGBConvertColorSpace(rgba, baseToAltCoeffs);
+        for (int i = 0; i < 3; ++i) {
+            altColorspaceChannelMin = AVIF_MIN(altColorspaceChannelMin, rgba[i]);
+        }
+    }
+    // Pick the colorspace that has the largest min value (which is more or less the largest color space).
+    *gainMapMathColorSpace = (altColorspaceChannelMin <= baseColorspaceChannelMin) ? basePrimaries : altPrimaries;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRGBImageComputeGainMap(const avifRGBImage * baseRgbImage,
+                                      avifColorPrimaries baseColorPrimaries,
+                                      avifTransferCharacteristics baseTransferCharacteristics,
+                                      const avifRGBImage * altRgbImage,
+                                      avifColorPrimaries altColorPrimaries,
+                                      avifTransferCharacteristics altTransferCharacteristics,
+                                      avifGainMap * gainMap,
+                                      avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    AVIF_CHECKERR(baseRgbImage != NULL && altRgbImage != NULL && gainMap != NULL && gainMap->image != NULL, AVIF_RESULT_INVALID_ARGUMENT);
+    if (baseRgbImage->width != altRgbImage->width || baseRgbImage->height != altRgbImage->height) {
+        avifDiagnosticsPrintf(diag, "Both images should have the same dimensions");
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (gainMap->image->width == 0 || gainMap->image->height == 0 || gainMap->image->depth == 0 ||
+        gainMap->image->yuvFormat <= AVIF_PIXEL_FORMAT_NONE || gainMap->image->yuvFormat >= AVIF_PIXEL_FORMAT_COUNT) {
+        avifDiagnosticsPrintf(diag, "gainMap->image should be non null with desired width, height, depth and yuvFormat set");
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    const avifBool colorSpacesDiffer = (baseColorPrimaries != altColorPrimaries);
+    avifColorPrimaries gainMapMathPrimaries;
+    AVIF_CHECKRES(avifChooseColorSpaceForGainMapMath(baseColorPrimaries, altColorPrimaries, &gainMapMathPrimaries));
+    const int width = baseRgbImage->width;
+    const int height = baseRgbImage->height;
+
+    avifRGBColorSpaceInfo baseRGBInfo;
+    avifRGBColorSpaceInfo altRGBInfo;
+    if (!avifGetRGBColorSpaceInfo(baseRgbImage, &baseRGBInfo) || !avifGetRGBColorSpaceInfo(altRgbImage, &altRGBInfo)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space");
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    float * gainMapF[3] = { 0 }; // Temporary buffers for the gain map as floating point values, one per RGB channel.
+    avifRGBImage gainMapRGB;
+    memset(&gainMapRGB, 0, sizeof(gainMapRGB));
+    avifImage * gainMapImage = gainMap->image;
+
+    avifResult res = AVIF_RESULT_OK;
+    // --- After this point, the function should exit with 'goto cleanup' to free allocated resources.
+
+    const avifBool singleChannel = (gainMap->image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400);
+    const int numGainMapChannels = singleChannel ? 1 : 3;
+    for (int c = 0; c < numGainMapChannels; ++c) {
+        gainMapF[c] = avifAlloc(width * height * sizeof(float));
+        if (gainMapF[c] == NULL) {
+            res = AVIF_RESULT_OUT_OF_MEMORY;
+            goto cleanup;
+        }
+    }
+
+    avifGainMapSetDefaults(gainMap);
+    gainMap->useBaseColorSpace = (gainMapMathPrimaries == baseColorPrimaries);
+
+    float (*baseGammaToLinear)(float) = avifTransferCharacteristicsGetGammaToLinearFunction(baseTransferCharacteristics);
+    float (*altGammaToLinear)(float) = avifTransferCharacteristicsGetGammaToLinearFunction(altTransferCharacteristics);
+    float yCoeffs[3];
+    avifColorPrimariesComputeYCoeffs(gainMapMathPrimaries, yCoeffs);
+
+    double rgbConversionCoeffs[3][3];
+    if (colorSpacesDiffer) {
+        if (gainMap->useBaseColorSpace) {
+            if (!avifColorPrimariesComputeRGBToRGBMatrix(altColorPrimaries, baseColorPrimaries, rgbConversionCoeffs)) {
+                avifDiagnosticsPrintf(diag, "Unsupported RGB color space conversion");
+                res = AVIF_RESULT_NOT_IMPLEMENTED;
+                goto cleanup;
+            }
+        } else {
+            if (!avifColorPrimariesComputeRGBToRGBMatrix(baseColorPrimaries, altColorPrimaries, rgbConversionCoeffs)) {
+                avifDiagnosticsPrintf(diag, "Unsupported RGB color space conversion");
+                res = AVIF_RESULT_NOT_IMPLEMENTED;
+                goto cleanup;
+            }
+        }
+    }
+
+    float baseOffset[3] = { avifSignedFractionToFloat(gainMap->baseOffset[0]),
+                            avifSignedFractionToFloat(gainMap->baseOffset[1]),
+                            avifSignedFractionToFloat(gainMap->baseOffset[2]) };
+    float alternateOffset[3] = { avifSignedFractionToFloat(gainMap->alternateOffset[0]),
+                                 avifSignedFractionToFloat(gainMap->alternateOffset[1]),
+                                 avifSignedFractionToFloat(gainMap->alternateOffset[2]) };
+
+    // If we are converting from one colorspace to another, some RGB values may be negative and an offset must be added to
+    // avoid clamping (although the choice of color space to do the gain map computation with
+    // avifChooseColorSpaceForGainMapMath() should mostly avoid this).
+    if (colorSpacesDiffer) {
+        // Color convert pure red, pure green and pure blue in turn and see if they result in negative values.
+        float rgba[4] = { 0.0f };
+        float channelMin[3] = { 0.0f };
+        for (int j = 0; j < height; ++j) {
+            for (int i = 0; i < width; ++i) {
+                avifGetRGBAPixel(gainMap->useBaseColorSpace ? altRgbImage : baseRgbImage,
+                                 i,
+                                 j,
+                                 gainMap->useBaseColorSpace ? &altRGBInfo : &baseRGBInfo,
+                                 rgba);
+
+                // Convert to linear.
+                for (int c = 0; c < 3; ++c) {
+                    if (gainMap->useBaseColorSpace) {
+                        rgba[c] = altGammaToLinear(rgba[c]);
+                    } else {
+                        rgba[c] = baseGammaToLinear(rgba[c]);
+                    }
+                }
+                avifLinearRGBConvertColorSpace(rgba, rgbConversionCoeffs);
+                for (int c = 0; c < 3; ++c) {
+                    channelMin[c] = AVIF_MIN(channelMin[c], rgba[c]);
+                }
+            }
+        }
+
+        for (int c = 0; c < 3; ++c) {
+            // Large offsets cause artefacts when partially applying the gain map, so set a max (empirical) offset value.
+            // If the offset is clamped, some gain map values will get clamped as well.
+            const float maxOffset = 0.1f;
+            if (channelMin[c] < -kEpsilon) {
+                // Increase the offset to avoid negative values.
+                if (gainMap->useBaseColorSpace) {
+                    alternateOffset[c] = AVIF_MIN(alternateOffset[c] - channelMin[c], maxOffset);
+                } else {
+                    baseOffset[c] = AVIF_MIN(baseOffset[c] - channelMin[c], maxOffset);
+                }
+            }
+        }
+    }
+
+    // Compute raw gain map values.
+    float baseMax = 1.0f;
+    float altMax = 1.0f;
+    for (int j = 0; j < height; ++j) {
+        for (int i = 0; i < width; ++i) {
+            float baseRGBA[4];
+            avifGetRGBAPixel(baseRgbImage, i, j, &baseRGBInfo, baseRGBA);
+            float altRGBA[4];
+            avifGetRGBAPixel(altRgbImage, i, j, &altRGBInfo, altRGBA);
+
+            // Convert to linear.
+            for (int c = 0; c < 3; ++c) {
+                baseRGBA[c] = baseGammaToLinear(baseRGBA[c]);
+                altRGBA[c] = altGammaToLinear(altRGBA[c]);
+            }
+
+            if (colorSpacesDiffer) {
+                if (gainMap->useBaseColorSpace) {
+                    // convert altRGBA to baseRGBA's color space
+                    avifLinearRGBConvertColorSpace(altRGBA, rgbConversionCoeffs);
+                } else {
+                    // convert baseRGBA to altRGBA's color space
+                    avifLinearRGBConvertColorSpace(baseRGBA, rgbConversionCoeffs);
+                }
+            }
+
+            for (int c = 0; c < numGainMapChannels; ++c) {
+                float base = baseRGBA[c];
+                float alt = altRGBA[c];
+                if (singleChannel) {
+                    // Convert to grayscale.
+                    base = yCoeffs[0] * baseRGBA[0] + yCoeffs[1] * baseRGBA[1] + yCoeffs[2] * baseRGBA[2];
+                    alt = yCoeffs[0] * altRGBA[0] + yCoeffs[1] * altRGBA[1] + yCoeffs[2] * altRGBA[2];
+                }
+                if (base > baseMax) {
+                    baseMax = base;
+                }
+                if (alt > altMax) {
+                    altMax = alt;
+                }
+                const float ratio = (alt + alternateOffset[c]) / (base + baseOffset[c]);
+                const float ratioLog2 = log2f(AVIF_MAX(ratio, kEpsilon));
+                gainMapF[c][j * width + i] = ratioLog2;
+            }
+        }
+    }
+
+    // Populate the gain map metadata's headrooms.
+    const double baseHeadroom = log2f(AVIF_MAX(baseMax, kEpsilon));
+    const double alternateHeadroom = log2f(AVIF_MAX(altMax, kEpsilon));
+    if (!avifDoubleToUnsignedFraction(baseHeadroom, &gainMap->baseHdrHeadroom) ||
+        !avifDoubleToUnsignedFraction(alternateHeadroom, &gainMap->alternateHdrHeadroom)) {
+        res = AVIF_RESULT_INVALID_ARGUMENT;
+        goto cleanup;
+    }
+
+    // Multiply the gainmap by sign(alternateHdrHeadroom - baseHdrHeadroom), to
+    // ensure that it stores the log-ratio of the HDR representation to the SDR
+    // representation.
+    if (alternateHeadroom < baseHeadroom) {
+        for (int c = 0; c < numGainMapChannels; ++c) {
+            for (int j = 0; j < height; ++j) {
+                for (int i = 0; i < width; ++i) {
+                    gainMapF[c][j * width + i] *= -1.f;
+                }
+            }
+        }
+    }
+
+    // Find approximate min/max for each channel, discarding outliers.
+    float gainMapMinLog2[3] = { 0.0f, 0.0f, 0.0f };
+    float gainMapMaxLog2[3] = { 0.0f, 0.0f, 0.0f };
+    for (int c = 0; c < numGainMapChannels; ++c) {
+        res = avifFindMinMaxWithoutOutliers(gainMapF[c], width * height, &gainMapMinLog2[c], &gainMapMaxLog2[c]);
+        if (res != AVIF_RESULT_OK) {
+            goto cleanup;
+        }
+    }
+
+    // Populate the gain map metadata's min and max values.
+    for (int c = 0; c < 3; ++c) {
+        if (!avifDoubleToSignedFraction(gainMapMinLog2[singleChannel ? 0 : c], &gainMap->gainMapMin[c]) ||
+            !avifDoubleToSignedFraction(gainMapMaxLog2[singleChannel ? 0 : c], &gainMap->gainMapMax[c]) ||
+            !avifDoubleToSignedFraction(alternateOffset[c], &gainMap->alternateOffset[c]) ||
+            !avifDoubleToSignedFraction(baseOffset[c], &gainMap->baseOffset[c])) {
+            res = AVIF_RESULT_INVALID_ARGUMENT;
+            goto cleanup;
+        }
+    }
+
+    // Scale the gain map values to map [min, max] range to [0, 1].
+    for (int c = 0; c < numGainMapChannels; ++c) {
+        const float range = gainMapMaxLog2[c] - gainMapMinLog2[c];
+        if (range <= 0.0f) {
+            continue;
+        }
+        const float gainMapGamma = avifUnsignedFractionToFloat(gainMap->gainMapGamma[c]);
+
+        for (int j = 0; j < height; ++j) {
+            for (int i = 0; i < width; ++i) {
+                // Remap [min; max] range to [0; 1]
+                const float v = AVIF_CLAMP(gainMapF[c][j * width + i], gainMapMinLog2[c], gainMapMaxLog2[c]);
+                gainMapF[c][j * width + i] = powf((v - gainMapMinLog2[c]) / range, gainMapGamma);
+            }
+        }
+    }
+
+    // Convert the gain map to YUV.
+    const uint32_t requestedWidth = gainMapImage->width;
+    const uint32_t requestedHeight = gainMapImage->height;
+    gainMapImage->width = width;
+    gainMapImage->height = height;
+
+    avifImageFreePlanes(gainMapImage, AVIF_PLANES_ALL); // Free planes in case they were already allocated.
+    res = avifImageAllocatePlanes(gainMapImage, AVIF_PLANES_YUV);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    avifRGBImageSetDefaults(&gainMapRGB, gainMapImage);
+    res = avifRGBImageAllocatePixels(&gainMapRGB);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    avifRGBColorSpaceInfo gainMapRGBInfo;
+    if (!avifGetRGBColorSpaceInfo(&gainMapRGB, &gainMapRGBInfo)) {
+        avifDiagnosticsPrintf(diag, "Unsupported RGB color space");
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    for (int j = 0; j < height; ++j) {
+        for (int i = 0; i < width; ++i) {
+            const int offset = j * width + i;
+            const float r = gainMapF[0][offset];
+            const float g = singleChannel ? r : gainMapF[1][offset];
+            const float b = singleChannel ? r : gainMapF[2][offset];
+            const float rgbaPixel[4] = { r, g, b, 1.0f };
+            avifSetRGBAPixel(&gainMapRGB, i, j, &gainMapRGBInfo, rgbaPixel);
+        }
+    }
+
+    res = avifImageRGBToYUV(gainMapImage, &gainMapRGB);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    // Scale down the gain map if requested.
+    // Another way would be to scale the source images, but it seems to perform worse.
+    if (requestedWidth != gainMapImage->width || requestedHeight != gainMapImage->height) {
+        AVIF_CHECKRES(avifImageScale(gainMap->image, requestedWidth, requestedHeight, diag));
+    }
+
+cleanup:
+    for (int c = 0; c < 3; ++c) {
+        avifFree(gainMapF[c]);
+    }
+    avifRGBImageFreePixels(&gainMapRGB);
+    if (res != AVIF_RESULT_OK) {
+        avifImageFreePlanes(gainMapImage, AVIF_PLANES_ALL);
+    }
+
+    return res;
+}
+
+avifResult avifImageComputeGainMap(const avifImage * baseImage, const avifImage * altImage, avifGainMap * gainMap, avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+
+    if (baseImage == NULL || altImage == NULL || gainMap == NULL) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (baseImage->icc.size > 0 || altImage->icc.size > 0) {
+        avifDiagnosticsPrintf(diag, "Computing gain maps for images with ICC profiles is not supported");
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (baseImage->width != altImage->width || baseImage->height != altImage->height) {
+        avifDiagnosticsPrintf(diag,
+                              "Image dimensions don't match, got %dx%d and %dx%d",
+                              baseImage->width,
+                              baseImage->height,
+                              altImage->width,
+                              altImage->height);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+
+    avifResult res = AVIF_RESULT_OK;
+
+    avifRGBImage baseImageRgb;
+    avifRGBImageSetDefaults(&baseImageRgb, baseImage);
+    avifRGBImage altImageRgb;
+    avifRGBImageSetDefaults(&altImageRgb, altImage);
+
+    AVIF_CHECKRES(avifRGBImageAllocatePixels(&baseImageRgb));
+    // --- After this point, the function should exit with 'goto cleanup' to free allocated resources.
+
+    res = avifImageYUVToRGB(baseImage, &baseImageRgb);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+    res = avifRGBImageAllocatePixels(&altImageRgb);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+    res = avifImageYUVToRGB(altImage, &altImageRgb);
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    res = avifRGBImageComputeGainMap(&baseImageRgb,
+                                     baseImage->colorPrimaries,
+                                     baseImage->transferCharacteristics,
+                                     &altImageRgb,
+                                     altImage->colorPrimaries,
+                                     altImage->transferCharacteristics,
+                                     gainMap,
+                                     diag);
+
+    if (res != AVIF_RESULT_OK) {
+        goto cleanup;
+    }
+
+    AVIF_CHECKRES(avifRWDataSet(&gainMap->altICC, altImage->icc.data, altImage->icc.size));
+    gainMap->altColorPrimaries = altImage->colorPrimaries;
+    gainMap->altTransferCharacteristics = altImage->transferCharacteristics;
+    gainMap->altMatrixCoefficients = altImage->matrixCoefficients;
+    gainMap->altDepth = altImage->depth;
+    gainMap->altPlaneCount = (altImage->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) ? 1 : 3;
+    gainMap->altCLLI = altImage->clli;
+
+cleanup:
+    avifRGBImageFreePixels(&baseImageRgb);
+    avifRGBImageFreePixels(&altImageRgb);
+    return res;
+}
+
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
diff --git a/third_party/libavif/src/src/io.c b/third_party/libavif/src/src/io.c
new file mode 100644
index 0000000000..e43bdb5f2e
--- /dev/null
+++ b/third_party/libavif/src/src/io.c
@@ -0,0 +1,170 @@
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <limits.h>
+#include <stdio.h>
+#include <string.h>
+
+void avifIODestroy(avifIO * io)
+{
+    if (io && io->destroy) {
+        io->destroy(io);
+    }
+}
+
+// --------------------------------------------------------------------------------------
+// avifIOMemoryReader
+
+typedef struct avifIOMemoryReader
+{
+    avifIO io; // this must be the first member for easy casting to avifIO*
+    avifROData rodata;
+} avifIOMemoryReader;
+
+static avifResult avifIOMemoryReaderRead(struct avifIO * io, uint32_t readFlags, uint64_t offset, size_t size, avifROData * out)
+{
+    // printf("avifIOMemoryReaderRead offset %" PRIu64 " size %zu\n", offset, size);
+
+    if (readFlags != 0) {
+        // Unsupported readFlags
+        return AVIF_RESULT_IO_ERROR;
+    }
+
+    avifIOMemoryReader * reader = (avifIOMemoryReader *)io;
+
+    // Sanitize/clamp incoming request
+    if (offset > reader->rodata.size) {
+        // The offset is past the end of the buffer.
+        return AVIF_RESULT_IO_ERROR;
+    }
+    uint64_t availableSize = reader->rodata.size - offset;
+    if (size > availableSize) {
+        size = (size_t)availableSize;
+    }
+
+    // Prevent the offset addition from triggering an undefined behavior
+    // sanitizer error if data is NULL (happens even with offset zero).
+    out->data = offset ? reader->rodata.data + offset : reader->rodata.data;
+    out->size = size;
+    return AVIF_RESULT_OK;
+}
+
+static void avifIOMemoryReaderDestroy(struct avifIO * io)
+{
+    avifFree(io);
+}
+
+avifIO * avifIOCreateMemoryReader(const uint8_t * data, size_t size)
+{
+    avifIOMemoryReader * reader = (avifIOMemoryReader *)avifAlloc(sizeof(avifIOMemoryReader));
+    if (reader == NULL) {
+        return NULL;
+    }
+    memset(reader, 0, sizeof(avifIOMemoryReader));
+    reader->io.destroy = avifIOMemoryReaderDestroy;
+    reader->io.read = avifIOMemoryReaderRead;
+    reader->io.sizeHint = size;
+    reader->io.persistent = AVIF_TRUE;
+    reader->rodata.data = data;
+    reader->rodata.size = size;
+    return (avifIO *)reader;
+}
+
+// --------------------------------------------------------------------------------------
+// avifIOFileReader
+
+typedef struct avifIOFileReader
+{
+    avifIO io; // this must be the first member for easy casting to avifIO*
+    avifRWData buffer;
+    FILE * f;
+} avifIOFileReader;
+
+static avifResult avifIOFileReaderRead(struct avifIO * io, uint32_t readFlags, uint64_t offset, size_t size, avifROData * out)
+{
+    // printf("avifIOFileReaderRead offset %" PRIu64 " size %zu\n", offset, size);
+
+    if (readFlags != 0) {
+        // Unsupported readFlags
+        return AVIF_RESULT_IO_ERROR;
+    }
+
+    avifIOFileReader * reader = (avifIOFileReader *)io;
+
+    // Sanitize/clamp incoming request
+    if (offset > reader->io.sizeHint) {
+        // The offset is past the EOF.
+        return AVIF_RESULT_IO_ERROR;
+    }
+    uint64_t availableSize = reader->io.sizeHint - offset;
+    if (size > availableSize) {
+        size = (size_t)availableSize;
+    }
+
+    if (size > 0) {
+        if (offset > LONG_MAX) {
+            return AVIF_RESULT_IO_ERROR;
+        }
+        if (reader->buffer.size < size) {
+            AVIF_CHECKRES(avifRWDataRealloc(&reader->buffer, size));
+        }
+        if (fseek(reader->f, (long)offset, SEEK_SET) != 0) {
+            return AVIF_RESULT_IO_ERROR;
+        }
+        size_t bytesRead = fread(reader->buffer.data, 1, size, reader->f);
+        if (size != bytesRead) {
+            if (ferror(reader->f)) {
+                return AVIF_RESULT_IO_ERROR;
+            }
+            size = bytesRead;
+        }
+    }
+
+    out->data = reader->buffer.data;
+    out->size = size;
+    return AVIF_RESULT_OK;
+}
+
+static void avifIOFileReaderDestroy(struct avifIO * io)
+{
+    avifIOFileReader * reader = (avifIOFileReader *)io;
+    fclose(reader->f);
+    avifRWDataFree(&reader->buffer);
+    avifFree(io);
+}
+
+avifIO * avifIOCreateFileReader(const char * filename)
+{
+    FILE * f = fopen(filename, "rb");
+    if (!f) {
+        return NULL;
+    }
+
+    fseek(f, 0, SEEK_END);
+    long fileSize = ftell(f);
+    if (fileSize < 0) {
+        fclose(f);
+        return NULL;
+    }
+    fseek(f, 0, SEEK_SET);
+
+    avifIOFileReader * reader = (avifIOFileReader *)avifAlloc(sizeof(avifIOFileReader));
+    if (!reader) {
+        fclose(f);
+        return NULL;
+    }
+    memset(reader, 0, sizeof(avifIOFileReader));
+    reader->f = f;
+    reader->io.destroy = avifIOFileReaderDestroy;
+    reader->io.read = avifIOFileReaderRead;
+    reader->io.sizeHint = (uint64_t)fileSize;
+    reader->io.persistent = AVIF_FALSE;
+    if (avifRWDataRealloc(&reader->buffer, 1024) != AVIF_RESULT_OK) {
+        avifFree(reader);
+        fclose(f);
+        return NULL;
+    }
+    return (avifIO *)reader;
+}
diff --git a/third_party/libavif/src/src/mem.c b/third_party/libavif/src/src/mem.c
new file mode 100644
index 0000000000..5ccf5f3e0e
--- /dev/null
+++ b/third_party/libavif/src/src/mem.c
@@ -0,0 +1,18 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/avif.h"
+
+#include <assert.h>
+#include <stdlib.h>
+
+void * avifAlloc(size_t size)
+{
+    assert(size != 0); // Implementation-defined. See https://en.cppreference.com/w/cpp/memory/c/malloc
+    return malloc(size);
+}
+
+void avifFree(void * p)
+{
+    free(p);
+}
diff --git a/third_party/libavif/src/src/obu.c b/third_party/libavif/src/src/obu.c
new file mode 100644
index 0000000000..c7a2151584
--- /dev/null
+++ b/third_party/libavif/src/src/obu.c
@@ -0,0 +1,487 @@
+/*
+ * Copyright  2018, VideoLAN and dav1d authors
+ * Copyright  2018, Two Orioles, LLC
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice, this
+ *    list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright notice,
+ *    this list of conditions and the following disclaimer in the documentation
+ *    and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
+ * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+// OBU parsing and bit magic all originally from dav1d's obu.c and getbits.c,
+// but heavily modified/reduced down to simply find the Sequence Header OBU
+// and pull a few interesting pieces from it.
+//
+// Any other code in here is under this license:
+//
+// Copyright 2020 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <stdint.h>
+#include <string.h>
+
+#if defined(AVIF_CODEC_AVM)
+#include "config/aom_config.h"
+#endif
+
+// ---------------------------------------------------------------------------
+// avifBits - Originally dav1d's GetBits struct (see dav1d's getbits.c)
+
+typedef struct avifBits
+{
+    int error, eof;
+    uint64_t state;
+    uint32_t bitsLeft;
+    const uint8_t *ptr, *start, *end;
+} avifBits;
+
+static inline uint32_t avifBitsReadPos(const avifBits * bits)
+{
+    return (uint32_t)(bits->ptr - bits->start) * 8 - bits->bitsLeft;
+}
+
+static void avifBitsInit(avifBits * const bits, const uint8_t * const data, const size_t size)
+{
+    bits->ptr = bits->start = data;
+    bits->end = &bits->start[size];
+    bits->bitsLeft = 0;
+    bits->state = 0;
+    bits->error = 0;
+    bits->eof = (size == 0);
+}
+
+static void avifBitsRefill(avifBits * const bits, const uint32_t n)
+{
+    uint64_t state = 0;
+    do {
+        state <<= 8;
+        bits->bitsLeft += 8;
+        if (!bits->eof)
+            state |= *bits->ptr++;
+        if (bits->ptr >= bits->end) {
+            bits->error = bits->eof;
+            bits->eof = 1;
+        }
+    } while (n > bits->bitsLeft);
+    bits->state |= state << (64 - bits->bitsLeft);
+}
+
+static uint32_t avifBitsRead(avifBits * const bits, const uint32_t n)
+{
+    if (n > bits->bitsLeft)
+        avifBitsRefill(bits, n);
+
+    const uint64_t state = bits->state;
+    bits->bitsLeft -= n;
+    bits->state <<= n;
+
+    return (uint32_t)(state >> (64 - n));
+}
+
+static uint32_t avifBitsReadUleb128(avifBits * bits)
+{
+    uint64_t val = 0;
+    uint32_t more;
+    uint32_t i = 0;
+
+    do {
+        const uint32_t v = avifBitsRead(bits, 8);
+        more = v & 0x80;
+        val |= ((uint64_t)(v & 0x7F)) << i;
+        i += 7;
+    } while (more && i < 56);
+
+    if (val > UINT32_MAX || more) {
+        bits->error = 1;
+        return 0;
+    }
+
+    return (uint32_t)val;
+}
+
+static uint32_t avifBitsReadVLC(avifBits * const bits)
+{
+    int numBits = 0;
+    while (!avifBitsRead(bits, 1))
+        if (++numBits == 32)
+            return 0xFFFFFFFFU;
+    return numBits ? ((1U << numBits) - 1) + avifBitsRead(bits, numBits) : 0;
+}
+
+// ---------------------------------------------------------------------------
+// Variables in here use snake_case to self-document from the AV1 spec and the draft AV2 spec:
+//
+// https://aomediacodec.github.io/av1-spec/av1-spec.pdf
+//
+// Originally dav1d's parse_seq_hdr() function (heavily modified and split)
+
+static avifBool parseSequenceHeaderProfile(avifBits * bits, avifSequenceHeader * header)
+{
+    uint32_t seq_profile = avifBitsRead(bits, 3);
+    if (seq_profile > 2) {
+        return AVIF_FALSE;
+    }
+    header->av1C.seqProfile = (uint8_t)seq_profile;
+    return !bits->error;
+}
+
+static avifBool parseSequenceHeaderLevelIdxAndTier(avifBits * bits, avifSequenceHeader * header)
+{
+    uint32_t still_picture = avifBitsRead(bits, 1);
+    header->reduced_still_picture_header = (uint8_t)avifBitsRead(bits, 1);
+    if (header->reduced_still_picture_header && !still_picture) {
+        return AVIF_FALSE;
+    }
+
+    if (header->reduced_still_picture_header) {
+        header->av1C.seqLevelIdx0 = (uint8_t)avifBitsRead(bits, 5);
+        header->av1C.seqTier0 = 0;
+    } else {
+        uint32_t timing_info_present_flag = avifBitsRead(bits, 1);
+        uint32_t decoder_model_info_present_flag = 0;
+        uint32_t buffer_delay_length = 0;
+        if (timing_info_present_flag) { // timing_info()
+            avifBitsRead(bits, 32);     // num_units_in_display_tick
+            avifBitsRead(bits, 32);     // time_scale
+            uint32_t equal_picture_interval = avifBitsRead(bits, 1);
+            if (equal_picture_interval) {
+                uint32_t num_ticks_per_picture_minus_1 = avifBitsReadVLC(bits);
+                if (num_ticks_per_picture_minus_1 == 0xFFFFFFFFU)
+                    return AVIF_FALSE;
+            }
+
+            decoder_model_info_present_flag = avifBitsRead(bits, 1);
+            if (decoder_model_info_present_flag) { // decoder_model_info()
+                buffer_delay_length = avifBitsRead(bits, 5) + 1;
+                avifBitsRead(bits, 32); // num_units_in_decoding_tick
+                avifBitsRead(bits, 10); // buffer_removal_time_length_minus_1, frame_presentation_time_length_minus_1
+            }
+        }
+
+        uint32_t initial_display_delay_present_flag = avifBitsRead(bits, 1);
+        uint32_t operating_points_cnt = avifBitsRead(bits, 5) + 1;
+        for (uint32_t i = 0; i < operating_points_cnt; i++) {
+            avifBitsRead(bits, 12); // operating_point_idc
+            uint32_t seq_level_idx = avifBitsRead(bits, 5);
+            if (i == 0) {
+                header->av1C.seqLevelIdx0 = (uint8_t)seq_level_idx;
+                header->av1C.seqTier0 = 0;
+            }
+            if (seq_level_idx > 7) {
+                uint32_t seq_tier = avifBitsRead(bits, 1);
+                if (i == 0) {
+                    header->av1C.seqTier0 = (uint8_t)seq_tier;
+                }
+            }
+            if (decoder_model_info_present_flag) {
+                uint32_t decoder_model_present_for_this_op = avifBitsRead(bits, 1);
+                if (decoder_model_present_for_this_op) {     // operating_parameters_info()
+                    avifBitsRead(bits, buffer_delay_length); // decoder_buffer_delay
+                    avifBitsRead(bits, buffer_delay_length); // encoder_buffer_delay
+                    avifBitsRead(bits, 1);                   // low_delay_mode_flag
+                }
+            }
+            if (initial_display_delay_present_flag) {
+                uint32_t initial_display_delay_present_for_this_op = avifBitsRead(bits, 1);
+                if (initial_display_delay_present_for_this_op) {
+                    avifBitsRead(bits, 4); // initial_display_delay_minus_1
+                }
+            }
+        }
+    }
+    return !bits->error;
+}
+
+static avifBool parseSequenceHeaderFrameMaxDimensions(avifBits * bits, avifSequenceHeader * header)
+{
+    uint32_t frame_width_bits = avifBitsRead(bits, 4) + 1;
+    uint32_t frame_height_bits = avifBitsRead(bits, 4) + 1;
+    header->maxWidth = avifBitsRead(bits, frame_width_bits) + 1;   // max_frame_width
+    header->maxHeight = avifBitsRead(bits, frame_height_bits) + 1; // max_frame_height
+    uint32_t frame_id_numbers_present_flag = 0;
+    if (!header->reduced_still_picture_header) {
+        frame_id_numbers_present_flag = avifBitsRead(bits, 1);
+    }
+    if (frame_id_numbers_present_flag) {
+        avifBitsRead(bits, 7); // delta_frame_id_length_minus_2, additional_frame_id_length_minus_1
+    }
+    return !bits->error;
+}
+
+static avifBool parseSequenceHeaderEnabledFeatures(avifBits * bits, avifSequenceHeader * header)
+{
+    avifBitsRead(bits, 2); // enable_filter_intra, enable_intra_edge_filter
+
+    if (!header->reduced_still_picture_header) {
+        avifBitsRead(bits, 4); // enable_interintra_compound, enable_masked_compound, enable_warped_motion, enable_dual_filter
+        uint32_t enable_order_hint = avifBitsRead(bits, 1);
+        if (enable_order_hint) {
+            avifBitsRead(bits, 2); // enable_jnt_comp, enable_ref_frame_mvs
+        }
+
+        uint32_t seq_force_screen_content_tools = 0;
+        uint32_t seq_choose_screen_content_tools = avifBitsRead(bits, 1);
+        if (seq_choose_screen_content_tools) {
+            seq_force_screen_content_tools = 2;
+        } else {
+            seq_force_screen_content_tools = avifBitsRead(bits, 1);
+        }
+        if (seq_force_screen_content_tools > 0) {
+            uint32_t seq_choose_integer_mv = avifBitsRead(bits, 1);
+            if (!seq_choose_integer_mv) {
+                avifBitsRead(bits, 1); // seq_force_integer_mv
+            }
+        }
+        if (enable_order_hint) {
+            avifBitsRead(bits, 3); // order_hint_bits_minus_1
+        }
+    }
+
+    return !bits->error;
+}
+
+// Note: Does not parse separate_uv_delta_q.
+static avifBool parseSequenceHeaderColorConfig(avifBits * bits, avifSequenceHeader * header)
+{
+    header->bitDepth = 8;
+    header->chromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+    header->av1C.chromaSamplePosition = (uint8_t)header->chromaSamplePosition;
+    uint32_t high_bitdepth = avifBitsRead(bits, 1);
+    header->av1C.highBitdepth = (uint8_t)high_bitdepth;
+    if ((header->av1C.seqProfile == 2) && high_bitdepth) {
+        uint32_t twelve_bit = avifBitsRead(bits, 1);
+        header->bitDepth = twelve_bit ? 12 : 10;
+        header->av1C.twelveBit = (uint8_t)twelve_bit;
+    } else /* if (seq_profile <= 2) */ {
+        header->bitDepth = high_bitdepth ? 10 : 8;
+        header->av1C.twelveBit = 0;
+    }
+    uint32_t mono_chrome = 0;
+    if (header->av1C.seqProfile != 1) {
+        mono_chrome = avifBitsRead(bits, 1);
+    }
+    header->av1C.monochrome = (uint8_t)mono_chrome;
+    uint32_t color_description_present_flag = avifBitsRead(bits, 1);
+    if (color_description_present_flag) {
+        header->colorPrimaries = (avifColorPrimaries)avifBitsRead(bits, 8);                   // color_primaries
+        header->transferCharacteristics = (avifTransferCharacteristics)avifBitsRead(bits, 8); // transfer_characteristics
+        header->matrixCoefficients = (avifMatrixCoefficients)avifBitsRead(bits, 8);           // matrix_coefficients
+    } else {
+        header->colorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;
+        header->transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED;
+        header->matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED;
+    }
+    if (mono_chrome) {
+        header->range = avifBitsRead(bits, 1) ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED; // color_range
+        header->av1C.chromaSubsamplingX = 1;
+        header->av1C.chromaSubsamplingY = 1;
+        header->yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+    } else if (header->colorPrimaries == AVIF_COLOR_PRIMARIES_BT709 &&
+               header->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_SRGB &&
+               header->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) {
+        header->range = AVIF_RANGE_FULL;
+        header->av1C.chromaSubsamplingX = 0;
+        header->av1C.chromaSubsamplingY = 0;
+        header->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+    } else {
+        uint32_t subsampling_x = 0;
+        uint32_t subsampling_y = 0;
+        header->range = avifBitsRead(bits, 1) ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED; // color_range
+        switch (header->av1C.seqProfile) {
+            case 0:
+                subsampling_x = 1;
+                subsampling_y = 1;
+                header->yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+                break;
+            case 1:
+                subsampling_x = 0;
+                subsampling_y = 0;
+                header->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                break;
+            case 2:
+                if (header->bitDepth == 12) {
+                    subsampling_x = avifBitsRead(bits, 1);
+                    if (subsampling_x) {
+                        subsampling_y = avifBitsRead(bits, 1);
+                    }
+                } else {
+                    subsampling_x = 1;
+                    subsampling_y = 0;
+                }
+                if (subsampling_x) {
+                    header->yuvFormat = subsampling_y ? AVIF_PIXEL_FORMAT_YUV420 : AVIF_PIXEL_FORMAT_YUV422;
+                } else {
+                    header->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+                }
+                break;
+            default:
+                return AVIF_FALSE;
+        }
+
+        if (subsampling_x && subsampling_y) {
+            header->chromaSamplePosition = (avifChromaSamplePosition)avifBitsRead(bits, 2); // chroma_sample_position
+            header->av1C.chromaSamplePosition = (uint8_t)header->chromaSamplePosition;
+        }
+        header->av1C.chromaSubsamplingX = (uint8_t)subsampling_x;
+        header->av1C.chromaSubsamplingY = (uint8_t)subsampling_y;
+    }
+
+    return !bits->error;
+}
+
+static avifBool parseAV1SequenceHeader(avifBits * bits, avifSequenceHeader * header)
+{
+    AVIF_CHECK(parseSequenceHeaderProfile(bits, header));
+    AVIF_CHECK(parseSequenceHeaderLevelIdxAndTier(bits, header));
+
+    AVIF_CHECK(parseSequenceHeaderFrameMaxDimensions(bits, header));
+    avifBitsRead(bits, 1); // use_128x128_superblock
+    AVIF_CHECK(parseSequenceHeaderEnabledFeatures(bits, header));
+
+    avifBitsRead(bits, 3); // enable_superres, enable_cdef, enable_restoration
+
+    AVIF_CHECK(parseSequenceHeaderColorConfig(bits, header));
+    if (!header->av1C.monochrome) {
+        avifBitsRead(bits, 1); // separate_uv_delta_q
+    }
+
+    avifBitsRead(bits, 1); // film_grain_params_present
+    return !bits->error;
+}
+
+#if defined(AVIF_CODEC_AVM)
+// See https://gitlab.com/AOMediaCodec/avm/-/blob/main/av1/decoder/decodeframe.c
+static avifBool parseAV2SequenceHeader(avifBits * bits, avifSequenceHeader * header)
+{
+#if defined(AVIF_ENABLE_CWG_E103)
+    // See read_sequence_header_obu() in avm.
+    AVIF_CHECK(parseSequenceHeaderProfile(bits, header));
+
+    uint32_t frame_width_bits = avifBitsRead(bits, 4) + 1;
+    uint32_t frame_height_bits = avifBitsRead(bits, 4) + 1;
+    header->maxWidth = avifBitsRead(bits, frame_width_bits) + 1;   // max_frame_width
+    header->maxHeight = avifBitsRead(bits, frame_height_bits) + 1; // max_frame_height
+
+    // See av1_read_color_config() in avm.
+    AVIF_CHECK(parseSequenceHeaderColorConfig(bits, header));
+
+    // See read_sequence_header_obu() in avm.
+    AVIF_CHECK(parseSequenceHeaderLevelIdxAndTier(bits, header));
+
+    return !bits->error;
+#else  // !defined(AVIF_ENABLE_CWG_E103)
+    // See read_sequence_header_obu() in avm.
+    AVIF_CHECK(parseSequenceHeaderProfile(bits, header));
+    AVIF_CHECK(parseSequenceHeaderLevelIdxAndTier(bits, header));
+
+    // See av1_read_sequence_header() in avm.
+    AVIF_CHECK(parseSequenceHeaderFrameMaxDimensions(bits, header));
+    if (!avifBitsRead(bits, 1)) // BLOCK_256X256
+        avifBitsRead(bits, 1);  // BLOCK_128X128
+    AVIF_CHECK(parseSequenceHeaderEnabledFeatures(bits, header));
+
+    avifBitsRead(bits, 2);       // enable_superres, enable_cdef
+    if (avifBitsRead(bits, 1)) { // enable_restoration
+        const int lr_tools_disable_mask_length = /*RESTORE_SWITCHABLE_TYPES=*/5 - 1;
+        avifBitsRead(bits, lr_tools_disable_mask_length); // lr_tools_disable_mask[0]
+        if (avifBitsRead(bits, 1)) {
+            avifBitsRead(bits, lr_tools_disable_mask_length - 1); // lr_tools_disable_mask[1]
+        }
+    }
+
+    // See av1_read_color_config() in avm.
+    AVIF_CHECK(parseSequenceHeaderColorConfig(bits, header));
+    // Ignored fields.
+    //   separate_uv_delta_q
+    //   base_y_dc_delta_q
+    //   base_uv_dc_delta_q
+
+    // See read_sequence_header_obu() in avm.
+    // Ignored field.
+    //   film_grain_params_present
+
+    // See av1_read_sequence_header_beyond_av1() in avm.
+    // Other ignored fields.
+    return !bits->error;
+#endif // defined(AVIF_ENABLE_CWG_E103)
+}
+#endif
+
+avifBool avifSequenceHeaderParse(avifSequenceHeader * header, const avifROData * sample, avifCodecType codecType)
+{
+    avifROData obus = *sample;
+
+    // Find the sequence header OBU
+    while (obus.size > 0) {
+        avifBits bits;
+        avifBitsInit(&bits, obus.data, obus.size);
+
+        // obu_header()
+        const uint32_t obu_forbidden_bit = avifBitsRead(&bits, 1);
+        if (obu_forbidden_bit != 0) {
+            return AVIF_FALSE;
+        }
+        const uint32_t obu_type = avifBitsRead(&bits, 4);
+        const uint32_t obu_extension_flag = avifBitsRead(&bits, 1);
+        const uint32_t obu_has_size_field = avifBitsRead(&bits, 1);
+        avifBitsRead(&bits, 1); // obu_reserved_1bit
+
+        if (obu_extension_flag) {   // obu_extension_header()
+            avifBitsRead(&bits, 8); // temporal_id, spatial_id, extension_header_reserved_3bits
+        }
+
+        uint32_t obu_size = 0;
+        if (obu_has_size_field)
+            obu_size = avifBitsReadUleb128(&bits);
+        else
+            obu_size = (int)obus.size - 1 - obu_extension_flag;
+
+        if (bits.error) {
+            return AVIF_FALSE;
+        }
+
+        const uint32_t init_bit_pos = avifBitsReadPos(&bits);
+        const uint32_t init_byte_pos = init_bit_pos >> 3;
+        if (obu_size > obus.size - init_byte_pos)
+            return AVIF_FALSE;
+
+        if (obu_type == 1) { // Sequence Header
+            avifBits seqHdrBits;
+            avifBitsInit(&seqHdrBits, obus.data + init_byte_pos, obu_size);
+            switch (codecType) {
+                case AVIF_CODEC_TYPE_AV1:
+                    return parseAV1SequenceHeader(&seqHdrBits, header);
+#if defined(AVIF_CODEC_AVM)
+                case AVIF_CODEC_TYPE_AV2:
+                    return parseAV2SequenceHeader(&seqHdrBits, header);
+#endif
+                default:
+                    return AVIF_FALSE;
+            }
+        }
+
+        // Skip this OBU
+        obus.data += (size_t)obu_size + init_byte_pos;
+        obus.size -= (size_t)obu_size + init_byte_pos;
+    }
+    return AVIF_FALSE;
+}
diff --git a/third_party/libavif/src/src/rawdata.c b/third_party/libavif/src/src/rawdata.c
new file mode 100644
index 0000000000..6f8ff67464
--- /dev/null
+++ b/third_party/libavif/src/src/rawdata.c
@@ -0,0 +1,39 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <string.h>
+
+avifResult avifRWDataRealloc(avifRWData * raw, size_t newSize)
+{
+    if (raw->size != newSize) {
+        uint8_t * newData = (uint8_t *)avifAlloc(newSize);
+        AVIF_CHECKERR(newData, AVIF_RESULT_OUT_OF_MEMORY);
+        if (raw->size && newSize) {
+            memcpy(newData, raw->data, AVIF_MIN(raw->size, newSize));
+        }
+        avifFree(raw->data);
+        raw->data = newData;
+        raw->size = newSize;
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWDataSet(avifRWData * raw, const uint8_t * data, size_t len)
+{
+    if (len) {
+        AVIF_CHECKRES(avifRWDataRealloc(raw, len));
+        memcpy(raw->data, data, len);
+    } else {
+        avifRWDataFree(raw);
+    }
+    return AVIF_RESULT_OK;
+}
+
+void avifRWDataFree(avifRWData * raw)
+{
+    avifFree(raw->data);
+    raw->data = NULL;
+    raw->size = 0;
+}
diff --git a/third_party/libavif/src/src/read.c b/third_party/libavif/src/src/read.c
new file mode 100644
index 0000000000..f85868ccb2
--- /dev/null
+++ b/third_party/libavif/src/src/read.c
@@ -0,0 +1,6690 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <ctype.h>
+#include <inttypes.h>
+#include <limits.h>
+#include <math.h>
+#include <stdio.h>
+#include <string.h>
+
+#define AUXTYPE_SIZE 64
+#define CONTENTTYPE_SIZE 64
+
+// class VisualSampleEntry(codingname) extends SampleEntry(codingname) {
+//     unsigned int(16) pre_defined = 0;
+//     const unsigned int(16) reserved = 0;
+//     unsigned int(32)[3] pre_defined = 0;
+//     unsigned int(16) width;
+//     unsigned int(16) height;
+//     template unsigned int(32) horizresolution = 0x00480000; // 72 dpi
+//     template unsigned int(32) vertresolution = 0x00480000;  // 72 dpi
+//     const unsigned int(32) reserved = 0;
+//     template unsigned int(16) frame_count = 1;
+//     string[32] compressorname;
+//     template unsigned int(16) depth = 0x0018;
+//     int(16) pre_defined = -1;
+//     // other boxes from derived specifications
+//     CleanApertureBox clap;    // optional
+//     PixelAspectRatioBox pasp; // optional
+// }
+static const size_t VISUALSAMPLEENTRY_SIZE = 78;
+
+// The only supported ipma box values for both version and flags are [0,1], so there technically
+// can't be more than 4 unique tuples right now.
+#define MAX_IPMA_VERSION_AND_FLAGS_SEEN 4
+
+// ---------------------------------------------------------------------------
+// AVIF codec type (AV1 or AV2)
+
+static avifCodecType avifGetCodecType(const uint8_t * fourcc)
+{
+    if (!memcmp(fourcc, "av01", 4)) {
+        return AVIF_CODEC_TYPE_AV1;
+    }
+#if defined(AVIF_CODEC_AVM)
+    if (!memcmp(fourcc, "av02", 4)) {
+        return AVIF_CODEC_TYPE_AV2;
+    }
+#endif
+    return AVIF_CODEC_TYPE_UNKNOWN;
+}
+
+static const char * avifGetConfigurationPropertyName(avifCodecType codecType)
+{
+    switch (codecType) {
+        case AVIF_CODEC_TYPE_AV1:
+            return "av1C";
+#if defined(AVIF_CODEC_AVM)
+        case AVIF_CODEC_TYPE_AV2:
+            return "av2C";
+#endif
+        default:
+            assert(AVIF_FALSE);
+            return NULL;
+    }
+}
+
+// ---------------------------------------------------------------------------
+// Box data structures
+
+typedef uint8_t avifBrand[4];
+AVIF_ARRAY_DECLARE(avifBrandArray, avifBrand, brand);
+
+// ftyp
+typedef struct avifFileType
+{
+    uint8_t majorBrand[4];
+    uint8_t minorVersion[4];
+    // If not null, points to a memory block of 4 * compatibleBrandsCount bytes.
+    const uint8_t * compatibleBrands;
+    int compatibleBrandsCount;
+} avifFileType;
+
+// ispe
+typedef struct avifImageSpatialExtents
+{
+    uint32_t width;
+    uint32_t height;
+} avifImageSpatialExtents;
+
+// auxC
+typedef struct avifAuxiliaryType
+{
+    char auxType[AUXTYPE_SIZE];
+} avifAuxiliaryType;
+
+// infe mime content_type
+typedef struct avifContentType
+{
+    char contentType[CONTENTTYPE_SIZE];
+} avifContentType;
+
+// colr
+typedef struct avifColourInformationBox
+{
+    avifBool hasICC;
+    uint64_t iccOffset;
+    size_t iccSize;
+
+    avifBool hasNCLX;
+    avifColorPrimaries colorPrimaries;
+    avifTransferCharacteristics transferCharacteristics;
+    avifMatrixCoefficients matrixCoefficients;
+    avifRange range;
+} avifColourInformationBox;
+
+#define MAX_PIXI_PLANE_DEPTHS 4
+typedef struct avifPixelInformationProperty
+{
+    uint8_t planeDepths[MAX_PIXI_PLANE_DEPTHS];
+    uint8_t planeCount;
+} avifPixelInformationProperty;
+
+typedef struct avifOperatingPointSelectorProperty
+{
+    uint8_t opIndex;
+} avifOperatingPointSelectorProperty;
+
+typedef struct avifLayerSelectorProperty
+{
+    uint16_t layerID;
+} avifLayerSelectorProperty;
+
+typedef struct avifAV1LayeredImageIndexingProperty
+{
+    uint32_t layerSize[3];
+} avifAV1LayeredImageIndexingProperty;
+
+// ---------------------------------------------------------------------------
+// Top-level structures
+
+struct avifMeta;
+
+// Temporary storage for ipco/stsd contents until they can be associated and memcpy'd to an avifDecoderItem
+typedef struct avifProperty
+{
+    uint8_t type[4];
+    union
+    {
+        avifImageSpatialExtents ispe;
+        avifAuxiliaryType auxC;
+        avifColourInformationBox colr;
+        avifCodecConfigurationBox av1C; // TODO(yguyon): Rename or add av2C
+        avifPixelAspectRatioBox pasp;
+        avifCleanApertureBox clap;
+        avifImageRotation irot;
+        avifImageMirror imir;
+        avifPixelInformationProperty pixi;
+        avifOperatingPointSelectorProperty a1op;
+        avifLayerSelectorProperty lsel;
+        avifAV1LayeredImageIndexingProperty a1lx;
+        avifContentLightLevelInformationBox clli;
+    } u;
+} avifProperty;
+AVIF_ARRAY_DECLARE(avifPropertyArray, avifProperty, prop);
+
+// Finds the first property of a given type.
+static const avifProperty * avifPropertyArrayFind(const avifPropertyArray * properties, const char * type)
+{
+    for (uint32_t propertyIndex = 0; propertyIndex < properties->count; ++propertyIndex) {
+        const avifProperty * prop = &properties->prop[propertyIndex];
+        if (!memcmp(prop->type, type, 4)) {
+            return prop;
+        }
+    }
+    return NULL;
+}
+
+AVIF_ARRAY_DECLARE(avifExtentArray, avifExtent, extent);
+
+// one "item" worth for decoding (all iref, iloc, iprp, etc refer to one of these)
+typedef struct avifDecoderItem
+{
+    uint32_t id;
+    struct avifMeta * meta; // Unowned; A back-pointer for convenience
+    uint8_t type[4];
+    size_t size;
+    avifBool idatStored; // If true, offset is relative to the associated meta box's idat box (iloc construction_method==1)
+    uint32_t width;      // Set from this item's ispe property, if present
+    uint32_t height;     // Set from this item's ispe property, if present
+    avifContentType contentType;
+    avifPropertyArray properties;
+    avifExtentArray extents;       // All extent offsets/sizes
+    avifRWData mergedExtents;      // if set, is a single contiguous block of this item's extents (unused when extents.count == 1)
+    avifBool ownsMergedExtents;    // if true, mergedExtents must be freed when this item is destroyed
+    avifBool partialMergedExtents; // If true, mergedExtents doesn't have all of the item data yet
+    uint32_t thumbnailForID;       // if non-zero, this item is a thumbnail for Item #{thumbnailForID}
+    uint32_t auxForID;             // if non-zero, this item is an auxC plane for Item #{auxForID}
+    uint32_t descForID;            // if non-zero, this item is a content description for Item #{descForID}
+    uint32_t dimgForID;            // if non-zero, this item is an input of derived Item #{dimgForID}
+    uint32_t dimgIdx; // If dimgForId is non-zero, this is the zero-based index of this item in the list of Item #{dimgForID}'s dimg.
+    avifBool hasDimgFrom; // whether there is a 'dimg' box with this item's id as 'fromID'
+    uint32_t premByID;    // if non-zero, this item is premultiplied by Item #{premByID}
+    avifBool hasUnsupportedEssentialProperty; // If true, this item cites a property flagged as 'essential' that libavif doesn't support (yet). Ignore the item, if so.
+    avifBool ipmaSeen;    // if true, this item already received a property association
+    avifBool progressive; // if true, this item has progressive layers (a1lx), but does not select a specific layer (the layer_id value in lsel is set to 0xFFFF)
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    avifPixelFormat miniBoxPixelFormat; // Set from the MinimizedImageBox, if present (AVIF_PIXEL_FORMAT_NONE otherwise)
+    avifChromaSamplePosition miniBoxChromaSamplePosition; // Set from the MinimizedImageBox, if present (AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN otherwise)
+#endif
+} avifDecoderItem;
+AVIF_ARRAY_DECLARE(avifDecoderItemArray, avifDecoderItem *, item);
+
+// grid storage
+typedef struct avifImageGrid
+{
+    uint32_t rows;    // Legal range: [1-256]
+    uint32_t columns; // Legal range: [1-256]
+    uint32_t outputWidth;
+    uint32_t outputHeight;
+} avifImageGrid;
+
+// ---------------------------------------------------------------------------
+// avifTrack
+
+typedef struct avifSampleTableChunk
+{
+    uint64_t offset;
+} avifSampleTableChunk;
+AVIF_ARRAY_DECLARE(avifSampleTableChunkArray, avifSampleTableChunk, chunk);
+
+typedef struct avifSampleTableSampleToChunk
+{
+    uint32_t firstChunk;
+    uint32_t samplesPerChunk;
+    uint32_t sampleDescriptionIndex;
+} avifSampleTableSampleToChunk;
+AVIF_ARRAY_DECLARE(avifSampleTableSampleToChunkArray, avifSampleTableSampleToChunk, sampleToChunk);
+
+typedef struct avifSampleTableSampleSize
+{
+    uint32_t size;
+} avifSampleTableSampleSize;
+AVIF_ARRAY_DECLARE(avifSampleTableSampleSizeArray, avifSampleTableSampleSize, sampleSize);
+
+typedef struct avifSampleTableTimeToSample
+{
+    uint32_t sampleCount;
+    uint32_t sampleDelta;
+} avifSampleTableTimeToSample;
+AVIF_ARRAY_DECLARE(avifSampleTableTimeToSampleArray, avifSampleTableTimeToSample, timeToSample);
+
+typedef struct avifSyncSample
+{
+    uint32_t sampleNumber;
+} avifSyncSample;
+AVIF_ARRAY_DECLARE(avifSyncSampleArray, avifSyncSample, syncSample);
+
+typedef struct avifSampleDescription
+{
+    uint8_t format[4];
+    avifPropertyArray properties;
+} avifSampleDescription;
+AVIF_ARRAY_DECLARE(avifSampleDescriptionArray, avifSampleDescription, description);
+
+typedef struct avifSampleTable
+{
+    avifSampleTableChunkArray chunks;
+    avifSampleDescriptionArray sampleDescriptions;
+    avifSampleTableSampleToChunkArray sampleToChunks;
+    avifSampleTableSampleSizeArray sampleSizes;
+    avifSampleTableTimeToSampleArray timeToSamples;
+    avifSyncSampleArray syncSamples;
+    uint32_t allSamplesSize; // If this is non-zero, sampleSizes will be empty and all samples will be this size
+} avifSampleTable;
+
+static void avifSampleTableDestroy(avifSampleTable * sampleTable);
+
+static avifSampleTable * avifSampleTableCreate(void)
+{
+    avifSampleTable * sampleTable = (avifSampleTable *)avifAlloc(sizeof(avifSampleTable));
+    if (sampleTable == NULL) {
+        return NULL;
+    }
+    memset(sampleTable, 0, sizeof(avifSampleTable));
+    if (!avifArrayCreate(&sampleTable->chunks, sizeof(avifSampleTableChunk), 16) ||
+        !avifArrayCreate(&sampleTable->sampleDescriptions, sizeof(avifSampleDescription), 2) ||
+        !avifArrayCreate(&sampleTable->sampleToChunks, sizeof(avifSampleTableSampleToChunk), 16) ||
+        !avifArrayCreate(&sampleTable->sampleSizes, sizeof(avifSampleTableSampleSize), 16) ||
+        !avifArrayCreate(&sampleTable->timeToSamples, sizeof(avifSampleTableTimeToSample), 16) ||
+        !avifArrayCreate(&sampleTable->syncSamples, sizeof(avifSyncSample), 16)) {
+        avifSampleTableDestroy(sampleTable);
+        return NULL;
+    }
+    return sampleTable;
+}
+
+static void avifSampleTableDestroy(avifSampleTable * sampleTable)
+{
+    avifArrayDestroy(&sampleTable->chunks);
+    for (uint32_t i = 0; i < sampleTable->sampleDescriptions.count; ++i) {
+        avifSampleDescription * description = &sampleTable->sampleDescriptions.description[i];
+        avifArrayDestroy(&description->properties);
+    }
+    avifArrayDestroy(&sampleTable->sampleDescriptions);
+    avifArrayDestroy(&sampleTable->sampleToChunks);
+    avifArrayDestroy(&sampleTable->sampleSizes);
+    avifArrayDestroy(&sampleTable->timeToSamples);
+    avifArrayDestroy(&sampleTable->syncSamples);
+    avifFree(sampleTable);
+}
+
+static uint32_t avifSampleTableGetImageDelta(const avifSampleTable * sampleTable, uint32_t imageIndex)
+{
+    uint32_t maxSampleIndex = 0;
+    for (uint32_t i = 0; i < sampleTable->timeToSamples.count; ++i) {
+        const avifSampleTableTimeToSample * timeToSample = &sampleTable->timeToSamples.timeToSample[i];
+        maxSampleIndex += timeToSample->sampleCount;
+        if ((imageIndex < maxSampleIndex) || (i == (sampleTable->timeToSamples.count - 1))) {
+            return timeToSample->sampleDelta;
+        }
+    }
+
+    // TODO: fail here?
+    return 1;
+}
+
+static avifCodecType avifSampleTableGetCodecType(const avifSampleTable * sampleTable)
+{
+    for (uint32_t i = 0; i < sampleTable->sampleDescriptions.count; ++i) {
+        const avifCodecType codecType = avifGetCodecType(sampleTable->sampleDescriptions.description[i].format);
+        if (codecType != AVIF_CODEC_TYPE_UNKNOWN) {
+            return codecType;
+        }
+    }
+    return AVIF_CODEC_TYPE_UNKNOWN;
+}
+
+static uint32_t avifCodecConfigurationBoxGetDepth(const avifCodecConfigurationBox * av1C)
+{
+    if (av1C->twelveBit) {
+        return 12;
+    } else if (av1C->highBitdepth) {
+        return 10;
+    }
+    return 8;
+}
+
+// This is used as a hint to validating the clap box in avifDecoderItemValidateProperties.
+static avifPixelFormat avifCodecConfigurationBoxGetFormat(const avifCodecConfigurationBox * av1C)
+{
+    if (av1C->monochrome) {
+        return AVIF_PIXEL_FORMAT_YUV400;
+    } else if (av1C->chromaSubsamplingY == 1) {
+        return AVIF_PIXEL_FORMAT_YUV420;
+    } else if (av1C->chromaSubsamplingX == 1) {
+        return AVIF_PIXEL_FORMAT_YUV422;
+    }
+    return AVIF_PIXEL_FORMAT_YUV444;
+}
+
+static const avifPropertyArray * avifSampleTableGetProperties(const avifSampleTable * sampleTable, avifCodecType codecType)
+{
+    for (uint32_t i = 0; i < sampleTable->sampleDescriptions.count; ++i) {
+        const avifSampleDescription * description = &sampleTable->sampleDescriptions.description[i];
+        if (avifGetCodecType(description->format) == codecType) {
+            return &description->properties;
+        }
+    }
+    return NULL;
+}
+
+// one video track ("trak" contents)
+typedef struct avifTrack
+{
+    uint32_t id;
+    uint32_t auxForID; // if non-zero, this track is an auxC plane for Track #{auxForID}
+    uint32_t premByID; // if non-zero, this track is premultiplied by Track #{premByID}
+    uint32_t mediaTimescale;
+    uint64_t mediaDuration;
+    uint64_t trackDuration;
+    uint64_t segmentDuration;
+    avifBool isRepeating;
+    int repetitionCount;
+    uint32_t width;
+    uint32_t height;
+    avifSampleTable * sampleTable;
+    struct avifMeta * meta;
+} avifTrack;
+AVIF_ARRAY_DECLARE(avifTrackArray, avifTrack, track);
+
+// ---------------------------------------------------------------------------
+// avifCodecDecodeInput
+
+avifCodecDecodeInput * avifCodecDecodeInputCreate(void)
+{
+    avifCodecDecodeInput * decodeInput = (avifCodecDecodeInput *)avifAlloc(sizeof(avifCodecDecodeInput));
+    if (decodeInput == NULL) {
+        return NULL;
+    }
+    memset(decodeInput, 0, sizeof(avifCodecDecodeInput));
+    if (!avifArrayCreate(&decodeInput->samples, sizeof(avifDecodeSample), 1)) {
+        avifFree(decodeInput);
+        return NULL;
+    }
+    return decodeInput;
+}
+
+void avifCodecDecodeInputDestroy(avifCodecDecodeInput * decodeInput)
+{
+    for (uint32_t sampleIndex = 0; sampleIndex < decodeInput->samples.count; ++sampleIndex) {
+        avifDecodeSample * sample = &decodeInput->samples.sample[sampleIndex];
+        if (sample->ownsData) {
+            avifRWDataFree((avifRWData *)&sample->data);
+        }
+    }
+    avifArrayDestroy(&decodeInput->samples);
+    avifFree(decodeInput);
+}
+
+// Returns how many samples are in the chunk.
+static uint32_t avifGetSampleCountOfChunk(const avifSampleTableSampleToChunkArray * sampleToChunks, uint32_t chunkIndex)
+{
+    uint32_t sampleCount = 0;
+    for (int sampleToChunkIndex = sampleToChunks->count - 1; sampleToChunkIndex >= 0; --sampleToChunkIndex) {
+        const avifSampleTableSampleToChunk * sampleToChunk = &sampleToChunks->sampleToChunk[sampleToChunkIndex];
+        if (sampleToChunk->firstChunk <= (chunkIndex + 1)) {
+            sampleCount = sampleToChunk->samplesPerChunk;
+            break;
+        }
+    }
+    return sampleCount;
+}
+
+static avifResult avifCodecDecodeInputFillFromSampleTable(avifCodecDecodeInput * decodeInput,
+                                                          avifSampleTable * sampleTable,
+                                                          const uint32_t imageCountLimit,
+                                                          const uint64_t sizeHint,
+                                                          avifDiagnostics * diag)
+{
+    if (imageCountLimit) {
+        // Verify that the we're not about to exceed the frame count limit.
+
+        uint32_t imageCountLeft = imageCountLimit;
+        for (uint32_t chunkIndex = 0; chunkIndex < sampleTable->chunks.count; ++chunkIndex) {
+            // First, figure out how many samples are in this chunk
+            uint32_t sampleCount = avifGetSampleCountOfChunk(&sampleTable->sampleToChunks, chunkIndex);
+            if (sampleCount == 0) {
+                // chunks with 0 samples are invalid
+                avifDiagnosticsPrintf(diag, "Sample table contains a chunk with 0 samples");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            if (sampleCount > imageCountLeft) {
+                // This file exceeds the imageCountLimit, bail out
+                avifDiagnosticsPrintf(diag, "Exceeded avifDecoder's imageCountLimit");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            imageCountLeft -= sampleCount;
+        }
+    }
+
+    uint32_t sampleSizeIndex = 0;
+    for (uint32_t chunkIndex = 0; chunkIndex < sampleTable->chunks.count; ++chunkIndex) {
+        avifSampleTableChunk * chunk = &sampleTable->chunks.chunk[chunkIndex];
+
+        // First, figure out how many samples are in this chunk
+        uint32_t sampleCount = avifGetSampleCountOfChunk(&sampleTable->sampleToChunks, chunkIndex);
+        if (sampleCount == 0) {
+            // chunks with 0 samples are invalid
+            avifDiagnosticsPrintf(diag, "Sample table contains a chunk with 0 samples");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        uint64_t sampleOffset = chunk->offset;
+        for (uint32_t sampleIndex = 0; sampleIndex < sampleCount; ++sampleIndex) {
+            uint32_t sampleSize = sampleTable->allSamplesSize;
+            if (sampleSize == 0) {
+                if (sampleSizeIndex >= sampleTable->sampleSizes.count) {
+                    // We've run out of samples to sum
+                    avifDiagnosticsPrintf(diag, "Truncated sample table");
+                    return AVIF_RESULT_BMFF_PARSE_FAILED;
+                }
+                avifSampleTableSampleSize * sampleSizePtr = &sampleTable->sampleSizes.sampleSize[sampleSizeIndex];
+                sampleSize = sampleSizePtr->size;
+            }
+
+            avifDecodeSample * sample = (avifDecodeSample *)avifArrayPush(&decodeInput->samples);
+            AVIF_CHECKERR(sample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            sample->offset = sampleOffset;
+            sample->size = sampleSize;
+            sample->spatialID = AVIF_SPATIAL_ID_UNSET; // Not filtering by spatial_id
+            sample->sync = AVIF_FALSE;                 // to potentially be set to true following the outer loop
+
+            if (sampleSize > UINT64_MAX - sampleOffset) {
+                avifDiagnosticsPrintf(diag,
+                                      "Sample table contains an offset/size pair which overflows: [%" PRIu64 " / %u]",
+                                      sampleOffset,
+                                      sampleSize);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            if (sizeHint && ((sampleOffset + sampleSize) > sizeHint)) {
+                avifDiagnosticsPrintf(diag, "Exceeded avifIO's sizeHint, possibly truncated data");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            sampleOffset += sampleSize;
+            ++sampleSizeIndex;
+        }
+    }
+
+    // Mark appropriate samples as sync
+    for (uint32_t syncSampleIndex = 0; syncSampleIndex < sampleTable->syncSamples.count; ++syncSampleIndex) {
+        uint32_t frameIndex = sampleTable->syncSamples.syncSample[syncSampleIndex].sampleNumber - 1; // sampleNumber is 1-based
+        if (frameIndex < decodeInput->samples.count) {
+            decodeInput->samples.sample[frameIndex].sync = AVIF_TRUE;
+        }
+    }
+
+    // Assume frame 0 is sync, just in case the stss box is absent in the BMFF. (Unnecessary?)
+    if (decodeInput->samples.count > 0) {
+        decodeInput->samples.sample[0].sync = AVIF_TRUE;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifCodecDecodeInputFillFromDecoderItem(avifCodecDecodeInput * decodeInput,
+                                                          avifDecoderItem * item,
+                                                          avifBool allowProgressive,
+                                                          const uint32_t imageCountLimit,
+                                                          const uint64_t sizeHint,
+                                                          avifDiagnostics * diag)
+{
+    if (sizeHint && (item->size > sizeHint)) {
+        avifDiagnosticsPrintf(diag, "Exceeded avifIO's sizeHint, possibly truncated data");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    uint8_t layerCount = 0;
+    size_t layerSizes[4] = { 0 };
+    const avifProperty * a1lxProp = avifPropertyArrayFind(&item->properties, "a1lx");
+    if (a1lxProp) {
+        // Calculate layer count and all layer sizes from the a1lx box, and then validate
+
+        size_t remainingSize = item->size;
+        for (int i = 0; i < 3; ++i) {
+            ++layerCount;
+
+            const size_t layerSize = (size_t)a1lxProp->u.a1lx.layerSize[i];
+            if (layerSize) {
+                if (layerSize >= remainingSize) { // >= instead of > because there must be room for the last layer
+                    avifDiagnosticsPrintf(diag, "a1lx layer index [%d] does not fit in item size", i);
+                    return AVIF_RESULT_BMFF_PARSE_FAILED;
+                }
+                layerSizes[i] = layerSize;
+                remainingSize -= layerSize;
+            } else {
+                layerSizes[i] = remainingSize;
+                remainingSize = 0;
+                break;
+            }
+        }
+        if (remainingSize > 0) {
+            AVIF_ASSERT_OR_RETURN(layerCount == 3);
+            ++layerCount;
+            layerSizes[3] = remainingSize;
+        }
+    }
+
+    const avifProperty * lselProp = avifPropertyArrayFind(&item->properties, "lsel");
+    // Progressive images offer layers via the a1lxProp, but don't specify a layer selection with lsel.
+    //
+    // For backward compatibility with earlier drafts of AVIF spec v1.1.0, treat an absent lsel as
+    // equivalent to layer_id == 0xFFFF during the transitional period. Remove !lselProp when the test
+    // images have been updated to the v1.1.0 spec.
+    item->progressive = (a1lxProp && (!lselProp || (lselProp->u.lsel.layerID == 0xFFFF)));
+    if (lselProp && (lselProp->u.lsel.layerID != 0xFFFF)) {
+        // Layer selection. This requires that the underlying AV1 codec decodes all layers,
+        // and then only returns the requested layer as a single frame. To the user of libavif,
+        // this appears to be a single frame.
+
+        decodeInput->allLayers = AVIF_TRUE;
+
+        size_t sampleSize = 0;
+        if (layerCount > 0) {
+            // Optimization: If we're selecting a layer that doesn't require the entire image's payload (hinted via the a1lx box)
+
+            if (lselProp->u.lsel.layerID >= layerCount) {
+                avifDiagnosticsPrintf(diag,
+                                      "lsel property requests layer index [%u] which isn't present in a1lx property ([%u] layers)",
+                                      lselProp->u.lsel.layerID,
+                                      layerCount);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            for (uint8_t i = 0; i <= lselProp->u.lsel.layerID; ++i) {
+                sampleSize += layerSizes[i];
+            }
+        } else {
+            // This layer's payload subsection is unknown, just use the whole payload
+            sampleSize = item->size;
+        }
+
+        avifDecodeSample * sample = (avifDecodeSample *)avifArrayPush(&decodeInput->samples);
+        AVIF_CHECKERR(sample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        sample->itemID = item->id;
+        sample->offset = 0;
+        sample->size = sampleSize;
+        AVIF_ASSERT_OR_RETURN(lselProp->u.lsel.layerID < AVIF_MAX_AV1_LAYER_COUNT);
+        sample->spatialID = (uint8_t)lselProp->u.lsel.layerID;
+        sample->sync = AVIF_TRUE;
+    } else if (allowProgressive && item->progressive) {
+        // Progressive image. Decode all layers and expose them all to the user.
+
+        if (imageCountLimit && (layerCount > imageCountLimit)) {
+            avifDiagnosticsPrintf(diag, "Exceeded avifDecoder's imageCountLimit (progressive)");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        decodeInput->allLayers = AVIF_TRUE;
+
+        size_t offset = 0;
+        for (int i = 0; i < layerCount; ++i) {
+            avifDecodeSample * sample = (avifDecodeSample *)avifArrayPush(&decodeInput->samples);
+            AVIF_CHECKERR(sample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            sample->itemID = item->id;
+            sample->offset = offset;
+            sample->size = layerSizes[i];
+            sample->spatialID = AVIF_SPATIAL_ID_UNSET;
+            sample->sync = (i == 0); // Assume all layers depend on the first layer
+
+            offset += layerSizes[i];
+        }
+    } else {
+        // Typical case: Use the entire item's payload for a single frame output
+
+        avifDecodeSample * sample = (avifDecodeSample *)avifArrayPush(&decodeInput->samples);
+        AVIF_CHECKERR(sample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        sample->itemID = item->id;
+        sample->offset = 0;
+        sample->size = item->size;
+        sample->spatialID = AVIF_SPATIAL_ID_UNSET;
+        sample->sync = AVIF_TRUE;
+    }
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+// Helper macros / functions
+
+#define BEGIN_STREAM(VARNAME, PTR, SIZE, DIAG, CONTEXT) \
+    avifROStream VARNAME;                               \
+    avifROData VARNAME##_roData;                        \
+    VARNAME##_roData.data = PTR;                        \
+    VARNAME##_roData.size = SIZE;                       \
+    avifROStreamStart(&VARNAME, &VARNAME##_roData, DIAG, CONTEXT)
+
+// Use this to keep track of whether or not a child box that must be unique (0 or 1 present) has
+// been seen yet, when parsing a parent box. If the "seen" bit is already set for a given box when
+// it is encountered during parse, an error is thrown. Which bit corresponds to which box is
+// dictated entirely by the calling function.
+static avifBool uniqueBoxSeen(uint32_t * uniqueBoxFlags, uint32_t whichFlag, const char * parentBoxType, const char * boxType, avifDiagnostics * diagnostics)
+{
+    const uint32_t flag = 1 << whichFlag;
+    if (*uniqueBoxFlags & flag) {
+        // This box has already been seen. Error!
+        avifDiagnosticsPrintf(diagnostics, "Box[%s] contains a duplicate unique box of type '%s'", parentBoxType, boxType);
+        return AVIF_FALSE;
+    }
+
+    // Mark this box as seen.
+    *uniqueBoxFlags |= flag;
+    return AVIF_TRUE;
+}
+
+// ---------------------------------------------------------------------------
+// avifDecoderData
+
+typedef struct avifTile
+{
+    avifCodecDecodeInput * input;
+    avifCodecType codecType;
+    // This may point to a codec that it owns or point to a shared codec that it does not own. In the shared case, this will
+    // point to one of the avifCodec instances in avifDecoderData.
+    struct avifCodec * codec;
+    avifImage * image;
+    uint32_t width;  // Either avifTrack.width or avifDecoderItem.width
+    uint32_t height; // Either avifTrack.height or avifDecoderItem.height
+    uint8_t operatingPoint;
+} avifTile;
+AVIF_ARRAY_DECLARE(avifTileArray, avifTile, tile);
+
+// This holds one "meta" box (from the BMFF and HEIF standards) worth of relevant-to-AVIF information.
+// * If a meta box is parsed from the root level of the BMFF, it can contain the information about
+//   "items" which might be color planes, alpha planes, or EXIF or XMP metadata.
+// * If a meta box is parsed from inside of a track ("trak") box, any metadata (EXIF/XMP) items inside
+//   of that box are implicitly associated with that track.
+typedef struct avifMeta
+{
+    // Items (from HEIF) are the generic storage for any data that does not require timed processing
+    // (single image color planes, alpha planes, EXIF, XMP, etc). Each item has a unique integer ID >1,
+    // and is defined by a series of child boxes in a meta box:
+    //  * iloc - location:     byte offset to item data, item size in bytes
+    //  * iinf - information:  type of item (color planes, alpha plane, EXIF, XMP)
+    //  * ipco - properties:   dimensions, aspect ratio, image transformations, references to other items
+    //  * ipma - associations: Attaches an item in the properties list to a given item
+    //
+    // Items are lazily created in this array when any of the above boxes refer to one by a new (unseen) ID,
+    // and are then further modified/updated as new information for an item's ID is parsed.
+    avifDecoderItemArray items;
+
+    // Any ipco boxes explained above are populated into this array as a staging area, which are
+    // then duplicated into the appropriate items upon encountering an item property association
+    // (ipma) box.
+    avifPropertyArray properties;
+
+    // Filled with the contents of this meta box's "idat" box, which is raw data that an item can
+    // directly refer to in its item location box (iloc) instead of just giving an offset into the
+    // overall file. If all items' iloc boxes simply point at an offset/length in the file itself,
+    // this buffer will likely be empty.
+    avifRWData idat;
+
+    // Ever-incrementing ID for uniquely identifying which 'meta' box contains an idat (when
+    // multiple meta boxes exist as BMFF siblings). Each time avifParseMetaBox() is called on an
+    // avifMeta struct, this value is incremented. Any time an additional meta box is detected at
+    // the same "level" (root level, trak level, etc), this ID helps distinguish which meta box's
+    // "idat" is which, as items implicitly reference idat boxes that exist in the same meta
+    // box.
+    uint32_t idatID;
+
+    // Contents of a pitm box, which signal which of the items in this file is the main image. For
+    // AVIF, this should point at an image item containing color planes, and all other items
+    // are ignored unless they refer to this item in some way (alpha plane, EXIF/XMP metadata).
+    uint32_t primaryItemID;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    // If true, the fields above were extracted from a MinimizedImageBox.
+    avifBool fromMiniBox;
+#endif
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    // Parsed from Sample Transform metadata if present, otherwise empty.
+    avifSampleTransformExpression sampleTransformExpression;
+    // Bit depth extracted from the pixi property of the Sample Transform derived image item, if any.
+    uint32_t sampleTransformDepth;
+#endif
+} avifMeta;
+
+static void avifMetaDestroy(avifMeta * meta);
+
+static avifMeta * avifMetaCreate(void)
+{
+    avifMeta * meta = (avifMeta *)avifAlloc(sizeof(avifMeta));
+    if (meta == NULL) {
+        return NULL;
+    }
+    memset(meta, 0, sizeof(avifMeta));
+    if (!avifArrayCreate(&meta->items, sizeof(avifDecoderItem *), 8) || !avifArrayCreate(&meta->properties, sizeof(avifProperty), 16)) {
+        avifMetaDestroy(meta);
+        return NULL;
+    }
+    return meta;
+}
+
+static void avifMetaDestroy(avifMeta * meta)
+{
+    for (uint32_t i = 0; i < meta->items.count; ++i) {
+        avifDecoderItem * item = meta->items.item[i];
+        avifArrayDestroy(&item->properties);
+        avifArrayDestroy(&item->extents);
+        if (item->ownsMergedExtents) {
+            avifRWDataFree(&item->mergedExtents);
+        }
+        avifFree(item);
+    }
+    avifArrayDestroy(&meta->items);
+    avifArrayDestroy(&meta->properties);
+    avifRWDataFree(&meta->idat);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    avifArrayDestroy(&meta->sampleTransformExpression);
+#endif
+    avifFree(meta);
+}
+
+static avifResult avifCheckItemID(const char * boxFourcc, uint32_t itemID, avifDiagnostics * diag)
+{
+    if (itemID == 0) {
+        avifDiagnosticsPrintf(diag, "Box[%.4s] has an invalid item ID [%u]", boxFourcc, itemID);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifMetaFindOrCreateItem(avifMeta * meta, uint32_t itemID, avifDecoderItem ** item)
+{
+    *item = NULL;
+    AVIF_ASSERT_OR_RETURN(itemID != 0);
+
+    for (uint32_t i = 0; i < meta->items.count; ++i) {
+        if (meta->items.item[i]->id == itemID) {
+            *item = meta->items.item[i];
+            return AVIF_RESULT_OK;
+        }
+    }
+
+    avifDecoderItem ** itemPtr = (avifDecoderItem **)avifArrayPush(&meta->items);
+    AVIF_CHECKERR(itemPtr != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    *item = (avifDecoderItem *)avifAlloc(sizeof(avifDecoderItem));
+    if (*item == NULL) {
+        avifArrayPop(&meta->items);
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    memset(*item, 0, sizeof(avifDecoderItem));
+
+    *itemPtr = *item;
+    if (!avifArrayCreate(&(*item)->properties, sizeof(avifProperty), 16)) {
+        avifFree(*item);
+        *item = NULL;
+        avifArrayPop(&meta->items);
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    if (!avifArrayCreate(&(*item)->extents, sizeof(avifExtent), 1)) {
+        avifArrayDestroy(&(*item)->properties);
+        avifFree(*item);
+        *item = NULL;
+        avifArrayPop(&meta->items);
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    (*item)->id = itemID;
+    (*item)->meta = meta;
+    return AVIF_RESULT_OK;
+}
+
+// A group of AVIF tiles in an image item, such as a single tile or a grid of multiple tiles.
+typedef struct avifTileInfo
+{
+    unsigned int tileCount;
+    unsigned int decodedTileCount;
+    unsigned int firstTileIndex; // Within avifDecoderData.tiles.
+    avifImageGrid grid;
+} avifTileInfo;
+
+typedef struct avifDecoderData
+{
+    avifMeta * meta; // The root-level meta box
+    avifTrackArray tracks;
+    avifTileArray tiles;
+    avifTileInfo tileInfos[AVIF_ITEM_CATEGORY_COUNT];
+    avifDecoderSource source;
+    // When decoding AVIF images with grid, use a single decoder instance for all the tiles instead of creating a decoder instance
+    // for each tile. If that is the case, |codec| will be used by all the tiles.
+    //
+    // There are some edge cases where we will still need multiple decoder instances:
+    // * For animated AVIF with alpha, we will need two instances (one for the color planes and one for the alpha plane since they are both
+    //   encoded as separate video sequences). In this case, |codec| will be used for the color planes and |codecAlpha| will be
+    //   used for the alpha plane.
+    // * For grid images with multiple layers. In this case, each tile will need its own decoder instance since there would be
+    //   multiple layers in each tile. In this case, |codec| and |codecAlpha| are not used and each tile will have its own
+    //   decoder instance.
+    // * For grid images where the operating points of all the tiles are not the same. In this case, each tile needs its own
+    //   decoder instance (same as above).
+    avifCodec * codec;
+    avifCodec * codecAlpha;
+    uint8_t majorBrand[4];                     // From the file's ftyp, used by AVIF_DECODER_SOURCE_AUTO
+    avifBrandArray compatibleBrands;           // From the file's ftyp
+    avifDiagnostics * diag;                    // Shallow copy; owned by avifDecoder
+    const avifSampleTable * sourceSampleTable; // NULL unless (source == AVIF_DECODER_SOURCE_TRACKS), owned by an avifTrack
+    avifBool cicpSet;                          // True if avifDecoder's image has had its CICP set correctly yet.
+                                               // This allows nclx colr boxes to override AV1 CICP, as specified in the MIAF
+                                               // standard (ISO/IEC 23000-22:2019), section 7.3.6.4:
+                                               //   The colour information property takes precedence over any colour information
+                                               //   in the image bitstream, i.e. if the property is present, colour information in
+                                               //   the bitstream shall be ignored.
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    // Remember the dimg association order to the Sample Transform derived image item.
+    // Colour items only. The alpha items are implicit.
+    uint8_t sampleTransformNumInputImageItems; // At most AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS.
+    avifItemCategory sampleTransformInputImageItems[AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS];
+#endif
+} avifDecoderData;
+
+static void avifDecoderDataDestroy(avifDecoderData * data);
+
+static avifDecoderData * avifDecoderDataCreate(void)
+{
+    avifDecoderData * data = (avifDecoderData *)avifAlloc(sizeof(avifDecoderData));
+    if (data == NULL) {
+        return NULL;
+    }
+    memset(data, 0, sizeof(avifDecoderData));
+    data->meta = avifMetaCreate();
+    if (data->meta == NULL || !avifArrayCreate(&data->tracks, sizeof(avifTrack), 2) ||
+        !avifArrayCreate(&data->tiles, sizeof(avifTile), 8)) {
+        avifDecoderDataDestroy(data);
+        return NULL;
+    }
+    return data;
+}
+
+static void avifDecoderDataResetCodec(avifDecoderData * data)
+{
+    for (unsigned int i = 0; i < data->tiles.count; ++i) {
+        avifTile * tile = &data->tiles.tile[i];
+        if (tile->image) {
+            avifImageFreePlanes(tile->image, AVIF_PLANES_ALL); // forget any pointers into codec image buffers
+        }
+        if (tile->codec) {
+            // Check if tile->codec was created separately and destroy it in that case.
+            if (tile->codec != data->codec && tile->codec != data->codecAlpha) {
+                avifCodecDestroy(tile->codec);
+            }
+            tile->codec = NULL;
+        }
+    }
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        data->tileInfos[c].decodedTileCount = 0;
+    }
+    if (data->codec) {
+        avifCodecDestroy(data->codec);
+        data->codec = NULL;
+    }
+    if (data->codecAlpha) {
+        avifCodecDestroy(data->codecAlpha);
+        data->codecAlpha = NULL;
+    }
+}
+
+static avifTile * avifDecoderDataCreateTile(avifDecoderData * data, avifCodecType codecType, uint32_t width, uint32_t height, uint8_t operatingPoint)
+{
+    avifTile * tile = (avifTile *)avifArrayPush(&data->tiles);
+    if (tile == NULL) {
+        return NULL;
+    }
+    tile->codecType = codecType;
+    tile->image = avifImageCreateEmpty();
+    if (!tile->image) {
+        goto error;
+    }
+    tile->input = avifCodecDecodeInputCreate();
+    if (!tile->input) {
+        goto error;
+    }
+    tile->width = width;
+    tile->height = height;
+    tile->operatingPoint = operatingPoint;
+    return tile;
+
+error:
+    if (tile->input) {
+        avifCodecDecodeInputDestroy(tile->input);
+    }
+    if (tile->image) {
+        avifImageDestroy(tile->image);
+    }
+    avifArrayPop(&data->tiles);
+    return NULL;
+}
+
+static avifTrack * avifDecoderDataCreateTrack(avifDecoderData * data)
+{
+    avifTrack * track = (avifTrack *)avifArrayPush(&data->tracks);
+    if (track == NULL) {
+        return NULL;
+    }
+    track->meta = avifMetaCreate();
+    if (track->meta == NULL) {
+        avifArrayPop(&data->tracks);
+        return NULL;
+    }
+    return track;
+}
+
+static void avifDecoderDataClearTiles(avifDecoderData * data)
+{
+    for (unsigned int i = 0; i < data->tiles.count; ++i) {
+        avifTile * tile = &data->tiles.tile[i];
+        if (tile->input) {
+            avifCodecDecodeInputDestroy(tile->input);
+            tile->input = NULL;
+        }
+        if (tile->codec) {
+            // Check if tile->codec was created separately and destroy it in that case.
+            if (tile->codec != data->codec && tile->codec != data->codecAlpha) {
+                avifCodecDestroy(tile->codec);
+            }
+            tile->codec = NULL;
+        }
+        if (tile->image) {
+            avifImageDestroy(tile->image);
+            tile->image = NULL;
+        }
+    }
+    data->tiles.count = 0;
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        data->tileInfos[c].tileCount = 0;
+        data->tileInfos[c].decodedTileCount = 0;
+    }
+    if (data->codec) {
+        avifCodecDestroy(data->codec);
+        data->codec = NULL;
+    }
+    if (data->codecAlpha) {
+        avifCodecDestroy(data->codecAlpha);
+        data->codecAlpha = NULL;
+    }
+}
+
+static void avifDecoderDataDestroy(avifDecoderData * data)
+{
+    if (data->meta) {
+        avifMetaDestroy(data->meta);
+    }
+    for (uint32_t i = 0; i < data->tracks.count; ++i) {
+        avifTrack * track = &data->tracks.track[i];
+        if (track->sampleTable) {
+            avifSampleTableDestroy(track->sampleTable);
+        }
+        if (track->meta) {
+            avifMetaDestroy(track->meta);
+        }
+    }
+    avifArrayDestroy(&data->tracks);
+    avifDecoderDataClearTiles(data);
+    avifArrayDestroy(&data->tiles);
+    avifArrayDestroy(&data->compatibleBrands);
+    avifFree(data);
+}
+
+// This returns the max extent that has to be read in order to decode this item. If
+// the item is stored in an idat, the data has already been read during Parse() and
+// this function will return AVIF_RESULT_OK with a 0-byte extent.
+static avifResult avifDecoderItemMaxExtent(const avifDecoderItem * item, const avifDecodeSample * sample, avifExtent * outExtent)
+{
+    if (item->extents.count == 0) {
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+
+    if (item->idatStored) {
+        // construction_method: idat(1)
+
+        if (item->meta->idat.size > 0) {
+            // Already read from a meta box during Parse()
+            memset(outExtent, 0, sizeof(avifExtent));
+            return AVIF_RESULT_OK;
+        }
+
+        // no associated idat box was found in the meta box, bail out
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    // construction_method: file(0)
+
+    if (sample->size == 0) {
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+    uint64_t remainingOffset = sample->offset;
+    size_t remainingBytes = sample->size; // This may be smaller than item->size if the item is progressive
+
+    // Assert that the for loop below will execute at least one iteration.
+    AVIF_ASSERT_OR_RETURN(item->extents.count != 0);
+    uint64_t minOffset = UINT64_MAX;
+    uint64_t maxOffset = 0;
+    for (uint32_t extentIter = 0; extentIter < item->extents.count; ++extentIter) {
+        avifExtent * extent = &item->extents.extent[extentIter];
+
+        // Make local copies of extent->offset and extent->size as they might need to be adjusted
+        // due to the sample's offset.
+        uint64_t startOffset = extent->offset;
+        size_t extentSize = extent->size;
+        if (remainingOffset) {
+            if (remainingOffset >= extentSize) {
+                remainingOffset -= extentSize;
+                continue;
+            } else {
+                if (remainingOffset > UINT64_MAX - startOffset) {
+                    return AVIF_RESULT_BMFF_PARSE_FAILED;
+                }
+                startOffset += remainingOffset;
+                extentSize -= (size_t)remainingOffset;
+                remainingOffset = 0;
+            }
+        }
+
+        const size_t usedExtentSize = (extentSize < remainingBytes) ? extentSize : remainingBytes;
+
+        if (usedExtentSize > UINT64_MAX - startOffset) {
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        const uint64_t endOffset = startOffset + usedExtentSize;
+
+        if (minOffset > startOffset) {
+            minOffset = startOffset;
+        }
+        if (maxOffset < endOffset) {
+            maxOffset = endOffset;
+        }
+
+        remainingBytes -= usedExtentSize;
+        if (remainingBytes == 0) {
+            // We've got enough bytes for this sample.
+            break;
+        }
+    }
+
+    if (remainingBytes != 0) {
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+
+    outExtent->offset = minOffset;
+    const uint64_t extentLength = maxOffset - minOffset;
+    if (extentLength > SIZE_MAX) {
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    outExtent->size = (size_t)extentLength;
+    return AVIF_RESULT_OK;
+}
+
+static uint8_t avifDecoderItemOperatingPoint(const avifDecoderItem * item)
+{
+    const avifProperty * a1opProp = avifPropertyArrayFind(&item->properties, "a1op");
+    if (a1opProp) {
+        return a1opProp->u.a1op.opIndex;
+    }
+    return 0; // default
+}
+
+static avifResult avifDecoderItemValidateProperties(const avifDecoderItem * item,
+                                                    const char * configPropName,
+                                                    avifDiagnostics * diag,
+                                                    const avifStrictFlags strictFlags)
+{
+    const avifProperty * const configProp = avifPropertyArrayFind(&item->properties, configPropName);
+    if (!configProp) {
+        // An item configuration property box is mandatory in all valid AVIF configurations. Bail out.
+        avifDiagnosticsPrintf(diag, "Item ID %u of type '%.4s' is missing mandatory %s property", item->id, (const char *)item->type, configPropName);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    if (!memcmp(item->type, "grid", 4)) {
+        for (uint32_t i = 0; i < item->meta->items.count; ++i) {
+            avifDecoderItem * tile = item->meta->items.item[i];
+            if (tile->dimgForID != item->id) {
+                continue;
+            }
+            // Tile item types were checked in avifDecoderGenerateImageTiles(), no need to do it here.
+
+            // MIAF (ISO 23000-22:2019), Section 7.3.11.4.1:
+            //   All input images of a grid image item shall use the same [...] chroma sampling format,
+            //   and the same decoder configuration (see 7.3.6.2).
+
+            // The chroma sampling format is part of the decoder configuration.
+            const avifProperty * tileConfigProp = avifPropertyArrayFind(&tile->properties, configPropName);
+            if (!tileConfigProp) {
+                avifDiagnosticsPrintf(diag,
+                                      "Tile item ID %u of type '%.4s' is missing mandatory %s property",
+                                      tile->id,
+                                      (const char *)tile->type,
+                                      configPropName);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            // configProp was copied from a tile item to the grid item. Comparing tileConfigProp with it
+            // is equivalent to comparing tileConfigProp with the configPropName from the first tile.
+            if ((tileConfigProp->u.av1C.seqProfile != configProp->u.av1C.seqProfile) ||
+                (tileConfigProp->u.av1C.seqLevelIdx0 != configProp->u.av1C.seqLevelIdx0) ||
+                (tileConfigProp->u.av1C.seqTier0 != configProp->u.av1C.seqTier0) ||
+                (tileConfigProp->u.av1C.highBitdepth != configProp->u.av1C.highBitdepth) ||
+                (tileConfigProp->u.av1C.twelveBit != configProp->u.av1C.twelveBit) ||
+                (tileConfigProp->u.av1C.monochrome != configProp->u.av1C.monochrome) ||
+                (tileConfigProp->u.av1C.chromaSubsamplingX != configProp->u.av1C.chromaSubsamplingX) ||
+                (tileConfigProp->u.av1C.chromaSubsamplingY != configProp->u.av1C.chromaSubsamplingY) ||
+                (tileConfigProp->u.av1C.chromaSamplePosition != configProp->u.av1C.chromaSamplePosition)) {
+                avifDiagnosticsPrintf(diag,
+                                      "The fields of the %s property of tile item ID %u of type '%.4s' differs from other tiles",
+                                      configPropName,
+                                      tile->id,
+                                      (const char *)tile->type);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+    }
+
+    const avifProperty * pixiProp = avifPropertyArrayFind(&item->properties, "pixi");
+    if (!pixiProp && (strictFlags & AVIF_STRICT_PIXI_REQUIRED)) {
+        // A pixi box is mandatory in all valid AVIF configurations. Bail out.
+        avifDiagnosticsPrintf(diag,
+                              "[Strict] Item ID %u of type '%.4s' is missing mandatory pixi property",
+                              item->id,
+                              (const char *)item->type);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    if (pixiProp) {
+        const uint32_t configDepth = avifCodecConfigurationBoxGetDepth(&configProp->u.av1C);
+        for (uint8_t i = 0; i < pixiProp->u.pixi.planeCount; ++i) {
+            if (pixiProp->u.pixi.planeDepths[i] != configDepth) {
+                // pixi depth must match configuration property depth
+                avifDiagnosticsPrintf(diag,
+                                      "Item ID %u depth specified by pixi property [%u] does not match %s property depth [%u]",
+                                      item->id,
+                                      pixiProp->u.pixi.planeDepths[i],
+                                      configPropName,
+                                      configDepth);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    if (item->miniBoxPixelFormat != AVIF_PIXEL_FORMAT_NONE) {
+        // This is a MinimizedImageBox ('mini').
+
+        if (item->miniBoxPixelFormat != avifCodecConfigurationBoxGetFormat(&configProp->u.av1C)) {
+            if (!memcmp(configPropName, "av2C", 4) && item->miniBoxPixelFormat == AVIF_PIXEL_FORMAT_YUV400 &&
+                avifCodecConfigurationBoxGetFormat(&configProp->u.av1C) == AVIF_PIXEL_FORMAT_YUV420) {
+                // avm does not handle monochrome as of research-v8.0.0.
+                // 4:2:0 is used instead.
+            } else {
+                avifDiagnosticsPrintf(diag,
+                                      "Item ID %u format [%s] specified by MinimizedImageBox does not match %s property format [%s]",
+                                      item->id,
+                                      avifPixelFormatToString(item->miniBoxPixelFormat),
+                                      configPropName,
+                                      avifPixelFormatToString(avifCodecConfigurationBoxGetFormat(&configProp->u.av1C)));
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+
+        if (configProp->u.av1C.chromaSamplePosition == /*CSP_UNKNOWN=*/0) {
+            // Section 6.4.2. Color config semantics of AV1 specification says:
+            //   CSP_UNKNOWN - the source video transfer function must be signaled outside the AV1 bitstream
+            // See https://aomediacodec.github.io/av1-spec/#color-config-semantics
+
+            // So item->miniBoxChromaSamplePosition can differ and will override the AV1 value.
+        } else if ((uint8_t)item->miniBoxChromaSamplePosition != configProp->u.av1C.chromaSamplePosition) {
+            avifDiagnosticsPrintf(diag,
+                                  "Item ID %u chroma sample position [%u] specified by MinimizedImageBox does not match %s property chroma sample position [%u]",
+                                  item->id,
+                                  (uint32_t)item->miniBoxChromaSamplePosition,
+                                  configPropName,
+                                  configProp->u.av1C.chromaSamplePosition);
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+    if (strictFlags & AVIF_STRICT_CLAP_VALID) {
+        const avifProperty * clapProp = avifPropertyArrayFind(&item->properties, "clap");
+        if (clapProp) {
+            const avifProperty * ispeProp = avifPropertyArrayFind(&item->properties, "ispe");
+            if (!ispeProp) {
+                avifDiagnosticsPrintf(diag,
+                                      "[Strict] Item ID %u is missing an ispe property, so its clap property cannot be validated",
+                                      item->id);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            avifCropRect cropRect;
+            const uint32_t imageW = ispeProp->u.ispe.width;
+            const uint32_t imageH = ispeProp->u.ispe.height;
+            const avifPixelFormat configFormat = avifCodecConfigurationBoxGetFormat(&configProp->u.av1C);
+            avifBool validClap = avifCropRectConvertCleanApertureBox(&cropRect, &clapProp->u.clap, imageW, imageH, configFormat, diag);
+            if (!validClap) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifDecoderItemRead(avifDecoderItem * item,
+                                      avifIO * io,
+                                      avifROData * outData,
+                                      size_t offset,
+                                      size_t partialByteCount,
+                                      avifDiagnostics * diag)
+{
+    if (item->mergedExtents.data && !item->partialMergedExtents) {
+        // Multiple extents have already been concatenated for this item, just return it
+        if (offset >= item->mergedExtents.size) {
+            avifDiagnosticsPrintf(diag, "Item ID %u read has overflowing offset", item->id);
+            return AVIF_RESULT_TRUNCATED_DATA;
+        }
+        outData->data = item->mergedExtents.data + offset;
+        outData->size = item->mergedExtents.size - offset;
+        return AVIF_RESULT_OK;
+    }
+
+    if (item->extents.count == 0) {
+        avifDiagnosticsPrintf(diag, "Item ID %u has zero extents", item->id);
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+
+    // Find this item's source of all extents' data, based on the construction method
+    const avifRWData * idatBuffer = NULL;
+    if (item->idatStored) {
+        // construction_method: idat(1)
+
+        if (item->meta->idat.size > 0) {
+            idatBuffer = &item->meta->idat;
+        } else {
+            // no associated idat box was found in the meta box, bail out
+            avifDiagnosticsPrintf(diag, "Item ID %u is stored in an idat, but no associated idat box was found", item->id);
+            return AVIF_RESULT_NO_CONTENT;
+        }
+    }
+
+    // Merge extents into a single contiguous buffer
+    if ((io->sizeHint > 0) && (item->size > io->sizeHint)) {
+        // Sanity check: somehow the sum of extents exceeds the entire file or idat size!
+        avifDiagnosticsPrintf(diag, "Item ID %u reported size failed size hint sanity check. Truncated data?", item->id);
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+
+    if (offset >= item->size) {
+        avifDiagnosticsPrintf(diag, "Item ID %u read has overflowing offset", item->id);
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+    const size_t maxOutputSize = item->size - offset;
+    const size_t readOutputSize = (partialByteCount && (partialByteCount < maxOutputSize)) ? partialByteCount : maxOutputSize;
+    const size_t totalBytesToRead = offset + readOutputSize;
+
+    // If there is a single extent for this item and the source of the read buffer is going to be
+    // persistent for the lifetime of the avifDecoder (whether it comes from its own internal
+    // idatBuffer or from a known-persistent IO), we can avoid buffer duplication and just use the
+    // preexisting buffer.
+    avifBool singlePersistentBuffer = ((item->extents.count == 1) && (idatBuffer || io->persistent));
+    if (!singlePersistentBuffer) {
+        // Always allocate the item's full size here, as progressive image decodes will do partial
+        // reads into this buffer and begin feeding the buffer to the underlying AV1 decoder, but
+        // will then write more into this buffer without flushing the AV1 decoder (which is still
+        // holding the address of the previous allocation of this buffer). This strategy avoids
+        // use-after-free issues in the AV1 decoder and unnecessary reallocs as a typical
+        // progressive decode use case will eventually decode the final layer anyway.
+        AVIF_CHECKRES(avifRWDataRealloc(&item->mergedExtents, item->size));
+        item->ownsMergedExtents = AVIF_TRUE;
+    }
+
+    // Set this until we manage to fill the entire mergedExtents buffer
+    item->partialMergedExtents = AVIF_TRUE;
+
+    uint8_t * front = item->mergedExtents.data;
+    size_t remainingBytes = totalBytesToRead;
+    for (uint32_t extentIter = 0; extentIter < item->extents.count; ++extentIter) {
+        avifExtent * extent = &item->extents.extent[extentIter];
+
+        size_t bytesToRead = extent->size;
+        if (bytesToRead > remainingBytes) {
+            bytesToRead = remainingBytes;
+        }
+
+        avifROData offsetBuffer;
+        if (idatBuffer) {
+            if (extent->offset > idatBuffer->size) {
+                avifDiagnosticsPrintf(diag, "Item ID %u has impossible extent offset in idat buffer", item->id);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            // Since extent->offset (a uint64_t) is not bigger than idatBuffer->size (a size_t),
+            // it is safe to cast extent->offset to size_t.
+            const size_t extentOffset = (size_t)extent->offset;
+            if (extent->size > idatBuffer->size - extentOffset) {
+                avifDiagnosticsPrintf(diag, "Item ID %u has impossible extent size in idat buffer", item->id);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            offsetBuffer.data = idatBuffer->data + extentOffset;
+            offsetBuffer.size = idatBuffer->size - extentOffset;
+        } else {
+            // construction_method: file(0)
+
+            if ((io->sizeHint > 0) && (extent->offset > io->sizeHint)) {
+                avifDiagnosticsPrintf(diag, "Item ID %u extent offset failed size hint sanity check. Truncated data?", item->id);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            avifResult readResult = io->read(io, 0, extent->offset, bytesToRead, &offsetBuffer);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+            if (bytesToRead != offsetBuffer.size) {
+                avifDiagnosticsPrintf(diag,
+                                      "Item ID %u tried to read %zu bytes, but only received %zu bytes",
+                                      item->id,
+                                      bytesToRead,
+                                      offsetBuffer.size);
+                return AVIF_RESULT_TRUNCATED_DATA;
+            }
+        }
+
+        if (singlePersistentBuffer) {
+            memcpy(&item->mergedExtents, &offsetBuffer, sizeof(avifRWData));
+            item->mergedExtents.size = bytesToRead;
+        } else {
+            AVIF_ASSERT_OR_RETURN(item->ownsMergedExtents);
+            AVIF_ASSERT_OR_RETURN(front);
+            memcpy(front, offsetBuffer.data, bytesToRead);
+            front += bytesToRead;
+        }
+
+        remainingBytes -= bytesToRead;
+        if (remainingBytes == 0) {
+            // This happens when partialByteCount is set
+            break;
+        }
+    }
+    if (remainingBytes != 0) {
+        // This should be impossible?
+        avifDiagnosticsPrintf(diag, "Item ID %u has %zu unexpected trailing bytes", item->id, remainingBytes);
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+
+    outData->data = item->mergedExtents.data + offset;
+    outData->size = readOutputSize;
+    item->partialMergedExtents = (item->size != totalBytesToRead);
+    return AVIF_RESULT_OK;
+}
+
+// Returns the avifCodecType of the first tile of the gridItem.
+static avifCodecType avifDecoderItemGetGridCodecType(const avifDecoderItem * gridItem)
+{
+    for (uint32_t i = 0; i < gridItem->meta->items.count; ++i) {
+        avifDecoderItem * item = gridItem->meta->items.item[i];
+        const avifCodecType tileCodecType = avifGetCodecType(item->type);
+        if ((item->dimgForID == gridItem->id) && (tileCodecType != AVIF_CODEC_TYPE_UNKNOWN)) {
+            return tileCodecType;
+        }
+    }
+    return AVIF_CODEC_TYPE_UNKNOWN;
+}
+
+// Fills the dimgIdxToItemIdx array with a mapping from each 0-based tile index in the 'dimg' reference
+// to its corresponding 0-based index in the avifMeta::items array.
+static avifResult avifFillDimgIdxToItemIdxArray(uint32_t * dimgIdxToItemIdx, uint32_t numExpectedTiles, const avifDecoderItem * gridItem)
+{
+    const uint32_t itemIndexNotSet = UINT32_MAX;
+    for (uint32_t dimgIdx = 0; dimgIdx < numExpectedTiles; ++dimgIdx) {
+        dimgIdxToItemIdx[dimgIdx] = itemIndexNotSet;
+    }
+    uint32_t numTiles = 0;
+    for (uint32_t i = 0; i < gridItem->meta->items.count; ++i) {
+        if (gridItem->meta->items.item[i]->dimgForID == gridItem->id) {
+            const uint32_t tileItemDimgIdx = gridItem->meta->items.item[i]->dimgIdx;
+            AVIF_CHECKERR(tileItemDimgIdx < numExpectedTiles, AVIF_RESULT_INVALID_IMAGE_GRID);
+            AVIF_CHECKERR(dimgIdxToItemIdx[tileItemDimgIdx] == itemIndexNotSet, AVIF_RESULT_INVALID_IMAGE_GRID);
+            dimgIdxToItemIdx[tileItemDimgIdx] = i;
+            ++numTiles;
+        }
+    }
+    // The number of tiles has been verified in avifDecoderItemReadAndParse().
+    AVIF_ASSERT_OR_RETURN(numTiles == numExpectedTiles);
+    return AVIF_RESULT_OK;
+}
+
+// Copies the codec type property (av1C or av2C) from the first grid tile to the grid item.
+// Also checks that all tiles have the same codec type and that it's valid.
+static avifResult avifDecoderAdoptGridTileCodecType(avifDecoder * decoder,
+                                                    avifDecoderItem * gridItem,
+                                                    const uint32_t * dimgIdxToItemIdx,
+                                                    uint32_t numTiles)
+{
+    avifDecoderItem * firstTileItem = NULL;
+    for (uint32_t dimgIdx = 0; dimgIdx < numTiles; ++dimgIdx) {
+        const uint32_t itemIdx = dimgIdxToItemIdx[dimgIdx];
+        AVIF_ASSERT_OR_RETURN(itemIdx < gridItem->meta->items.count);
+        avifDecoderItem * item = gridItem->meta->items.item[itemIdx];
+
+        // According to HEIF (ISO 14496-12), Section 6.6.2.3.1, the SingleItemTypeReferenceBox of type 'dimg'
+        // identifies the input images of the derived image item of type 'grid'. Since the reference_count
+        // shall be equal to rows*columns, unknown tile item types cannot be skipped but must be considered
+        // as errors.
+        const avifCodecType tileCodecType = avifGetCodecType(item->type);
+        if (tileCodecType == AVIF_CODEC_TYPE_UNKNOWN) {
+            char type[4];
+            for (int j = 0; j < 4; j++) {
+                if (isprint((unsigned char)item->type[j])) {
+                    type[j] = item->type[j];
+                } else {
+                    type[j] = '.';
+                }
+            }
+            avifDiagnosticsPrintf(&decoder->diag,
+                                  "Tile item ID %u has an unknown item type '%.4s' (%02x%02x%02x%02x)",
+                                  item->id,
+                                  type,
+                                  item->type[0],
+                                  item->type[1],
+                                  item->type[2],
+                                  item->type[3]);
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+
+        if (item->hasUnsupportedEssentialProperty) {
+            // An essential property isn't supported by libavif; can't
+            // decode a grid image if any tile in the grid isn't supported.
+            avifDiagnosticsPrintf(&decoder->diag, "Grid image contains tile with an unsupported property marked as essential");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+
+        if (firstTileItem == NULL) {
+            firstTileItem = item;
+            // Adopt the configuration property of the first image item tile, so that it can be queried from
+            // the top-level color/alpha item during avifDecoderReset().
+            const avifCodecType codecType = avifGetCodecType(item->type);
+            const char * configPropName = avifGetConfigurationPropertyName(codecType);
+            const avifProperty * srcProp = avifPropertyArrayFind(&item->properties, configPropName);
+            if (!srcProp) {
+                avifDiagnosticsPrintf(&decoder->diag, "Grid image's first tile is missing an %s property", configPropName);
+                return AVIF_RESULT_INVALID_IMAGE_GRID;
+            }
+            avifProperty * dstProp = (avifProperty *)avifArrayPush(&gridItem->properties);
+            AVIF_CHECKERR(dstProp != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            *dstProp = *srcProp;
+
+        } else if (memcmp(item->type, firstTileItem->type, 4)) {
+            // MIAF (ISO 23000-22:2019), Section 7.3.11.4.1:
+            //   All input images of a grid image item shall use the same coding format [...]
+            // The coding format is defined by the item type.
+            avifDiagnosticsPrintf(&decoder->diag,
+                                  "Tile item ID %u of type '%.4s' differs from other tile type '%.4s'",
+                                  item->id,
+                                  (const char *)item->type,
+                                  (const char *)firstTileItem->type);
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// If the item is a grid, copies the codec type property (av1C or av2C) from the first grid tile to the grid item.
+// Also checks that all tiles have the same codec type and that it's valid.
+static avifResult avifDecoderAdoptGridTileCodecTypeIfNeeded(avifDecoder * decoder, avifDecoderItem * item, const avifTileInfo * info)
+{
+    if ((info->grid.rows > 0) && (info->grid.columns > 0)) {
+        // The number of tiles was verified in avifDecoderItemReadAndParse().
+        const uint32_t numTiles = info->grid.rows * info->grid.columns;
+        uint32_t * dimgIdxToItemIdx = (uint32_t *)avifAlloc(numTiles * sizeof(uint32_t));
+        AVIF_CHECKERR(dimgIdxToItemIdx != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        avifResult result = avifFillDimgIdxToItemIdxArray(dimgIdxToItemIdx, numTiles, item);
+        if (result == AVIF_RESULT_OK) {
+            result = avifDecoderAdoptGridTileCodecType(decoder, item, dimgIdxToItemIdx, numTiles);
+        }
+        avifFree(dimgIdxToItemIdx);
+        AVIF_CHECKRES(result);
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Creates the tiles and associate them to the items in the order of the 'dimg' association.
+static avifResult avifDecoderGenerateImageGridTiles(avifDecoder * decoder,
+                                                    avifDecoderItem * gridItem,
+                                                    avifItemCategory itemCategory,
+                                                    const uint32_t * dimgIdxToItemIdx,
+                                                    uint32_t numTiles)
+{
+    avifBool progressive = AVIF_TRUE;
+    for (uint32_t dimgIdx = 0; dimgIdx < numTiles; ++dimgIdx) {
+        const uint32_t itemIdx = dimgIdxToItemIdx[dimgIdx];
+        AVIF_ASSERT_OR_RETURN(itemIdx < gridItem->meta->items.count);
+        avifDecoderItem * item = gridItem->meta->items.item[itemIdx];
+
+        const avifCodecType tileCodecType = avifGetCodecType(item->type);
+        AVIF_CHECKERR(tileCodecType != AVIF_CODEC_TYPE_UNKNOWN, AVIF_RESULT_INVALID_IMAGE_GRID);
+        const avifTile * tile =
+            avifDecoderDataCreateTile(decoder->data, tileCodecType, item->width, item->height, avifDecoderItemOperatingPoint(item));
+        AVIF_CHECKERR(tile != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKRES(avifCodecDecodeInputFillFromDecoderItem(tile->input,
+                                                              item,
+                                                              decoder->allowProgressive,
+                                                              decoder->imageCountLimit,
+                                                              decoder->io->sizeHint,
+                                                              &decoder->diag));
+        tile->input->itemCategory = itemCategory;
+
+        if (!item->progressive) {
+            progressive = AVIF_FALSE;
+        }
+    }
+    if (itemCategory == AVIF_ITEM_COLOR && progressive) {
+        // If all the items that make up the grid are progressive, then propagate that status to the top-level grid item.
+        gridItem->progressive = AVIF_TRUE;
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Allocates the dstImage. Also verifies some spec compliance rules for grids, if relevant.
+static avifResult avifDecoderDataAllocateImagePlanes(avifDecoderData * data, const avifTileInfo * info, avifImage * dstImage)
+{
+    const avifTile * tile = &data->tiles.tile[info->firstTileIndex];
+    uint32_t dstWidth;
+    uint32_t dstHeight;
+
+    if (info->grid.rows > 0 && info->grid.columns > 0) {
+        const avifImageGrid * grid = &info->grid;
+        // Validate grid image size and tile size.
+        //
+        // HEIF (ISO/IEC 23008-12:2017), Section 6.6.2.3.1:
+        //   The tiled input images shall completely "cover" the reconstructed image grid canvas, ...
+        if (((tile->image->width * grid->columns) < grid->outputWidth) || ((tile->image->height * grid->rows) < grid->outputHeight)) {
+            avifDiagnosticsPrintf(data->diag,
+                                  "Grid image tiles do not completely cover the image (HEIF (ISO/IEC 23008-12:2017), Section 6.6.2.3.1)");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+        // Tiles in the rightmost column and bottommost row must overlap the reconstructed image grid canvas. See MIAF (ISO/IEC 23000-22:2019), Section 7.3.11.4.2, Figure 2.
+        if (((tile->image->width * (grid->columns - 1)) >= grid->outputWidth) ||
+            ((tile->image->height * (grid->rows - 1)) >= grid->outputHeight)) {
+            avifDiagnosticsPrintf(data->diag,
+                                  "Grid image tiles in the rightmost column and bottommost row do not overlap the reconstructed image grid canvas. See MIAF (ISO/IEC 23000-22:2019), Section 7.3.11.4.2, Figure 2");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+        if (!avifAreGridDimensionsValid(tile->image->yuvFormat,
+                                        grid->outputWidth,
+                                        grid->outputHeight,
+                                        tile->image->width,
+                                        tile->image->height,
+                                        data->diag)) {
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+        dstWidth = grid->outputWidth;
+        dstHeight = grid->outputHeight;
+    } else {
+        // Only one tile. Width and height are inherited from the 'ispe' property of the corresponding avifDecoderItem.
+        dstWidth = tile->width;
+        dstHeight = tile->height;
+    }
+
+    const avifBool alpha = avifIsAlpha(tile->input->itemCategory);
+    if (alpha) {
+        // An alpha tile does not contain any YUV pixels.
+        AVIF_ASSERT_OR_RETURN(tile->image->yuvFormat == AVIF_PIXEL_FORMAT_NONE);
+    }
+
+    const uint32_t dstDepth = tile->image->depth;
+
+    // Lazily populate dstImage with the new frame's properties.
+    const avifBool dimsOrDepthIsDifferent = (dstImage->width != dstWidth) || (dstImage->height != dstHeight) ||
+                                            (dstImage->depth != dstDepth);
+    const avifBool yuvFormatIsDifferent = !alpha && (dstImage->yuvFormat != tile->image->yuvFormat);
+    if (dimsOrDepthIsDifferent || yuvFormatIsDifferent) {
+        if (alpha) {
+            // Alpha doesn't match size, just bail out
+            avifDiagnosticsPrintf(data->diag, "Alpha plane dimensions do not match color plane dimensions");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+
+        if (dimsOrDepthIsDifferent) {
+            avifImageFreePlanes(dstImage, AVIF_PLANES_ALL);
+            dstImage->width = dstWidth;
+            dstImage->height = dstHeight;
+            dstImage->depth = dstDepth;
+        }
+        if (yuvFormatIsDifferent) {
+            avifImageFreePlanes(dstImage, AVIF_PLANES_YUV);
+            dstImage->yuvFormat = tile->image->yuvFormat;
+        }
+        // Keep dstImage->yuvRange which is already set to its correct value
+        // (extracted from the 'colr' box if parsed or from a Sequence Header OBU otherwise).
+
+        if (!data->cicpSet) {
+            data->cicpSet = AVIF_TRUE;
+            dstImage->colorPrimaries = tile->image->colorPrimaries;
+            dstImage->transferCharacteristics = tile->image->transferCharacteristics;
+            dstImage->matrixCoefficients = tile->image->matrixCoefficients;
+        }
+    }
+
+    if (avifImageAllocatePlanes(dstImage, alpha ? AVIF_PLANES_A : AVIF_PLANES_YUV) != AVIF_RESULT_OK) {
+        avifDiagnosticsPrintf(data->diag, "Image allocation failure");
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Copies over the pixels from the tile into dstImage.
+// Verifies that the relevant properties of the tile match those of the first tile in case of a grid.
+static avifResult avifDecoderDataCopyTileToImage(avifDecoderData * data,
+                                                 const avifTileInfo * info,
+                                                 avifImage * dstImage,
+                                                 const avifTile * tile,
+                                                 unsigned int tileIndex)
+{
+    const avifTile * firstTile = &data->tiles.tile[info->firstTileIndex];
+    if (tile != firstTile) {
+        // Check for tile consistency. All tiles in a grid image should match the first tile in the properties checked below.
+        if ((tile->image->width != firstTile->image->width) || (tile->image->height != firstTile->image->height) ||
+            (tile->image->depth != firstTile->image->depth) || (tile->image->yuvFormat != firstTile->image->yuvFormat) ||
+            (tile->image->yuvRange != firstTile->image->yuvRange) || (tile->image->colorPrimaries != firstTile->image->colorPrimaries) ||
+            (tile->image->transferCharacteristics != firstTile->image->transferCharacteristics) ||
+            (tile->image->matrixCoefficients != firstTile->image->matrixCoefficients)) {
+            avifDiagnosticsPrintf(data->diag, "Grid image contains mismatched tiles");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+    }
+
+    avifImage srcView;
+    avifImageSetDefaults(&srcView);
+    avifImage dstView;
+    avifImageSetDefaults(&dstView);
+    avifCropRect dstViewRect = { 0, 0, firstTile->image->width, firstTile->image->height };
+    if (info->grid.rows > 0 && info->grid.columns > 0) {
+        unsigned int rowIndex = tileIndex / info->grid.columns;
+        unsigned int colIndex = tileIndex % info->grid.columns;
+        dstViewRect.x = firstTile->image->width * colIndex;
+        dstViewRect.y = firstTile->image->height * rowIndex;
+        if (dstViewRect.x + dstViewRect.width > info->grid.outputWidth) {
+            dstViewRect.width = info->grid.outputWidth - dstViewRect.x;
+        }
+        if (dstViewRect.y + dstViewRect.height > info->grid.outputHeight) {
+            dstViewRect.height = info->grid.outputHeight - dstViewRect.y;
+        }
+    }
+    const avifCropRect srcViewRect = { 0, 0, dstViewRect.width, dstViewRect.height };
+    AVIF_ASSERT_OR_RETURN(avifImageSetViewRect(&dstView, dstImage, &dstViewRect) == AVIF_RESULT_OK &&
+                          avifImageSetViewRect(&srcView, tile->image, &srcViewRect) == AVIF_RESULT_OK);
+    avifImageCopySamples(&dstView, &srcView, avifIsAlpha(tile->input->itemCategory) ? AVIF_PLANES_A : AVIF_PLANES_YUV);
+    return AVIF_RESULT_OK;
+}
+
+// If colorId == 0 (a sentinel value as item IDs must be nonzero), accept any found EXIF/XMP metadata. Passing in 0
+// is used when finding metadata in a meta box embedded in a trak box, as any items inside of a meta box that is
+// inside of a trak box are implicitly associated to the track.
+static avifResult avifDecoderFindMetadata(avifDecoder * decoder, avifMeta * meta, avifImage * image, uint32_t colorId)
+{
+    if (decoder->ignoreExif && decoder->ignoreXMP) {
+        // Nothing to do!
+        return AVIF_RESULT_OK;
+    }
+
+    for (uint32_t itemIndex = 0; itemIndex < meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = meta->items.item[itemIndex];
+        if (!item->size) {
+            continue;
+        }
+        if (item->hasUnsupportedEssentialProperty) {
+            // An essential property isn't supported by libavif; ignore the item.
+            continue;
+        }
+
+        if ((colorId > 0) && (item->descForID != colorId)) {
+            // Not a content description (metadata) for the colorOBU, skip it
+            continue;
+        }
+
+        if (!decoder->ignoreExif && !memcmp(item->type, "Exif", 4)) {
+            avifROData exifContents;
+            avifResult readResult = avifDecoderItemRead(item, decoder->io, &exifContents, 0, 0, &decoder->diag);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+
+            // Advance past Annex A.2.1's header
+            BEGIN_STREAM(exifBoxStream, exifContents.data, exifContents.size, &decoder->diag, "Exif header");
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+            // The MinimizedImageBox does not signal the exifTiffHeaderOffset.
+            if (!meta->fromMiniBox)
+#endif
+            {
+                uint32_t exifTiffHeaderOffset;
+                AVIF_CHECKERR(avifROStreamReadU32(&exifBoxStream, &exifTiffHeaderOffset),
+                              AVIF_RESULT_INVALID_EXIF_PAYLOAD); // unsigned int(32) exif_tiff_header_offset;
+                size_t expectedExifTiffHeaderOffset;
+                AVIF_CHECKRES(avifGetExifTiffHeaderOffset(avifROStreamCurrent(&exifBoxStream),
+                                                          avifROStreamRemainingBytes(&exifBoxStream),
+                                                          &expectedExifTiffHeaderOffset));
+                AVIF_CHECKERR(exifTiffHeaderOffset == expectedExifTiffHeaderOffset, AVIF_RESULT_INVALID_EXIF_PAYLOAD);
+            }
+
+            AVIF_CHECKRES(avifRWDataSet(&image->exif, avifROStreamCurrent(&exifBoxStream), avifROStreamRemainingBytes(&exifBoxStream)));
+        } else if (!decoder->ignoreXMP && !memcmp(item->type, "mime", 4) &&
+                   !strcmp(item->contentType.contentType, AVIF_CONTENT_TYPE_XMP)) {
+            avifROData xmpContents;
+            avifResult readResult = avifDecoderItemRead(item, decoder->io, &xmpContents, 0, 0, &decoder->diag);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+
+            AVIF_CHECKRES(avifImageSetMetadataXMP(image, xmpContents.data, xmpContents.size));
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+// URN
+
+static avifBool isAlphaURN(const char * urn)
+{
+    return !strcmp(urn, AVIF_URN_ALPHA0) || !strcmp(urn, AVIF_URN_ALPHA1);
+}
+
+// ---------------------------------------------------------------------------
+// BMFF Parsing
+
+static avifBool avifParseHandlerBox(const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[hdlr]");
+
+    AVIF_CHECK(avifROStreamReadAndEnforceVersion(&s, 0));
+
+    uint32_t predefined;
+    AVIF_CHECK(avifROStreamReadU32(&s, &predefined)); // unsigned int(32) pre_defined = 0;
+    if (predefined != 0) {
+        avifDiagnosticsPrintf(diag, "Box[hdlr] contains a pre_defined value that is nonzero");
+        return AVIF_FALSE;
+    }
+
+    uint8_t handlerType[4];
+    AVIF_CHECK(avifROStreamRead(&s, handlerType, 4)); // unsigned int(32) handler_type;
+    if (memcmp(handlerType, "pict", 4) != 0) {
+        avifDiagnosticsPrintf(diag, "Box[hdlr] handler_type is not 'pict'");
+        return AVIF_FALSE;
+    }
+
+    for (int i = 0; i < 3; ++i) {
+        uint32_t reserved;
+        AVIF_CHECK(avifROStreamReadU32(&s, &reserved)); // const unsigned int(32)[3] reserved = 0;
+    }
+
+    // Verify that a valid string is here, but don't bother to store it
+    AVIF_CHECK(avifROStreamReadString(&s, NULL, 0)); // string name;
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseItemLocationBox(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[iloc]");
+
+    // Section 8.11.3.2 of ISO/IEC 14496-12.
+    uint8_t version;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, NULL), AVIF_RESULT_BMFF_PARSE_FAILED);
+    if (version > 2) {
+        avifDiagnosticsPrintf(diag, "Box[iloc] has an unsupported version [%u]", version);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    uint8_t offsetSize, lengthSize, baseOffsetSize, indexSize = 0;
+    uint32_t reserved;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &offsetSize, /*bitCount=*/4), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) offset_size;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &lengthSize, /*bitCount=*/4), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) length_size;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &baseOffsetSize, /*bitCount=*/4), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) base_offset_size;
+    if (version == 1 || version == 2) {
+        AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &indexSize, /*bitCount=*/4), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) index_size;
+    } else {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &reserved, /*bitCount=*/4), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) reserved;
+    }
+
+    // Section 8.11.3.3 of ISO/IEC 14496-12.
+    if ((offsetSize != 0 && offsetSize != 4 && offsetSize != 8) || (lengthSize != 0 && lengthSize != 4 && lengthSize != 8) ||
+        (baseOffsetSize != 0 && baseOffsetSize != 4 && baseOffsetSize != 8) || (indexSize != 0 && indexSize != 4 && indexSize != 8)) {
+        avifDiagnosticsPrintf(diag, "Box[iloc] has an invalid size");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    uint16_t tmp16;
+    uint32_t itemCount;
+    if (version < 2) {
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) item_count;
+        itemCount = tmp16;
+    } else {
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &itemCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) item_count;
+    }
+    for (uint32_t i = 0; i < itemCount; ++i) {
+        uint32_t itemID;
+        if (version < 2) {
+            AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) item_ID;
+            itemID = tmp16;
+        } else {
+            AVIF_CHECKERR(avifROStreamReadU32(&s, &itemID), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) item_ID;
+        }
+        AVIF_CHECKRES(avifCheckItemID("iloc", itemID, diag));
+
+        avifDecoderItem * item;
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, itemID, &item));
+        if (item->extents.count > 0) {
+            // This item has already been given extents via this iloc box. This is invalid.
+            avifDiagnosticsPrintf(diag, "Item ID [%u] contains duplicate sets of extents", itemID);
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        if (version == 1 || version == 2) {
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &reserved, /*bitCount=*/12), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(12) reserved = 0;
+            if (reserved) {
+                avifDiagnosticsPrintf(diag, "Box[iloc] has a non null reserved field [%u]", reserved);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            uint8_t constructionMethod;
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &constructionMethod, /*bitCount=*/4),
+                          AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(4) construction_method;
+            if (constructionMethod != 0 /* file offset */ && constructionMethod != 1 /* idat offset */) {
+                // construction method 2 (item offset) unsupported
+                avifDiagnosticsPrintf(diag, "Box[iloc] has an unsupported construction method [%u]", constructionMethod);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            if (constructionMethod == 1) {
+                item->idatStored = AVIF_TRUE;
+            }
+        }
+
+        uint16_t dataReferenceIndex;
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &dataReferenceIndex), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) data_reference_index;
+        uint64_t baseOffset;
+        AVIF_CHECKERR(avifROStreamReadUX8(&s, &baseOffset, baseOffsetSize), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(base_offset_size*8) base_offset;
+        uint16_t extentCount;
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &extentCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) extent_count;
+        for (int extentIter = 0; extentIter < extentCount; ++extentIter) {
+            if ((version == 1 || version == 2) && indexSize > 0) {
+                // Section 8.11.3.1 of ISO/IEC 14496-12:
+                //   The item_reference_index is only used for the method item_offset; it indicates the 1-based index
+                //   of the item reference with referenceType 'iloc' linked from this item. If index_size is 0, then
+                //   the value 1 is implied; the value 0 is reserved.
+                uint64_t itemReferenceIndex; // Ignored unless construction_method=2 which is unsupported, but still read it.
+                AVIF_CHECKERR(avifROStreamReadUX8(&s, &itemReferenceIndex, indexSize),
+                              AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(index_size*8) item_reference_index;
+            }
+
+            uint64_t extentOffset;
+            AVIF_CHECKERR(avifROStreamReadUX8(&s, &extentOffset, offsetSize), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(offset_size*8) extent_offset;
+            uint64_t extentLength;
+            AVIF_CHECKERR(avifROStreamReadUX8(&s, &extentLength, lengthSize), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(length_size*8) extent_length;
+
+            avifExtent * extent = (avifExtent *)avifArrayPush(&item->extents);
+            AVIF_CHECKERR(extent != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            if (extentOffset > UINT64_MAX - baseOffset) {
+                avifDiagnosticsPrintf(diag,
+                                      "Item ID [%u] contains an extent offset which overflows: [base: %" PRIu64 " offset:%" PRIu64 "]",
+                                      itemID,
+                                      baseOffset,
+                                      extentOffset);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            uint64_t offset = baseOffset + extentOffset;
+            extent->offset = offset;
+            if (extentLength > SIZE_MAX) {
+                avifDiagnosticsPrintf(diag, "Item ID [%u] contains an extent length which overflows: [%" PRIu64 "]", itemID, extentLength);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            extent->size = (size_t)extentLength;
+            if (extent->size > SIZE_MAX - item->size) {
+                avifDiagnosticsPrintf(diag,
+                                      "Item ID [%u] contains an extent length which overflows the item size: [%zu, %zu]",
+                                      itemID,
+                                      extent->size,
+                                      item->size);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            item->size += extent->size;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifParseImageGridBox(avifImageGrid * grid,
+                                      const uint8_t * raw,
+                                      size_t rawLen,
+                                      uint32_t imageSizeLimit,
+                                      uint32_t imageDimensionLimit,
+                                      avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[grid]");
+
+    uint8_t version, flags;
+    AVIF_CHECK(avifROStreamRead(&s, &version, 1)); // unsigned int(8) version = 0;
+    if (version != 0) {
+        avifDiagnosticsPrintf(diag, "Box[grid] has unsupported version [%u]", version);
+        return AVIF_FALSE;
+    }
+    uint8_t rowsMinusOne, columnsMinusOne;
+    AVIF_CHECK(avifROStreamRead(&s, &flags, 1));           // unsigned int(8) flags;
+    AVIF_CHECK(avifROStreamRead(&s, &rowsMinusOne, 1));    // unsigned int(8) rows_minus_one;
+    AVIF_CHECK(avifROStreamRead(&s, &columnsMinusOne, 1)); // unsigned int(8) columns_minus_one;
+    grid->rows = (uint32_t)rowsMinusOne + 1;
+    grid->columns = (uint32_t)columnsMinusOne + 1;
+
+    uint32_t fieldLength = ((flags & 1) + 1) * 16;
+    if (fieldLength == 16) {
+        uint16_t outputWidth16, outputHeight16;
+        AVIF_CHECK(avifROStreamReadU16(&s, &outputWidth16));  // unsigned int(FieldLength) output_width;
+        AVIF_CHECK(avifROStreamReadU16(&s, &outputHeight16)); // unsigned int(FieldLength) output_height;
+        grid->outputWidth = outputWidth16;
+        grid->outputHeight = outputHeight16;
+    } else {
+        if (fieldLength != 32) {
+            // This should be impossible
+            avifDiagnosticsPrintf(diag, "Grid box contains illegal field length: [%u]", fieldLength);
+            return AVIF_FALSE;
+        }
+        AVIF_CHECK(avifROStreamReadU32(&s, &grid->outputWidth));  // unsigned int(FieldLength) output_width;
+        AVIF_CHECK(avifROStreamReadU32(&s, &grid->outputHeight)); // unsigned int(FieldLength) output_height;
+    }
+    if ((grid->outputWidth == 0) || (grid->outputHeight == 0)) {
+        avifDiagnosticsPrintf(diag, "Grid box contains illegal dimensions: [%u x %u]", grid->outputWidth, grid->outputHeight);
+        return AVIF_FALSE;
+    }
+    if (avifDimensionsTooLarge(grid->outputWidth, grid->outputHeight, imageSizeLimit, imageDimensionLimit)) {
+        avifDiagnosticsPrintf(diag, "Grid box dimensions are too large: [%u x %u]", grid->outputWidth, grid->outputHeight);
+        return AVIF_FALSE;
+    }
+    return avifROStreamRemainingBytes(&s) == 0;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+
+static avifBool avifParseGainMapMetadata(avifGainMap * gainMap, avifROStream * s)
+{
+    uint32_t isMultichannel;
+    AVIF_CHECK(avifROStreamReadBitsU32(s, &isMultichannel, 1)); // unsigned int(1) is_multichannel;
+    const uint8_t channelCount = isMultichannel ? 3 : 1;
+
+    uint32_t useBaseColorSpace;
+    AVIF_CHECK(avifROStreamReadBitsU32(s, &useBaseColorSpace, 1)); // unsigned int(1) use_base_colour_space;
+    gainMap->useBaseColorSpace = useBaseColorSpace ? AVIF_TRUE : AVIF_FALSE;
+
+    uint32_t reserved;
+    AVIF_CHECK(avifROStreamReadBitsU32(s, &reserved, 6)); // unsigned int(6) reserved;
+
+    AVIF_CHECK(avifROStreamReadU32(s, &gainMap->baseHdrHeadroom.n));      // unsigned int(32) base_hdr_headroom_numerator;
+    AVIF_CHECK(avifROStreamReadU32(s, &gainMap->baseHdrHeadroom.d));      // unsigned int(32) base_hdr_headroom_denominator;
+    AVIF_CHECK(avifROStreamReadU32(s, &gainMap->alternateHdrHeadroom.n)); // unsigned int(32) alternate_hdr_headroom_numerator;
+    AVIF_CHECK(avifROStreamReadU32(s, &gainMap->alternateHdrHeadroom.d)); // unsigned int(32) alternate_hdr_headroom_denominator;
+
+    for (int c = 0; c < channelCount; ++c) {
+        AVIF_CHECK(avifROStreamReadU32(s, (uint32_t *)&gainMap->gainMapMin[c].n)); // int(32) gain_map_min_numerator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->gainMapMin[c].d));             // unsigned int(32) gain_map_min_denominator;
+        AVIF_CHECK(avifROStreamReadU32(s, (uint32_t *)&gainMap->gainMapMax[c].n)); // int(32) gain_map_max_numerator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->gainMapMax[c].d));             // unsigned int(32) gain_map_max_denominator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->gainMapGamma[c].n));           // unsigned int(32) gamma_numerator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->gainMapGamma[c].d));           // unsigned int(32) gamma_denominator;
+        AVIF_CHECK(avifROStreamReadU32(s, (uint32_t *)&gainMap->baseOffset[c].n)); // int(32) base_offset_numerator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->baseOffset[c].d));             // unsigned int(32) base_offset_denominator;
+        AVIF_CHECK(avifROStreamReadU32(s, (uint32_t *)&gainMap->alternateOffset[c].n)); // int(32) alternate_offset_numerator;
+        AVIF_CHECK(avifROStreamReadU32(s, &gainMap->alternateOffset[c].d)); // unsigned int(32) alternate_offset_denominator;
+    }
+
+    // Fill the remaining values by copying those from the first channel.
+    for (int c = channelCount; c < 3; ++c) {
+        gainMap->gainMapMin[c] = gainMap->gainMapMin[0];
+        gainMap->gainMapMax[c] = gainMap->gainMapMax[0];
+        gainMap->gainMapGamma[c] = gainMap->gainMapGamma[0];
+        gainMap->baseOffset[c] = gainMap->baseOffset[0];
+        gainMap->alternateOffset[c] = gainMap->alternateOffset[0];
+    }
+    return AVIF_TRUE;
+}
+
+// If the gain map's version or minimum_version tag is not supported, returns AVIF_RESULT_NOT_IMPLEMENTED.
+static avifResult avifParseToneMappedImageBox(avifGainMap * gainMap, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[tmap]");
+
+    uint8_t version;
+    AVIF_CHECKERR(avifROStreamRead(&s, &version, 1), AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE); // unsigned int(8) version = 0;
+    if (version != 0) {
+        avifDiagnosticsPrintf(diag, "Box[tmap] has unsupported version [%u]", version);
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    uint16_t minimumVersion;
+    AVIF_CHECKERR(avifROStreamReadU16(&s, &minimumVersion), AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE); // unsigned int(16) minimum_version;
+    const uint16_t supportedMetadataVersion = 0;
+    if (minimumVersion > supportedMetadataVersion) {
+        avifDiagnosticsPrintf(diag, "Box[tmap] has unsupported minimum version [%u]", minimumVersion);
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    uint16_t writerVersion;
+    AVIF_CHECKERR(avifROStreamReadU16(&s, &writerVersion), AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE); // unsigned int(16) writer_version;
+    AVIF_CHECKERR(writerVersion >= minimumVersion, AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE);
+
+    AVIF_CHECKERR(avifParseGainMapMetadata(gainMap, &s), AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE);
+
+    if (writerVersion <= supportedMetadataVersion) {
+        AVIF_CHECKERR(avifROStreamRemainingBytes(&s) == 0, AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE);
+    }
+
+    if (avifGainMapValidateMetadata(gainMap, diag) != AVIF_RESULT_OK) {
+        return AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE;
+    }
+
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+// bit_depth is assumed to be 2 (32-bit).
+static avifResult avifParseSampleTransformTokens(avifROStream * s, avifSampleTransformExpression * expression)
+{
+    uint8_t tokenCount;
+    AVIF_CHECK(avifROStreamRead(s, &tokenCount, /*size=*/1)); // unsigned int(8) token_count;
+    AVIF_CHECKERR(tokenCount != 0, AVIF_RESULT_BMFF_PARSE_FAILED);
+    AVIF_CHECKERR(avifArrayCreate(expression, sizeof(expression->tokens[0]), tokenCount), AVIF_RESULT_OUT_OF_MEMORY);
+
+    for (uint32_t t = 0; t < tokenCount; ++t) {
+        avifSampleTransformToken * token = (avifSampleTransformToken *)avifArrayPush(expression);
+        AVIF_CHECKERR(token != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+
+        AVIF_CHECK(avifROStreamRead(s, &token->type, /*size=*/1)); // unsigned int(8) token;
+        if (token->type == AVIF_SAMPLE_TRANSFORM_CONSTANT) {
+            // Two's complement representation is assumed here.
+            uint32_t constant;
+            AVIF_CHECK(avifROStreamReadU32(s, &constant)); // signed int(1<<(bit_depth+3)) constant;
+            token->constant = *(int32_t *)&constant;       // maybe =(int32_t)constant; is enough
+        } else if (token->type == AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX) {
+            AVIF_CHECK(avifROStreamRead(s, &token->inputImageItemIndex, 1)); // unsigned int(8) input_image_item_index;
+        }
+    }
+    AVIF_CHECKERR(avifROStreamRemainingBytes(s) == 0, AVIF_RESULT_BMFF_PARSE_FAILED);
+    return AVIF_RESULT_OK;
+}
+
+// Parses the raw bitstream of the 'sato' Sample Transform derived image item and extracts the expression.
+static avifResult avifParseSampleTransformImageBox(const uint8_t * raw,
+                                                   size_t rawLen,
+                                                   uint32_t numInputImageItems,
+                                                   avifSampleTransformExpression * expression,
+                                                   avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[sato]");
+
+    uint8_t version, bitDepth;
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &version, /*bitCount=*/6));  // unsigned int(6) version = 0;
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &bitDepth, /*bitCount=*/2)); // unsigned int(2) bit_depth;
+    AVIF_CHECKERR(version == 0, AVIF_RESULT_NOT_IMPLEMENTED);
+    AVIF_CHECKERR(bitDepth == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32, AVIF_RESULT_NOT_IMPLEMENTED);
+
+    const avifResult result = avifParseSampleTransformTokens(&s, expression);
+    if (result != AVIF_RESULT_OK) {
+        avifArrayDestroy(expression);
+        return result;
+    }
+    if (!avifSampleTransformExpressionIsValid(expression, numInputImageItems)) {
+        avifArrayDestroy(expression);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifDecoderSampleTransformItemValidateProperties(const avifDecoderItem * item, avifDiagnostics * diag)
+{
+    const avifProperty * pixiProp = avifPropertyArrayFind(&item->properties, "pixi");
+    if (!pixiProp) {
+        avifDiagnosticsPrintf(diag, "Item ID %u of type '%.4s' is missing mandatory pixi property", item->id, (const char *)item->type);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    for (uint8_t i = 0; i < pixiProp->u.pixi.planeCount; ++i) {
+        if (pixiProp->u.pixi.planeDepths[i] != pixiProp->u.pixi.planeDepths[0]) {
+            avifDiagnosticsPrintf(diag,
+                                  "Item ID %u of type '%.4s' has different depths specified by pixi property [%u, %u], this is not supported",
+                                  item->id,
+                                  (const char *)item->type,
+                                  pixiProp->u.pixi.planeDepths[0],
+                                  pixiProp->u.pixi.planeDepths[i]);
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+    }
+
+    const avifProperty * ispeProp = avifPropertyArrayFind(&item->properties, "ispe");
+    if (!ispeProp) {
+        avifDiagnosticsPrintf(diag, "Item ID %u of type '%.4s' is missing mandatory ispe property", item->id, (const char *)item->type);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    for (uint32_t i = 0; i < item->meta->items.count; ++i) {
+        avifDecoderItem * inputImageItem = item->meta->items.item[i];
+        if (inputImageItem->dimgForID != item->id) {
+            continue;
+        }
+        // Even if inputImageItem is a grid, the ispe property from its first tile should have been copied to the grid item.
+        const avifProperty * inputImageItemIspeProp = avifPropertyArrayFind(&inputImageItem->properties, "ispe");
+        AVIF_ASSERT_OR_RETURN(inputImageItemIspeProp != NULL);
+        if (inputImageItemIspeProp->u.ispe.width != ispeProp->u.ispe.width ||
+            inputImageItemIspeProp->u.ispe.height != ispeProp->u.ispe.height) {
+            avifDiagnosticsPrintf(diag,
+                                  "The fields of the ispe property of item ID %u of type '%.4s' differs from item ID %u",
+                                  inputImageItem->id,
+                                  (const char *)inputImageItem->type,
+                                  item->id);
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        // TODO(yguyon): Check that all input image items share the same codec config (except for the bit depth value).
+    }
+
+    AVIF_CHECKERR(avifPropertyArrayFind(&item->properties, "clap") == NULL, AVIF_RESULT_NOT_IMPLEMENTED);
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+// Extracts the codecType from the item type or from its children.
+// Also parses and outputs grid information if the item is a grid.
+// isItemInInput must be false if the item is a made-up structure
+// (and thus not part of the parseable input bitstream).
+static avifResult avifDecoderItemReadAndParse(const avifDecoder * decoder,
+                                              avifDecoderItem * item,
+                                              avifBool isItemInInput,
+                                              avifImageGrid * grid,
+                                              avifCodecType * codecType)
+{
+    if (!memcmp(item->type, "grid", 4)) {
+        if (isItemInInput) {
+            avifROData readData;
+            AVIF_CHECKRES(avifDecoderItemRead(item, decoder->io, &readData, 0, 0, decoder->data->diag));
+            AVIF_CHECKERR(avifParseImageGridBox(grid,
+                                                readData.data,
+                                                readData.size,
+                                                decoder->imageSizeLimit,
+                                                decoder->imageDimensionLimit,
+                                                decoder->data->diag),
+                          AVIF_RESULT_INVALID_IMAGE_GRID);
+            // Validate that there are exactly the same number of dimg items to form the grid.
+            uint32_t dimgItemCount = 0;
+            for (uint32_t i = 0; i < item->meta->items.count; ++i) {
+                if (item->meta->items.item[i]->dimgForID == item->id) {
+                    ++dimgItemCount;
+                }
+            }
+            AVIF_CHECKERR(dimgItemCount == grid->rows * grid->columns, AVIF_RESULT_INVALID_IMAGE_GRID);
+        } else {
+            // item was generated for convenience and is not part of the bitstream.
+            // grid information should already be set.
+            AVIF_ASSERT_OR_RETURN(grid->rows > 0 && grid->columns > 0);
+        }
+        *codecType = avifDecoderItemGetGridCodecType(item);
+        AVIF_CHECKERR(*codecType != AVIF_CODEC_TYPE_UNKNOWN, AVIF_RESULT_INVALID_IMAGE_GRID);
+    } else {
+        *codecType = avifGetCodecType(item->type);
+        AVIF_ASSERT_OR_RETURN(*codecType != AVIF_CODEC_TYPE_UNKNOWN);
+    }
+    // TODO(yguyon): If AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM is defined, backward-incompatible
+    //               files with a primary 'sato' Sample Transform derived image item could be
+    //               handled here (compared to backward-compatible files with a 'sato' item in the
+    //               same 'altr' group as the primary regular color item which are handled in
+    //               avifDecoderDataFindSampleTransformImageItem() below).
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifParseImageSpatialExtentsProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[ispe]");
+    AVIF_CHECK(avifROStreamReadAndEnforceVersion(&s, 0));
+
+    avifImageSpatialExtents * ispe = &prop->u.ispe;
+    AVIF_CHECK(avifROStreamReadU32(&s, &ispe->width));
+    AVIF_CHECK(avifROStreamReadU32(&s, &ispe->height));
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseAuxiliaryTypeProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[auxC]");
+    AVIF_CHECK(avifROStreamReadAndEnforceVersion(&s, 0));
+
+    AVIF_CHECK(avifROStreamReadString(&s, prop->u.auxC.auxType, AUXTYPE_SIZE));
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseColourInformationBox(avifProperty * prop, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[colr]");
+
+    avifColourInformationBox * colr = &prop->u.colr;
+    colr->hasICC = AVIF_FALSE;
+    colr->hasNCLX = AVIF_FALSE;
+
+    uint8_t colorType[4]; // unsigned int(32) colour_type;
+    AVIF_CHECK(avifROStreamRead(&s, colorType, 4));
+    if (!memcmp(colorType, "rICC", 4) || !memcmp(colorType, "prof", 4)) {
+        colr->hasICC = AVIF_TRUE;
+        // Remember the offset of the ICC payload relative to the beginning of the stream. A direct pointer cannot be stored
+        // because decoder->io->persistent could have been AVIF_FALSE when obtaining raw through decoder->io->read().
+        // The bytes could be copied now instead of remembering the offset, but it is as invasive as passing rawOffset everywhere.
+        colr->iccOffset = rawOffset + avifROStreamOffset(&s);
+        colr->iccSize = avifROStreamRemainingBytes(&s);
+    } else if (!memcmp(colorType, "nclx", 4)) {
+        AVIF_CHECK(avifROStreamReadU16(&s, &colr->colorPrimaries));          // unsigned int(16) colour_primaries;
+        AVIF_CHECK(avifROStreamReadU16(&s, &colr->transferCharacteristics)); // unsigned int(16) transfer_characteristics;
+        AVIF_CHECK(avifROStreamReadU16(&s, &colr->matrixCoefficients));      // unsigned int(16) matrix_coefficients;
+        uint8_t full_range_flag;
+        AVIF_CHECK(avifROStreamReadBitsU8(&s, &full_range_flag, /*bitCount=*/1)); // unsigned int(1) full_range_flag;
+        colr->range = full_range_flag ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED;
+        uint8_t reserved;
+        AVIF_CHECK(avifROStreamReadBitsU8(&s, &reserved, /*bitCount=*/7)); // unsigned int(7) reserved = 0;
+        if (reserved) {
+            avifDiagnosticsPrintf(diag, "Box[colr] contains nonzero reserved bits [%u]", reserved);
+            return AVIF_FALSE;
+        }
+        colr->hasNCLX = AVIF_TRUE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseContentLightLevelInformation(avifROStream * s, avifContentLightLevelInformationBox * clli)
+{
+    AVIF_CHECKERR(avifROStreamReadBitsU16(s, &clli->maxCLL, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) max_content_light_level
+    AVIF_CHECKERR(avifROStreamReadBitsU16(s, &clli->maxPALL, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) max_pic_average_light_level
+    return AVIF_RESULT_OK;
+}
+static avifResult avifParseContentLightLevelInformationBox(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[clli]");
+    AVIF_CHECKRES(avifParseContentLightLevelInformation(&s, &prop->u.clli));
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI) && defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+static avifResult avifSkipMasteringDisplayColourVolume(avifROStream * s)
+{
+    for (int c = 0; c < 3; c++) {
+        AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) display_primaries_x;
+        AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) display_primaries_y;
+    }
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) white_point_x;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) white_point_y;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) max_display_mastering_luminance;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) min_display_mastering_luminance;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifSkipContentColourVolume(avifROStream * s)
+{
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) reserved = 0; // ccv_cancel_flag
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) reserved = 0; // ccv_persistence_flag
+    uint8_t ccvPrimariesPresent;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(s, &ccvPrimariesPresent, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) ccv_primaries_present_flag;
+    uint8_t ccvMinLuminanceValuePresent, ccvMaxLuminanceValuePresent, ccvAvgLuminanceValuePresent;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(s, &ccvMinLuminanceValuePresent, 1),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) ccv_min_luminance_value_present_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(s, &ccvMaxLuminanceValuePresent, 1),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) ccv_max_luminance_value_present_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU8(s, &ccvAvgLuminanceValuePresent, 1),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(1) ccv_avg_luminance_value_present_flag;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 2), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(2) reserved = 0;
+
+    if (ccvPrimariesPresent) {
+        for (int c = 0; c < 3; c++) {
+            AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // signed int(32) ccv_primaries_x[[c]];
+            AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // signed int(32) ccv_primaries_y[[c]];
+        }
+    }
+    if (ccvMinLuminanceValuePresent) {
+        AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) ccv_min_luminance_value;
+    }
+    if (ccvMaxLuminanceValuePresent) {
+        AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) ccv_max_luminance_value;
+    }
+    if (ccvAvgLuminanceValuePresent) {
+        AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) ccv_avg_luminance_value;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifSkipAmbientViewingEnvironment(avifROStream * s)
+{
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) ambient_illuminance;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) ambient_light_x;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) ambient_light_y;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifSkipReferenceViewingEnvironment(avifROStream * s)
+{
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) surround_luminance;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) surround_light_x;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) surround_light_y;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) periphery_luminance;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) periphery_light_x;
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 16), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) periphery_light_y;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifSkipNominalDiffuseWhite(avifROStream * s)
+{
+    AVIF_CHECKERR(avifROStreamSkipBits(s, 32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) diffuse_white_luminance;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseMiniHDRProperties(avifROStream * s, uint32_t * hasClli, avifContentLightLevelInformationBox * clli)
+{
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, hasClli, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) clli_flag;
+    uint32_t hasMdcv, hasCclv, hasAmve, hasReve, hasNdwt;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, &hasMdcv, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) mdcv_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, &hasCclv, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) cclv_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, &hasAmve, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) amve_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, &hasReve, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) reve_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(s, &hasNdwt, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) ndwt_flag;
+    if (*hasClli) {
+        AVIF_CHECKRES(avifParseContentLightLevelInformation(s, clli)); // ContentLightLevel clli;
+    }
+    if (hasMdcv) {
+        AVIF_CHECKRES(avifSkipMasteringDisplayColourVolume(s)); // MasteringDisplayColourVolume mdcv;
+    }
+    if (hasCclv) {
+        AVIF_CHECKRES(avifSkipContentColourVolume(s)); // ContentColourVolume cclv;
+    }
+    if (hasAmve) {
+        AVIF_CHECKRES(avifSkipAmbientViewingEnvironment(s)); // AmbientViewingEnvironment amve;
+    }
+    if (hasReve) {
+        AVIF_CHECKRES(avifSkipReferenceViewingEnvironment(s)); // ReferenceViewingEnvironment reve;
+    }
+    if (hasNdwt) {
+        AVIF_CHECKRES(avifSkipNominalDiffuseWhite(s)); // NominalDiffuseWhite ndwt;
+    }
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI && AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+// Implementation of section 2.3.3 of AV1 Codec ISO Media File Format Binding specification v1.2.0.
+// See https://aomediacodec.github.io/av1-isobmff/v1.2.0.html#av1codecconfigurationbox-syntax.
+static avifBool avifParseCodecConfiguration(avifROStream * s, avifCodecConfigurationBox * config, const char * configPropName, avifDiagnostics * diag)
+{
+    const size_t av1COffset = s->offset;
+
+    uint32_t marker, version;
+    AVIF_CHECK(avifROStreamReadBitsU32(s, &marker, /*bitCount=*/1)); // unsigned int (1) marker = 1;
+    if (!marker) {
+        avifDiagnosticsPrintf(diag, "%.4s contains illegal marker: [%u]", configPropName, marker);
+        return AVIF_FALSE;
+    }
+    AVIF_CHECK(avifROStreamReadBitsU32(s, &version, /*bitCount=*/7)); // unsigned int (7) version = 1;
+    if (version != 1) {
+        avifDiagnosticsPrintf(diag, "%.4s contains illegal version: [%u]", configPropName, version);
+        return AVIF_FALSE;
+    }
+
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->seqProfile, /*bitCount=*/3));         // unsigned int (3) seq_profile;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->seqLevelIdx0, /*bitCount=*/5));       // unsigned int (5) seq_level_idx_0;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->seqTier0, /*bitCount=*/1));           // unsigned int (1) seq_tier_0;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->highBitdepth, /*bitCount=*/1));       // unsigned int (1) high_bitdepth;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->twelveBit, /*bitCount=*/1));          // unsigned int (1) twelve_bit;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->monochrome, /*bitCount=*/1));         // unsigned int (1) monochrome;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->chromaSubsamplingX, /*bitCount=*/1)); // unsigned int (1) chroma_subsampling_x;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->chromaSubsamplingY, /*bitCount=*/1)); // unsigned int (1) chroma_subsampling_y;
+    AVIF_CHECK(avifROStreamReadBitsU8(s, &config->chromaSamplePosition, /*bitCount=*/2)); // unsigned int (2) chroma_sample_position;
+
+    // unsigned int (3) reserved = 0;
+    // unsigned int (1) initial_presentation_delay_present;
+    // if (initial_presentation_delay_present) {
+    //   unsigned int (4) initial_presentation_delay_minus_one;
+    // } else {
+    //   unsigned int (4) reserved = 0;
+    // }
+    AVIF_CHECK(avifROStreamSkip(s, /*byteCount=*/1));
+
+    // According to section 2.2.1 of AV1 Image File Format specification v1.1.0:
+    //   - Sequence Header OBUs should not be present in the AV1CodecConfigurationBox.
+    //   - If a Sequence Header OBU is present in the AV1CodecConfigurationBox,
+    //     it shall match the Sequence Header OBU in the AV1 Image Item Data.
+    //   - Metadata OBUs, if present, shall match the values given in other item properties,
+    //     such as the PixelInformationProperty or ColourInformationBox.
+    // See https://aomediacodec.github.io/av1-avif/v1.1.0.html#av1-configuration-item-property.
+    // For simplicity, the constraints above are not enforced.
+    // The following is skipped by avifParseItemPropertyContainerBox().
+    // unsigned int (8) configOBUs[];
+
+    AVIF_CHECK(s->offset - av1COffset == 4); // Make sure avifParseCodecConfiguration() reads exactly 4 bytes.
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseCodecConfigurationBoxProperty(avifProperty * prop,
+                                                       const uint8_t * raw,
+                                                       size_t rawLen,
+                                                       const char * configPropName,
+                                                       avifDiagnostics * diag)
+{
+    char diagContext[10];
+    snprintf(diagContext, sizeof(diagContext), "Box[%.4s]", configPropName); // "Box[av1C]" or "Box[av2C]"
+    BEGIN_STREAM(s, raw, rawLen, diag, diagContext);
+    return avifParseCodecConfiguration(&s, &prop->u.av1C, configPropName, diag);
+}
+
+static avifBool avifParsePixelAspectRatioBoxProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[pasp]");
+
+    avifPixelAspectRatioBox * pasp = &prop->u.pasp;
+    AVIF_CHECK(avifROStreamReadU32(&s, &pasp->hSpacing)); // unsigned int(32) hSpacing;
+    AVIF_CHECK(avifROStreamReadU32(&s, &pasp->vSpacing)); // unsigned int(32) vSpacing;
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseCleanApertureBoxProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[clap]");
+
+    avifCleanApertureBox * clap = &prop->u.clap;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->widthN));    // unsigned int(32) cleanApertureWidthN;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->widthD));    // unsigned int(32) cleanApertureWidthD;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->heightN));   // unsigned int(32) cleanApertureHeightN;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->heightD));   // unsigned int(32) cleanApertureHeightD;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->horizOffN)); // unsigned int(32) horizOffN;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->horizOffD)); // unsigned int(32) horizOffD;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->vertOffN));  // unsigned int(32) vertOffN;
+    AVIF_CHECK(avifROStreamReadU32(&s, &clap->vertOffD));  // unsigned int(32) vertOffD;
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseImageRotationProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[irot]");
+
+    avifImageRotation * irot = &prop->u.irot;
+    uint8_t reserved;
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &reserved, /*bitCount=*/6)); // unsigned int (6) reserved = 0;
+    if (reserved) {
+        avifDiagnosticsPrintf(diag, "Box[irot] contains nonzero reserved bits [%u]", reserved);
+        return AVIF_FALSE;
+    }
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &irot->angle, /*bitCount=*/2)); // unsigned int (2) angle;
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseImageMirrorProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[imir]");
+
+    avifImageMirror * imir = &prop->u.imir;
+    uint8_t reserved;
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &reserved, /*bitCount=*/7)); // unsigned int(7) reserved = 0;
+    if (reserved) {
+        avifDiagnosticsPrintf(diag, "Box[imir] contains nonzero reserved bits [%u]", reserved);
+        return AVIF_FALSE;
+    }
+    AVIF_CHECK(avifROStreamReadBitsU8(&s, &imir->axis, /*bitCount=*/1)); // unsigned int(1) axis;
+    return AVIF_TRUE;
+}
+
+static avifBool avifParsePixelInformationProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[pixi]");
+    AVIF_CHECK(avifROStreamReadAndEnforceVersion(&s, 0));
+
+    avifPixelInformationProperty * pixi = &prop->u.pixi;
+    AVIF_CHECK(avifROStreamRead(&s, &pixi->planeCount, 1)); // unsigned int (8) num_channels;
+    if (pixi->planeCount < 1 || pixi->planeCount > MAX_PIXI_PLANE_DEPTHS) {
+        avifDiagnosticsPrintf(diag, "Box[pixi] contains unsupported plane count [%u]", pixi->planeCount);
+        return AVIF_FALSE;
+    }
+    for (uint8_t i = 0; i < pixi->planeCount; ++i) {
+        AVIF_CHECK(avifROStreamRead(&s, &pixi->planeDepths[i], 1)); // unsigned int (8) bits_per_channel;
+        if (pixi->planeDepths[i] != pixi->planeDepths[0]) {
+            avifDiagnosticsPrintf(diag,
+                                  "Box[pixi] contains unsupported mismatched plane depths [%u != %u]",
+                                  pixi->planeDepths[i],
+                                  pixi->planeDepths[0]);
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseOperatingPointSelectorProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[a1op]");
+
+    avifOperatingPointSelectorProperty * a1op = &prop->u.a1op;
+    AVIF_CHECK(avifROStreamRead(&s, &a1op->opIndex, 1));
+    if (a1op->opIndex > 31) { // 31 is AV1's max operating point value
+        avifDiagnosticsPrintf(diag, "Box[a1op] contains an unsupported operating point [%u]", a1op->opIndex);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseLayerSelectorProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[lsel]");
+
+    avifLayerSelectorProperty * lsel = &prop->u.lsel;
+    AVIF_CHECK(avifROStreamReadU16(&s, &lsel->layerID));
+    if ((lsel->layerID != 0xFFFF) && (lsel->layerID >= AVIF_MAX_AV1_LAYER_COUNT)) {
+        avifDiagnosticsPrintf(diag, "Box[lsel] contains an unsupported layer [%u]", lsel->layerID);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseAV1LayeredImageIndexingProperty(avifProperty * prop, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[a1lx]");
+
+    avifAV1LayeredImageIndexingProperty * a1lx = &prop->u.a1lx;
+
+    uint8_t largeSize = 0;
+    AVIF_CHECK(avifROStreamRead(&s, &largeSize, 1));
+    if (largeSize & 0xFE) {
+        avifDiagnosticsPrintf(diag, "Box[a1lx] has bits set in the reserved section [%u]", largeSize);
+        return AVIF_FALSE;
+    }
+
+    for (int i = 0; i < 3; ++i) {
+        if (largeSize) {
+            AVIF_CHECK(avifROStreamReadU32(&s, &a1lx->layerSize[i]));
+        } else {
+            uint16_t layerSize16;
+            AVIF_CHECK(avifROStreamReadU16(&s, &layerSize16));
+            a1lx->layerSize[i] = (uint32_t)layerSize16;
+        }
+    }
+
+    // Layer sizes will be validated later (when the item's size is known)
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseItemPropertyContainerBox(avifPropertyArray * properties,
+                                                    uint64_t rawOffset,
+                                                    const uint8_t * raw,
+                                                    size_t rawLen,
+                                                    avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[ipco]");
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        avifProperty * prop = (avifProperty *)avifArrayPush(properties);
+        AVIF_CHECKERR(prop != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        memcpy(prop->type, header.type, 4);
+        if (!memcmp(header.type, "ispe", 4)) {
+            AVIF_CHECKERR(avifParseImageSpatialExtentsProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "auxC", 4)) {
+            AVIF_CHECKERR(avifParseAuxiliaryTypeProperty(prop, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "colr", 4)) {
+            AVIF_CHECKERR(avifParseColourInformationBox(prop, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "av1C", 4)) {
+            AVIF_CHECKERR(avifParseCodecConfigurationBoxProperty(prop, avifROStreamCurrent(&s), header.size, "av1C", diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+#if defined(AVIF_CODEC_AVM)
+        } else if (!memcmp(header.type, "av2C", 4)) {
+            AVIF_CHECKERR(avifParseCodecConfigurationBoxProperty(prop, avifROStreamCurrent(&s), header.size, "av2C", diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+#endif
+        } else if (!memcmp(header.type, "pasp", 4)) {
+            AVIF_CHECKERR(avifParsePixelAspectRatioBoxProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "clap", 4)) {
+            AVIF_CHECKERR(avifParseCleanApertureBoxProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "irot", 4)) {
+            AVIF_CHECKERR(avifParseImageRotationProperty(prop, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "imir", 4)) {
+            AVIF_CHECKERR(avifParseImageMirrorProperty(prop, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "pixi", 4)) {
+            AVIF_CHECKERR(avifParsePixelInformationProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "a1op", 4)) {
+            AVIF_CHECKERR(avifParseOperatingPointSelectorProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "lsel", 4)) {
+            AVIF_CHECKERR(avifParseLayerSelectorProperty(prop, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "a1lx", 4)) {
+            AVIF_CHECKERR(avifParseAV1LayeredImageIndexingProperty(prop, avifROStreamCurrent(&s), header.size, diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "clli", 4)) {
+            AVIF_CHECKRES(avifParseContentLightLevelInformationBox(prop, avifROStreamCurrent(&s), header.size, diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseItemPropertyAssociation(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag, uint32_t * outVersionAndFlags)
+{
+    // NOTE: If this function ever adds support for versions other than [0,1] or flags other than
+    //       [0,1], please increase the value of MAX_IPMA_VERSION_AND_FLAGS_SEEN accordingly.
+
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[ipma]");
+
+    uint8_t version;
+    uint32_t flags;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, &flags), AVIF_RESULT_BMFF_PARSE_FAILED);
+    avifBool propertyIndexIsU15 = ((flags & 0x1) != 0);
+    *outVersionAndFlags = ((uint32_t)version << 24) | flags;
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED);
+    unsigned int prevItemID = 0;
+    for (uint32_t entryIndex = 0; entryIndex < entryCount; ++entryIndex) {
+        // ISO/IEC 14496-12, Seventh edition, 2022-01, Section 8.11.14.1:
+        //   Each ItemPropertyAssociationBox shall be ordered by increasing item_ID, and there shall
+        //   be at most one occurrence of a given item_ID, in the set of ItemPropertyAssociationBox
+        //   boxes.
+        unsigned int itemID;
+        if (version < 1) {
+            uint16_t tmp;
+            AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp), AVIF_RESULT_BMFF_PARSE_FAILED);
+            itemID = tmp;
+        } else {
+            AVIF_CHECKERR(avifROStreamReadU32(&s, &itemID), AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+        AVIF_CHECKRES(avifCheckItemID("ipma", itemID, diag));
+        if (itemID <= prevItemID) {
+            avifDiagnosticsPrintf(diag, "Box[ipma] item IDs are not ordered by increasing ID");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        prevItemID = itemID;
+
+        avifDecoderItem * item;
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, itemID, &item));
+        if (item->ipmaSeen) {
+            avifDiagnosticsPrintf(diag, "Duplicate Box[ipma] for item ID [%u]", itemID);
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        item->ipmaSeen = AVIF_TRUE;
+
+        uint8_t associationCount;
+        AVIF_CHECKERR(avifROStreamRead(&s, &associationCount, 1), AVIF_RESULT_BMFF_PARSE_FAILED);
+        for (uint8_t associationIndex = 0; associationIndex < associationCount; ++associationIndex) {
+            uint8_t essential;
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &essential, /*bitCount=*/1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) essential;
+            uint32_t propertyIndex;
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &propertyIndex, /*bitCount=*/propertyIndexIsU15 ? 15 : 7),
+                          AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(7/15) property_index;
+
+            if (propertyIndex == 0) {
+                // Not associated with any item
+                continue;
+            }
+            --propertyIndex; // 1-indexed
+
+            if (propertyIndex >= meta->properties.count) {
+                avifDiagnosticsPrintf(diag,
+                                      "Box[ipma] for item ID [%u] contains an illegal property index [%u] (out of [%u] properties)",
+                                      itemID,
+                                      propertyIndex,
+                                      meta->properties.count);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            // Copy property to item
+            const avifProperty * srcProp = &meta->properties.prop[propertyIndex];
+
+            static const char * supportedTypes[] = {
+                "ispe",
+                "auxC",
+                "colr",
+                "av1C",
+#if defined(AVIF_CODEC_AVM)
+                "av2C",
+#endif
+                "pasp",
+                "clap",
+                "irot",
+                "imir",
+                "pixi",
+                "a1op",
+                "lsel",
+                "a1lx",
+                "clli"
+            };
+            size_t supportedTypesCount = sizeof(supportedTypes) / sizeof(supportedTypes[0]);
+            avifBool supportedType = AVIF_FALSE;
+            for (size_t i = 0; i < supportedTypesCount; ++i) {
+                if (!memcmp(srcProp->type, supportedTypes[i], 4)) {
+                    supportedType = AVIF_TRUE;
+                    break;
+                }
+            }
+            if (supportedType) {
+                if (essential) {
+                    // Verify that it is legal for this property to be flagged as essential. Any
+                    // types in this list are *required* in the spec to not be flagged as essential
+                    // when associated with an item.
+                    static const char * const nonessentialTypes[] = {
+
+                        // AVIF: Section 2.3.2.3.2: "If associated, it shall not be marked as essential."
+                        "a1lx"
+
+                    };
+                    size_t nonessentialTypesCount = sizeof(nonessentialTypes) / sizeof(nonessentialTypes[0]);
+                    for (size_t i = 0; i < nonessentialTypesCount; ++i) {
+                        if (!memcmp(srcProp->type, nonessentialTypes[i], 4)) {
+                            avifDiagnosticsPrintf(diag,
+                                                  "Item ID [%u] has a %s property association which must not be marked essential, but is",
+                                                  itemID,
+                                                  nonessentialTypes[i]);
+                            return AVIF_RESULT_BMFF_PARSE_FAILED;
+                        }
+                    }
+                } else {
+                    // Verify that it is legal for this property to not be flagged as essential. Any
+                    // types in this list are *required* in the spec to be flagged as essential when
+                    // associated with an item.
+                    static const char * const essentialTypes[] = {
+
+                        // AVIF: Section 2.3.2.1.1: "If associated, it shall be marked as essential."
+                        "a1op",
+
+                        // HEIF: Section 6.5.11.1: "essential shall be equal to 1 for an 'lsel' item property."
+                        "lsel"
+
+                    };
+                    size_t essentialTypesCount = sizeof(essentialTypes) / sizeof(essentialTypes[0]);
+                    for (size_t i = 0; i < essentialTypesCount; ++i) {
+                        if (!memcmp(srcProp->type, essentialTypes[i], 4)) {
+                            avifDiagnosticsPrintf(diag,
+                                                  "Item ID [%u] has a %s property association which must be marked essential, but is not",
+                                                  itemID,
+                                                  essentialTypes[i]);
+                            return AVIF_RESULT_BMFF_PARSE_FAILED;
+                        }
+                    }
+                }
+
+                // Supported and valid; associate it with this item.
+                avifProperty * dstProp = (avifProperty *)avifArrayPush(&item->properties);
+                AVIF_CHECKERR(dstProp != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+                *dstProp = *srcProp;
+            } else {
+                if (essential) {
+                    // Discovered an essential item property that libavif doesn't support!
+                    // Make a note to ignore this item later.
+                    item->hasUnsupportedEssentialProperty = AVIF_TRUE;
+                }
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifParsePrimaryItemBox(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    if (meta->primaryItemID > 0) {
+        // Illegal to have multiple pitm boxes, bail out
+        avifDiagnosticsPrintf(diag, "Multiple boxes of unique Box[pitm] found");
+        return AVIF_FALSE;
+    }
+
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[pitm]");
+
+    uint8_t version;
+    AVIF_CHECK(avifROStreamReadVersionAndFlags(&s, &version, NULL));
+
+    if (version == 0) {
+        uint16_t tmp16;
+        AVIF_CHECK(avifROStreamReadU16(&s, &tmp16)); // unsigned int(16) item_ID;
+        meta->primaryItemID = tmp16;
+    } else {
+        AVIF_CHECK(avifROStreamReadU32(&s, &meta->primaryItemID)); // unsigned int(32) item_ID;
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseItemDataBox(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    // Check to see if we've already seen an idat box for this meta box. If so, bail out
+    if (meta->idat.size > 0) {
+        avifDiagnosticsPrintf(diag, "Meta box contains multiple idat boxes");
+        return AVIF_FALSE;
+    }
+    if (rawLen == 0) {
+        avifDiagnosticsPrintf(diag, "idat box has a length of 0");
+        return AVIF_FALSE;
+    }
+
+    if (avifRWDataSet(&meta->idat, raw, rawLen) != AVIF_RESULT_OK) {
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseItemPropertiesBox(avifMeta * meta, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[iprp]");
+
+    avifBoxHeader ipcoHeader;
+    AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &ipcoHeader), AVIF_RESULT_BMFF_PARSE_FAILED);
+    if (memcmp(ipcoHeader.type, "ipco", 4)) {
+        avifDiagnosticsPrintf(diag, "Failed to find Box[ipco] as the first box in Box[iprp]");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    // Read all item properties inside of ItemPropertyContainerBox
+    AVIF_CHECKRES(avifParseItemPropertyContainerBox(&meta->properties,
+                                                    rawOffset + avifROStreamOffset(&s),
+                                                    avifROStreamCurrent(&s),
+                                                    ipcoHeader.size,
+                                                    diag));
+    AVIF_CHECKERR(avifROStreamSkip(&s, ipcoHeader.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t versionAndFlagsSeen[MAX_IPMA_VERSION_AND_FLAGS_SEEN];
+    uint32_t versionAndFlagsSeenCount = 0;
+
+    // Now read all ItemPropertyAssociation until the end of the box, and make associations
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader ipmaHeader;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &ipmaHeader), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(ipmaHeader.type, "ipma", 4)) {
+            uint32_t versionAndFlags;
+            AVIF_CHECKRES(avifParseItemPropertyAssociation(meta, avifROStreamCurrent(&s), ipmaHeader.size, diag, &versionAndFlags));
+            for (uint32_t i = 0; i < versionAndFlagsSeenCount; ++i) {
+                if (versionAndFlagsSeen[i] == versionAndFlags) {
+                    // BMFF (ISO/IEC 14496-12:2022) 8.11.14.1 - There shall be at most one
+                    // ItemPropertyAssociationBox with a given pair of values of version and
+                    // flags.
+                    avifDiagnosticsPrintf(diag, "Multiple Box[ipma] with a given pair of values of version and flags. See BMFF (ISO/IEC 14496-12:2022) 8.11.14.1");
+                    return AVIF_RESULT_BMFF_PARSE_FAILED;
+                }
+            }
+            if (versionAndFlagsSeenCount == MAX_IPMA_VERSION_AND_FLAGS_SEEN) {
+                avifDiagnosticsPrintf(diag, "Exceeded possible count of unique ipma version and flags tuples");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            versionAndFlagsSeen[versionAndFlagsSeenCount] = versionAndFlags;
+            ++versionAndFlagsSeenCount;
+        } else {
+            // These must all be type ipma
+            avifDiagnosticsPrintf(diag, "Box[iprp] contains a box that isn't type 'ipma'");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, ipmaHeader.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseItemInfoEntry(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    // Section 8.11.6.2 of ISO/IEC 14496-12.
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[infe]");
+
+    uint8_t version;
+    uint32_t flags;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, &flags), AVIF_RESULT_BMFF_PARSE_FAILED);
+    // Version 2+ is required for item_type
+    if (version != 2 && version != 3) {
+        avifDiagnosticsPrintf(s.diag, "%s: Expecting box version 2 or 3, got version %u", s.diagContext, version);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    // TODO: check flags. ISO/IEC 23008-12:2017, Section 9.2 says:
+    //   The flags field of ItemInfoEntry with version greater than or equal to 2 is specified as
+    //   follows:
+    //
+    //   (flags & 1) equal to 1 indicates that the item is not intended to be a part of the
+    //   presentation. For example, when (flags & 1) is equal to 1 for an image item, the image
+    //   item should not be displayed.
+    //   (flags & 1) equal to 0 indicates that the item is intended to be a part of the
+    //   presentation.
+    //
+    // See also Section 6.4.2.
+
+    uint32_t itemID;
+    if (version == 2) {
+        uint16_t tmp;
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) item_ID;
+        itemID = tmp;
+    } else {
+        AVIF_ASSERT_OR_RETURN(version == 3);
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &itemID), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) item_ID;
+    }
+    AVIF_CHECKRES(avifCheckItemID("infe", itemID, diag));
+    uint16_t itemProtectionIndex;
+    AVIF_CHECKERR(avifROStreamReadU16(&s, &itemProtectionIndex), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) item_protection_index;
+    uint8_t itemType[4];
+    AVIF_CHECKERR(avifROStreamRead(&s, itemType, 4), AVIF_RESULT_BMFF_PARSE_FAILED);   // unsigned int(32) item_type;
+    AVIF_CHECKERR(avifROStreamReadString(&s, NULL, 0), AVIF_RESULT_BMFF_PARSE_FAILED); // utf8string item_name; (skipped)
+    avifContentType contentType;
+    if (!memcmp(itemType, "mime", 4)) {
+        AVIF_CHECKERR(avifROStreamReadString(&s, contentType.contentType, CONTENTTYPE_SIZE), AVIF_RESULT_BMFF_PARSE_FAILED); // utf8string content_type;
+        // utf8string content_encoding; //optional
+    } else {
+        // if (item_type == 'uri ') {
+        //  utf8string item_uri_type;
+        // }
+        memset(&contentType, 0, sizeof(contentType));
+    }
+
+    avifDecoderItem * item;
+    AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, itemID, &item));
+
+    memcpy(item->type, itemType, sizeof(itemType));
+    item->contentType = contentType;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseItemInfoBox(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[iinf]");
+
+    uint8_t version;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, NULL), AVIF_RESULT_BMFF_PARSE_FAILED);
+    uint32_t entryCount;
+    if (version == 0) {
+        uint16_t tmp;
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) entry_count;
+        entryCount = tmp;
+    } else if (version == 1) {
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+    } else {
+        avifDiagnosticsPrintf(diag, "Box[iinf] has an unsupported version %u", version);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    for (uint32_t entryIndex = 0; entryIndex < entryCount; ++entryIndex) {
+        avifBoxHeader infeHeader;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &infeHeader), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(infeHeader.type, "infe", 4)) {
+            AVIF_CHECKRES(avifParseItemInfoEntry(meta, avifROStreamCurrent(&s), infeHeader.size, diag));
+        } else {
+            // These must all be type infe
+            avifDiagnosticsPrintf(diag, "Box[iinf] contains a box that isn't type 'infe'");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, infeHeader.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseItemReferenceBox(avifMeta * meta, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[iref]");
+
+    uint8_t version;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, NULL), AVIF_RESULT_BMFF_PARSE_FAILED);
+    if (version > 1) {
+        // iref versions > 1 are not supported. Skip it.
+        return AVIF_RESULT_OK;
+    }
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader irefHeader;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &irefHeader), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        uint32_t fromID = 0;
+        if (version == 0) {
+            uint16_t tmp;
+            AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) from_item_ID;
+            fromID = tmp;
+        } else {
+            // version == 1
+            AVIF_CHECKERR(avifROStreamReadU32(&s, &fromID), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) from_item_ID;
+        }
+        // ISO 14496-12 section 8.11.12.1: "index values start at 1"
+        AVIF_CHECKRES(avifCheckItemID("iref", fromID, diag));
+
+        avifDecoderItem * item;
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, fromID, &item));
+        if (!memcmp(irefHeader.type, "dimg", 4)) {
+            if (item->hasDimgFrom) {
+                // ISO/IEC 23008-12 (HEIF) 6.6.1: The number of SingleItemTypeReferenceBoxes with the box type 'dimg'
+                // and with the same value of from_item_ID shall not be greater than 1.
+                avifDiagnosticsPrintf(diag, "Box[iinf] contains duplicate boxes of type 'dimg' with the same from_item_ID value %u", fromID);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            item->hasDimgFrom = AVIF_TRUE;
+        }
+
+        uint16_t referenceCount = 0;
+        AVIF_CHECKERR(avifROStreamReadU16(&s, &referenceCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) reference_count;
+
+        for (uint16_t refIndex = 0; refIndex < referenceCount; ++refIndex) {
+            uint32_t toID = 0;
+            if (version == 0) {
+                uint16_t tmp;
+                AVIF_CHECKERR(avifROStreamReadU16(&s, &tmp), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(16) to_item_ID;
+                toID = tmp;
+            } else {
+                // version == 1
+                AVIF_CHECKERR(avifROStreamReadU32(&s, &toID), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) to_item_ID;
+            }
+            AVIF_CHECKRES(avifCheckItemID("iref", toID, diag));
+
+            // Read this reference as "{fromID} is a {irefType} for {toID}"
+            if (!memcmp(irefHeader.type, "thmb", 4)) {
+                item->thumbnailForID = toID;
+            } else if (!memcmp(irefHeader.type, "auxl", 4)) {
+                item->auxForID = toID;
+            } else if (!memcmp(irefHeader.type, "cdsc", 4)) {
+                item->descForID = toID;
+            } else if (!memcmp(irefHeader.type, "dimg", 4)) {
+                // derived images refer in the opposite direction
+                avifDecoderItem * dimg;
+                AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, toID, &dimg));
+
+                // Section 8.11.12.1 of ISO/IEC 14496-12:
+                //   The items linked to are then represented by an array of to_item_IDs;
+                //   within a given array, a given value shall occur at most once.
+                AVIF_CHECKERR(dimg->dimgForID != fromID, AVIF_RESULT_INVALID_IMAGE_GRID);
+                // A given value may occur within multiple arrays but this is not supported by libavif.
+                AVIF_CHECKERR(dimg->dimgForID == 0, AVIF_RESULT_NOT_IMPLEMENTED);
+                dimg->dimgForID = fromID;
+                dimg->dimgIdx = refIndex;
+            } else if (!memcmp(irefHeader.type, "prem", 4)) {
+                item->premByID = toID;
+            }
+        }
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseMetaBox(avifMeta * meta, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[meta]");
+
+    uint8_t version;
+    uint32_t flags;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, &flags), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    if (version != 0) {
+        avifDiagnosticsPrintf(diag, "Box[meta]: Expecting box version 0, got version %u", version);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    ++meta->idatID; // for tracking idat
+
+    avifBool firstBox = AVIF_TRUE;
+    uint32_t uniqueBoxFlags = 0;
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (firstBox) {
+            if (!memcmp(header.type, "hdlr", 4)) {
+                AVIF_CHECKERR(avifParseHandlerBox(avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+                firstBox = AVIF_FALSE;
+            } else {
+                // hdlr must be the first box!
+                avifDiagnosticsPrintf(diag, "Box[meta] does not have a Box[hdlr] as its first child box");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        } else if (!memcmp(header.type, "hdlr", 4)) {
+            avifDiagnosticsPrintf(diag, "Box[meta] contains a duplicate unique box of type 'hdlr'");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        } else if (!memcmp(header.type, "iloc", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 0, "meta", "iloc", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKRES(avifParseItemLocationBox(meta, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "pitm", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 1, "meta", "pitm", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(avifParsePrimaryItemBox(meta, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "idat", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 2, "meta", "idat", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(avifParseItemDataBox(meta, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "iprp", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 3, "meta", "iprp", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKRES(avifParseItemPropertiesBox(meta, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "iinf", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 4, "meta", "iinf", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKRES(avifParseItemInfoBox(meta, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "iref", 4)) {
+            AVIF_CHECKERR(uniqueBoxSeen(&uniqueBoxFlags, 5, "meta", "iref", diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKRES(avifParseItemReferenceBox(meta, avifROStreamCurrent(&s), header.size, diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    if (firstBox) {
+        // The meta box must not be empty (it must contain at least a hdlr box)
+        avifDiagnosticsPrintf(diag, "Box[meta] has no child boxes");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifParseTrackHeaderBox(avifTrack * track,
+                                        const uint8_t * raw,
+                                        size_t rawLen,
+                                        uint32_t imageSizeLimit,
+                                        uint32_t imageDimensionLimit,
+                                        avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[tkhd]");
+
+    uint8_t version;
+    AVIF_CHECK(avifROStreamReadVersionAndFlags(&s, &version, NULL));
+
+    uint32_t ignored32, trackID;
+    uint64_t ignored64;
+    if (version == 1) {
+        AVIF_CHECK(avifROStreamReadU64(&s, &ignored64));            // unsigned int(64) creation_time;
+        AVIF_CHECK(avifROStreamReadU64(&s, &ignored64));            // unsigned int(64) modification_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &trackID));              // unsigned int(32) track_ID;
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));            // const unsigned int(32) reserved = 0;
+        AVIF_CHECK(avifROStreamReadU64(&s, &track->trackDuration)); // unsigned int(64) duration;
+    } else if (version == 0) {
+        uint32_t trackDuration;
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));     // unsigned int(32) creation_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));     // unsigned int(32) modification_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &trackID));       // unsigned int(32) track_ID;
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));     // const unsigned int(32) reserved = 0;
+        AVIF_CHECK(avifROStreamReadU32(&s, &trackDuration)); // unsigned int(32) duration;
+        track->trackDuration = (trackDuration == AVIF_INDEFINITE_DURATION32) ? AVIF_INDEFINITE_DURATION64 : trackDuration;
+    } else {
+        // Unsupported version
+        avifDiagnosticsPrintf(diag, "Box[tkhd] has an unsupported version [%u]", version);
+        return AVIF_FALSE;
+    }
+
+    // Skipping the following 52 bytes here:
+    // ------------------------------------
+    // const unsigned int(32)[2] reserved = 0;
+    // template int(16) layer = 0;
+    // template int(16) alternate_group = 0;
+    // template int(16) volume = {if track_is_audio 0x0100 else 0};
+    // const unsigned int(16) reserved = 0;
+    // template int(32)[9] matrix= { 0x00010000,0,0,0,0x00010000,0,0,0,0x40000000 }; // unity matrix
+    AVIF_CHECK(avifROStreamSkip(&s, 52));
+
+    uint32_t width, height;
+    AVIF_CHECK(avifROStreamReadU32(&s, &width));  // unsigned int(32) width;
+    AVIF_CHECK(avifROStreamReadU32(&s, &height)); // unsigned int(32) height;
+    track->width = width >> 16;
+    track->height = height >> 16;
+
+    if ((track->width == 0) || (track->height == 0)) {
+        avifDiagnosticsPrintf(diag, "Track ID [%u] has an invalid size [%ux%u]", track->id, track->width, track->height);
+        return AVIF_FALSE;
+    }
+    if (avifDimensionsTooLarge(track->width, track->height, imageSizeLimit, imageDimensionLimit)) {
+        avifDiagnosticsPrintf(diag, "Track ID [%u] dimensions are too large [%ux%u]", track->id, track->width, track->height);
+        return AVIF_FALSE;
+    }
+
+    // TODO: support scaling based on width/height track header info?
+
+    track->id = trackID;
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseMediaHeaderBox(avifTrack * track, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[mdhd]");
+
+    uint8_t version;
+    AVIF_CHECK(avifROStreamReadVersionAndFlags(&s, &version, NULL));
+
+    uint32_t ignored32, mediaTimescale, mediaDuration32;
+    uint64_t ignored64, mediaDuration64;
+    if (version == 1) {
+        AVIF_CHECK(avifROStreamReadU64(&s, &ignored64));       // unsigned int(64) creation_time;
+        AVIF_CHECK(avifROStreamReadU64(&s, &ignored64));       // unsigned int(64) modification_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &mediaTimescale));  // unsigned int(32) timescale;
+        AVIF_CHECK(avifROStreamReadU64(&s, &mediaDuration64)); // unsigned int(64) duration;
+        track->mediaDuration = mediaDuration64;
+    } else if (version == 0) {
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));       // unsigned int(32) creation_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &ignored32));       // unsigned int(32) modification_time;
+        AVIF_CHECK(avifROStreamReadU32(&s, &mediaTimescale));  // unsigned int(32) timescale;
+        AVIF_CHECK(avifROStreamReadU32(&s, &mediaDuration32)); // unsigned int(32) duration;
+        track->mediaDuration = (uint64_t)mediaDuration32;
+    } else {
+        // Unsupported version
+        avifDiagnosticsPrintf(diag, "Box[mdhd] has an unsupported version [%u]", version);
+        return AVIF_FALSE;
+    }
+
+    track->mediaTimescale = mediaTimescale;
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseChunkOffsetBox(avifSampleTable * sampleTable, avifBool largeOffsets, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, largeOffsets ? "Box[co64]" : "Box[stco]");
+
+    AVIF_CHECKERR(avifROStreamReadAndEnforceVersion(&s, 0), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+    for (uint32_t i = 0; i < entryCount; ++i) {
+        uint64_t offset;
+        if (largeOffsets) {
+            AVIF_CHECKERR(avifROStreamReadU64(&s, &offset), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(64) chunk_offset;
+        } else {
+            uint32_t offset32;
+            AVIF_CHECKERR(avifROStreamReadU32(&s, &offset32), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) chunk_offset;
+            offset = (uint64_t)offset32;
+        }
+
+        avifSampleTableChunk * chunk = (avifSampleTableChunk *)avifArrayPush(&sampleTable->chunks);
+        AVIF_CHECKERR(chunk != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        chunk->offset = offset;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseSampleToChunkBox(avifSampleTable * sampleTable, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stsc]");
+
+    AVIF_CHECKERR(avifROStreamReadAndEnforceVersion(&s, 0), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+    uint32_t prevFirstChunk = 0;
+    for (uint32_t i = 0; i < entryCount; ++i) {
+        avifSampleTableSampleToChunk * sampleToChunk = (avifSampleTableSampleToChunk *)avifArrayPush(&sampleTable->sampleToChunks);
+        AVIF_CHECKERR(sampleToChunk != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleToChunk->firstChunk), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) first_chunk;
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleToChunk->samplesPerChunk), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) samples_per_chunk;
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleToChunk->sampleDescriptionIndex),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) sample_description_index;
+        // The first_chunk fields should start with 1 and be strictly increasing.
+        if (i == 0) {
+            if (sampleToChunk->firstChunk != 1) {
+                avifDiagnosticsPrintf(diag, "Box[stsc] does not begin with chunk 1 [%u]", sampleToChunk->firstChunk);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        } else {
+            if (sampleToChunk->firstChunk <= prevFirstChunk) {
+                avifDiagnosticsPrintf(diag, "Box[stsc] chunks are not strictly increasing");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+        prevFirstChunk = sampleToChunk->firstChunk;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseSampleSizeBox(avifSampleTable * sampleTable, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stsz]");
+
+    AVIF_CHECKERR(avifROStreamReadAndEnforceVersion(&s, 0), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t allSamplesSize, sampleCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &allSamplesSize), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) sample_size;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleCount), AVIF_RESULT_BMFF_PARSE_FAILED);    // unsigned int(32) sample_count;
+
+    if (allSamplesSize > 0) {
+        sampleTable->allSamplesSize = allSamplesSize;
+    } else {
+        for (uint32_t i = 0; i < sampleCount; ++i) {
+            avifSampleTableSampleSize * sampleSize = (avifSampleTableSampleSize *)avifArrayPush(&sampleTable->sampleSizes);
+            AVIF_CHECKERR(sampleSize != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleSize->size), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_size;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseSyncSampleBox(avifSampleTable * sampleTable, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stss]");
+
+    AVIF_CHECKERR(avifROStreamReadAndEnforceVersion(&s, 0), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+
+    for (uint32_t i = 0; i < entryCount; ++i) {
+        uint32_t sampleNumber = 0;
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &sampleNumber), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) sample_number;
+        avifSyncSample * syncSample = (avifSyncSample *)avifArrayPush(&sampleTable->syncSamples);
+        AVIF_CHECKERR(syncSample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        syncSample->sampleNumber = sampleNumber;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseTimeToSampleBox(avifSampleTable * sampleTable, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stts]");
+
+    AVIF_CHECKERR(avifROStreamReadAndEnforceVersion(&s, 0), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+
+    for (uint32_t i = 0; i < entryCount; ++i) {
+        avifSampleTableTimeToSample * timeToSample = (avifSampleTableTimeToSample *)avifArrayPush(&sampleTable->timeToSamples);
+        AVIF_CHECKERR(timeToSample != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &timeToSample->sampleCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) sample_count;
+        AVIF_CHECKERR(avifROStreamReadU32(&s, &timeToSample->sampleDelta), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) sample_delta;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseSampleDescriptionBox(avifSampleTable * sampleTable,
+                                                uint64_t rawOffset,
+                                                const uint8_t * raw,
+                                                size_t rawLen,
+                                                avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stsd]");
+
+    uint8_t version;
+    AVIF_CHECKERR(avifROStreamReadVersionAndFlags(&s, &version, NULL), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    // Section 8.5.2.3 of ISO/IEC 14496-12:
+    //   version is set to zero. A version number of 1 shall be treated as a version of 0.
+    if (version != 0 && version != 1) {
+        avifDiagnosticsPrintf(diag, "Box[stsd]: Expecting box version 0 or 1, got version %u", version);
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+
+    uint32_t entryCount;
+    AVIF_CHECKERR(avifROStreamReadU32(&s, &entryCount), AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(32) entry_count;
+
+    for (uint32_t i = 0; i < entryCount; ++i) {
+        avifBoxHeader sampleEntryHeader;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &sampleEntryHeader), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        avifSampleDescription * description = (avifSampleDescription *)avifArrayPush(&sampleTable->sampleDescriptions);
+        AVIF_CHECKERR(description != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        if (!avifArrayCreate(&description->properties, sizeof(avifProperty), 16)) {
+            avifArrayPop(&sampleTable->sampleDescriptions);
+            return AVIF_RESULT_OUT_OF_MEMORY;
+        }
+        memcpy(description->format, sampleEntryHeader.type, sizeof(description->format));
+        const size_t sampleEntryBytes = sampleEntryHeader.size;
+        if (avifGetCodecType(description->format) != AVIF_CODEC_TYPE_UNKNOWN) {
+            if (sampleEntryBytes < VISUALSAMPLEENTRY_SIZE) {
+                avifDiagnosticsPrintf(diag, "Not enough bytes to parse VisualSampleEntry");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            AVIF_CHECKRES(avifParseItemPropertyContainerBox(&description->properties,
+                                                            rawOffset + avifROStreamOffset(&s) + VISUALSAMPLEENTRY_SIZE,
+                                                            avifROStreamCurrent(&s) + VISUALSAMPLEENTRY_SIZE,
+                                                            sampleEntryBytes - VISUALSAMPLEENTRY_SIZE,
+                                                            diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, sampleEntryBytes), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseSampleTableBox(avifTrack * track, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    if (track->sampleTable) {
+        // A TrackBox may only have one SampleTable
+        avifDiagnosticsPrintf(diag, "Duplicate Box[stbl] for a single track detected");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    track->sampleTable = avifSampleTableCreate();
+    AVIF_CHECKERR(track->sampleTable != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[stbl]");
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(header.type, "stco", 4)) {
+            AVIF_CHECKRES(avifParseChunkOffsetBox(track->sampleTable, AVIF_FALSE, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "co64", 4)) {
+            AVIF_CHECKRES(avifParseChunkOffsetBox(track->sampleTable, AVIF_TRUE, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "stsc", 4)) {
+            AVIF_CHECKRES(avifParseSampleToChunkBox(track->sampleTable, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "stsz", 4)) {
+            AVIF_CHECKRES(avifParseSampleSizeBox(track->sampleTable, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "stss", 4)) {
+            AVIF_CHECKRES(avifParseSyncSampleBox(track->sampleTable, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "stts", 4)) {
+            AVIF_CHECKRES(avifParseTimeToSampleBox(track->sampleTable, avifROStreamCurrent(&s), header.size, diag));
+        } else if (!memcmp(header.type, "stsd", 4)) {
+            AVIF_CHECKRES(avifParseSampleDescriptionBox(track->sampleTable,
+                                                        rawOffset + avifROStreamOffset(&s),
+                                                        avifROStreamCurrent(&s),
+                                                        header.size,
+                                                        diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseMediaInformationBox(avifTrack * track, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[minf]");
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(header.type, "stbl", 4)) {
+            AVIF_CHECKRES(avifParseSampleTableBox(track, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseMediaBox(avifTrack * track, uint64_t rawOffset, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[mdia]");
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(header.type, "mdhd", 4)) {
+            AVIF_CHECKERR(avifParseMediaHeaderBox(track, avifROStreamCurrent(&s), header.size, diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "minf", 4)) {
+            AVIF_CHECKRES(
+                avifParseMediaInformationBox(track, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, diag));
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifTrackReferenceBox(avifTrack * track, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[tref]");
+
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECK(avifROStreamReadBoxHeader(&s, &header));
+
+        if (!memcmp(header.type, "auxl", 4)) {
+            uint32_t toID;
+            AVIF_CHECK(avifROStreamReadU32(&s, &toID));                       // unsigned int(32) track_IDs[];
+            AVIF_CHECK(avifROStreamSkip(&s, header.size - sizeof(uint32_t))); // just take the first one
+            track->auxForID = toID;
+        } else if (!memcmp(header.type, "prem", 4)) {
+            uint32_t byID;
+            AVIF_CHECK(avifROStreamReadU32(&s, &byID));                       // unsigned int(32) track_IDs[];
+            AVIF_CHECK(avifROStreamSkip(&s, header.size - sizeof(uint32_t))); // just take the first one
+            track->premByID = byID;
+        } else {
+            AVIF_CHECK(avifROStreamSkip(&s, header.size));
+        }
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseEditListBox(avifTrack * track, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[elst]");
+
+    uint8_t version;
+    uint32_t flags;
+    AVIF_CHECK(avifROStreamReadVersionAndFlags(&s, &version, &flags));
+
+    if ((flags & 1) == 0) {
+        track->isRepeating = AVIF_FALSE;
+        return AVIF_TRUE;
+    }
+
+    track->isRepeating = AVIF_TRUE;
+    uint32_t entryCount;
+    AVIF_CHECK(avifROStreamReadU32(&s, &entryCount)); // unsigned int(32) entry_count;
+    if (entryCount != 1) {
+        avifDiagnosticsPrintf(diag, "Box[elst] contains an entry_count != 1 [%u]", entryCount);
+        return AVIF_FALSE;
+    }
+
+    if (version == 1) {
+        AVIF_CHECK(avifROStreamReadU64(&s, &track->segmentDuration)); // unsigned int(64) segment_duration;
+    } else if (version == 0) {
+        uint32_t segmentDuration;
+        AVIF_CHECK(avifROStreamReadU32(&s, &segmentDuration)); // unsigned int(32) segment_duration;
+        track->segmentDuration = segmentDuration;
+    } else {
+        // Unsupported version
+        avifDiagnosticsPrintf(diag, "Box[elst] has an unsupported version [%u]", version);
+        return AVIF_FALSE;
+    }
+    if (track->segmentDuration == 0) {
+        avifDiagnosticsPrintf(diag, "Box[elst] Invalid value for segment_duration (0).");
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifBool avifParseEditBox(avifTrack * track, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[edts]");
+
+    avifBool elstBoxSeen = AVIF_FALSE;
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECK(avifROStreamReadBoxHeader(&s, &header));
+
+        if (!memcmp(header.type, "elst", 4)) {
+            if (elstBoxSeen) {
+                avifDiagnosticsPrintf(diag, "More than one [elst] Box was found.");
+                return AVIF_FALSE;
+            }
+            AVIF_CHECK(avifParseEditListBox(track, avifROStreamCurrent(&s), header.size, diag));
+            elstBoxSeen = AVIF_TRUE;
+        }
+        AVIF_CHECK(avifROStreamSkip(&s, header.size));
+    }
+    if (!elstBoxSeen) {
+        avifDiagnosticsPrintf(diag, "Box[edts] contains no [elst] Box.");
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifResult avifParseTrackBox(avifDecoderData * data,
+                                    uint64_t rawOffset,
+                                    const uint8_t * raw,
+                                    size_t rawLen,
+                                    uint32_t imageSizeLimit,
+                                    uint32_t imageDimensionLimit)
+{
+    BEGIN_STREAM(s, raw, rawLen, data->diag, "Box[trak]");
+
+    avifTrack * track = avifDecoderDataCreateTrack(data);
+    AVIF_CHECKERR(track != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+
+    avifBool edtsBoxSeen = AVIF_FALSE;
+    avifBool tkhdSeen = AVIF_FALSE;
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(header.type, "tkhd", 4)) {
+            if (tkhdSeen) {
+                avifDiagnosticsPrintf(data->diag, "Box[trak] contains a duplicate unique box of type 'tkhd'");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            AVIF_CHECKERR(avifParseTrackHeaderBox(track, avifROStreamCurrent(&s), header.size, imageSizeLimit, imageDimensionLimit, data->diag),
+                          AVIF_RESULT_BMFF_PARSE_FAILED);
+            tkhdSeen = AVIF_TRUE;
+        } else if (!memcmp(header.type, "meta", 4)) {
+            AVIF_CHECKRES(
+                avifParseMetaBox(track->meta, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, data->diag));
+        } else if (!memcmp(header.type, "mdia", 4)) {
+            AVIF_CHECKRES(avifParseMediaBox(track, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, data->diag));
+        } else if (!memcmp(header.type, "tref", 4)) {
+            AVIF_CHECKERR(avifTrackReferenceBox(track, avifROStreamCurrent(&s), header.size, data->diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+        } else if (!memcmp(header.type, "edts", 4)) {
+            if (edtsBoxSeen) {
+                avifDiagnosticsPrintf(data->diag, "Box[trak] contains a duplicate unique box of type 'edts'");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            AVIF_CHECKERR(avifParseEditBox(track, avifROStreamCurrent(&s), header.size, data->diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            edtsBoxSeen = AVIF_TRUE;
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    if (!tkhdSeen) {
+        avifDiagnosticsPrintf(data->diag, "Box[trak] does not contain a mandatory [tkhd] box");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    if (!edtsBoxSeen) {
+        track->repetitionCount = AVIF_REPETITION_COUNT_UNKNOWN;
+    } else if (track->isRepeating) {
+        if (track->trackDuration == AVIF_INDEFINITE_DURATION64) {
+            // If isRepeating is true and the track duration is unknown/indefinite, then set the repetition count to infinite
+            // (Section 9.6.1 of ISO/IEC 23008-12 Part 12).
+            track->repetitionCount = AVIF_REPETITION_COUNT_INFINITE;
+        } else {
+            // Section 9.6.1. of ISO/IEC 23008-12 Part 12: 1, the entire edit list is repeated a sufficient number of times to
+            // equal the track duration.
+            //
+            // Since libavif uses repetitionCount (which is 0-based), we subtract the value by 1 to derive the number of
+            // repetitions.
+            AVIF_ASSERT_OR_RETURN(track->segmentDuration != 0);
+            // We specifically check for trackDuration == 0 here and not when it is actually read in order to accept files which
+            // inadvertently has a trackDuration of 0 without any edit lists.
+            if (track->trackDuration == 0) {
+                avifDiagnosticsPrintf(data->diag, "Invalid track duration 0.");
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            const uint64_t repetitionCount =
+                (track->trackDuration / track->segmentDuration) + (track->trackDuration % track->segmentDuration != 0) - 1;
+            if (repetitionCount > INT_MAX) {
+                // repetitionCount does not fit in an integer and hence it is
+                // likely to be a very large value. So, we just set it to
+                // infinite.
+                track->repetitionCount = AVIF_REPETITION_COUNT_INFINITE;
+            } else {
+                track->repetitionCount = (int)repetitionCount;
+            }
+        }
+    } else {
+        track->repetitionCount = 0;
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifParseMovieBox(avifDecoderData * data,
+                                    uint64_t rawOffset,
+                                    const uint8_t * raw,
+                                    size_t rawLen,
+                                    uint32_t imageSizeLimit,
+                                    uint32_t imageDimensionLimit)
+{
+    BEGIN_STREAM(s, raw, rawLen, data->diag, "Box[moov]");
+
+    avifBool hasTrak = AVIF_FALSE;
+    while (avifROStreamHasBytesLeft(&s, 1)) {
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeader(&s, &header), AVIF_RESULT_BMFF_PARSE_FAILED);
+
+        if (!memcmp(header.type, "trak", 4)) {
+            AVIF_CHECKRES(
+                avifParseTrackBox(data, rawOffset + avifROStreamOffset(&s), avifROStreamCurrent(&s), header.size, imageSizeLimit, imageDimensionLimit));
+            hasTrak = AVIF_TRUE;
+        }
+
+        AVIF_CHECKERR(avifROStreamSkip(&s, header.size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+    if (!hasTrak) {
+        avifDiagnosticsPrintf(data->diag, "moov box does not contain any tracks");
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+static avifProperty * avifMetaCreateProperty(avifMeta * meta, const char * propertyType)
+{
+    avifProperty * metaProperty = avifArrayPush(&meta->properties);
+    AVIF_CHECK(metaProperty);
+    memcpy(metaProperty->type, propertyType, 4);
+    return metaProperty;
+}
+
+static avifProperty * avifDecoderItemAddProperty(avifDecoderItem * item, const avifProperty * metaProperty)
+{
+    avifProperty * itemProperty = avifArrayPush(&item->properties);
+    AVIF_CHECK(itemProperty);
+    *itemProperty = *metaProperty;
+    return itemProperty;
+}
+
+static avifResult avifParseMinimizedImageBox(avifDecoderData * data,
+                                             uint64_t rawOffset,
+                                             const uint8_t * raw,
+                                             size_t rawLen,
+                                             avifBool isAvifAccordingToMinorVersion,
+                                             avifDiagnostics * diag)
+{
+    avifMeta * meta = data->meta;
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[mini]");
+
+    meta->fromMiniBox = AVIF_TRUE;
+
+    uint32_t version;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &version, 2), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(2) version = 0;
+    AVIF_CHECKERR(version == 0, AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    // flags
+    uint32_t hasExplicitCodecTypes, floatFlag, fullRange, hasAlpha, hasExplicitCicp, hasHdr, hasIcc, hasExif, hasXmp;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasExplicitCodecTypes, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) explicit_codec_types_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &floatFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED);             // bit(1) float_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &fullRange, 1), AVIF_RESULT_BMFF_PARSE_FAILED);       // bit(1) full_range_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasAlpha, 1), AVIF_RESULT_BMFF_PARSE_FAILED);        // bit(1) alpha_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasExplicitCicp, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) explicit_cicp_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasHdr, 1), AVIF_RESULT_BMFF_PARSE_FAILED);          // bit(1) hdr_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasIcc, 1), AVIF_RESULT_BMFF_PARSE_FAILED);          // bit(1) icc_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasExif, 1), AVIF_RESULT_BMFF_PARSE_FAILED);         // bit(1) exif_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasXmp, 1), AVIF_RESULT_BMFF_PARSE_FAILED);          // bit(1) xmp_flag;
+
+    uint32_t chromaSubsampling, orientation;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &chromaSubsampling, 2), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(2) chroma_subsampling;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &orientation, 3), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(3) orientation_minus1;
+    ++orientation;
+
+    // Spatial extents
+    uint32_t smallDimensionsFlag, width, height;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &smallDimensionsFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) small_dimensions_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &width, smallDimensionsFlag ? 7 : 15),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(small_dimensions_flag ? 7 : 15) width_minus1;
+    ++width;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &height, smallDimensionsFlag ? 7 : 15),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(small_dimensions_flag ? 7 : 15) height_minus1;
+    ++height;
+
+    // Pixel information
+    uint32_t chromaIsHorizontallyCentered = 0, chromaIsVerticallyCentered = 0;
+    if (chromaSubsampling == 1 || chromaSubsampling == 2) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &chromaIsHorizontallyCentered, 1),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) chroma_is_horizontally_centered;
+    }
+    if (chromaSubsampling == 1) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &chromaIsVerticallyCentered, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) chroma_is_vertically_centered;
+    }
+
+    uint32_t bitDepth;
+    if (floatFlag) {
+        // bit(2) bit_depth_log2_minus4;
+        return AVIF_RESULT_BMFF_PARSE_FAILED; // Either invalid AVIF or unsupported non-AVIF.
+    } else {
+        uint32_t highBitDepthFlag;
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &highBitDepthFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) high_bit_depth_flag;
+        if (highBitDepthFlag) {
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &bitDepth, 3), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(3) bit_depth_minus9;
+            bitDepth += 9;
+        } else {
+            bitDepth = 8;
+        }
+    }
+
+    uint32_t alphaIsPremultiplied = 0;
+    if (hasAlpha) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &alphaIsPremultiplied, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) alpha_is_premultiplied;
+    }
+
+    // Colour properties
+    uint8_t colorPrimaries;
+    uint8_t transferCharacteristics;
+    uint8_t matrixCoefficients;
+    if (hasExplicitCicp) {
+        AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &colorPrimaries, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) colour_primaries;
+        AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &transferCharacteristics, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) transfer_characteristics;
+        if (chromaSubsampling != 0) {
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &matrixCoefficients, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) matrix_coefficients;
+        } else {
+            matrixCoefficients = AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED; // 2
+        }
+    } else {
+        colorPrimaries = hasIcc ? AVIF_COLOR_PRIMARIES_UNSPECIFIED                         // 2
+                                : AVIF_COLOR_PRIMARIES_BT709;                              // 1
+        transferCharacteristics = hasIcc ? AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED       // 2
+                                         : AVIF_TRANSFER_CHARACTERISTICS_SRGB;             // 13
+        matrixCoefficients = chromaSubsampling == 0 ? AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED // 2
+                                                    : AVIF_MATRIX_COEFFICIENTS_BT601;      // 6
+    }
+
+    uint8_t infeType[4];
+    uint8_t codecConfigType[4];
+    if (hasExplicitCodecTypes) {
+        // bit(32) infe_type;
+        for (int i = 0; i < 4; ++i) {
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &infeType[i], 8), AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+        // bit(32) codec_config_type;
+        for (int i = 0; i < 4; ++i) {
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &codecConfigType[i], 8), AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+#if defined(AVIF_CODEC_AVM)
+        AVIF_CHECKERR((!memcmp(infeType, "av01", 4) && !memcmp(codecConfigType, "av1C", 4)) ||
+                          (!memcmp(infeType, "av02", 4) && !memcmp(codecConfigType, "av2C", 4)),
+                      AVIF_RESULT_BMFF_PARSE_FAILED);
+#else
+        AVIF_CHECKERR(!memcmp(infeType, "av01", 4) && !memcmp(codecConfigType, "av1C", 4), AVIF_RESULT_BMFF_PARSE_FAILED);
+#endif
+    } else {
+        AVIF_CHECKERR(isAvifAccordingToMinorVersion, AVIF_RESULT_BMFF_PARSE_FAILED);
+        memcpy(infeType, "av01", 4);
+        memcpy(codecConfigType, "av1C", 4);
+    }
+
+    // High Dynamic Range properties
+    uint32_t hasGainmap = AVIF_FALSE;
+    uint32_t tmapHasIcc = AVIF_FALSE;
+    uint32_t gainmapWidth = 0, gainmapHeight = 0;
+    uint8_t gainmapMatrixCoefficients = 0;
+    uint32_t gainmapFullRange = 0;
+    uint32_t gainmapChromaSubsampling = 0;
+    uint32_t gainmapBitDepth = 0;
+    uint32_t tmapHasExplicitCicp = AVIF_FALSE;
+    uint8_t tmapColorPrimaries = AVIF_COLOR_PRIMARIES_UNKNOWN;
+    uint8_t tmapTransferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNKNOWN;
+    uint8_t tmapMatrixCoefficients = AVIF_MATRIX_COEFFICIENTS_IDENTITY;
+    uint32_t tmapFullRange = AVIF_FALSE;
+    uint32_t hasClli = AVIF_FALSE, tmapHasClli = AVIF_FALSE;
+    avifContentLightLevelInformationBox clli = {}, tmapClli = {};
+    if (hasHdr) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &hasGainmap, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_flag;
+        if (hasGainmap) {
+            // avifDecoderReset() requires the 'tmap' brand to be registered for the tone mapping derived image item to be parsed.
+            if (data->compatibleBrands.capacity == 0) {
+                AVIF_CHECKERR(avifArrayCreate(&data->compatibleBrands, sizeof(avifBrand), 1), AVIF_RESULT_OUT_OF_MEMORY);
+            }
+            avifBrand * brand = avifArrayPush(&data->compatibleBrands);
+            AVIF_CHECKERR(brand != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            memcpy(brand, "tmap", sizeof(avifBrand));
+
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapWidth, smallDimensionsFlag ? 7 : 15),
+                          AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(small_dimensions_flag ? 7 : 15) gainmap_width_minus1;
+            ++gainmapWidth;
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapHeight, smallDimensionsFlag ? 7 : 15),
+                          AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(small_dimensions_flag ? 7 : 15) gainmap_height_minus1;
+            ++gainmapHeight;
+            AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &gainmapMatrixCoefficients, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) gainmap_matrix_coefficients;
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapFullRange, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_full_range_flag;
+
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapChromaSubsampling, 2), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(2) gainmap_chroma_subsampling;
+            uint32_t gainmapChromaIsHorizontallyCentered = 0, gainmapChromaIsVerticallyCentered = 0;
+            if (gainmapChromaSubsampling == 1 || gainmapChromaSubsampling == 2) {
+                AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapChromaIsHorizontallyCentered, 1),
+                              AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_chroma_is_horizontally_centered;
+            }
+            if (gainmapChromaSubsampling == 1) {
+                AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapChromaIsVerticallyCentered, 1),
+                              AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_chroma_is_vertically_centered;
+            }
+
+            uint32_t gainmapFloatFlag;
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapFloatFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_float_flag;
+            if (gainmapFloatFlag) {
+                // bit(2) gainmap_bit_depth_log2_minus4;
+                return AVIF_RESULT_BMFF_PARSE_FAILED; // Either invalid AVIF or unsupported non-AVIF.
+            } else {
+                uint32_t gainmapHighBitDepthFlag;
+                AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapHighBitDepthFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) gainmap_high_bit_depth_flag;
+                if (gainmapHighBitDepthFlag) {
+                    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapBitDepth, 3), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(3) gainmap_bit_depth_minus9;
+                    gainmapBitDepth += 9;
+                } else {
+                    gainmapBitDepth = 8;
+                }
+            }
+
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &tmapHasIcc, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) tmap_icc_flag;
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &tmapHasExplicitCicp, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) tmap_explicit_cicp_flag;
+            if (tmapHasExplicitCicp) {
+                AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &tmapColorPrimaries, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) tmap_colour_primaries;
+                AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &tmapTransferCharacteristics, 8),
+                              AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) tmap_transfer_characteristics;
+                AVIF_CHECKERR(avifROStreamReadBitsU8(&s, &tmapMatrixCoefficients, 8), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(8) tmap_matrix_coefficients;
+                AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &tmapFullRange, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) tmap_full_range_flag;
+            } else {
+                tmapColorPrimaries = AVIF_COLOR_PRIMARIES_BT709;                  // 1
+                tmapTransferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_SRGB; // 13
+                tmapMatrixCoefficients = AVIF_MATRIX_COEFFICIENTS_BT601;          // 6
+                tmapFullRange = 1;
+            }
+        }
+        AVIF_CHECKRES(avifParseMiniHDRProperties(&s, &hasClli, &clli));
+        if (hasGainmap) {
+            AVIF_CHECKRES(avifParseMiniHDRProperties(&s, &tmapHasClli, &tmapClli));
+        }
+#else
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+    }
+
+    // Chunk sizes
+    uint32_t fewMetadataBytesFlag = 0, fewCodecConfigBytesFlag = 0, fewItemDataBytesFlag = 0;
+    if (hasIcc || hasExif || hasXmp || (hasHdr && hasGainmap)) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &fewMetadataBytesFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) few_metadata_bytes_flag;
+    }
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &fewCodecConfigBytesFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) few_codec_config_bytes_flag;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &fewItemDataBytesFlag, 1), AVIF_RESULT_BMFF_PARSE_FAILED); // bit(1) few_item_data_bytes_flag;
+
+    uint32_t iccDataSize = 0;
+    if (hasIcc) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &iccDataSize, fewMetadataBytesFlag ? 10 : 20),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_metadata_bytes_flag ? 10 : 20) icc_data_size_minus1;
+        ++iccDataSize;
+    }
+    uint32_t tmapIccDataSize = 0;
+    if (hasHdr && hasGainmap && tmapHasIcc) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &tmapIccDataSize, fewMetadataBytesFlag ? 10 : 20),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_metadata_bytes_flag ? 10 : 20) tmap_icc_data_size_minus1;
+        ++tmapIccDataSize;
+    }
+
+    uint32_t gainmapMetadataSize = 0, gainmapItemDataSize = 0, gainmapItemCodecConfigSize = 0;
+    if (hasHdr && hasGainmap) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapMetadataSize, fewMetadataBytesFlag ? 10 : 20),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_metadata_bytes_flag ? 10 : 20) gainmap_metadata_size;
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapItemDataSize, fewItemDataBytesFlag ? 15 : 28),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_item_data_bytes_flag ? 15 : 28) gainmap_item_data_size;
+        if (gainmapItemDataSize > 0) {
+            AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &gainmapItemCodecConfigSize, fewCodecConfigBytesFlag ? 3 : 12),
+                          AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) gainmap_item_codec_config_size;
+        }
+    }
+
+    uint32_t mainItemCodecConfigSize, mainItemDataSize;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &mainItemCodecConfigSize, fewCodecConfigBytesFlag ? 3 : 12),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) main_item_codec_config_size;
+    AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &mainItemDataSize, fewItemDataBytesFlag ? 15 : 28),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_item_data_bytes_flag ? 15 : 28) main_item_data_size_minus1;
+    ++mainItemDataSize;
+
+    uint32_t alphaItemCodecConfigSize = 0, alphaItemDataSize = 0;
+    if (hasAlpha) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &alphaItemDataSize, fewItemDataBytesFlag ? 15 : 28),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_item_data_bytes_flag ? 15 : 28) alpha_item_data_size;
+    }
+    if (hasAlpha && alphaItemDataSize != 0) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &alphaItemCodecConfigSize, fewCodecConfigBytesFlag ? 3 : 12),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) alpha_item_codec_config_size;
+    }
+
+    uint32_t exifDataSize = 0;
+    if (hasExif) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &exifDataSize, fewMetadataBytesFlag ? 10 : 20),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_metadata_bytes_flag ? 10 : 20) exif_data_size_minus_one;
+        ++exifDataSize;
+    }
+    uint32_t xmpDataSize = 0;
+    if (hasXmp) {
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &xmpDataSize, fewMetadataBytesFlag ? 10 : 20),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(few_metadata_bytes_flag ? 10 : 20) xmp_data_size_minus_one;
+        ++xmpDataSize;
+    }
+
+    // trailing_bits(); // bit padding till byte alignment
+    if (s.numUsedBitsInPartialByte) {
+        uint32_t padding;
+        AVIF_CHECKERR(avifROStreamReadBitsU32(&s, &padding, 8 - s.numUsedBitsInPartialByte), AVIF_RESULT_BMFF_PARSE_FAILED);
+        AVIF_CHECKERR(padding == 0, AVIF_RESULT_BMFF_PARSE_FAILED); // Only accept zeros as padding.
+    }
+
+    // Codec configuration ('av1C' always uses 4 bytes)
+    avifCodecConfigurationBox alphaItemCodecConfig = { 0 };
+    if (hasAlpha && alphaItemDataSize != 0 && alphaItemCodecConfigSize != 0) {
+        AVIF_CHECKERR(alphaItemCodecConfigSize == 4, AVIF_RESULT_BMFF_PARSE_FAILED);
+        AVIF_CHECKERR(avifParseCodecConfiguration(&s, &alphaItemCodecConfig, (const char *)codecConfigType, diag),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(8) alpha_item_codec_config[alpha_item_codec_config_size];
+    }
+    avifCodecConfigurationBox gainmapItemCodecConfig = { 0 };
+    if (hasHdr && hasGainmap && gainmapItemCodecConfigSize != 0) {
+        AVIF_CHECKERR(gainmapItemCodecConfigSize == 4, AVIF_RESULT_BMFF_PARSE_FAILED);
+        AVIF_CHECKERR(avifParseCodecConfiguration(&s, &gainmapItemCodecConfig, (const char *)codecConfigType, diag),
+                      AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(8) gainmap_item_codec_config[gainmap_item_codec_config_size];
+    }
+    avifCodecConfigurationBox mainItemCodecConfig;
+    AVIF_CHECKERR(mainItemCodecConfigSize == 4, AVIF_RESULT_BMFF_PARSE_FAILED);
+    AVIF_CHECKERR(avifParseCodecConfiguration(&s, &mainItemCodecConfig, (const char *)codecConfigType, diag),
+                  AVIF_RESULT_BMFF_PARSE_FAILED); // unsigned int(8) main_item_codec_config[main_item_codec_config_size];
+
+    // Make sure all metadata and coded chunks fit into the 'meta' box whose size is rawLen.
+    // There should be no missing nor unused byte.
+
+    AVIF_CHECKERR(avifROStreamRemainingBytes(&s) == (uint64_t)iccDataSize + tmapIccDataSize + gainmapMetadataSize + alphaItemDataSize +
+                                                        gainmapItemDataSize + mainItemDataSize + exifDataSize + xmpDataSize,
+                  AVIF_RESULT_BMFF_PARSE_FAILED);
+
+    // Create the items and properties generated by the MinimizedImageBox.
+    // The MinimizedImageBox always creates 8 properties for specification easiness.
+    // Use FreeSpaceBoxes as no-op placeholder properties when necessary.
+    // There is no need to use placeholder items because item IDs do not have to
+    // be contiguous, whereas property indices shall be 1, 2, 3, 4, 5 etc.
+
+    meta->primaryItemID = 1;
+    avifDecoderItem * colorItem;
+    AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, meta->primaryItemID, &colorItem));
+    memcpy(colorItem->type, infeType, 4);
+    colorItem->width = width;
+    colorItem->height = height;
+    colorItem->miniBoxPixelFormat = chromaSubsampling == 0   ? AVIF_PIXEL_FORMAT_YUV400
+                                    : chromaSubsampling == 1 ? AVIF_PIXEL_FORMAT_YUV420
+                                    : chromaSubsampling == 2 ? AVIF_PIXEL_FORMAT_YUV422
+                                                             : AVIF_PIXEL_FORMAT_YUV444;
+    if (colorItem->miniBoxPixelFormat == AVIF_PIXEL_FORMAT_YUV422) {
+        // In AV1, the chroma_sample_position syntax element is not present for the YUV 4:2:2 format.
+        // Assume that AV1 uses the same 4:2:2 chroma sample location as HEVC and VVC (colocated).
+        AVIF_CHECKERR(!chromaIsHorizontallyCentered, AVIF_RESULT_BMFF_PARSE_FAILED);
+        // chromaIsVerticallyCentered: Ignored unless chroma_subsampling is 1.
+        colorItem->miniBoxChromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+    } else if (colorItem->miniBoxPixelFormat == AVIF_PIXEL_FORMAT_YUV420) {
+        if (chromaIsHorizontallyCentered) {
+            // There is no way to describe this with AV1's chroma_sample_position enum besides CSP_UNKNOWN.
+            // There is a proposal to assign the reserved value 3 (CSP_RESERVED) to the center chroma sample position.
+            colorItem->miniBoxChromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+        } else {
+            colorItem->miniBoxChromaSamplePosition = chromaIsVerticallyCentered ? AVIF_CHROMA_SAMPLE_POSITION_VERTICAL
+                                                                                : AVIF_CHROMA_SAMPLE_POSITION_COLOCATED;
+        }
+    } else {
+        // chromaIsHorizontallyCentered: Ignored unless chroma_subsampling is 1 or 2.
+        // chromaIsVerticallyCentered: Ignored unless chroma_subsampling is 1.
+        colorItem->miniBoxChromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+    }
+
+    avifDecoderItem * alphaItem = NULL;
+    if (hasAlpha) {
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, /*itemID=*/2, &alphaItem));
+        memcpy(alphaItem->type, infeType, 4);
+        alphaItem->width = width;
+        alphaItem->height = height;
+        alphaItem->miniBoxPixelFormat = AVIF_PIXEL_FORMAT_YUV400;
+        alphaItem->miniBoxChromaSamplePosition = AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN;
+    }
+
+    avifDecoderItem * tmapItem = NULL;
+    if (hasGainmap) {
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, /*itemID=*/3, &tmapItem));
+        memcpy(tmapItem->type, "tmap", 4);
+        colorItem->dimgForID = tmapItem->id;
+        colorItem->dimgIdx = 0;
+    }
+    avifDecoderItem * gainmapItem = NULL;
+    if (gainmapItemDataSize != 0) {
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, /*itemID=*/4, &gainmapItem));
+        memcpy(gainmapItem->type, infeType, 4);
+        gainmapItem->width = gainmapWidth;
+        gainmapItem->height = gainmapHeight;
+        gainmapItem->dimgForID = tmapItem->id;
+        gainmapItem->dimgIdx = 1;
+    }
+
+    // Property with fixed index 1.
+    avifProperty * colorCodecConfigProp = avifMetaCreateProperty(meta, (const char *)codecConfigType);
+    AVIF_CHECKERR(colorCodecConfigProp, AVIF_RESULT_OUT_OF_MEMORY);
+    colorCodecConfigProp->u.av1C = mainItemCodecConfig;
+    AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, colorCodecConfigProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+    // Property with fixed index 2.
+    avifProperty * ispeProp = avifMetaCreateProperty(meta, "ispe");
+    AVIF_CHECKERR(ispeProp, AVIF_RESULT_OUT_OF_MEMORY);
+    ispeProp->u.ispe.width = width;
+    ispeProp->u.ispe.height = height;
+    AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, ispeProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+    // Property with fixed index 3.
+    avifProperty * pixiProp = avifMetaCreateProperty(meta, "pixi");
+    AVIF_CHECKERR(pixiProp, AVIF_RESULT_OUT_OF_MEMORY);
+    pixiProp->u.pixi.planeCount = chromaSubsampling == 0 ? 1 : 3;
+    for (uint8_t plane = 0; plane < pixiProp->u.pixi.planeCount; ++plane) {
+        pixiProp->u.pixi.planeDepths[plane] = (uint8_t)bitDepth;
+    }
+    AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, pixiProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+    // Property with fixed index 4.
+    avifProperty * colrPropNCLX = avifMetaCreateProperty(meta, "colr");
+    AVIF_CHECKERR(colrPropNCLX, AVIF_RESULT_OUT_OF_MEMORY);
+    colrPropNCLX->u.colr.hasNCLX = AVIF_TRUE; // colour_type "nclx"
+    colrPropNCLX->u.colr.colorPrimaries = (avifColorPrimaries)colorPrimaries;
+    colrPropNCLX->u.colr.transferCharacteristics = (avifTransferCharacteristics)transferCharacteristics;
+    colrPropNCLX->u.colr.matrixCoefficients = (avifMatrixCoefficients)matrixCoefficients;
+    colrPropNCLX->u.colr.range = fullRange ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED;
+    AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, colrPropNCLX), AVIF_RESULT_OUT_OF_MEMORY);
+
+    // Property with fixed index 5.
+    if (iccDataSize != 0) {
+        avifProperty * colrPropICC = avifMetaCreateProperty(meta, "colr");
+        AVIF_CHECKERR(colrPropICC, AVIF_RESULT_OUT_OF_MEMORY);
+        colrPropICC->u.colr.hasICC = AVIF_TRUE; // colour_type "rICC" or "prof"
+        colrPropICC->u.colr.iccOffset = rawOffset + avifROStreamOffset(&s);
+        colrPropICC->u.colr.iccSize = (size_t)iccDataSize;
+        AVIF_CHECKERR(avifROStreamSkip(&s, colrPropICC->u.colr.iccSize), AVIF_RESULT_BMFF_PARSE_FAILED);
+        AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, colrPropICC), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (hasAlpha) {
+        // Property with fixed index 6.
+        avifProperty * alphaCodecConfigProp = avifMetaCreateProperty(meta, (const char *)codecConfigType);
+        AVIF_CHECKERR(alphaCodecConfigProp, AVIF_RESULT_OUT_OF_MEMORY);
+        alphaCodecConfigProp->u.av1C = alphaItemCodecConfig;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(alphaItem, alphaCodecConfigProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Property with fixed index 7.
+        alphaItem->auxForID = colorItem->id;
+        colorItem->premByID = alphaIsPremultiplied;
+        avifProperty * alphaAuxProp = avifMetaCreateProperty(meta, "auxC");
+        AVIF_CHECKERR(alphaAuxProp, AVIF_RESULT_OUT_OF_MEMORY);
+        strcpy(alphaAuxProp->u.auxC.auxType, AVIF_URN_ALPHA0);
+        AVIF_CHECKERR(avifDecoderItemAddProperty(alphaItem, alphaAuxProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Property with fixed index 2 (reused).
+        AVIF_CHECKERR(avifDecoderItemAddProperty(alphaItem, ispeProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Property with fixed index 8.
+        avifProperty * alphaPixiProp = avifMetaCreateProperty(meta, "pixi");
+        AVIF_CHECKERR(alphaPixiProp, AVIF_RESULT_OUT_OF_MEMORY);
+        memcpy(alphaPixiProp->type, "pixi", 4);
+        alphaPixiProp->u.pixi.planeCount = 1;
+        alphaPixiProp->u.pixi.planeDepths[0] = (uint8_t)bitDepth;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(alphaItem, alphaPixiProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        // Placeholders 6, 7 and 8.
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+    }
+
+    // Same behavior as avifImageExtractExifOrientationToIrotImir().
+    if (orientation == 3 || orientation == 5 || orientation == 6 || orientation == 7 || orientation == 8) {
+        // Property with fixed index 9.
+        avifProperty * irotProp = avifMetaCreateProperty(meta, "irot");
+        AVIF_CHECKERR(irotProp, AVIF_RESULT_OUT_OF_MEMORY);
+        irotProp->u.irot.angle = orientation == 3 ? 2 : (orientation == 5 || orientation == 8) ? 1 : 3;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, irotProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+    if (orientation == 2 || orientation == 4 || orientation == 5 || orientation == 7) {
+        // Property with fixed index 10.
+        avifProperty * imirProp = avifMetaCreateProperty(meta, "imir");
+        AVIF_CHECKERR(imirProp, AVIF_RESULT_OUT_OF_MEMORY);
+        imirProp->u.imir.axis = orientation == 2 ? 1 : 0;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, imirProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (hasClli) {
+        // Property with fixed index 11.
+        avifProperty * clliProp = avifMetaCreateProperty(meta, "clli");
+        AVIF_CHECKERR(clliProp, AVIF_RESULT_OUT_OF_MEMORY);
+        clliProp->u.clli = clli;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, clliProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+    // Properties with fixed indices 12 to 16 are ignored by libavif (mdcv, cclv, amve, reve and ndwt).
+    for (int i = 12; i <= 16; ++i) {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (gainmapItemCodecConfigSize != 0) {
+        // Property with fixed index 17.
+        avifProperty * gainmapCodecConfigProp = avifMetaCreateProperty(meta, (const char *)codecConfigType);
+        AVIF_CHECKERR(gainmapCodecConfigProp, AVIF_RESULT_OUT_OF_MEMORY);
+        gainmapCodecConfigProp->u.av1C = gainmapItemCodecConfig;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(gainmapItem, gainmapCodecConfigProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (gainmapItemDataSize != 0) {
+        // Property with fixed index 18.
+        avifProperty * gainmapIspeProp = avifMetaCreateProperty(meta, "ispe");
+        AVIF_CHECKERR(gainmapIspeProp, AVIF_RESULT_OUT_OF_MEMORY);
+        gainmapIspeProp->u.ispe.width = gainmapWidth;
+        gainmapIspeProp->u.ispe.height = gainmapHeight;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(gainmapItem, gainmapIspeProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Property with fixed index 19.
+        avifProperty * gainmapPixiProp = avifMetaCreateProperty(meta, "pixi");
+        AVIF_CHECKERR(gainmapPixiProp, AVIF_RESULT_OUT_OF_MEMORY);
+        memcpy(gainmapPixiProp->type, "pixi", 4);
+        gainmapPixiProp->u.pixi.planeCount = gainmapChromaSubsampling == 0 ? 1 : 3;
+        for (uint8_t plane = 0; plane < gainmapPixiProp->u.pixi.planeCount; ++plane) {
+            gainmapPixiProp->u.pixi.planeDepths[plane] = (uint8_t)gainmapBitDepth;
+        }
+        AVIF_CHECKERR(avifDecoderItemAddProperty(gainmapItem, gainmapPixiProp), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Property with fixed index 20.
+        avifProperty * gainmapColrPropNCLX = avifMetaCreateProperty(meta, "colr");
+        AVIF_CHECKERR(gainmapColrPropNCLX, AVIF_RESULT_OUT_OF_MEMORY);
+        gainmapColrPropNCLX->u.colr.hasNCLX = AVIF_TRUE;                                                 // colour_type "nclx"
+        gainmapColrPropNCLX->u.colr.colorPrimaries = AVIF_COLOR_PRIMARIES_UNSPECIFIED;                   // 2
+        gainmapColrPropNCLX->u.colr.transferCharacteristics = AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED; // 2
+        gainmapColrPropNCLX->u.colr.matrixCoefficients = (avifMatrixCoefficients)gainmapMatrixCoefficients;
+        gainmapColrPropNCLX->u.colr.range = gainmapFullRange ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(gainmapItem, gainmapColrPropNCLX), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        // Placeholders 18, 19 and 20.
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY);
+    }
+
+    if (hasGainmap) {
+        // Property with fixed index 21.
+        avifProperty * tmapIspeProp = avifMetaCreateProperty(meta, "ispe");
+        AVIF_CHECKERR(tmapIspeProp, AVIF_RESULT_OUT_OF_MEMORY);
+        tmapIspeProp->u.ispe.width = orientation <= 4 ? width : height;
+        tmapIspeProp->u.ispe.height = orientation <= 4 ? height : width;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(tmapItem, tmapIspeProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (hasGainmap && (tmapHasExplicitCicp || !tmapHasIcc)) {
+        // Property with fixed index 22.
+        avifProperty * tmapColrPropNCLX = avifMetaCreateProperty(meta, "colr");
+        AVIF_CHECKERR(tmapColrPropNCLX, AVIF_RESULT_OUT_OF_MEMORY);
+        tmapColrPropNCLX->u.colr.hasNCLX = AVIF_TRUE; // colour_type "nclx"
+        tmapColrPropNCLX->u.colr.colorPrimaries = (avifColorPrimaries)tmapColorPrimaries;
+        tmapColrPropNCLX->u.colr.transferCharacteristics = (avifTransferCharacteristics)tmapTransferCharacteristics;
+        tmapColrPropNCLX->u.colr.matrixCoefficients = (avifMatrixCoefficients)tmapMatrixCoefficients;
+        tmapColrPropNCLX->u.colr.range = tmapFullRange ? AVIF_RANGE_FULL : AVIF_RANGE_LIMITED;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(tmapItem, tmapColrPropNCLX), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (tmapIccDataSize != 0) {
+        // Property with fixed index 23.
+        avifProperty * tmapColrPropICC = avifMetaCreateProperty(meta, "colr");
+        AVIF_CHECKERR(tmapColrPropICC, AVIF_RESULT_OUT_OF_MEMORY);
+        tmapColrPropICC->u.colr.hasICC = AVIF_TRUE; // colour_type "rICC" or "prof"
+        tmapColrPropICC->u.colr.iccOffset = rawOffset + avifROStreamOffset(&s);
+        tmapColrPropICC->u.colr.iccSize = tmapIccDataSize;
+        AVIF_CHECKERR(avifROStreamSkip(&s, tmapColrPropICC->u.colr.iccSize), AVIF_RESULT_BMFF_PARSE_FAILED);
+        AVIF_CHECKERR(avifDecoderItemAddProperty(colorItem, tmapColrPropICC), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+
+    if (tmapHasClli) {
+        // Property with fixed index 24.
+        avifProperty * tmapClliProp = avifMetaCreateProperty(meta, "clli");
+        AVIF_CHECKERR(tmapClliProp, AVIF_RESULT_OUT_OF_MEMORY);
+        tmapClliProp->u.clli = tmapClli;
+        AVIF_CHECKERR(avifDecoderItemAddProperty(tmapItem, tmapClliProp), AVIF_RESULT_OUT_OF_MEMORY);
+    } else {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+    // Properties with fixed indices 25 to 29 are ignored by libavif (mdcv, cclv, amve, reve and ndwt).
+    for (int i = 25; i <= 29; ++i) {
+        AVIF_CHECKERR(avifMetaCreateProperty(meta, "skip"), AVIF_RESULT_OUT_OF_MEMORY); // Placeholder.
+    }
+    AVIF_ASSERT_OR_RETURN(meta->properties.count == 29);
+
+    // Extents.
+
+    if (gainmapMetadataSize != 0) {
+        // Prepend the version field to the GainMapMetadata to form the ToneMapImage syntax.
+        tmapItem->size = gainmapMetadataSize + 1;
+        AVIF_CHECKRES(avifRWDataRealloc(&tmapItem->mergedExtents, tmapItem->size));
+        tmapItem->ownsMergedExtents = AVIF_TRUE;
+        tmapItem->mergedExtents.data[0] = 0; // unsigned int(8) version = 0;
+        AVIF_CHECKERR(avifROStreamRead(&s, tmapItem->mergedExtents.data + 1, gainmapMetadataSize), AVIF_RESULT_BMFF_PARSE_FAILED);
+    }
+
+    if (hasAlpha) {
+        avifExtent * alphaExtent = (avifExtent *)avifArrayPush(&alphaItem->extents);
+        AVIF_CHECKERR(alphaExtent, AVIF_RESULT_OUT_OF_MEMORY);
+        alphaExtent->offset = rawOffset + avifROStreamOffset(&s);
+        alphaExtent->size = alphaItemDataSize;
+        AVIF_CHECKERR(avifROStreamSkip(&s, alphaExtent->size), AVIF_RESULT_BMFF_PARSE_FAILED);
+        alphaItem->size = alphaExtent->size;
+    }
+
+    if (gainmapItemDataSize != 0) {
+        avifExtent * gainmapExtent = (avifExtent *)avifArrayPush(&gainmapItem->extents);
+        AVIF_CHECKERR(gainmapExtent, AVIF_RESULT_OUT_OF_MEMORY);
+        gainmapExtent->offset = rawOffset + avifROStreamOffset(&s);
+        gainmapExtent->size = gainmapItemDataSize;
+        AVIF_CHECKERR(avifROStreamSkip(&s, gainmapExtent->size), AVIF_RESULT_BMFF_PARSE_FAILED);
+        gainmapItem->size = gainmapExtent->size;
+    }
+
+    avifExtent * colorExtent = (avifExtent *)avifArrayPush(&colorItem->extents);
+    AVIF_CHECKERR(colorExtent, AVIF_RESULT_OUT_OF_MEMORY);
+    colorExtent->offset = rawOffset + avifROStreamOffset(&s);
+    colorExtent->size = mainItemDataSize;
+    AVIF_CHECKERR(avifROStreamSkip(&s, colorExtent->size), AVIF_RESULT_BMFF_PARSE_FAILED);
+    colorItem->size = colorExtent->size;
+
+    if (hasExif) {
+        avifDecoderItem * exifItem;
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, /*itemID=*/6, &exifItem));
+        memcpy(exifItem->type, "Exif", 4);
+        exifItem->descForID = colorItem->id; // 'cdsc'
+
+        avifExtent * exifExtent = (avifExtent *)avifArrayPush(&exifItem->extents);
+        AVIF_CHECKERR(exifExtent, AVIF_RESULT_OUT_OF_MEMORY);
+        exifExtent->offset = rawOffset + avifROStreamOffset(&s);
+        exifExtent->size = exifDataSize; // Does not include unsigned int(32) exif_tiff_header_offset;
+        AVIF_CHECKERR(avifROStreamSkip(&s, exifExtent->size), AVIF_RESULT_BMFF_PARSE_FAILED);
+        exifItem->size = exifExtent->size;
+    }
+
+    if (hasXmp) {
+        avifDecoderItem * xmpItem;
+        AVIF_CHECKRES(avifMetaFindOrCreateItem(meta, /*itemID=*/7, &xmpItem));
+        memcpy(xmpItem->type, "mime", 4);
+        memcpy(xmpItem->contentType.contentType, AVIF_CONTENT_TYPE_XMP, sizeof(AVIF_CONTENT_TYPE_XMP));
+        xmpItem->descForID = colorItem->id; // 'cdsc'
+
+        avifExtent * xmpExtent = (avifExtent *)avifArrayPush(&xmpItem->extents);
+        AVIF_CHECKERR(xmpExtent, AVIF_RESULT_OUT_OF_MEMORY);
+        xmpExtent->offset = rawOffset + avifROStreamOffset(&s);
+        xmpExtent->size = xmpDataSize;
+        AVIF_CHECKERR(avifROStreamSkip(&s, xmpExtent->size), AVIF_RESULT_BMFF_PARSE_FAILED);
+        xmpItem->size = xmpExtent->size;
+    }
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+static avifBool avifParseFileTypeBox(avifFileType * ftyp, const uint8_t * raw, size_t rawLen, avifDiagnostics * diag)
+{
+    BEGIN_STREAM(s, raw, rawLen, diag, "Box[ftyp]");
+
+    AVIF_CHECK(avifROStreamRead(&s, ftyp->majorBrand, 4));
+    AVIF_CHECK(avifROStreamRead(&s, ftyp->minorVersion, 4));
+
+    size_t compatibleBrandsBytes = avifROStreamRemainingBytes(&s);
+    if ((compatibleBrandsBytes % 4) != 0) {
+        avifDiagnosticsPrintf(diag, "Box[ftyp] contains a compatible brands section that isn't divisible by 4 [%zu]", compatibleBrandsBytes);
+        return AVIF_FALSE;
+    }
+    ftyp->compatibleBrands = avifROStreamCurrent(&s);
+    AVIF_CHECK(avifROStreamSkip(&s, compatibleBrandsBytes));
+    ftyp->compatibleBrandsCount = (int)compatibleBrandsBytes / 4;
+
+    return AVIF_TRUE;
+}
+
+static avifBool avifFileTypeHasBrand(avifFileType * ftyp, const char * brand);
+static avifBool avifFileTypeIsCompatible(avifFileType * ftyp);
+
+static avifResult avifParse(avifDecoder * decoder)
+{
+    // Note: this top-level function is the only avifParse*() function that returns avifResult instead of avifBool.
+    // Be sure to use AVIF_CHECKERR() in this function with an explicit error result instead of simply using AVIF_CHECK().
+
+    avifResult readResult;
+    uint64_t parseOffset = 0;
+    avifDecoderData * data = decoder->data;
+    avifBool ftypSeen = AVIF_FALSE;
+    avifBool metaSeen = AVIF_FALSE;
+    avifBool metaIsSizeZero = AVIF_FALSE;
+    avifBool moovSeen = AVIF_FALSE;
+    avifBool needsMeta = AVIF_FALSE;
+    avifBool needsMoov = AVIF_FALSE;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    avifBool miniSeen = AVIF_FALSE;
+    avifBool needsMini = AVIF_FALSE;
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    avifBool needsTmap = AVIF_FALSE;
+    avifBool tmapSeen = AVIF_FALSE;
+#endif
+    avifFileType ftyp = {};
+
+    for (;;) {
+        // Read just enough to get the next box header (a max of 32 bytes)
+        avifROData headerContents;
+        if ((decoder->io->sizeHint > 0) && (parseOffset > decoder->io->sizeHint)) {
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        readResult = decoder->io->read(decoder->io, 0, parseOffset, 32, &headerContents);
+        if (readResult != AVIF_RESULT_OK) {
+            return readResult;
+        }
+        if (!headerContents.size) {
+            // If we got AVIF_RESULT_OK from the reader but received 0 bytes,
+            // we've reached the end of the file with no errors. Hooray!
+            break;
+        }
+
+        // Parse the header, and find out how many bytes it actually was
+        BEGIN_STREAM(headerStream, headerContents.data, headerContents.size, &decoder->diag, "File-level box header");
+        avifBoxHeader header;
+        AVIF_CHECKERR(avifROStreamReadBoxHeaderPartial(&headerStream, &header, /*topLevel=*/AVIF_TRUE), AVIF_RESULT_BMFF_PARSE_FAILED);
+        parseOffset += headerStream.offset;
+        AVIF_ASSERT_OR_RETURN(decoder->io->sizeHint == 0 || parseOffset <= decoder->io->sizeHint);
+
+        // Try to get the remainder of the box, if necessary
+        uint64_t boxOffset = 0;
+        avifROData boxContents = AVIF_DATA_EMPTY;
+
+        avifBool isFtyp = AVIF_FALSE, isMeta = AVIF_FALSE, isMoov = AVIF_FALSE;
+        avifBool isNonSkippableVariableLengthBox = AVIF_FALSE;
+        if (!memcmp(header.type, "ftyp", 4)) {
+            isFtyp = AVIF_TRUE;
+            isNonSkippableVariableLengthBox = AVIF_TRUE;
+        } else if (!memcmp(header.type, "meta", 4)) {
+            isMeta = AVIF_TRUE;
+            isNonSkippableVariableLengthBox = AVIF_TRUE;
+            metaIsSizeZero = header.isSizeZeroBox;
+        } else if (!memcmp(header.type, "moov", 4)) {
+            isMoov = AVIF_TRUE;
+            isNonSkippableVariableLengthBox = AVIF_TRUE;
+        }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+        avifBool isMini = AVIF_FALSE;
+        if (!isNonSkippableVariableLengthBox && !memcmp(header.type, "mini", 4)) {
+            isMini = AVIF_TRUE;
+            isNonSkippableVariableLengthBox = AVIF_TRUE;
+        }
+#endif
+
+        if (!isFtyp && (isNonSkippableVariableLengthBox || !memcmp(header.type, "free", 4) || !memcmp(header.type, "skip", 4) ||
+                        !memcmp(header.type, "mdat", 4))) {
+            // Section 6.3.4 of ISO/IEC 14496-12:
+            //   The FileTypeBox shall occur before any variable-length box (e.g. movie, free space, media data).
+            AVIF_CHECKERR(ftypSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+
+        if (isNonSkippableVariableLengthBox) {
+            boxOffset = parseOffset;
+            size_t sizeToRead;
+            if (header.isSizeZeroBox) {
+                // The box body goes till the end of the file.
+                if (decoder->io->sizeHint != 0 && decoder->io->sizeHint - parseOffset < SIZE_MAX) {
+                    sizeToRead = decoder->io->sizeHint - parseOffset;
+                } else {
+                    sizeToRead = SIZE_MAX; // This will get truncated. See the documentation of avifIOReadFunc.
+                }
+            } else {
+                sizeToRead = header.size;
+            }
+            readResult = decoder->io->read(decoder->io, 0, parseOffset, sizeToRead, &boxContents);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+            if (header.isSizeZeroBox) {
+                header.size = boxContents.size;
+            } else if (boxContents.size != header.size) {
+                // A truncated box, bail out
+                return AVIF_RESULT_TRUNCATED_DATA;
+            }
+        } else if (header.isSizeZeroBox) {
+            // An unknown top level box with size 0 was found. If we reach here it means we haven't completed parsing successfully
+            // since there are no further boxes left.
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        } else if (header.size > (UINT64_MAX - parseOffset)) {
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+        parseOffset += header.size;
+
+        if (isFtyp) {
+            AVIF_CHECKERR(!ftypSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(avifParseFileTypeBox(&ftyp, boxContents.data, boxContents.size, data->diag), AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(avifFileTypeIsCompatible(&ftyp), AVIF_RESULT_INVALID_FTYP);
+            ftypSeen = AVIF_TRUE;
+            memcpy(data->majorBrand, ftyp.majorBrand, 4); // Remember the major brand for future AVIF_DECODER_SOURCE_AUTO decisions
+            if (ftyp.compatibleBrandsCount > 0) {
+                AVIF_CHECKERR(avifArrayCreate(&data->compatibleBrands, sizeof(avifBrand), ftyp.compatibleBrandsCount),
+                              AVIF_RESULT_OUT_OF_MEMORY);
+                memcpy(data->compatibleBrands.brand, ftyp.compatibleBrands, sizeof(avifBrand) * ftyp.compatibleBrandsCount);
+                data->compatibleBrands.count = ftyp.compatibleBrandsCount;
+            }
+            needsMeta = avifFileTypeHasBrand(&ftyp, "avif");
+            needsMoov = avifFileTypeHasBrand(&ftyp, "avis");
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+            needsMini = avifFileTypeHasBrand(&ftyp, "mif3");
+            if (needsMini) {
+                AVIF_CHECKERR(!needsMeta, AVIF_RESULT_INVALID_FTYP);
+                // Section O.2.1.2 of ISO/IEC 23008-12:2014, CDAM 2:
+                //   When the 'mif3' brand is present as the major_brand of the FileTypeBox,
+                //   the minor_version of the FileTypeBox shall be 0 or a brand that is either
+                //   structurally compatible with the 'mif3' brand, such as a codec brand
+                //   complying with the 'mif3' structural brand, or a brand to which the file
+                //   conforms after the equivalent MetaBox has been transformed from
+                //   MinimizedImageBox as specified in Clause O.4.
+                AVIF_CHECKERR(!memcmp(ftyp.minorVersion, "\0\0\0\0", 4) || !memcmp(ftyp.minorVersion, "avif", 4),
+                              AVIF_RESULT_BMFF_PARSE_FAILED);
+            }
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            needsTmap = avifFileTypeHasBrand(&ftyp, "tmap");
+            if (needsTmap) {
+                needsMeta = AVIF_TRUE;
+            }
+#endif
+        } else if (isMeta) {
+            AVIF_CHECKERR(!metaSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+            AVIF_CHECKERR(!miniSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+#endif
+            AVIF_CHECKRES(avifParseMetaBox(data->meta, boxOffset, boxContents.data, boxContents.size, data->diag));
+            metaSeen = AVIF_TRUE;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            for (uint32_t itemIndex = 0; itemIndex < data->meta->items.count; ++itemIndex) {
+                if (!memcmp(data->meta->items.item[itemIndex]->type, "tmap", 4)) {
+                    tmapSeen = AVIF_TRUE;
+                    break;
+                }
+            }
+#endif
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+        } else if (isMini) {
+            AVIF_CHECKERR(!metaSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(!miniSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+            const avifBool isAvifAccordingToMinorVersion = !memcmp(ftyp.minorVersion, "avif", 4);
+            AVIF_CHECKRES(
+                avifParseMinimizedImageBox(data, boxOffset, boxContents.data, boxContents.size, isAvifAccordingToMinorVersion, data->diag));
+            miniSeen = AVIF_TRUE;
+#endif
+        } else if (isMoov) {
+            AVIF_CHECKERR(!moovSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKRES(
+                avifParseMovieBox(data, boxOffset, boxContents.data, boxContents.size, decoder->imageSizeLimit, decoder->imageDimensionLimit));
+            moovSeen = AVIF_TRUE;
+            decoder->imageSequenceTrackPresent = AVIF_TRUE;
+        }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+        if (ftypSeen && !needsMini) {
+            // When MinimizedImageBox is present in a file, the 'mif3' brand or a derived brand that implies the 'mif3'
+            // brand shall be the major brand or present among the compatible brands in the FileTypeBox.
+            AVIF_CHECKERR(!miniSeen, AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+        // See if there is enough information to consider Parse() a success and early-out:
+        // * If the brand 'avif' is present, require a meta box
+        // * If the brand 'avis' is present, require a moov box
+        // * If AVIF_ENABLE_EXPERIMENTAL_MINI is defined and the brand 'mif3' is present, require a mini box
+        avifBool sawEverythingNeeded = ftypSeen && (!needsMeta || metaSeen) && (!needsMoov || moovSeen);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+        sawEverythingNeeded = sawEverythingNeeded && (!needsMini || miniSeen);
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        sawEverythingNeeded = sawEverythingNeeded && (!needsTmap || tmapSeen);
+#endif
+        if (sawEverythingNeeded) {
+            return AVIF_RESULT_OK;
+        }
+    }
+    if (!ftypSeen) {
+        return AVIF_RESULT_INVALID_FTYP;
+    }
+    if ((needsMeta && !metaSeen) || (needsMoov && !moovSeen)) {
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (needsTmap && !tmapSeen) {
+        return metaIsSizeZero ? AVIF_RESULT_TRUNCATED_DATA : AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+#else
+    (void)metaIsSizeZero;
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    if (needsMini && !miniSeen) {
+        return AVIF_RESULT_TRUNCATED_DATA;
+    }
+#endif
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+
+static avifBool avifFileTypeHasBrand(avifFileType * ftyp, const char * brand)
+{
+    if (!memcmp(ftyp->majorBrand, brand, 4)) {
+        return AVIF_TRUE;
+    }
+
+    for (int compatibleBrandIndex = 0; compatibleBrandIndex < ftyp->compatibleBrandsCount; ++compatibleBrandIndex) {
+        const uint8_t * compatibleBrand = &ftyp->compatibleBrands[4 * compatibleBrandIndex];
+        if (!memcmp(compatibleBrand, brand, 4)) {
+            return AVIF_TRUE;
+        }
+    }
+    return AVIF_FALSE;
+}
+
+static avifBool avifFileTypeIsCompatible(avifFileType * ftyp)
+{
+    return avifFileTypeHasBrand(ftyp, "avif") || avifFileTypeHasBrand(ftyp, "avis")
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+           || avifFileTypeHasBrand(ftyp, "mif3")
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+        ;
+}
+
+avifBool avifPeekCompatibleFileType(const avifROData * input)
+{
+    BEGIN_STREAM(s, input->data, input->size, NULL, NULL);
+
+    avifBoxHeader header;
+    if (!avifROStreamReadBoxHeaderPartial(&s, &header, /*topLevel=*/AVIF_TRUE) || memcmp(header.type, "ftyp", 4)) {
+        return AVIF_FALSE;
+    }
+    if (header.isSizeZeroBox) {
+        // The ftyp box goes on till the end of the file. Either there is no brand requiring anything in the file but a
+        // FileTypebox (so not AVIF), or it is invalid.
+        return AVIF_FALSE;
+    }
+    AVIF_CHECK(avifROStreamHasBytesLeft(&s, header.size));
+
+    avifFileType ftyp;
+    memset(&ftyp, 0, sizeof(avifFileType));
+    avifBool parsed = avifParseFileTypeBox(&ftyp, avifROStreamCurrent(&s), header.size, NULL);
+    if (!parsed) {
+        return AVIF_FALSE;
+    }
+    return avifFileTypeIsCompatible(&ftyp);
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+static avifBool avifBrandArrayHasBrand(avifBrandArray * brands, const char * brand)
+{
+    for (uint32_t brandIndex = 0; brandIndex < brands->count; ++brandIndex) {
+        if (!memcmp(brands->brand[brandIndex], brand, 4)) {
+            return AVIF_TRUE;
+        }
+    }
+    return AVIF_FALSE;
+}
+#endif
+
+// ---------------------------------------------------------------------------
+
+avifDecoder * avifDecoderCreate(void)
+{
+    avifDecoder * decoder = (avifDecoder *)avifAlloc(sizeof(avifDecoder));
+    if (decoder == NULL) {
+        return NULL;
+    }
+    memset(decoder, 0, sizeof(avifDecoder));
+    decoder->maxThreads = 1;
+    decoder->imageSizeLimit = AVIF_DEFAULT_IMAGE_SIZE_LIMIT;
+    decoder->imageDimensionLimit = AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT;
+    decoder->imageCountLimit = AVIF_DEFAULT_IMAGE_COUNT_LIMIT;
+    decoder->strictFlags = AVIF_STRICT_ENABLED;
+    decoder->imageContentToDecode = AVIF_IMAGE_CONTENT_DECODE_DEFAULT;
+    return decoder;
+}
+
+static void avifDecoderCleanup(avifDecoder * decoder)
+{
+    if (decoder->data) {
+        avifDecoderDataDestroy(decoder->data);
+        decoder->data = NULL;
+    }
+
+    if (decoder->image) {
+        avifImageDestroy(decoder->image);
+        decoder->image = NULL;
+    }
+    avifDiagnosticsClearError(&decoder->diag);
+}
+
+void avifDecoderDestroy(avifDecoder * decoder)
+{
+    avifDecoderCleanup(decoder);
+    avifIODestroy(decoder->io);
+    avifFree(decoder);
+}
+
+avifResult avifDecoderSetSource(avifDecoder * decoder, avifDecoderSource source)
+{
+    decoder->requestedSource = source;
+    return avifDecoderReset(decoder);
+}
+
+void avifDecoderSetIO(avifDecoder * decoder, avifIO * io)
+{
+    avifIODestroy(decoder->io);
+    decoder->io = io;
+}
+
+avifResult avifDecoderSetIOMemory(avifDecoder * decoder, const uint8_t * data, size_t size)
+{
+    avifIO * io = avifIOCreateMemoryReader(data, size);
+    AVIF_CHECKERR(io != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    avifDecoderSetIO(decoder, io);
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifDecoderSetIOFile(avifDecoder * decoder, const char * filename)
+{
+    avifIO * io = avifIOCreateFileReader(filename);
+    if (!io) {
+        return AVIF_RESULT_IO_ERROR;
+    }
+    avifDecoderSetIO(decoder, io);
+    return AVIF_RESULT_OK;
+}
+
+// 0-byte extents are ignored/overwritten during the merge, as they are the signal from helper
+// functions that no extent was necessary for this given sample. If both provided extents are
+// >0 bytes, this will set dst to be an extent that bounds both supplied extents.
+static avifResult avifExtentMerge(avifExtent * dst, const avifExtent * src)
+{
+    if (!dst->size) {
+        *dst = *src;
+        return AVIF_RESULT_OK;
+    }
+    if (!src->size) {
+        return AVIF_RESULT_OK;
+    }
+
+    const uint64_t minExtent1 = dst->offset;
+    const uint64_t maxExtent1 = dst->offset + dst->size;
+    const uint64_t minExtent2 = src->offset;
+    const uint64_t maxExtent2 = src->offset + src->size;
+    dst->offset = AVIF_MIN(minExtent1, minExtent2);
+    const uint64_t extentLength = AVIF_MAX(maxExtent1, maxExtent2) - dst->offset;
+    if (extentLength > SIZE_MAX) {
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    dst->size = (size_t)extentLength;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifDecoderNthImageMaxExtent(const avifDecoder * decoder, uint32_t frameIndex, avifExtent * outExtent)
+{
+    if (!decoder->data) {
+        // Nothing has been parsed yet
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    memset(outExtent, 0, sizeof(avifExtent));
+
+    uint32_t startFrameIndex = avifDecoderNearestKeyframe(decoder, frameIndex);
+    uint32_t endFrameIndex = frameIndex;
+    for (uint32_t currentFrameIndex = startFrameIndex; currentFrameIndex <= endFrameIndex; ++currentFrameIndex) {
+        for (unsigned int tileIndex = 0; tileIndex < decoder->data->tiles.count; ++tileIndex) {
+            avifTile * tile = &decoder->data->tiles.tile[tileIndex];
+            if (currentFrameIndex >= tile->input->samples.count) {
+                return AVIF_RESULT_NO_IMAGES_REMAINING;
+            }
+
+            avifDecodeSample * sample = &tile->input->samples.sample[currentFrameIndex];
+            avifExtent sampleExtent;
+            if (sample->itemID) {
+                // The data comes from an item. Let avifDecoderItemMaxExtent() do the heavy lifting.
+
+                avifDecoderItem * item;
+                AVIF_CHECKRES(avifMetaFindOrCreateItem(decoder->data->meta, sample->itemID, &item));
+                avifResult maxExtentResult = avifDecoderItemMaxExtent(item, sample, &sampleExtent);
+                if (maxExtentResult != AVIF_RESULT_OK) {
+                    return maxExtentResult;
+                }
+            } else {
+                // The data likely comes from a sample table. Use the sample position directly.
+
+                sampleExtent.offset = sample->offset;
+                sampleExtent.size = sample->size;
+            }
+
+            if (sampleExtent.size > UINT64_MAX - sampleExtent.offset) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            avifResult extentMergeResult = avifExtentMerge(outExtent, &sampleExtent);
+            if (extentMergeResult != AVIF_RESULT_OK) {
+                return extentMergeResult;
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifDecoderPrepareSample(avifDecoder * decoder, avifDecodeSample * sample, size_t partialByteCount)
+{
+    if (!sample->data.size || sample->partialData) {
+        // This sample hasn't been read from IO or had its extents fully merged yet.
+
+        size_t bytesToRead = sample->size;
+        if (partialByteCount && (bytesToRead > partialByteCount)) {
+            bytesToRead = partialByteCount;
+        }
+
+        if (sample->itemID) {
+            // The data comes from an item. Let avifDecoderItemRead() do the heavy lifting.
+
+            avifDecoderItem * item;
+            AVIF_CHECKRES(avifMetaFindOrCreateItem(decoder->data->meta, sample->itemID, &item));
+            avifROData itemContents;
+            if (sample->offset > SIZE_MAX) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            size_t offset = (size_t)sample->offset;
+            avifResult readResult = avifDecoderItemRead(item, decoder->io, &itemContents, offset, bytesToRead, &decoder->diag);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+
+            // avifDecoderItemRead is guaranteed to already be persisted by either the underlying IO
+            // or by mergedExtents; just reuse the buffer here.
+            sample->data = itemContents;
+            sample->ownsData = AVIF_FALSE;
+            sample->partialData = item->partialMergedExtents;
+        } else {
+            // The data likely comes from a sample table. Pull the sample and make a copy if necessary.
+
+            avifROData sampleContents;
+            if ((decoder->io->sizeHint > 0) && (sample->offset > decoder->io->sizeHint)) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            avifResult readResult = decoder->io->read(decoder->io, 0, sample->offset, bytesToRead, &sampleContents);
+            if (readResult != AVIF_RESULT_OK) {
+                return readResult;
+            }
+            if (sampleContents.size != bytesToRead) {
+                return AVIF_RESULT_TRUNCATED_DATA;
+            }
+
+            sample->ownsData = !decoder->io->persistent;
+            sample->partialData = (bytesToRead != sample->size);
+            if (decoder->io->persistent) {
+                sample->data = sampleContents;
+            } else {
+                AVIF_CHECKRES(avifRWDataSet((avifRWData *)&sample->data, sampleContents.data, sampleContents.size));
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Returns AVIF_TRUE if the item should be skipped. Items should be skipped for one of the following reasons:
+//  * Size is 0.
+//  * Has an essential property that isn't supported by libavif.
+//  * Item is not a single image or a grid.
+//  * Item is a thumbnail.
+static avifBool avifDecoderItemShouldBeSkipped(const avifDecoderItem * item)
+{
+    return !item->size || item->hasUnsupportedEssentialProperty ||
+           (avifGetCodecType(item->type) == AVIF_CODEC_TYPE_UNKNOWN && memcmp(item->type, "grid", 4)) || item->thumbnailForID != 0;
+}
+
+avifResult avifDecoderParse(avifDecoder * decoder)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+
+    // An imageSizeLimit greater than AVIF_DEFAULT_IMAGE_SIZE_LIMIT and the special value of 0 to
+    // disable the limit are not yet implemented.
+    if ((decoder->imageSizeLimit > AVIF_DEFAULT_IMAGE_SIZE_LIMIT) || (decoder->imageSizeLimit == 0)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (!decoder->io || !decoder->io->read) {
+        return AVIF_RESULT_IO_NOT_SET;
+    }
+
+    // Cleanup anything lingering in the decoder
+    avifDecoderCleanup(decoder);
+
+    // -----------------------------------------------------------------------
+    // Parse BMFF boxes
+
+    decoder->data = avifDecoderDataCreate();
+    AVIF_CHECKERR(decoder->data != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    decoder->data->diag = &decoder->diag;
+
+    AVIF_CHECKRES(avifParse(decoder));
+
+    // Walk the decoded items (if any) and harvest ispe
+    avifDecoderData * data = decoder->data;
+    for (uint32_t itemIndex = 0; itemIndex < data->meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = data->meta->items.item[itemIndex];
+        if (avifDecoderItemShouldBeSkipped(item)) {
+            continue;
+        }
+
+        const avifProperty * ispeProp = avifPropertyArrayFind(&item->properties, "ispe");
+        if (ispeProp) {
+            item->width = ispeProp->u.ispe.width;
+            item->height = ispeProp->u.ispe.height;
+
+            if ((item->width == 0) || (item->height == 0)) {
+                avifDiagnosticsPrintf(data->diag, "Item ID [%u] has an invalid size [%ux%u]", item->id, item->width, item->height);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            if (avifDimensionsTooLarge(item->width, item->height, decoder->imageSizeLimit, decoder->imageDimensionLimit)) {
+                avifDiagnosticsPrintf(data->diag, "Item ID [%u] dimensions are too large [%ux%u]", item->id, item->width, item->height);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        } else {
+            const avifProperty * auxCProp = avifPropertyArrayFind(&item->properties, "auxC");
+            if (auxCProp && isAlphaURN(auxCProp->u.auxC.auxType)) {
+                if (decoder->strictFlags & AVIF_STRICT_ALPHA_ISPE_REQUIRED) {
+                    avifDiagnosticsPrintf(data->diag,
+                                          "[Strict] Alpha auxiliary image item ID [%u] is missing a mandatory ispe property",
+                                          item->id);
+                    return AVIF_RESULT_BMFF_PARSE_FAILED;
+                }
+            } else {
+                avifDiagnosticsPrintf(data->diag, "Item ID [%u] is missing a mandatory ispe property", item->id);
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+        }
+    }
+    return avifDecoderReset(decoder);
+}
+
+static avifResult avifCodecCreateInternal(avifCodecChoice choice, const avifTile * tile, avifDiagnostics * diag, avifCodec ** codec)
+{
+#if defined(AVIF_CODEC_AVM)
+    // AVIF_CODEC_CHOICE_AUTO leads to AVIF_CODEC_TYPE_AV1 by default. Reroute correctly.
+    if (choice == AVIF_CODEC_CHOICE_AUTO && tile->codecType == AVIF_CODEC_TYPE_AV2) {
+        choice = AVIF_CODEC_CHOICE_AVM;
+    }
+#endif
+
+    const avifCodecType codecTypeFromChoice = avifCodecTypeFromChoice(choice, AVIF_CODEC_FLAG_CAN_DECODE);
+    if (codecTypeFromChoice == AVIF_CODEC_TYPE_UNKNOWN) {
+        avifDiagnosticsPrintf(diag,
+                              "Tile type is %s but there is no compatible codec available to decode it",
+                              avifGetConfigurationPropertyName(tile->codecType));
+        return AVIF_RESULT_NO_CODEC_AVAILABLE;
+    } else if (choice != AVIF_CODEC_CHOICE_AUTO && codecTypeFromChoice != tile->codecType) {
+        avifDiagnosticsPrintf(diag,
+                              "Tile type is %s but incompatible %s codec was explicitly set as decoding implementation",
+                              avifGetConfigurationPropertyName(tile->codecType),
+                              avifCodecName(choice, AVIF_CODEC_FLAG_CAN_DECODE));
+        return AVIF_RESULT_DECODE_COLOR_FAILED;
+    }
+
+    AVIF_CHECKRES(avifCodecCreate(choice, AVIF_CODEC_FLAG_CAN_DECODE, codec));
+    AVIF_CHECKERR(*codec, AVIF_RESULT_OUT_OF_MEMORY);
+    (*codec)->diag = diag;
+    (*codec)->operatingPoint = tile->operatingPoint;
+    (*codec)->allLayers = tile->input->allLayers;
+    return AVIF_RESULT_OK;
+}
+
+static avifBool avifTilesCanBeDecodedWithSameCodecInstance(avifDecoderData * data)
+{
+    int32_t numImageBuffers = 0, numStolenImageBuffers = 0;
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        if (data->tileInfos[c].tileCount > 0) {
+            ++numImageBuffers;
+        }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        // The sample operations require multiple buffers for compositing so no plane is stolen
+        // when there is a 'sato' Sample Transform derived image item.
+        if (c >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY && c <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY && data->tileInfos[c].tileCount > 0) {
+            continue;
+        }
+#endif
+        if (data->tileInfos[c].tileCount == 1) {
+            ++numStolenImageBuffers;
+        }
+    }
+    if (numStolenImageBuffers > 0 && numImageBuffers > 1) {
+        // Single tile image with single tile alpha plane or gain map. In this case each tile needs its own decoder since the planes will be
+        // "stolen". Stealing either the color or the alpha plane (or gain map) will invalidate the other ones when decode is called the second
+        // (or third) time.
+        return AVIF_FALSE;
+    }
+    const uint8_t firstTileOperatingPoint = data->tiles.tile[0].operatingPoint;
+    const avifBool firstTileAllLayers = data->tiles.tile[0].input->allLayers;
+    for (unsigned int i = 1; i < data->tiles.count; ++i) {
+        const avifTile * tile = &data->tiles.tile[i];
+        if (tile->operatingPoint != firstTileOperatingPoint || tile->input->allLayers != firstTileAllLayers) {
+            return AVIF_FALSE;
+        }
+        // avifDecoderItemValidateProperties() verified during avifDecoderParse() that all tiles
+        // share the same coding format so no need to check for codecType equality here.
+    }
+    return AVIF_TRUE;
+}
+
+static avifResult avifDecoderCreateCodecs(avifDecoder * decoder)
+{
+    avifDecoderData * data = decoder->data;
+    avifDecoderDataResetCodec(data);
+
+    if (data->source == AVIF_DECODER_SOURCE_TRACKS) {
+        // In this case, we will use at most two codec instances (one for the color planes and one for the alpha plane).
+        // Gain maps are not supported.
+        AVIF_CHECKRES(avifCodecCreateInternal(decoder->codecChoice, &decoder->data->tiles.tile[0], &decoder->diag, &data->codec));
+        data->tiles.tile[0].codec = data->codec;
+        if (data->tiles.count > 1) {
+            AVIF_CHECKRES(avifCodecCreateInternal(decoder->codecChoice, &decoder->data->tiles.tile[1], &decoder->diag, &data->codecAlpha));
+            data->tiles.tile[1].codec = data->codecAlpha;
+        }
+    } else {
+        // In this case, we will use one codec instance when there is only one tile or when all of the following conditions are
+        // met:
+        //   - The image must have exactly one layer (i.e.) decoder->imageCount == 1.
+        //   - All the tiles must have the same operating point (because the codecs take operating point once at initialization
+        //     and do not allow it to be changed later).
+        //   - All the tiles must have the same value for allLayers (because the codecs take allLayers once at initialization
+        //     and do not allow it to be changed later).
+        //   - If the image has a single tile, it must not have a single tile alpha plane (in this case we will steal the planes
+        //     from the decoder, so we cannot use the same decoder for both the color and the alpha planes).
+        //   - All tiles have the same type (AV1 or AV2).
+        // Otherwise, we will use |tiles.count| decoder instances (one instance for each tile).
+        avifBool canUseSingleCodecInstance = (data->tiles.count == 1) ||
+                                             (decoder->imageCount == 1 && avifTilesCanBeDecodedWithSameCodecInstance(data));
+        if (canUseSingleCodecInstance) {
+            AVIF_CHECKRES(avifCodecCreateInternal(decoder->codecChoice, &decoder->data->tiles.tile[0], &decoder->diag, &data->codec));
+            for (unsigned int i = 0; i < decoder->data->tiles.count; ++i) {
+                decoder->data->tiles.tile[i].codec = data->codec;
+            }
+        } else {
+            for (unsigned int i = 0; i < decoder->data->tiles.count; ++i) {
+                avifTile * tile = &decoder->data->tiles.tile[i];
+                AVIF_CHECKRES(avifCodecCreateInternal(decoder->codecChoice, tile, &decoder->diag, &tile->codec));
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Returns the primary color item if found, or NULL.
+static avifDecoderItem * avifMetaFindColorItem(avifMeta * meta)
+{
+    for (uint32_t itemIndex = 0; itemIndex < meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = meta->items.item[itemIndex];
+        if (avifDecoderItemShouldBeSkipped(item)) {
+            continue;
+        }
+        if (item->id == meta->primaryItemID) {
+            return item;
+        }
+    }
+    return NULL;
+}
+
+// Returns AVIF_TRUE if item is an alpha auxiliary item of the parent color
+// item.
+static avifBool avifDecoderItemIsAlphaAux(const avifDecoderItem * item, uint32_t colorItemId)
+{
+    if (item->auxForID != colorItemId)
+        return AVIF_FALSE;
+    const avifProperty * auxCProp = avifPropertyArrayFind(&item->properties, "auxC");
+    return auxCProp && isAlphaURN(auxCProp->u.auxC.auxType);
+}
+
+// Finds the alpha item whose parent item is colorItem and sets it in the alphaItem output parameter. Returns AVIF_RESULT_OK on
+// success. Note that *alphaItem can be NULL even if the return value is AVIF_RESULT_OK. If the colorItem is a grid and the alpha
+// item is represented as a set of auxl items to each color tile, then a fake item will be created and *isAlphaItemInInput will be
+// set to AVIF_FALSE. In this case, the alpha item merely exists to hold the locations of the alpha tile items. The data of this
+// item need not be read and the pixi property cannot be validated. Otherwise, *isAlphaItemInInput will be set to AVIF_TRUE when
+// *alphaItem is not NULL.
+static avifResult avifMetaFindAlphaItem(avifMeta * meta,
+                                        const avifDecoderItem * colorItem,
+                                        const avifTileInfo * colorInfo,
+                                        avifDecoderItem ** alphaItem,
+                                        avifTileInfo * alphaInfo,
+                                        avifBool * isAlphaItemInInput)
+{
+    for (uint32_t itemIndex = 0; itemIndex < meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = meta->items.item[itemIndex];
+        if (avifDecoderItemShouldBeSkipped(item)) {
+            continue;
+        }
+        if (avifDecoderItemIsAlphaAux(item, colorItem->id)) {
+            *alphaItem = item;
+            *isAlphaItemInInput = AVIF_TRUE;
+            return AVIF_RESULT_OK;
+        }
+    }
+    if (memcmp(colorItem->type, "grid", 4)) {
+        *alphaItem = NULL;
+        *isAlphaItemInInput = AVIF_FALSE;
+        return AVIF_RESULT_OK;
+    }
+    // If color item is a grid, check if there is an alpha channel which is represented as an auxl item to each color tile item.
+    const uint32_t tileCount = colorInfo->grid.rows * colorInfo->grid.columns;
+    if (tileCount == 0) {
+        *alphaItem = NULL;
+        *isAlphaItemInInput = AVIF_FALSE;
+        return AVIF_RESULT_OK;
+    }
+    // Keep the same 'dimg' order as it defines where each tile is located in the reconstructed image.
+    uint32_t * dimgIdxToAlphaItemIdx = (uint32_t *)avifAlloc(tileCount * sizeof(uint32_t));
+    AVIF_CHECKERR(dimgIdxToAlphaItemIdx != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    const uint32_t itemIndexNotSet = UINT32_MAX;
+    for (uint32_t dimgIdx = 0; dimgIdx < tileCount; ++dimgIdx) {
+        dimgIdxToAlphaItemIdx[dimgIdx] = itemIndexNotSet;
+    }
+    uint32_t alphaItemCount = 0;
+    for (uint32_t i = 0; i < meta->items.count; ++i) {
+        const avifDecoderItem * const item = meta->items.item[i];
+        if (item->dimgForID == colorItem->id) {
+            avifBool seenAlphaForCurrentItem = AVIF_FALSE;
+            for (uint32_t j = 0; j < meta->items.count; ++j) {
+                avifDecoderItem * auxlItem = meta->items.item[j];
+                if (avifDecoderItemIsAlphaAux(auxlItem, item->id)) {
+                    if (seenAlphaForCurrentItem || auxlItem->dimgForID != 0 || item->dimgIdx >= tileCount ||
+                        dimgIdxToAlphaItemIdx[item->dimgIdx] != itemIndexNotSet) {
+                        // One of the following invalid cases:
+                        // * Multiple items are claiming to be the alpha auxiliary of the current item.
+                        // * Alpha auxiliary is dimg for another item.
+                        // * There are too many items in the dimg array (also checked later in avifFillDimgIdxToItemIdxArray()).
+                        // * There is a repetition in the dimg array (also checked later in avifFillDimgIdxToItemIdxArray()).
+                        avifFree(dimgIdxToAlphaItemIdx);
+                        return AVIF_RESULT_INVALID_IMAGE_GRID;
+                    }
+                    dimgIdxToAlphaItemIdx[item->dimgIdx] = j;
+                    ++alphaItemCount;
+                    seenAlphaForCurrentItem = AVIF_TRUE;
+                }
+            }
+            if (!seenAlphaForCurrentItem) {
+                // No alpha auxiliary item was found for the current item. Treat this as an image without alpha.
+                avifFree(dimgIdxToAlphaItemIdx);
+                *alphaItem = NULL;
+                *isAlphaItemInInput = AVIF_FALSE;
+                return AVIF_RESULT_OK;
+            }
+        }
+    }
+    if (alphaItemCount != tileCount) {
+        avifFree(dimgIdxToAlphaItemIdx);
+        return AVIF_RESULT_INVALID_IMAGE_GRID;
+    }
+    // Find an unused ID.
+    avifResult result;
+    if (meta->items.count >= UINT32_MAX - 1) {
+        // In the improbable case where all IDs are used.
+        result = AVIF_RESULT_DECODE_ALPHA_FAILED;
+    } else {
+        uint32_t newItemID = 0;
+        avifBool isUsed;
+        do {
+            ++newItemID;
+            isUsed = AVIF_FALSE;
+            for (uint32_t i = 0; i < meta->items.count; ++i) {
+                if (meta->items.item[i]->id == newItemID) {
+                    isUsed = AVIF_TRUE;
+                    break;
+                }
+            }
+        } while (isUsed && newItemID != 0);
+        result = avifMetaFindOrCreateItem(meta, newItemID, alphaItem); // Create new empty item.
+    }
+    if (result != AVIF_RESULT_OK) {
+        avifFree(dimgIdxToAlphaItemIdx);
+        return result;
+    }
+    memcpy((*alphaItem)->type, "grid", 4); // Make it a grid and register alpha items as its tiles.
+    (*alphaItem)->width = colorItem->width;
+    (*alphaItem)->height = colorItem->height;
+    for (uint32_t dimgIdx = 0; dimgIdx < tileCount; ++dimgIdx) {
+        if (dimgIdxToAlphaItemIdx[dimgIdx] >= meta->items.count) {
+            avifFree(dimgIdxToAlphaItemIdx);
+            AVIF_ASSERT_OR_RETURN(AVIF_FALSE);
+        }
+        avifDecoderItem * alphaTileItem = meta->items.item[dimgIdxToAlphaItemIdx[dimgIdx]];
+        alphaTileItem->dimgForID = (*alphaItem)->id;
+        alphaTileItem->dimgIdx = dimgIdx;
+    }
+    avifFree(dimgIdxToAlphaItemIdx);
+    *isAlphaItemInInput = AVIF_FALSE;
+    alphaInfo->grid = colorInfo->grid;
+    return AVIF_RESULT_OK;
+}
+
+// On success, this function returns AVIF_RESULT_OK and does the following:
+// * If a nclx property was found in |properties|:
+//   - Set |*colorPrimaries|, |*transferCharacteristics|, |*matrixCoefficients|
+//     and |*yuvRange|.
+//   - If cicpSet is not NULL, set |*cicpSet| to AVIF_TRUE.
+// This function fails if more than one nclx property is found in |properties|.
+// The output parameters may be populated even in case of failure and must be
+// ignored.
+static avifResult avifReadColorNclxProperty(const avifPropertyArray * properties,
+                                            avifColorPrimaries * colorPrimaries,
+                                            avifTransferCharacteristics * transferCharacteristics,
+                                            avifMatrixCoefficients * matrixCoefficients,
+                                            avifRange * yuvRange,
+                                            avifBool * cicpSet)
+{
+    avifBool colrNCLXSeen = AVIF_FALSE;
+    for (uint32_t propertyIndex = 0; propertyIndex < properties->count; ++propertyIndex) {
+        avifProperty * prop = &properties->prop[propertyIndex];
+        if (!memcmp(prop->type, "colr", 4) && prop->u.colr.hasNCLX) {
+            if (colrNCLXSeen) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            colrNCLXSeen = AVIF_TRUE;
+            if (cicpSet != NULL) {
+                *cicpSet = AVIF_TRUE;
+            }
+            *colorPrimaries = prop->u.colr.colorPrimaries;
+            *transferCharacteristics = prop->u.colr.transferCharacteristics;
+            *matrixCoefficients = prop->u.colr.matrixCoefficients;
+            *yuvRange = prop->u.colr.range;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// On success, this function returns AVIF_RESULT_OK and does the following:
+// * If a colr property was found in |properties|:
+//   - Read the icc data into |icc| from |io|.
+//   - Sets the CICP values as documented in avifReadColorNclxProperty().
+// This function fails if more than one icc or nclx property is found in
+// |properties|. The output parameters may be populated even in case of failure
+// and must be ignored (and the |icc| object may need to be freed).
+static avifResult avifReadColorProperties(avifIO * io,
+                                          const avifPropertyArray * properties,
+                                          avifRWData * icc,
+                                          avifColorPrimaries * colorPrimaries,
+                                          avifTransferCharacteristics * transferCharacteristics,
+                                          avifMatrixCoefficients * matrixCoefficients,
+                                          avifRange * yuvRange,
+                                          avifBool * cicpSet)
+{
+    // Find and adopt all colr boxes "at most one for a given value of colour type" (HEIF 6.5.5.1, from Amendment 3)
+    // Accept one of each type, and bail out if more than one of a given type is provided.
+    avifBool colrICCSeen = AVIF_FALSE;
+    for (uint32_t propertyIndex = 0; propertyIndex < properties->count; ++propertyIndex) {
+        avifProperty * prop = &properties->prop[propertyIndex];
+        if (!memcmp(prop->type, "colr", 4) && prop->u.colr.hasICC) {
+            if (colrICCSeen) {
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+            avifROData iccRead;
+            AVIF_CHECKRES(io->read(io, 0, prop->u.colr.iccOffset, prop->u.colr.iccSize, &iccRead));
+            colrICCSeen = AVIF_TRUE;
+            AVIF_CHECKRES(avifRWDataSet(icc, iccRead.data, iccRead.size));
+        }
+    }
+    return avifReadColorNclxProperty(properties, colorPrimaries, transferCharacteristics, matrixCoefficients, yuvRange, cicpSet);
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+// Finds a 'tmap' (tone mapped image item) box associated with the given 'colorItem'.
+// If found, fills 'toneMappedImageItem' and  sets 'gainMapItemID' to the id of the gain map
+// item associated with the box. Otherwise, sets 'toneMappedImageItem' to NULL.
+// Returns AVIF_RESULT_OK if no errors were encountered (whether or not a tmap box was found).
+// Assumes that there is a single tmap item, and not, e.g., a grid of tmap items.
+// TODO(maryla): add support for files with multiple tmap items if it gets allowed by the spec.
+static avifResult avifDecoderDataFindToneMappedImageItem(const avifDecoderData * data,
+                                                         const avifDecoderItem * colorItem,
+                                                         avifDecoderItem ** toneMappedImageItem,
+                                                         uint32_t * gainMapItemID)
+{
+    for (uint32_t itemIndex = 0; itemIndex < data->meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = data->meta->items.item[itemIndex];
+        if (!item->size || item->hasUnsupportedEssentialProperty || item->thumbnailForID != 0) {
+            continue;
+        }
+        if (!memcmp(item->type, "tmap", 4)) {
+            // The tmap box should be associated (via 'iref'->'dimg') to two items:
+            // the first one is the base image, the second one is the gain map.
+            uint32_t dimgItemIDs[2] = { 0, 0 };
+            uint32_t numDimgItemIDs = 0;
+            for (uint32_t otherItemIndex = 0; otherItemIndex < data->meta->items.count; ++otherItemIndex) {
+                avifDecoderItem * otherItem = data->meta->items.item[otherItemIndex];
+                if (otherItem->dimgForID != item->id) {
+                    continue;
+                }
+                if (otherItem->dimgIdx < 2) {
+                    AVIF_ASSERT_OR_RETURN(dimgItemIDs[otherItem->dimgIdx] == 0);
+                    dimgItemIDs[otherItem->dimgIdx] = otherItem->id;
+                }
+                numDimgItemIDs++;
+            }
+            // Even with numDimgItemIDs == 2, one of the ids could be 0 if there are duplicate entries in the 'dimg' box.
+            if (numDimgItemIDs != 2 || dimgItemIDs[0] == 0 || dimgItemIDs[1] == 0) {
+                avifDiagnosticsPrintf(data->diag, "box[dimg] for 'tmap' item %d must have exactly 2 entries with distinct ids", item->id);
+                return AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE;
+            }
+            if (dimgItemIDs[0] != colorItem->id) {
+                continue;
+            }
+
+            *toneMappedImageItem = item;
+            *gainMapItemID = dimgItemIDs[1];
+            return AVIF_RESULT_OK;
+        }
+    }
+    *toneMappedImageItem = NULL;
+    *gainMapItemID = 0;
+    return AVIF_RESULT_OK;
+}
+
+// Finds a 'tmap' (tone mapped image item) box associated with the given 'colorItem',
+// then finds the associated gain map image.
+// If found, fills 'toneMappedImageItem', 'gainMapItem' and 'gainMapCodecType', and
+// allocates and fills metadata in decoder->image->gainMap.
+// Otherwise, sets 'toneMappedImageItem' and 'gainMapItem' to NULL.
+// Returns AVIF_RESULT_OK if no errors were encountered (whether or not a gain map was found).
+// Assumes that there is a single tmap item, and not, e.g., a grid of tmap items.
+static avifResult avifDecoderFindGainMapItem(const avifDecoder * decoder,
+                                             const avifDecoderItem * colorItem,
+                                             avifDecoderItem ** toneMappedImageItem,
+                                             avifDecoderItem ** gainMapItem,
+                                             avifCodecType * gainMapCodecType)
+{
+    *toneMappedImageItem = NULL;
+    *gainMapItem = NULL;
+    *gainMapCodecType = AVIF_CODEC_TYPE_UNKNOWN;
+
+    avifDecoderData * data = decoder->data;
+
+    uint32_t gainMapItemID;
+    avifDecoderItem * toneMappedImageItemTmp;
+    AVIF_CHECKRES(avifDecoderDataFindToneMappedImageItem(data, colorItem, &toneMappedImageItemTmp, &gainMapItemID));
+    if (!toneMappedImageItemTmp) {
+        return AVIF_RESULT_OK;
+    }
+
+    AVIF_ASSERT_OR_RETURN(gainMapItemID != 0);
+    avifDecoderItem * gainMapItemTmp;
+    AVIF_CHECKRES(avifMetaFindOrCreateItem(data->meta, gainMapItemID, &gainMapItemTmp));
+    if (avifDecoderItemShouldBeSkipped(gainMapItemTmp)) {
+        avifDiagnosticsPrintf(data->diag, "Box[tmap] gain map item %d is not a supported image type", gainMapItemID);
+        return AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE;
+    }
+
+    AVIF_CHECKRES(avifDecoderItemReadAndParse(decoder,
+                                              gainMapItemTmp,
+                                              /*isItemInInput=*/AVIF_TRUE,
+                                              &data->tileInfos[AVIF_ITEM_GAIN_MAP].grid,
+                                              gainMapCodecType));
+
+    decoder->image->gainMap = avifGainMapCreate();
+    AVIF_CHECKERR(decoder->image->gainMap, AVIF_RESULT_OUT_OF_MEMORY);
+
+    avifGainMap * const gainMap = decoder->image->gainMap;
+    AVIF_CHECKRES(avifReadColorProperties(decoder->io,
+                                          &toneMappedImageItemTmp->properties,
+                                          &gainMap->altICC,
+                                          &gainMap->altColorPrimaries,
+                                          &gainMap->altTransferCharacteristics,
+                                          &gainMap->altMatrixCoefficients,
+                                          &gainMap->altYUVRange,
+                                          /*cicpSet=*/NULL));
+
+    const avifProperty * clliProp = avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "clli");
+    if (clliProp) {
+        gainMap->altCLLI = clliProp->u.clli;
+    }
+
+    const avifProperty * pixiProp = avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "pixi");
+    if (pixiProp) {
+        gainMap->altPlaneCount = pixiProp->u.pixi.planeCount;
+        gainMap->altDepth = pixiProp->u.pixi.planeDepths[0];
+    }
+
+    if (avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "pasp") ||
+        avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "clap") ||
+        avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "irot") ||
+        avifPropertyArrayFind(&toneMappedImageItemTmp->properties, "imir")) {
+        // libavif requires the bitstream contain the same pasp, clap, irot, imir
+        // properties for both the base and gain map image items used as input to
+        // the tone-mapped derived image item. libavif also requires the tone-mapped
+        // derived image item itself not be associated with these properties. This is
+        // enforced at encoding. Other patterns are rejected at decoding.
+        avifDiagnosticsPrintf(data->diag,
+                              "Box[tmap] 'pasp', 'clap', 'irot' and 'imir' properties must be associated with base and gain map items instead of 'tmap'");
+        return AVIF_RESULT_INVALID_TONE_MAPPED_IMAGE;
+    }
+
+    if (decoder->imageContentToDecode & AVIF_IMAGE_CONTENT_GAIN_MAP) {
+        gainMap->image = avifImageCreateEmpty();
+        AVIF_CHECKERR(gainMap->image, AVIF_RESULT_OUT_OF_MEMORY);
+
+        // Look for a colr nclx box. Other colr box types (e.g. ICC) are not supported.
+        AVIF_CHECKRES(avifReadColorNclxProperty(&gainMapItemTmp->properties,
+                                                &gainMap->image->colorPrimaries,
+                                                &gainMap->image->transferCharacteristics,
+                                                &gainMap->image->matrixCoefficients,
+                                                &gainMap->image->yuvRange,
+                                                /*cicpSet=*/NULL));
+    }
+
+    // Only set the output parameters after everything has been validated.
+    *toneMappedImageItem = toneMappedImageItemTmp;
+    *gainMapItem = gainMapItemTmp;
+    return AVIF_RESULT_OK;
+}
+
+static avifResult aviDecoderCheckGainMapProperties(avifDecoder * decoder, const avifPropertyArray * gainMapProperties)
+{
+    const avifImage * image = decoder->image;
+    // libavif requires the bitstream contain the same 'pasp', 'clap', 'irot', 'imir'
+    // properties for both the base and gain map image items used as input to
+    // the tone-mapped derived image item. libavif also requires the tone-mapped
+    // derived image item itself not be associated with these properties. This is
+    // enforced at encoding. Other patterns are rejected at decoding.
+    const avifProperty * paspProp = avifPropertyArrayFind(gainMapProperties, "pasp");
+    if (!paspProp != !(image->transformFlags & AVIF_TRANSFORM_PASP) ||
+        (paspProp && (paspProp->u.pasp.hSpacing != image->pasp.hSpacing || paspProp->u.pasp.vSpacing != image->pasp.vSpacing))) {
+        avifDiagnosticsPrintf(&decoder->diag,
+                              "Pixel aspect ratio property mismatch between input items of tone-mapping derived image item");
+        return AVIF_RESULT_DECODE_GAIN_MAP_FAILED;
+    }
+    const avifProperty * clapProp = avifPropertyArrayFind(gainMapProperties, "clap");
+    if (!clapProp != !(image->transformFlags & AVIF_TRANSFORM_CLAP) ||
+        (clapProp && (clapProp->u.clap.widthN != image->clap.widthN || clapProp->u.clap.widthD != image->clap.widthD ||
+                      clapProp->u.clap.heightN != image->clap.heightN || clapProp->u.clap.heightD != image->clap.heightD ||
+                      clapProp->u.clap.horizOffN != image->clap.horizOffN || clapProp->u.clap.horizOffD != image->clap.horizOffD ||
+                      clapProp->u.clap.vertOffN != image->clap.vertOffN || clapProp->u.clap.vertOffD != image->clap.vertOffD))) {
+        avifDiagnosticsPrintf(&decoder->diag, "Clean aperture property mismatch between input items of tone-mapping derived image item");
+        return AVIF_RESULT_DECODE_GAIN_MAP_FAILED;
+    }
+    const avifProperty * irotProp = avifPropertyArrayFind(gainMapProperties, "irot");
+    if (!irotProp != !(image->transformFlags & AVIF_TRANSFORM_IROT) || (irotProp && irotProp->u.irot.angle != image->irot.angle)) {
+        avifDiagnosticsPrintf(&decoder->diag, "Rotation property mismatch between input items of tone-mapping derived image item");
+        return AVIF_RESULT_DECODE_GAIN_MAP_FAILED;
+    }
+    const avifProperty * imirProp = avifPropertyArrayFind(gainMapProperties, "imir");
+    if (!imirProp != !(image->transformFlags & AVIF_TRANSFORM_IMIR) || (imirProp && imirProp->u.imir.axis != image->imir.axis)) {
+        avifDiagnosticsPrintf(&decoder->diag, "Mirroring property mismatch between input items of tone-mapping derived image item");
+        return AVIF_RESULT_DECODE_GAIN_MAP_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+// Finds a 'sato' Sample Transform derived image item box.
+// If found, fills 'sampleTransformItem'. Otherwise, sets 'sampleTransformItem' to NULL.
+// Returns AVIF_RESULT_OK on success (whether or not a 'sato' box was found).
+// Assumes that there is a single 'sato' item.
+// Assumes that the 'sato' item is not the primary item and that both the primary item and 'sato'
+// are in the same 'altr' group.
+// TODO(yguyon): Check instead of assuming.
+static avifResult avifDecoderDataFindSampleTransformImageItem(avifDecoderData * data, avifDecoderItem ** sampleTransformItem)
+{
+    for (uint32_t itemIndex = 0; itemIndex < data->meta->items.count; ++itemIndex) {
+        avifDecoderItem * item = data->meta->items.item[itemIndex];
+        if (!item->size || item->hasUnsupportedEssentialProperty || item->thumbnailForID != 0) {
+            continue;
+        }
+        if (!memcmp(item->type, "sato", 4)) {
+            *sampleTransformItem = item;
+            return AVIF_RESULT_OK;
+        }
+    }
+    *sampleTransformItem = NULL;
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+static avifResult avifDecoderGenerateImageTiles(avifDecoder * decoder, avifTileInfo * info, avifDecoderItem * item, avifItemCategory itemCategory)
+{
+    const uint32_t previousTileCount = decoder->data->tiles.count;
+    if ((info->grid.rows > 0) && (info->grid.columns > 0)) {
+        // The number of tiles was verified in avifDecoderItemReadAndParse().
+        const uint32_t numTiles = info->grid.rows * info->grid.columns;
+        uint32_t * dimgIdxToItemIdx = (uint32_t *)avifAlloc(numTiles * sizeof(uint32_t));
+        AVIF_CHECKERR(dimgIdxToItemIdx != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        avifResult result = avifFillDimgIdxToItemIdxArray(dimgIdxToItemIdx, numTiles, item);
+        if (result == AVIF_RESULT_OK) {
+            result = avifDecoderGenerateImageGridTiles(decoder, item, itemCategory, dimgIdxToItemIdx, numTiles);
+        }
+        avifFree(dimgIdxToItemIdx);
+        AVIF_CHECKRES(result);
+    } else {
+        AVIF_CHECKERR(item->size != 0, AVIF_RESULT_MISSING_IMAGE_ITEM);
+
+        const avifCodecType codecType = avifGetCodecType(item->type);
+        AVIF_ASSERT_OR_RETURN(codecType != AVIF_CODEC_TYPE_UNKNOWN);
+        avifTile * tile =
+            avifDecoderDataCreateTile(decoder->data, codecType, item->width, item->height, avifDecoderItemOperatingPoint(item));
+        AVIF_CHECKERR(tile, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKRES(avifCodecDecodeInputFillFromDecoderItem(tile->input,
+                                                              item,
+                                                              decoder->allowProgressive,
+                                                              decoder->imageCountLimit,
+                                                              decoder->io->sizeHint,
+                                                              &decoder->diag));
+        tile->input->itemCategory = itemCategory;
+    }
+    info->tileCount = decoder->data->tiles.count - previousTileCount;
+    return AVIF_RESULT_OK;
+}
+
+// Populates depth, yuvFormat and yuvChromaSamplePosition fields on 'image' based on data from the codec config property (e.g. "av1C").
+static avifResult avifReadCodecConfigProperty(avifImage * image, const avifPropertyArray * properties, avifCodecType codecType)
+{
+    const avifProperty * configProp = avifPropertyArrayFind(properties, avifGetConfigurationPropertyName(codecType));
+    if (configProp) {
+        image->depth = avifCodecConfigurationBoxGetDepth(&configProp->u.av1C);
+        if (configProp->u.av1C.monochrome) {
+            image->yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+        } else {
+            if (configProp->u.av1C.chromaSubsamplingX && configProp->u.av1C.chromaSubsamplingY) {
+                image->yuvFormat = AVIF_PIXEL_FORMAT_YUV420;
+            } else if (configProp->u.av1C.chromaSubsamplingX) {
+                image->yuvFormat = AVIF_PIXEL_FORMAT_YUV422;
+            } else {
+                image->yuvFormat = AVIF_PIXEL_FORMAT_YUV444;
+            }
+        }
+        image->yuvChromaSamplePosition = (avifChromaSamplePosition)configProp->u.av1C.chromaSamplePosition;
+    } else {
+        // A configuration property box is mandatory in all valid AVIF configurations. Bail out.
+        return AVIF_RESULT_BMFF_PARSE_FAILED;
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifDecoderReset(avifDecoder * decoder)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+
+    avifDecoderData * data = decoder->data;
+    if (!data) {
+        // Nothing to reset.
+        return AVIF_RESULT_OK;
+    }
+
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        memset(&data->tileInfos[c].grid, 0, sizeof(data->tileInfos[c].grid));
+    }
+    avifDecoderDataClearTiles(data);
+
+    // Prepare / cleanup decoded image state
+    if (decoder->image) {
+        avifImageDestroy(decoder->image);
+    }
+    decoder->image = avifImageCreateEmpty();
+    AVIF_CHECKERR(decoder->image, AVIF_RESULT_OUT_OF_MEMORY);
+    decoder->progressiveState = AVIF_PROGRESSIVE_STATE_UNAVAILABLE;
+    data->cicpSet = AVIF_FALSE;
+
+    memset(&decoder->ioStats, 0, sizeof(decoder->ioStats));
+
+    // -----------------------------------------------------------------------
+    // Build decode input
+
+    data->sourceSampleTable = NULL; // Reset
+    if (decoder->requestedSource == AVIF_DECODER_SOURCE_AUTO) {
+        // Honor the major brand (avif or avis) if present, otherwise prefer avis (tracks) if possible.
+        if (!memcmp(data->majorBrand, "avis", 4)) {
+            data->source = AVIF_DECODER_SOURCE_TRACKS;
+        } else if (!memcmp(data->majorBrand, "avif", 4)) {
+            data->source = AVIF_DECODER_SOURCE_PRIMARY_ITEM;
+        } else if (data->tracks.count > 0) {
+            data->source = AVIF_DECODER_SOURCE_TRACKS;
+        } else {
+            data->source = AVIF_DECODER_SOURCE_PRIMARY_ITEM;
+        }
+    } else {
+        data->source = decoder->requestedSource;
+    }
+
+    avifCodecType colorCodecType = AVIF_CODEC_TYPE_UNKNOWN;
+    const avifPropertyArray * colorProperties = NULL;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    const avifPropertyArray * gainMapProperties = NULL;
+#endif
+    if (data->source == AVIF_DECODER_SOURCE_TRACKS) {
+        avifTrack * colorTrack = NULL;
+        avifTrack * alphaTrack = NULL;
+
+        // Find primary track - this probably needs some better detection
+        uint32_t colorTrackIndex = 0;
+        for (; colorTrackIndex < data->tracks.count; ++colorTrackIndex) {
+            avifTrack * track = &data->tracks.track[colorTrackIndex];
+            if (!track->sampleTable) {
+                continue;
+            }
+            if (!track->id) { // trak box might be missing a tkhd box inside, skip it
+                continue;
+            }
+            if (!track->sampleTable->chunks.count) {
+                continue;
+            }
+            colorCodecType = avifSampleTableGetCodecType(track->sampleTable);
+            if (colorCodecType == AVIF_CODEC_TYPE_UNKNOWN) {
+                continue;
+            }
+            if (track->auxForID != 0) {
+                continue;
+            }
+
+            // Found one!
+            break;
+        }
+        if (colorTrackIndex == data->tracks.count) {
+            avifDiagnosticsPrintf(&decoder->diag, "Failed to find AV1 color track");
+            return AVIF_RESULT_NO_CONTENT;
+        }
+        colorTrack = &data->tracks.track[colorTrackIndex];
+
+        colorProperties = avifSampleTableGetProperties(colorTrack->sampleTable, colorCodecType);
+        if (!colorProperties) {
+            avifDiagnosticsPrintf(&decoder->diag, "Failed to find AV1 color track's color properties");
+            return AVIF_RESULT_BMFF_PARSE_FAILED;
+        }
+
+        // Find Exif and/or XMP metadata, if any
+        if (colorTrack->meta) {
+            // See the comment above avifDecoderFindMetadata() for the explanation of using 0 here
+            avifResult findResult = avifDecoderFindMetadata(decoder, colorTrack->meta, decoder->image, 0);
+            if (findResult != AVIF_RESULT_OK) {
+                return findResult;
+            }
+        }
+
+        uint32_t alphaTrackIndex = 0;
+        avifCodecType alphaCodecType = AVIF_CODEC_TYPE_UNKNOWN;
+        for (; alphaTrackIndex < data->tracks.count; ++alphaTrackIndex) {
+            avifTrack * track = &data->tracks.track[alphaTrackIndex];
+            if (!track->sampleTable) {
+                continue;
+            }
+            if (!track->id) {
+                continue;
+            }
+            if (!track->sampleTable->chunks.count) {
+                continue;
+            }
+            alphaCodecType = avifSampleTableGetCodecType(track->sampleTable);
+            if (alphaCodecType == AVIF_CODEC_TYPE_UNKNOWN) {
+                continue;
+            }
+            if (track->auxForID == colorTrack->id) {
+                // Found it!
+                break;
+            }
+        }
+        if (alphaTrackIndex != data->tracks.count) {
+            alphaTrack = &data->tracks.track[alphaTrackIndex];
+        }
+
+        const uint8_t operatingPoint = 0; // No way to set operating point via tracks
+        avifTile * colorTile = avifDecoderDataCreateTile(data, colorCodecType, colorTrack->width, colorTrack->height, operatingPoint);
+        AVIF_CHECKERR(colorTile != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKRES(avifCodecDecodeInputFillFromSampleTable(colorTile->input,
+                                                              colorTrack->sampleTable,
+                                                              decoder->imageCountLimit,
+                                                              decoder->io->sizeHint,
+                                                              data->diag));
+        data->tileInfos[AVIF_ITEM_COLOR].tileCount = 1;
+
+        if (alphaTrack) {
+            avifTile * alphaTile = avifDecoderDataCreateTile(data, alphaCodecType, alphaTrack->width, alphaTrack->height, operatingPoint);
+            AVIF_CHECKERR(alphaTile != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            AVIF_CHECKRES(avifCodecDecodeInputFillFromSampleTable(alphaTile->input,
+                                                                  alphaTrack->sampleTable,
+                                                                  decoder->imageCountLimit,
+                                                                  decoder->io->sizeHint,
+                                                                  data->diag));
+            alphaTile->input->itemCategory = AVIF_ITEM_ALPHA;
+            data->tileInfos[AVIF_ITEM_ALPHA].tileCount = 1;
+        }
+
+        // Stash off sample table for future timing information
+        data->sourceSampleTable = colorTrack->sampleTable;
+
+        // Image sequence timing
+        decoder->imageIndex = -1;
+        decoder->imageCount = (int)colorTile->input->samples.count;
+        decoder->timescale = colorTrack->mediaTimescale;
+        decoder->durationInTimescales = colorTrack->mediaDuration;
+        if (colorTrack->mediaTimescale) {
+            decoder->duration = (double)decoder->durationInTimescales / (double)colorTrack->mediaTimescale;
+        } else {
+            decoder->duration = 0;
+        }
+        // If the alphaTrack->repetitionCount and colorTrack->repetitionCount are different, we will simply use the
+        // colorTrack's repetitionCount.
+        decoder->repetitionCount = colorTrack->repetitionCount;
+
+        memset(&decoder->imageTiming, 0, sizeof(decoder->imageTiming)); // to be set in avifDecoderNextImage()
+
+        decoder->image->width = colorTrack->width;
+        decoder->image->height = colorTrack->height;
+        decoder->alphaPresent = (alphaTrack != NULL);
+        decoder->image->alphaPremultiplied = decoder->alphaPresent && (colorTrack->premByID == alphaTrack->id);
+    } else {
+        // Create from items
+
+        if (data->meta->primaryItemID == 0) {
+            // A primary item is required
+            avifDiagnosticsPrintf(&decoder->diag, "Primary item not specified");
+            return AVIF_RESULT_MISSING_IMAGE_ITEM;
+        }
+
+        // Main item of each group category (top-level item such as grid or single tile), if any.
+        avifDecoderItem * mainItems[AVIF_ITEM_CATEGORY_COUNT];
+        avifCodecType codecType[AVIF_ITEM_CATEGORY_COUNT];
+        for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+            mainItems[c] = NULL;
+            codecType[c] = AVIF_CODEC_TYPE_UNKNOWN;
+        }
+
+        // Mandatory primary color item
+        mainItems[AVIF_ITEM_COLOR] = avifMetaFindColorItem(data->meta);
+        if (!mainItems[AVIF_ITEM_COLOR]) {
+            avifDiagnosticsPrintf(&decoder->diag, "Primary item not found");
+            return AVIF_RESULT_MISSING_IMAGE_ITEM;
+        }
+        AVIF_CHECKRES(avifDecoderItemReadAndParse(decoder,
+                                                  mainItems[AVIF_ITEM_COLOR],
+                                                  /*isItemInInput=*/AVIF_TRUE,
+                                                  &data->tileInfos[AVIF_ITEM_COLOR].grid,
+                                                  &codecType[AVIF_ITEM_COLOR]));
+        colorProperties = &mainItems[AVIF_ITEM_COLOR]->properties;
+        colorCodecType = codecType[AVIF_ITEM_COLOR];
+
+        // Optional alpha auxiliary item
+        avifBool isAlphaItemInInput;
+        AVIF_CHECKRES(avifMetaFindAlphaItem(data->meta,
+                                            mainItems[AVIF_ITEM_COLOR],
+                                            &data->tileInfos[AVIF_ITEM_COLOR],
+                                            &mainItems[AVIF_ITEM_ALPHA],
+                                            &data->tileInfos[AVIF_ITEM_ALPHA],
+                                            &isAlphaItemInInput));
+        if (mainItems[AVIF_ITEM_ALPHA]) {
+            AVIF_CHECKRES(avifDecoderItemReadAndParse(decoder,
+                                                      mainItems[AVIF_ITEM_ALPHA],
+                                                      isAlphaItemInInput,
+                                                      &data->tileInfos[AVIF_ITEM_ALPHA].grid,
+                                                      &codecType[AVIF_ITEM_ALPHA]));
+        }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        // Section 10.2.6 of 23008-12:2024/AMD 1:2024(E):
+        //   'tmap' brand
+        //   This brand enables file players to identify and decode HEIF files containing tone-map derived image
+        //   items. When present, this brand shall be among the brands included in the compatible_brands
+        //   array of the FileTypeBox.
+        //
+        // If the file contains a 'tmap' item but doesn't have the 'tmap' brand, it is technically invalid.
+        // However, we don't report any error because in order to do detect this case consistently, we would
+        // need to remove the early exit in avifParse() to check if a 'tmap' item might be present
+        // further down the file. Instead, we simply ignore tmap items in files that lack the 'tmap' brand.
+        if (avifBrandArrayHasBrand(&data->compatibleBrands, "tmap")) {
+            avifDecoderItem * toneMappedImageItem;
+            avifDecoderItem * gainMapItem;
+            avifCodecType gainMapCodecType;
+            AVIF_CHECKRES(
+                avifDecoderFindGainMapItem(decoder, mainItems[AVIF_ITEM_COLOR], &toneMappedImageItem, &gainMapItem, &gainMapCodecType));
+            if (toneMappedImageItem != NULL) {
+                // Read the gain map's metadata.
+                avifROData tmapData;
+                AVIF_CHECKRES(avifDecoderItemRead(toneMappedImageItem, decoder->io, &tmapData, 0, 0, data->diag));
+                AVIF_ASSERT_OR_RETURN(decoder->image->gainMap != NULL);
+                const avifResult tmapParsingRes =
+                    avifParseToneMappedImageBox(decoder->image->gainMap, tmapData.data, tmapData.size, data->diag);
+                if (tmapParsingRes == AVIF_RESULT_NOT_IMPLEMENTED) {
+                    // Unsupported gain map version. Simply ignore the gain map.
+                    avifGainMapDestroy(decoder->image->gainMap);
+                    decoder->image->gainMap = NULL;
+                } else {
+                    AVIF_CHECKRES(tmapParsingRes);
+                    if (decoder->imageContentToDecode & AVIF_IMAGE_CONTENT_GAIN_MAP) {
+                        mainItems[AVIF_ITEM_GAIN_MAP] = gainMapItem;
+                        codecType[AVIF_ITEM_GAIN_MAP] = gainMapCodecType;
+                    }
+                }
+            }
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        // AVIF_ITEM_SAMPLE_TRANSFORM (not used through mainItems because not a coded item (well grids are not coded items either but it's different)).
+        avifDecoderItem * sampleTransformItem = NULL;
+        AVIF_CHECKRES(avifDecoderDataFindSampleTransformImageItem(data, &sampleTransformItem));
+        if (sampleTransformItem != NULL) {
+            AVIF_ASSERT_OR_RETURN(data->sampleTransformNumInputImageItems == 0);
+            uint32_t numExtraInputImageItems = 0;
+            for (uint32_t i = 0; i < data->meta->items.count; ++i) {
+                avifDecoderItem * inputImageItem = data->meta->items.item[i];
+                if (inputImageItem->dimgForID != sampleTransformItem->id) {
+                    continue;
+                }
+                if (avifDecoderItemShouldBeSkipped(inputImageItem)) {
+                    avifDiagnosticsPrintf(data->diag, "Box[sato] input item %u is not a supported image type", inputImageItem->id);
+                    return AVIF_RESULT_DECODE_SAMPLE_TRANSFORM_FAILED;
+                }
+                // Input image item order is important because input image items are indexed according to this order.
+                AVIF_CHECKERR(inputImageItem->dimgIdx == data->sampleTransformNumInputImageItems, AVIF_RESULT_NOT_IMPLEMENTED);
+
+                AVIF_CHECKERR(data->sampleTransformNumInputImageItems < AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS,
+                              AVIF_RESULT_NOT_IMPLEMENTED);
+                avifItemCategory * category = &data->sampleTransformInputImageItems[data->sampleTransformNumInputImageItems];
+                avifBool foundItem = AVIF_FALSE;
+                avifItemCategory alphaCategory = AVIF_ITEM_CATEGORY_COUNT;
+                for (int c = AVIF_ITEM_COLOR; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+                    if (mainItems[c] && inputImageItem->id == mainItems[c]->id) {
+                        *category = c;
+                        AVIF_CHECKERR(*category == AVIF_ITEM_COLOR, AVIF_RESULT_NOT_IMPLEMENTED);
+                        alphaCategory = AVIF_ITEM_ALPHA;
+                        foundItem = AVIF_TRUE;
+                        break;
+                    }
+                }
+                if (!foundItem) {
+                    AVIF_CHECKERR(numExtraInputImageItems < AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS,
+                                  AVIF_RESULT_NOT_IMPLEMENTED);
+                    *category = (avifItemCategory)(AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR + numExtraInputImageItems);
+                    alphaCategory = (avifItemCategory)(AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA + numExtraInputImageItems);
+                    mainItems[*category] = inputImageItem;
+                    ++numExtraInputImageItems;
+
+                    AVIF_CHECKRES(avifDecoderItemReadAndParse(decoder,
+                                                              inputImageItem,
+                                                              /*isItemInInput=*/AVIF_TRUE,
+                                                              &data->tileInfos[*category].grid,
+                                                              &codecType[*category]));
+
+                    // Optional alpha auxiliary item
+                    avifBool isAlphaInputImageItemInInput = AVIF_FALSE;
+                    AVIF_CHECKRES(avifMetaFindAlphaItem(data->meta,
+                                                        mainItems[*category],
+                                                        &data->tileInfos[*category],
+                                                        &mainItems[alphaCategory],
+                                                        &data->tileInfos[alphaCategory],
+                                                        &isAlphaInputImageItemInInput));
+
+                    AVIF_CHECKERR(!mainItems[alphaCategory] == !mainItems[AVIF_ITEM_ALPHA], AVIF_RESULT_NOT_IMPLEMENTED);
+                    if (mainItems[alphaCategory] != NULL) {
+                        AVIF_CHECKERR(isAlphaInputImageItemInInput == isAlphaItemInInput, AVIF_RESULT_NOT_IMPLEMENTED);
+                        AVIF_CHECKERR((mainItems[*category]->premByID == mainItems[alphaCategory]->id) ==
+                                          (mainItems[AVIF_ITEM_COLOR]->premByID == mainItems[AVIF_ITEM_ALPHA]->id),
+                                      AVIF_RESULT_NOT_IMPLEMENTED);
+                        AVIF_CHECKRES(avifDecoderItemReadAndParse(decoder,
+                                                                  mainItems[alphaCategory],
+                                                                  isAlphaInputImageItemInInput,
+                                                                  &data->tileInfos[alphaCategory].grid,
+                                                                  &codecType[alphaCategory]));
+                    }
+                }
+
+                ++data->sampleTransformNumInputImageItems;
+            }
+
+            AVIF_ASSERT_OR_RETURN(data->meta->sampleTransformExpression.tokens == NULL);
+            avifROData satoData;
+            AVIF_CHECKRES(avifDecoderItemRead(sampleTransformItem, decoder->io, &satoData, 0, 0, data->diag));
+            AVIF_CHECKRES(avifParseSampleTransformImageBox(satoData.data,
+                                                           satoData.size,
+                                                           data->sampleTransformNumInputImageItems,
+                                                           &data->meta->sampleTransformExpression,
+                                                           data->diag));
+            AVIF_CHECKRES(avifDecoderSampleTransformItemValidateProperties(sampleTransformItem, data->diag));
+            const avifProperty * pixiProp = avifPropertyArrayFind(&sampleTransformItem->properties, "pixi");
+            AVIF_ASSERT_OR_RETURN(pixiProp != NULL);
+            data->meta->sampleTransformDepth = pixiProp->u.pixi.planeDepths[0];
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+        // Find Exif and/or XMP metadata, if any
+        AVIF_CHECKRES(avifDecoderFindMetadata(decoder, data->meta, decoder->image, mainItems[AVIF_ITEM_COLOR]->id));
+
+        // Set all counts and timing to safe-but-uninteresting values
+        decoder->imageIndex = -1;
+        decoder->imageCount = 1;
+        decoder->imageTiming.timescale = 1;
+        decoder->imageTiming.pts = 0;
+        decoder->imageTiming.ptsInTimescales = 0;
+        decoder->imageTiming.duration = 1;
+        decoder->imageTiming.durationInTimescales = 1;
+        decoder->timescale = 1;
+        decoder->duration = 1;
+        decoder->durationInTimescales = 1;
+
+        for (int c = AVIF_ITEM_COLOR; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+            if (!mainItems[c]) {
+                continue;
+            }
+
+            if (avifIsAlpha((avifItemCategory)c) && !mainItems[c]->width && !mainItems[c]->height) {
+                // NON-STANDARD: Alpha subimage does not have an ispe property; adopt width/height from color item
+                AVIF_ASSERT_OR_RETURN(!(decoder->strictFlags & AVIF_STRICT_ALPHA_ISPE_REQUIRED));
+                mainItems[c]->width = mainItems[AVIF_ITEM_COLOR]->width;
+                mainItems[c]->height = mainItems[AVIF_ITEM_COLOR]->height;
+            }
+
+            AVIF_CHECKRES(avifDecoderAdoptGridTileCodecTypeIfNeeded(decoder, mainItems[c], &data->tileInfos[c]));
+
+            if (!(decoder->imageContentToDecode & AVIF_IMAGE_CONTENT_COLOR_AND_ALPHA) && (c == AVIF_ITEM_COLOR || c == AVIF_ITEM_ALPHA)) {
+                continue;
+            }
+
+            AVIF_CHECKRES(avifDecoderGenerateImageTiles(decoder, &data->tileInfos[c], mainItems[c], (avifItemCategory)c));
+
+            avifStrictFlags strictFlags = decoder->strictFlags;
+            if (avifIsAlpha((avifItemCategory)c) && !isAlphaItemInInput) {
+                // In this case, the made up grid item will not have an associated pixi property. So validate everything else
+                // but the pixi property.
+                strictFlags &= ~(avifStrictFlags)AVIF_STRICT_PIXI_REQUIRED;
+            }
+            AVIF_CHECKRES(
+                avifDecoderItemValidateProperties(mainItems[c], avifGetConfigurationPropertyName(codecType[c]), &decoder->diag, strictFlags));
+        }
+
+        if (mainItems[AVIF_ITEM_COLOR]->progressive) {
+            decoder->progressiveState = AVIF_PROGRESSIVE_STATE_AVAILABLE;
+            // data->tileInfos[AVIF_ITEM_COLOR].firstTileIndex is not yet defined but will be set to 0 a few lines below.
+            const avifTile * colorTile = &data->tiles.tile[0];
+            if (colorTile->input->samples.count > 1) {
+                decoder->progressiveState = AVIF_PROGRESSIVE_STATE_ACTIVE;
+                decoder->imageCount = (int)colorTile->input->samples.count;
+            }
+        }
+
+        decoder->image->width = mainItems[AVIF_ITEM_COLOR]->width;
+        decoder->image->height = mainItems[AVIF_ITEM_COLOR]->height;
+        decoder->alphaPresent = (mainItems[AVIF_ITEM_ALPHA] != NULL);
+        decoder->image->alphaPremultiplied = decoder->alphaPresent &&
+                                             (mainItems[AVIF_ITEM_COLOR]->premByID == mainItems[AVIF_ITEM_ALPHA]->id);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (mainItems[AVIF_ITEM_GAIN_MAP]) {
+            AVIF_ASSERT_OR_RETURN(decoder->image->gainMap && decoder->image->gainMap->image);
+            decoder->image->gainMap->image->width = mainItems[AVIF_ITEM_GAIN_MAP]->width;
+            decoder->image->gainMap->image->height = mainItems[AVIF_ITEM_GAIN_MAP]->height;
+            // Must be called after avifDecoderGenerateImageTiles() which among other things copies the
+            // codec config property from the first tile of a grid to the grid item (when grids are used).
+            AVIF_CHECKRES(avifReadCodecConfigProperty(decoder->image->gainMap->image,
+                                                      &mainItems[AVIF_ITEM_GAIN_MAP]->properties,
+                                                      codecType[AVIF_ITEM_GAIN_MAP]));
+            gainMapProperties = &mainItems[AVIF_ITEM_GAIN_MAP]->properties;
+        }
+#endif
+    }
+
+    uint32_t firstTileIndex = 0;
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        data->tileInfos[c].firstTileIndex = firstTileIndex;
+        firstTileIndex += data->tileInfos[c].tileCount;
+    }
+
+    // Sanity check tiles
+    for (uint32_t tileIndex = 0; tileIndex < data->tiles.count; ++tileIndex) {
+        avifTile * tile = &data->tiles.tile[tileIndex];
+        for (uint32_t sampleIndex = 0; sampleIndex < tile->input->samples.count; ++sampleIndex) {
+            avifDecodeSample * sample = &tile->input->samples.sample[sampleIndex];
+            if (!sample->size) {
+                // Every sample must have some data
+                return AVIF_RESULT_BMFF_PARSE_FAILED;
+            }
+
+            if (tile->input->itemCategory == AVIF_ITEM_COLOR) {
+                decoder->ioStats.colorOBUSize += sample->size;
+            } else if (tile->input->itemCategory == AVIF_ITEM_ALPHA) {
+                decoder->ioStats.alphaOBUSize += sample->size;
+            }
+        }
+    }
+
+    AVIF_CHECKRES(avifReadColorProperties(decoder->io,
+                                          colorProperties,
+                                          &decoder->image->icc,
+                                          &decoder->image->colorPrimaries,
+                                          &decoder->image->transferCharacteristics,
+                                          &decoder->image->matrixCoefficients,
+                                          &decoder->image->yuvRange,
+                                          &data->cicpSet));
+
+    const avifProperty * clliProp = avifPropertyArrayFind(colorProperties, "clli");
+    if (clliProp) {
+        decoder->image->clli = clliProp->u.clli;
+    }
+
+    // Transformations
+    const avifProperty * paspProp = avifPropertyArrayFind(colorProperties, "pasp");
+    if (paspProp) {
+        decoder->image->transformFlags |= AVIF_TRANSFORM_PASP;
+        decoder->image->pasp = paspProp->u.pasp;
+    }
+    const avifProperty * clapProp = avifPropertyArrayFind(colorProperties, "clap");
+    if (clapProp) {
+        decoder->image->transformFlags |= AVIF_TRANSFORM_CLAP;
+        decoder->image->clap = clapProp->u.clap;
+    }
+    const avifProperty * irotProp = avifPropertyArrayFind(colorProperties, "irot");
+    if (irotProp) {
+        decoder->image->transformFlags |= AVIF_TRANSFORM_IROT;
+        decoder->image->irot = irotProp->u.irot;
+    }
+    const avifProperty * imirProp = avifPropertyArrayFind(colorProperties, "imir");
+    if (imirProp) {
+        decoder->image->transformFlags |= AVIF_TRANSFORM_IMIR;
+        decoder->image->imir = imirProp->u.imir;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (gainMapProperties != NULL) {
+        AVIF_CHECKRES(aviDecoderCheckGainMapProperties(decoder, gainMapProperties));
+    }
+#endif
+
+    if (!data->cicpSet && (data->tiles.count > 0)) {
+        avifTile * firstTile = &data->tiles.tile[0];
+        if (firstTile->input->samples.count > 0) {
+            avifDecodeSample * sample = &firstTile->input->samples.sample[0];
+
+            // Harvest CICP from the AV1's sequence header, which should be very close to the front
+            // of the first sample. Read in successively larger chunks until we successfully parse the sequence.
+            static const size_t searchSampleChunkIncrement = 64;
+            static const size_t searchSampleSizeMax = 4096;
+            size_t searchSampleSize = 0;
+            do {
+                searchSampleSize += searchSampleChunkIncrement;
+                if (searchSampleSize > sample->size) {
+                    searchSampleSize = sample->size;
+                }
+
+                avifResult prepareResult = avifDecoderPrepareSample(decoder, sample, searchSampleSize);
+                if (prepareResult != AVIF_RESULT_OK) {
+                    return prepareResult;
+                }
+
+                avifSequenceHeader sequenceHeader;
+                if (avifSequenceHeaderParse(&sequenceHeader, &sample->data, firstTile->codecType)) {
+                    data->cicpSet = AVIF_TRUE;
+                    decoder->image->colorPrimaries = sequenceHeader.colorPrimaries;
+                    decoder->image->transferCharacteristics = sequenceHeader.transferCharacteristics;
+                    decoder->image->matrixCoefficients = sequenceHeader.matrixCoefficients;
+                    decoder->image->yuvRange = sequenceHeader.range;
+                    break;
+                }
+            } while (searchSampleSize != sample->size && searchSampleSize < searchSampleSizeMax);
+        }
+    }
+
+    AVIF_CHECKRES(avifReadCodecConfigProperty(decoder->image, colorProperties, colorCodecType));
+
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifDecoderPrepareTiles(avifDecoder * decoder, uint32_t nextImageIndex, const avifTileInfo * info)
+{
+    for (unsigned int tileIndex = info->decodedTileCount; tileIndex < info->tileCount; ++tileIndex) {
+        avifTile * tile = &decoder->data->tiles.tile[info->firstTileIndex + tileIndex];
+
+        if (nextImageIndex >= tile->input->samples.count) {
+            return AVIF_RESULT_NO_IMAGES_REMAINING;
+        }
+
+        avifDecodeSample * sample = &tile->input->samples.sample[nextImageIndex];
+        avifResult prepareResult = avifDecoderPrepareSample(decoder, sample, 0);
+        if (prepareResult != AVIF_RESULT_OK) {
+            return prepareResult;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageLimitedToFullAlpha(avifImage * image)
+{
+    if (image->imageOwnsAlphaPlane) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    const uint8_t * alphaPlane = image->alphaPlane;
+    const uint32_t alphaRowBytes = image->alphaRowBytes;
+
+    // We cannot do the range conversion in place since it will modify the
+    // codec's internal frame buffers. Allocate memory for the conversion.
+    image->alphaPlane = NULL;
+    image->alphaRowBytes = 0;
+    const avifResult allocationResult = avifImageAllocatePlanes(image, AVIF_PLANES_A);
+    if (allocationResult != AVIF_RESULT_OK) {
+        return allocationResult;
+    }
+
+    if (image->depth > 8) {
+        for (uint32_t j = 0; j < image->height; ++j) {
+            const uint8_t * srcRow = &alphaPlane[j * alphaRowBytes];
+            uint8_t * dstRow = &image->alphaPlane[j * image->alphaRowBytes];
+            for (uint32_t i = 0; i < image->width; ++i) {
+                int srcAlpha = *((const uint16_t *)&srcRow[i * 2]);
+                int dstAlpha = avifLimitedToFullY(image->depth, srcAlpha);
+                *((uint16_t *)&dstRow[i * 2]) = (uint16_t)dstAlpha;
+            }
+        }
+    } else {
+        for (uint32_t j = 0; j < image->height; ++j) {
+            const uint8_t * srcRow = &alphaPlane[j * alphaRowBytes];
+            uint8_t * dstRow = &image->alphaPlane[j * image->alphaRowBytes];
+            for (uint32_t i = 0; i < image->width; ++i) {
+                int srcAlpha = srcRow[i];
+                int dstAlpha = avifLimitedToFullY(image->depth, srcAlpha);
+                dstRow[i] = (uint8_t)dstAlpha;
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifGetErrorForItemCategory(avifItemCategory itemCategory)
+{
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (itemCategory == AVIF_ITEM_GAIN_MAP) {
+        return AVIF_RESULT_DECODE_GAIN_MAP_FAILED;
+    }
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (itemCategory >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY && itemCategory <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY) {
+        return AVIF_RESULT_DECODE_SAMPLE_TRANSFORM_FAILED;
+    }
+#endif
+    return avifIsAlpha(itemCategory) ? AVIF_RESULT_DECODE_ALPHA_FAILED : AVIF_RESULT_DECODE_COLOR_FAILED;
+}
+
+static avifResult avifDecoderDecodeTiles(avifDecoder * decoder, uint32_t nextImageIndex, avifTileInfo * info)
+{
+    const unsigned int oldDecodedTileCount = info->decodedTileCount;
+    for (unsigned int tileIndex = oldDecodedTileCount; tileIndex < info->tileCount; ++tileIndex) {
+        avifTile * tile = &decoder->data->tiles.tile[info->firstTileIndex + tileIndex];
+
+        const avifDecodeSample * sample = &tile->input->samples.sample[nextImageIndex];
+        if (sample->data.size < sample->size) {
+            AVIF_ASSERT_OR_RETURN(decoder->allowIncremental);
+            // Data is missing but there is no error yet. Output available pixel rows.
+            return AVIF_RESULT_OK;
+        }
+
+        avifBool isLimitedRangeAlpha = AVIF_FALSE;
+        tile->codec->maxThreads = decoder->maxThreads;
+        tile->codec->imageSizeLimit = decoder->imageSizeLimit;
+        if (!tile->codec->getNextImage(tile->codec, sample, avifIsAlpha(tile->input->itemCategory), &isLimitedRangeAlpha, tile->image)) {
+            avifDiagnosticsPrintf(&decoder->diag, "tile->codec->getNextImage() failed");
+            return avifGetErrorForItemCategory(tile->input->itemCategory);
+        }
+
+        // Section 2.3.4 of AV1 Codec ISO Media File Format Binding v1.2.0 says:
+        //   the full_range_flag in the colr box shall match the color_range
+        //   flag in the Sequence Header OBU.
+        // See https://aomediacodec.github.io/av1-isobmff/v1.2.0.html#av1codecconfigurationbox-semantics.
+        // If a 'colr' box of colour_type 'nclx' was parsed, a mismatch between
+        // the 'colr' decoder->image->yuvRange and the AV1 OBU
+        // tile->image->yuvRange should be treated as an error.
+        // However codec_svt.c was not encoding the color_range field for
+        // multiple years, so there probably are files in the wild that will
+        // fail decoding if this is enforced. Thus this pattern is allowed.
+        // Section 12.1.5.1 of ISO 14496-12 (ISOBMFF) says:
+        //   If colour information is supplied in both this [colr] box, and also
+        //   in the video bitstream, this box takes precedence, and over-rides
+        //   the information in the bitstream.
+        // So decoder->image->yuvRange is kept because it was either the 'colr'
+        // value set when the 'colr' box was parsed, or it was the AV1 OBU value
+        // extracted from the sequence header OBU of the first tile of the first
+        // frame (if no 'colr' box of colour_type 'nclx' was found).
+
+        // Alpha plane with limited range is not allowed by the latest revision
+        // of the specification. However, it was allowed in version 1.0.0 of the
+        // specification. To allow such files, simply convert the alpha plane to
+        // full range.
+        if (avifIsAlpha(tile->input->itemCategory) && isLimitedRangeAlpha) {
+            avifResult result = avifImageLimitedToFullAlpha(tile->image);
+            if (result != AVIF_RESULT_OK) {
+                avifDiagnosticsPrintf(&decoder->diag, "avifImageLimitedToFullAlpha failed");
+                return result;
+            }
+        }
+
+        // Scale the decoded image so that it corresponds to this tile's output dimensions
+        if ((tile->width != tile->image->width) || (tile->height != tile->image->height)) {
+            if (avifImageScaleWithLimit(tile->image,
+                                        tile->width,
+                                        tile->height,
+                                        decoder->imageSizeLimit,
+                                        decoder->imageDimensionLimit,
+                                        &decoder->diag) != AVIF_RESULT_OK) {
+                return avifGetErrorForItemCategory(tile->input->itemCategory);
+            }
+        }
+
+#if defined(AVIF_CODEC_AVM)
+        avifDecoderItem * tileItem = NULL;
+        for (uint32_t itemIndex = 0; itemIndex < decoder->data->meta->items.count; ++itemIndex) {
+            avifDecoderItem * item = decoder->data->meta->items.item[itemIndex];
+            if (avifDecoderItemShouldBeSkipped(item)) {
+                continue;
+            }
+            if (item->id == sample->itemID) {
+                tileItem = item;
+                break;
+            }
+        }
+        if (tileItem != NULL) {
+            const avifProperty * prop = avifPropertyArrayFind(&tileItem->properties, "pixi");
+            // Match the decoded image format with the number of planes specified in 'pixi'.
+            if (prop != NULL && prop->u.pixi.planeCount == 1 && tile->image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420) {
+                // Codecs such as avm do not support monochrome so samples were encoded as 4:2:0.
+                // Ignore the UV planes at decoding.
+                tile->image->yuvFormat = AVIF_PIXEL_FORMAT_YUV400;
+                if (tile->image->imageOwnsYUVPlanes) {
+                    avifFree(tile->image->yuvPlanes[AVIF_CHAN_U]);
+                    avifFree(tile->image->yuvPlanes[AVIF_CHAN_V]);
+                }
+                tile->image->yuvPlanes[AVIF_CHAN_U] = NULL;
+                tile->image->yuvRowBytes[AVIF_CHAN_U] = 0;
+                tile->image->yuvPlanes[AVIF_CHAN_V] = NULL;
+                tile->image->yuvRowBytes[AVIF_CHAN_V] = 0;
+            }
+        }
+#endif
+
+        ++info->decodedTileCount;
+
+        const avifBool isGrid = (info->grid.rows > 0) && (info->grid.columns > 0);
+        avifBool stealPlanes = !isGrid;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        if (decoder->data->meta->sampleTransformExpression.count > 0) {
+            // Keep everything as a copy for now.
+            stealPlanes = AVIF_FALSE;
+        }
+        if (tile->input->itemCategory >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY &&
+            tile->input->itemCategory <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY) {
+            // Keep Sample Transform input image item samples in tiles.
+            // The expression will be applied in avifDecoderNextImage() below instead, once all the tiles are available.
+            continue;
+        }
+#endif
+
+        if (!stealPlanes) {
+            avifImage * dstImage = decoder->image;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            if (tile->input->itemCategory == AVIF_ITEM_GAIN_MAP) {
+                AVIF_ASSERT_OR_RETURN(dstImage->gainMap && dstImage->gainMap->image);
+                dstImage = dstImage->gainMap->image;
+            }
+#endif
+            if (tileIndex == 0) {
+                AVIF_CHECKRES(avifDecoderDataAllocateImagePlanes(decoder->data, info, dstImage));
+            }
+            AVIF_CHECKRES(avifDecoderDataCopyTileToImage(decoder->data, info, dstImage, tile, tileIndex));
+        } else {
+            AVIF_ASSERT_OR_RETURN(info->tileCount == 1);
+            AVIF_ASSERT_OR_RETURN(tileIndex == 0);
+            avifImage * src = tile->image;
+
+            switch (tile->input->itemCategory) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+                case AVIF_ITEM_GAIN_MAP:
+                    AVIF_ASSERT_OR_RETURN(decoder->image->gainMap && decoder->image->gainMap->image);
+                    decoder->image->gainMap->image->width = src->width;
+                    decoder->image->gainMap->image->height = src->height;
+                    decoder->image->gainMap->image->depth = src->depth;
+                    break;
+#endif
+                default:
+                    if ((decoder->image->width != src->width) || (decoder->image->height != src->height) ||
+                        (decoder->image->depth != src->depth)) {
+                        if (avifIsAlpha(tile->input->itemCategory)) {
+                            avifDiagnosticsPrintf(&decoder->diag,
+                                                  "The color image item does not match the alpha image item in width, height, or bit depth");
+                            return AVIF_RESULT_DECODE_ALPHA_FAILED;
+                        }
+                        avifImageFreePlanes(decoder->image, AVIF_PLANES_ALL);
+
+                        decoder->image->width = src->width;
+                        decoder->image->height = src->height;
+                        decoder->image->depth = src->depth;
+                    }
+                    break;
+            }
+
+            if (avifIsAlpha(tile->input->itemCategory)) {
+                avifImageStealPlanes(decoder->image, src, AVIF_PLANES_A);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            } else if (tile->input->itemCategory == AVIF_ITEM_GAIN_MAP) {
+                AVIF_ASSERT_OR_RETURN(decoder->image->gainMap && decoder->image->gainMap->image);
+                avifImageStealPlanes(decoder->image->gainMap->image, src, AVIF_PLANES_YUV);
+#endif
+            } else { // AVIF_ITEM_COLOR
+                avifImageStealPlanes(decoder->image, src, AVIF_PLANES_YUV);
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Returns AVIF_FALSE if there is currently a partially decoded frame.
+static avifBool avifDecoderDataFrameFullyDecoded(const avifDecoderData * data)
+{
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        if (data->tileInfos[c].decodedTileCount != data->tileInfos[c].tileCount) {
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+static avifResult avifDecoderApplySampleTransform(const avifDecoder * decoder, avifImage * dstImage)
+{
+    if (dstImage->depth != decoder->data->meta->sampleTransformDepth) {
+        AVIF_ASSERT_OR_RETURN(dstImage->yuvPlanes[0] != NULL);
+        AVIF_ASSERT_OR_RETURN(dstImage->imageOwnsYUVPlanes);
+
+        // Use a temporary buffer because dstImage may point to decoder->image, which could be an input image.
+        avifImage * dstImageWithCorrectDepth =
+            avifImageCreate(dstImage->width, dstImage->height, decoder->data->meta->sampleTransformDepth, dstImage->yuvFormat);
+        AVIF_CHECKERR(dstImageWithCorrectDepth != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        avifResult result =
+            avifImageAllocatePlanes(dstImageWithCorrectDepth, dstImage->alphaPlane != NULL ? AVIF_PLANES_ALL : AVIF_PLANES_YUV);
+        if (result == AVIF_RESULT_OK) {
+            result = avifDecoderApplySampleTransform(decoder, dstImageWithCorrectDepth);
+            if (result == AVIF_RESULT_OK) {
+                // Keep the same dstImage object rather than swapping decoder->image, in case the user already accessed it.
+                avifImageFreePlanes(dstImage, AVIF_PLANES_ALL);
+                dstImage->depth = dstImageWithCorrectDepth->depth;
+                avifImageStealPlanes(dstImage, dstImageWithCorrectDepth, AVIF_PLANES_ALL);
+            }
+        }
+        avifImageDestroy(dstImageWithCorrectDepth);
+        return result;
+    }
+
+    for (avifBool alpha = AVIF_FALSE; alpha <= decoder->alphaPresent ? AVIF_TRUE : AVIF_FALSE; ++alpha) {
+        AVIF_ASSERT_OR_RETURN(decoder->data->sampleTransformNumInputImageItems <= AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS);
+        const avifImage * inputImages[AVIF_SAMPLE_TRANSFORM_MAX_NUM_INPUT_IMAGE_ITEMS];
+        for (uint32_t i = 0; i < decoder->data->sampleTransformNumInputImageItems; ++i) {
+            avifItemCategory category = decoder->data->sampleTransformInputImageItems[i];
+            if (category == AVIF_ITEM_COLOR) {
+                inputImages[i] = decoder->image;
+            } else {
+                AVIF_ASSERT_OR_RETURN(category >= AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR &&
+                                      category < AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR +
+                                                     AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS);
+                if (alpha) {
+                    category += AVIF_SAMPLE_TRANSFORM_MAX_NUM_EXTRA_INPUT_IMAGE_ITEMS;
+                }
+                const avifTileInfo * tileInfo = &decoder->data->tileInfos[category];
+                AVIF_CHECKERR(tileInfo->tileCount == 1, AVIF_RESULT_NOT_IMPLEMENTED); // TODO(yguyon): Implement Sample Transform grids
+                inputImages[i] = decoder->data->tiles.tile[tileInfo->firstTileIndex].image;
+                AVIF_ASSERT_OR_RETURN(inputImages[i] != NULL);
+            }
+        }
+        AVIF_CHECKRES(avifImageApplyExpression(dstImage,
+                                               AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32,
+                                               &decoder->data->meta->sampleTransformExpression,
+                                               decoder->data->sampleTransformNumInputImageItems,
+                                               inputImages,
+                                               alpha ? AVIF_PLANES_A : AVIF_PLANES_YUV));
+    }
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+avifResult avifDecoderNextImage(avifDecoder * decoder)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+
+    if (!decoder->data || decoder->data->tiles.count == 0) {
+        // Nothing has been parsed yet
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    if (!decoder->io || !decoder->io->read) {
+        return AVIF_RESULT_IO_NOT_SET;
+    }
+
+    if (avifDecoderDataFrameFullyDecoded(decoder->data)) {
+        // A frame was decoded during the last avifDecoderNextImage() call.
+        for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+            decoder->data->tileInfos[c].decodedTileCount = 0;
+        }
+    }
+
+    AVIF_ASSERT_OR_RETURN(decoder->data->tiles.count == (decoder->data->tileInfos[AVIF_ITEM_CATEGORY_COUNT - 1].firstTileIndex +
+                                                         decoder->data->tileInfos[AVIF_ITEM_CATEGORY_COUNT - 1].tileCount));
+
+    const uint32_t nextImageIndex = (uint32_t)(decoder->imageIndex + 1);
+
+    // Ensure that we have created the codecs before proceeding with the decoding.
+    if (!decoder->data->tiles.tile[0].codec) {
+        AVIF_CHECKRES(avifDecoderCreateCodecs(decoder));
+    }
+
+    // Acquire all sample data for the current image first, allowing for any read call to bail out
+    // with AVIF_RESULT_WAITING_ON_IO harmlessly / idempotently, unless decoder->allowIncremental.
+    avifResult prepareTileResult[AVIF_ITEM_CATEGORY_COUNT];
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        prepareTileResult[c] = avifDecoderPrepareTiles(decoder, nextImageIndex, &decoder->data->tileInfos[c]);
+        if (!decoder->allowIncremental || (prepareTileResult[c] != AVIF_RESULT_WAITING_ON_IO)) {
+            AVIF_CHECKRES(prepareTileResult[c]);
+        }
+    }
+
+    // Decode all available color tiles now, then all available alpha tiles, then all available bit
+    // depth extension tiles. The order of appearance of the tiles in the bitstream is left to the
+    // encoder's choice, and decoding as many as possible of each category in parallel is beneficial
+    // for incremental decoding, as pixel rows need all channels to be decoded before being
+    // accessible to the user.
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        AVIF_CHECKRES(avifDecoderDecodeTiles(decoder, nextImageIndex, &decoder->data->tileInfos[c]));
+    }
+
+    if (!avifDecoderDataFrameFullyDecoded(decoder->data)) {
+        AVIF_ASSERT_OR_RETURN(decoder->allowIncremental);
+        // The image is not completely decoded. There should be no error unrelated to missing bytes,
+        // and at least some missing bytes.
+        avifResult firstNonOkResult = AVIF_RESULT_OK;
+        for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+            AVIF_ASSERT_OR_RETURN(prepareTileResult[c] == AVIF_RESULT_OK || prepareTileResult[c] == AVIF_RESULT_WAITING_ON_IO);
+            if (firstNonOkResult == AVIF_RESULT_OK) {
+                firstNonOkResult = prepareTileResult[c];
+            }
+        }
+        AVIF_ASSERT_OR_RETURN(firstNonOkResult != AVIF_RESULT_OK);
+        // Return the "not enough bytes" status now instead of moving on to the next frame.
+        return AVIF_RESULT_WAITING_ON_IO;
+    }
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+        AVIF_ASSERT_OR_RETURN(prepareTileResult[c] == AVIF_RESULT_OK);
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (decoder->data->meta->sampleTransformExpression.count > 0) {
+        // TODO(yguyon): Add a field in avifDecoder and only perform sample transformations upon request.
+        AVIF_CHECKRES(avifDecoderApplySampleTransform(decoder, decoder->image));
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+    // Only advance decoder->imageIndex once the image is completely decoded, so that
+    // avifDecoderNthImage(decoder, decoder->imageIndex + 1) is equivalent to avifDecoderNextImage(decoder)
+    // if the previous call to avifDecoderNextImage() returned AVIF_RESULT_WAITING_ON_IO.
+    decoder->imageIndex = (int)nextImageIndex;
+    // The decoded tile counts will be reset to 0 the next time avifDecoderNextImage() is called,
+    // for avifDecoderDecodedRowCount() to work until then.
+    if (decoder->data->sourceSampleTable) {
+        // Decoding from a track! Provide timing information.
+
+        avifResult timingResult = avifDecoderNthImageTiming(decoder, decoder->imageIndex, &decoder->imageTiming);
+        if (timingResult != AVIF_RESULT_OK) {
+            return timingResult;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifDecoderNthImageTiming(const avifDecoder * decoder, uint32_t frameIndex, avifImageTiming * outTiming)
+{
+    if (!decoder->data) {
+        // Nothing has been parsed yet
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    if ((frameIndex > INT_MAX) || ((int)frameIndex >= decoder->imageCount)) {
+        // Impossible index
+        return AVIF_RESULT_NO_IMAGES_REMAINING;
+    }
+
+    if (!decoder->data->sourceSampleTable) {
+        // There isn't any real timing associated with this decode, so
+        // just hand back the defaults chosen in avifDecoderReset().
+        *outTiming = decoder->imageTiming;
+        return AVIF_RESULT_OK;
+    }
+
+    outTiming->timescale = decoder->timescale;
+    outTiming->ptsInTimescales = 0;
+    for (uint32_t imageIndex = 0; imageIndex < frameIndex; ++imageIndex) {
+        outTiming->ptsInTimescales += avifSampleTableGetImageDelta(decoder->data->sourceSampleTable, imageIndex);
+    }
+    outTiming->durationInTimescales = avifSampleTableGetImageDelta(decoder->data->sourceSampleTable, frameIndex);
+
+    if (outTiming->timescale > 0) {
+        outTiming->pts = (double)outTiming->ptsInTimescales / (double)outTiming->timescale;
+        outTiming->duration = (double)outTiming->durationInTimescales / (double)outTiming->timescale;
+    } else {
+        outTiming->pts = 0.0;
+        outTiming->duration = 0.0;
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifDecoderNthImage(avifDecoder * decoder, uint32_t frameIndex)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+
+    if (!decoder->data) {
+        // Nothing has been parsed yet
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    if ((frameIndex > INT_MAX) || ((int)frameIndex >= decoder->imageCount)) {
+        // Impossible index
+        return AVIF_RESULT_NO_IMAGES_REMAINING;
+    }
+
+    int requestedIndex = (int)frameIndex;
+    if (requestedIndex == (decoder->imageIndex + 1)) {
+        // It's just the next image (already partially decoded or not at all), nothing special here
+        return avifDecoderNextImage(decoder);
+    }
+
+    if (requestedIndex == decoder->imageIndex) {
+        if (avifDecoderDataFrameFullyDecoded(decoder->data)) {
+            // The current fully decoded image (decoder->imageIndex) is requested, nothing to do
+            return AVIF_RESULT_OK;
+        }
+        // The next image (decoder->imageIndex + 1) is partially decoded but
+        // the previous image (decoder->imageIndex) is requested.
+        // Fall through to resetting the decoder data and start decoding from
+        // the nearest key frame.
+    }
+
+    int nearestKeyFrame = (int)avifDecoderNearestKeyframe(decoder, frameIndex);
+    if ((nearestKeyFrame > (decoder->imageIndex + 1)) || (requestedIndex <= decoder->imageIndex)) {
+        // If we get here, we need to start decoding from the nearest key frame.
+        // So discard the unused decoder state and its previous frames. This
+        // will force the setup of new AV1 decoder (avifCodec) instances in
+        // avifDecoderNextImage().
+        decoder->imageIndex = nearestKeyFrame - 1; // prepare to read nearest keyframe
+        avifDecoderDataResetCodec(decoder->data);
+    }
+    for (;;) {
+        avifResult result = avifDecoderNextImage(decoder);
+        if (result != AVIF_RESULT_OK) {
+            return result;
+        }
+
+        if (requestedIndex == decoder->imageIndex) {
+            break;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifBool avifDecoderIsKeyframe(const avifDecoder * decoder, uint32_t frameIndex)
+{
+    if (!decoder->data || (decoder->data->tiles.count == 0)) {
+        // Nothing has been parsed yet
+        return AVIF_FALSE;
+    }
+
+    // *All* tiles for the requested frameIndex must be keyframes in order for
+    //  avifDecoderIsKeyframe() to return true, otherwise we may seek to a frame in which the color
+    //  planes are a keyframe but the alpha plane isn't a keyframe, which will cause an alpha plane
+    //  decode failure.
+    for (unsigned int i = 0; i < decoder->data->tiles.count; ++i) {
+        const avifTile * tile = &decoder->data->tiles.tile[i];
+        if ((frameIndex >= tile->input->samples.count) || !tile->input->samples.sample[frameIndex].sync) {
+            return AVIF_FALSE;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+uint32_t avifDecoderNearestKeyframe(const avifDecoder * decoder, uint32_t frameIndex)
+{
+    if (!decoder->data) {
+        // Nothing has been parsed yet
+        return 0;
+    }
+
+    for (; frameIndex != 0; --frameIndex) {
+        if (avifDecoderIsKeyframe(decoder, frameIndex)) {
+            break;
+        }
+    }
+    return frameIndex;
+}
+
+// Returns the number of available rows in decoder->image given a color or alpha subimage.
+static uint32_t avifGetDecodedRowCount(const avifDecoder * decoder, const avifTileInfo * info, const avifImage * image)
+{
+    if (info->decodedTileCount == info->tileCount) {
+        return image->height;
+    }
+    if (info->decodedTileCount == 0) {
+        return 0;
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (decoder->data->meta->sampleTransformExpression.count > 0) {
+        // TODO(yguyon): Support incremental Sample Transforms
+        return 0;
+    }
+#endif
+
+    if ((info->grid.rows > 0) && (info->grid.columns > 0)) {
+        // Grid of AVIF tiles (not to be confused with AV1 tiles).
+        const uint32_t tileHeight = decoder->data->tiles.tile[info->firstTileIndex].height;
+        return AVIF_MIN((info->decodedTileCount / info->grid.columns) * tileHeight, image->height);
+    } else {
+        // Non-grid image.
+        return image->height;
+    }
+}
+
+uint32_t avifDecoderDecodedRowCount(const avifDecoder * decoder)
+{
+    uint32_t minRowCount = decoder->image->height;
+    for (int c = 0; c < AVIF_ITEM_CATEGORY_COUNT; ++c) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (c == AVIF_ITEM_GAIN_MAP) {
+            const avifImage * const gainMap = decoder->image->gainMap ? decoder->image->gainMap->image : NULL;
+            if ((decoder->imageContentToDecode & AVIF_IMAGE_CONTENT_GAIN_MAP) && gainMap != NULL && gainMap->height != 0) {
+                uint32_t gainMapRowCount = avifGetDecodedRowCount(decoder, &decoder->data->tileInfos[AVIF_ITEM_GAIN_MAP], gainMap);
+                if (gainMap->height != decoder->image->height) {
+                    const uint32_t scaledGainMapRowCount =
+                        (uint32_t)floorf((float)gainMapRowCount / gainMap->height * decoder->image->height);
+                    // Make sure it matches the formula described in the comment of avifDecoderDecodedRowCount() in avif.h.
+                    AVIF_CHECKERR((uint32_t)lround((double)scaledGainMapRowCount / decoder->image->height *
+                                                   decoder->image->gainMap->image->height) <= gainMapRowCount,
+                                  0);
+                    gainMapRowCount = scaledGainMapRowCount;
+                }
+                minRowCount = AVIF_MIN(minRowCount, gainMapRowCount);
+            }
+            continue;
+        }
+#endif
+        const uint32_t rowCount = avifGetDecodedRowCount(decoder, &decoder->data->tileInfos[c], decoder->image);
+        minRowCount = AVIF_MIN(minRowCount, rowCount);
+    }
+    return minRowCount;
+}
+
+avifResult avifDecoderRead(avifDecoder * decoder, avifImage * image)
+{
+    avifResult result = avifDecoderParse(decoder);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    result = avifDecoderNextImage(decoder);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    // If decoder->image->imageOwnsYUVPlanes is true and decoder->image is not used after this call,
+    // the ownership of the planes in decoder->image could be transferred here instead of copied.
+    // However most codec_*.c implementations allocate the output buffer themselves and return a
+    // view, unless some postprocessing is applied (container-level grid reconstruction for
+    // example), so the first condition rarely holds.
+    // The second condition does not hold either: it is not required by the documentation in avif.h.
+    return avifImageCopy(image, decoder->image, AVIF_PLANES_ALL);
+}
+
+avifResult avifDecoderReadMemory(avifDecoder * decoder, avifImage * image, const uint8_t * data, size_t size)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+    avifResult result = avifDecoderSetIOMemory(decoder, data, size);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    return avifDecoderRead(decoder, image);
+}
+
+avifResult avifDecoderReadFile(avifDecoder * decoder, avifImage * image, const char * filename)
+{
+    avifDiagnosticsClearError(&decoder->diag);
+    avifResult result = avifDecoderSetIOFile(decoder, filename);
+    if (result != AVIF_RESULT_OK) {
+        return result;
+    }
+    return avifDecoderRead(decoder, image);
+}
diff --git a/third_party/libavif/src/src/reformat.c b/third_party/libavif/src/src/reformat.c
new file mode 100644
index 0000000000..3a34d5fb59
--- /dev/null
+++ b/third_party/libavif/src/src/reformat.c
@@ -0,0 +1,1822 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <stdint.h>
+#include <string.h>
+
+#if defined(_WIN32)
+#include <process.h>
+#include <windows.h>
+#else
+#include <pthread.h>
+#endif
+
+struct YUVBlock
+{
+    float y;
+    float u;
+    float v;
+};
+
+avifBool avifGetRGBColorSpaceInfo(const avifRGBImage * rgb, avifRGBColorSpaceInfo * info)
+{
+    AVIF_CHECK(rgb->depth == 8 || rgb->depth == 10 || rgb->depth == 12 || rgb->depth == 16);
+    if (rgb->isFloat) {
+        AVIF_CHECK(rgb->depth == 16);
+    }
+    if (rgb->format == AVIF_RGB_FORMAT_RGB_565) {
+        AVIF_CHECK(rgb->depth == 8);
+    }
+    // Cast to silence "comparison of unsigned expression is always true" warning.
+    AVIF_CHECK((int)rgb->format >= AVIF_RGB_FORMAT_RGB && rgb->format < AVIF_RGB_FORMAT_COUNT);
+
+    info->channelBytes = (rgb->depth > 8) ? 2 : 1;
+    info->pixelBytes = avifRGBImagePixelSize(rgb);
+
+    switch (rgb->format) {
+        case AVIF_RGB_FORMAT_RGB:
+            info->offsetBytesR = info->channelBytes * 0;
+            info->offsetBytesG = info->channelBytes * 1;
+            info->offsetBytesB = info->channelBytes * 2;
+            info->offsetBytesA = 0;
+            break;
+        case AVIF_RGB_FORMAT_RGBA:
+            info->offsetBytesR = info->channelBytes * 0;
+            info->offsetBytesG = info->channelBytes * 1;
+            info->offsetBytesB = info->channelBytes * 2;
+            info->offsetBytesA = info->channelBytes * 3;
+            break;
+        case AVIF_RGB_FORMAT_ARGB:
+            info->offsetBytesA = info->channelBytes * 0;
+            info->offsetBytesR = info->channelBytes * 1;
+            info->offsetBytesG = info->channelBytes * 2;
+            info->offsetBytesB = info->channelBytes * 3;
+            break;
+        case AVIF_RGB_FORMAT_BGR:
+            info->offsetBytesB = info->channelBytes * 0;
+            info->offsetBytesG = info->channelBytes * 1;
+            info->offsetBytesR = info->channelBytes * 2;
+            info->offsetBytesA = 0;
+            break;
+        case AVIF_RGB_FORMAT_BGRA:
+            info->offsetBytesB = info->channelBytes * 0;
+            info->offsetBytesG = info->channelBytes * 1;
+            info->offsetBytesR = info->channelBytes * 2;
+            info->offsetBytesA = info->channelBytes * 3;
+            break;
+        case AVIF_RGB_FORMAT_ABGR:
+            info->offsetBytesA = info->channelBytes * 0;
+            info->offsetBytesB = info->channelBytes * 1;
+            info->offsetBytesG = info->channelBytes * 2;
+            info->offsetBytesR = info->channelBytes * 3;
+            break;
+        case AVIF_RGB_FORMAT_RGB_565:
+            // Since RGB_565 consists of two bytes per RGB pixel, we simply use
+            // the pointer to the red channel to populate the entire pixel value
+            // as a uint16_t. As a result only offsetBytesR is used and the
+            // other offsets are unused.
+            info->offsetBytesR = 0;
+            info->offsetBytesG = 0;
+            info->offsetBytesB = 0;
+            info->offsetBytesA = 0;
+            break;
+
+        case AVIF_RGB_FORMAT_COUNT:
+            return AVIF_FALSE;
+    }
+
+    info->maxChannel = (1 << rgb->depth) - 1;
+    info->maxChannelF = (float)info->maxChannel;
+
+    return AVIF_TRUE;
+}
+
+avifBool avifGetYUVColorSpaceInfo(const avifImage * image, avifYUVColorSpaceInfo * info)
+{
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    const avifBool useYCgCo = (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE) ||
+                              (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO);
+#endif
+
+    AVIF_CHECK(image->depth == 8 || image->depth == 10 || image->depth == 12 || image->depth == 16);
+    AVIF_CHECK(image->yuvFormat >= AVIF_PIXEL_FORMAT_YUV444 && image->yuvFormat < AVIF_PIXEL_FORMAT_COUNT);
+    AVIF_CHECK(image->yuvRange == AVIF_RANGE_LIMITED || image->yuvRange == AVIF_RANGE_FULL);
+
+    // These matrix coefficients values are currently unsupported. Revise this list as more support is added.
+    //
+    // YCgCo performs limited-full range adjustment on R,G,B but the current implementation performs range adjustment
+    // on Y,U,V. So YCgCo with limited range is unsupported.
+    if ((image->matrixCoefficients == 3 /* CICP reserved */) ||
+        ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+          || useYCgCo
+#endif
+          ) &&
+         (image->yuvRange == AVIF_RANGE_LIMITED)) ||
+        (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_BT2020_CL) ||
+        (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_SMPTE2085) ||
+        (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL) ||
+        (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_ICTCP) || (image->matrixCoefficients >= AVIF_MATRIX_COEFFICIENTS_LAST)) {
+        return AVIF_FALSE;
+    }
+
+    if ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) && (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV444) &&
+        (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV400)) {
+        return AVIF_FALSE;
+    }
+
+    avifGetPixelFormatInfo(image->yuvFormat, &info->formatInfo);
+    avifCalcYUVCoefficients(image, &info->kr, &info->kg, &info->kb);
+
+    info->channelBytes = (image->depth > 8) ? 2 : 1;
+
+    info->depth = image->depth;
+    info->range = image->yuvRange;
+    info->maxChannel = (1 << image->depth) - 1;
+    info->biasY = (info->range == AVIF_RANGE_LIMITED) ? (float)(16 << (info->depth - 8)) : 0.0f;
+    info->biasUV = (float)(1 << (info->depth - 1));
+    info->rangeY = (float)((info->range == AVIF_RANGE_LIMITED) ? (219 << (info->depth - 8)) : info->maxChannel);
+    info->rangeUV = (float)((info->range == AVIF_RANGE_LIMITED) ? (224 << (info->depth - 8)) : info->maxChannel);
+
+    return AVIF_TRUE;
+}
+
+static avifBool avifPrepareReformatState(const avifImage * image, const avifRGBImage * rgb, avifReformatState * state)
+{
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    const avifBool useYCgCoRe = (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RE);
+    const avifBool useYCgCoRo = (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO_RO);
+    if (useYCgCoRe || useYCgCoRo) {
+        const int bitOffset = (useYCgCoRe) ? 2 : 1;
+        if (image->depth - bitOffset != rgb->depth) {
+            return AVIF_FALSE;
+        }
+    }
+#endif
+
+    AVIF_CHECK(avifGetRGBColorSpaceInfo(rgb, &state->rgb));
+    AVIF_CHECK(avifGetYUVColorSpaceInfo(image, &state->yuv));
+
+    state->yuv.mode = AVIF_REFORMAT_MODE_YUV_COEFFICIENTS;
+
+    if (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY) {
+        state->yuv.mode = AVIF_REFORMAT_MODE_IDENTITY;
+    } else if (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_YCGCO) {
+        state->yuv.mode = AVIF_REFORMAT_MODE_YCGCO;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    } else if (useYCgCoRe) {
+        state->yuv.mode = AVIF_REFORMAT_MODE_YCGCO_RE;
+    } else if (useYCgCoRo) {
+        state->yuv.mode = AVIF_REFORMAT_MODE_YCGCO_RO;
+#endif
+    }
+
+    if (state->yuv.mode != AVIF_REFORMAT_MODE_YUV_COEFFICIENTS) {
+        state->yuv.kr = 0.0f;
+        state->yuv.kg = 0.0f;
+        state->yuv.kb = 0.0f;
+    }
+
+    return AVIF_TRUE;
+}
+
+// Formulas 20-31 from https://www.itu.int/rec/T-REC-H.273-201612-S
+static int avifYUVColorSpaceInfoYToUNorm(avifYUVColorSpaceInfo * info, float v)
+{
+    int unorm = (int)avifRoundf(v * info->rangeY + info->biasY);
+    return AVIF_CLAMP(unorm, 0, info->maxChannel);
+}
+
+static int avifYUVColorSpaceInfoUVToUNorm(avifYUVColorSpaceInfo * info, float v)
+{
+    int unorm;
+
+    // YCgCo performs limited-full range adjustment on R,G,B but the current implementation performs range adjustment
+    // on Y,U,V. So YCgCo with limited range is unsupported.
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+    assert((info->mode != AVIF_REFORMAT_MODE_YCGCO && info->mode != AVIF_REFORMAT_MODE_YCGCO_RE && info->mode != AVIF_REFORMAT_MODE_YCGCO_RO) ||
+           (info->range == AVIF_RANGE_FULL));
+#else
+    assert((info->mode != AVIF_REFORMAT_MODE_YCGCO) || (info->range == AVIF_RANGE_FULL));
+#endif
+
+    if (info->mode == AVIF_REFORMAT_MODE_IDENTITY) {
+        unorm = (int)avifRoundf(v * info->rangeY + info->biasY);
+    } else {
+        unorm = (int)avifRoundf(v * info->rangeUV + info->biasUV);
+    }
+
+    return AVIF_CLAMP(unorm, 0, info->maxChannel);
+}
+
+avifResult avifImageRGBToYUV(avifImage * image, const avifRGBImage * rgb)
+{
+    if (!rgb->pixels || rgb->format == AVIF_RGB_FORMAT_RGB_565) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    avifReformatState state;
+    if (!avifPrepareReformatState(image, rgb, &state)) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    if (rgb->isFloat) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    const avifBool hasAlpha = avifRGBFormatHasAlpha(rgb->format) && !rgb->ignoreAlpha;
+    avifResult allocationResult = avifImageAllocatePlanes(image, hasAlpha ? AVIF_PLANES_ALL : AVIF_PLANES_YUV);
+    if (allocationResult != AVIF_RESULT_OK) {
+        return allocationResult;
+    }
+
+    avifAlphaMultiplyMode alphaMode = AVIF_ALPHA_MULTIPLY_MODE_NO_OP;
+    if (hasAlpha) {
+        if (!rgb->alphaPremultiplied && image->alphaPremultiplied) {
+            alphaMode = AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY;
+        } else if (rgb->alphaPremultiplied && !image->alphaPremultiplied) {
+            alphaMode = AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY;
+        }
+    }
+
+    avifBool converted = AVIF_FALSE;
+
+    // Try converting with libsharpyuv.
+    if ((rgb->chromaDownsampling == AVIF_CHROMA_DOWNSAMPLING_SHARP_YUV) && (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420)) {
+        const avifResult libSharpYUVResult = avifImageRGBToYUVLibSharpYUV(image, rgb, &state);
+        if (libSharpYUVResult != AVIF_RESULT_OK) {
+            // Return the error if sharpyuv was requested but failed for any reason, including libsharpyuv not being available.
+            return libSharpYUVResult;
+        }
+        converted = AVIF_TRUE;
+    }
+
+    if (!converted && !rgb->avoidLibYUV && (alphaMode == AVIF_ALPHA_MULTIPLY_MODE_NO_OP)) {
+        avifResult libyuvResult = avifImageRGBToYUVLibYUV(image, rgb);
+        if (libyuvResult == AVIF_RESULT_OK) {
+            converted = AVIF_TRUE;
+        } else if (libyuvResult != AVIF_RESULT_NOT_IMPLEMENTED) {
+            return libyuvResult;
+        }
+    }
+
+    if (!converted) {
+        const float kr = state.yuv.kr;
+        const float kg = state.yuv.kg;
+        const float kb = state.yuv.kb;
+
+        struct YUVBlock yuvBlock[2][2];
+        float rgbPixel[3];
+        const uint32_t rgbPixelBytes = state.rgb.pixelBytes;
+        const uint32_t offsetBytesR = state.rgb.offsetBytesR;
+        const uint32_t offsetBytesG = state.rgb.offsetBytesG;
+        const uint32_t offsetBytesB = state.rgb.offsetBytesB;
+        const uint32_t offsetBytesA = state.rgb.offsetBytesA;
+        const uint32_t rgbRowBytes = rgb->rowBytes;
+        const float rgbMaxChannelF = state.rgb.maxChannelF;
+        uint8_t * yPlane = image->yuvPlanes[AVIF_CHAN_Y];
+        uint8_t * uPlane = image->yuvPlanes[AVIF_CHAN_U];
+        uint8_t * vPlane = image->yuvPlanes[AVIF_CHAN_V];
+        const uint32_t yRowBytes = image->yuvRowBytes[AVIF_CHAN_Y];
+        const uint32_t uRowBytes = image->yuvRowBytes[AVIF_CHAN_U];
+        const uint32_t vRowBytes = image->yuvRowBytes[AVIF_CHAN_V];
+        for (uint32_t outerJ = 0; outerJ < image->height; outerJ += 2) {
+            for (uint32_t outerI = 0; outerI < image->width; outerI += 2) {
+                int blockW = 2, blockH = 2;
+                if ((outerI + 1) >= image->width) {
+                    blockW = 1;
+                }
+                if ((outerJ + 1) >= image->height) {
+                    blockH = 1;
+                }
+
+                // Convert an entire 2x2 block to YUV, and populate any fully sampled channels as we go
+                for (int bJ = 0; bJ < blockH; ++bJ) {
+                    for (int bI = 0; bI < blockW; ++bI) {
+                        int i = outerI + bI;
+                        int j = outerJ + bJ;
+
+                        // Unpack RGB into normalized float
+                        if (state.rgb.channelBytes > 1) {
+                            rgbPixel[0] = *((uint16_t *)(&rgb->pixels[offsetBytesR + (i * rgbPixelBytes) + (j * rgbRowBytes)])) /
+                                          rgbMaxChannelF;
+                            rgbPixel[1] = *((uint16_t *)(&rgb->pixels[offsetBytesG + (i * rgbPixelBytes) + (j * rgbRowBytes)])) /
+                                          rgbMaxChannelF;
+                            rgbPixel[2] = *((uint16_t *)(&rgb->pixels[offsetBytesB + (i * rgbPixelBytes) + (j * rgbRowBytes)])) /
+                                          rgbMaxChannelF;
+                        } else {
+                            rgbPixel[0] = rgb->pixels[offsetBytesR + (i * rgbPixelBytes) + (j * rgbRowBytes)] / rgbMaxChannelF;
+                            rgbPixel[1] = rgb->pixels[offsetBytesG + (i * rgbPixelBytes) + (j * rgbRowBytes)] / rgbMaxChannelF;
+                            rgbPixel[2] = rgb->pixels[offsetBytesB + (i * rgbPixelBytes) + (j * rgbRowBytes)] / rgbMaxChannelF;
+                        }
+
+                        if (alphaMode != AVIF_ALPHA_MULTIPLY_MODE_NO_OP) {
+                            float a;
+                            if (state.rgb.channelBytes > 1) {
+                                a = *((uint16_t *)(&rgb->pixels[offsetBytesA + (i * rgbPixelBytes) + (j * rgbRowBytes)])) / rgbMaxChannelF;
+                            } else {
+                                a = rgb->pixels[offsetBytesA + (i * rgbPixelBytes) + (j * rgbRowBytes)] / rgbMaxChannelF;
+                            }
+
+                            if (alphaMode == AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY) {
+                                if (a == 0) {
+                                    rgbPixel[0] = 0;
+                                    rgbPixel[1] = 0;
+                                    rgbPixel[2] = 0;
+                                } else if (a < 1.0f) {
+                                    rgbPixel[0] *= a;
+                                    rgbPixel[1] *= a;
+                                    rgbPixel[2] *= a;
+                                }
+                            } else {
+                                // alphaMode == AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY
+                                if (a == 0) {
+                                    rgbPixel[0] = 0;
+                                    rgbPixel[1] = 0;
+                                    rgbPixel[2] = 0;
+                                } else if (a < 1.0f) {
+                                    rgbPixel[0] /= a;
+                                    rgbPixel[1] /= a;
+                                    rgbPixel[2] /= a;
+                                    rgbPixel[0] = AVIF_MIN(rgbPixel[0], 1.0f);
+                                    rgbPixel[1] = AVIF_MIN(rgbPixel[1], 1.0f);
+                                    rgbPixel[2] = AVIF_MIN(rgbPixel[2], 1.0f);
+                                }
+                            }
+                        }
+
+                        // RGB -> YUV conversion
+                        if (state.yuv.mode == AVIF_REFORMAT_MODE_IDENTITY) {
+                            // Formulas 41,42,43 from https://www.itu.int/rec/T-REC-H.273-201612-S
+                            yuvBlock[bI][bJ].y = rgbPixel[1]; // G
+                            yuvBlock[bI][bJ].u = rgbPixel[2]; // B
+                            yuvBlock[bI][bJ].v = rgbPixel[0]; // R
+                        } else if (state.yuv.mode == AVIF_REFORMAT_MODE_YCGCO) {
+                            // Formulas 44,45,46 from https://www.itu.int/rec/T-REC-H.273-201612-S
+                            yuvBlock[bI][bJ].y = 0.5f * rgbPixel[1] + 0.25f * (rgbPixel[0] + rgbPixel[2]);
+                            yuvBlock[bI][bJ].u = 0.5f * rgbPixel[1] - 0.25f * (rgbPixel[0] + rgbPixel[2]);
+                            yuvBlock[bI][bJ].v = 0.5f * (rgbPixel[0] - rgbPixel[2]);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                        } else if (state.yuv.mode == AVIF_REFORMAT_MODE_YCGCO_RE || state.yuv.mode == AVIF_REFORMAT_MODE_YCGCO_RO) {
+                            // Formulas 58,59,60,61 from https://www.itu.int/rec/T-REC-H.273-202407-P
+                            const int R = (int)avifRoundf(AVIF_CLAMP(rgbPixel[0] * rgbMaxChannelF, 0.0f, rgbMaxChannelF));
+                            const int G = (int)avifRoundf(AVIF_CLAMP(rgbPixel[1] * rgbMaxChannelF, 0.0f, rgbMaxChannelF));
+                            const int B = (int)avifRoundf(AVIF_CLAMP(rgbPixel[2] * rgbMaxChannelF, 0.0f, rgbMaxChannelF));
+                            const int Co = R - B;
+                            const int t = B + (Co >> 1);
+                            const int Cg = G - t;
+                            yuvBlock[bI][bJ].y = (t + (Cg >> 1)) / state.yuv.rangeY;
+                            yuvBlock[bI][bJ].u = Cg / state.yuv.rangeUV;
+                            yuvBlock[bI][bJ].v = Co / state.yuv.rangeUV;
+#endif
+                        } else {
+                            float Y = (kr * rgbPixel[0]) + (kg * rgbPixel[1]) + (kb * rgbPixel[2]);
+                            yuvBlock[bI][bJ].y = Y;
+                            yuvBlock[bI][bJ].u = (rgbPixel[2] - Y) / (2 * (1 - kb));
+                            yuvBlock[bI][bJ].v = (rgbPixel[0] - Y) / (2 * (1 - kr));
+                        }
+
+                        if (state.yuv.channelBytes > 1) {
+                            uint16_t * pY = (uint16_t *)&yPlane[(i * 2) + (j * yRowBytes)];
+                            *pY = (uint16_t)avifYUVColorSpaceInfoYToUNorm(&state.yuv, yuvBlock[bI][bJ].y);
+                            if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) {
+                                // YUV444, full chroma
+                                uint16_t * pU = (uint16_t *)&uPlane[(i * 2) + (j * uRowBytes)];
+                                *pU = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, yuvBlock[bI][bJ].u);
+                                uint16_t * pV = (uint16_t *)&vPlane[(i * 2) + (j * vRowBytes)];
+                                *pV = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, yuvBlock[bI][bJ].v);
+                            }
+                        } else {
+                            yPlane[i + (j * yRowBytes)] = (uint8_t)avifYUVColorSpaceInfoYToUNorm(&state.yuv, yuvBlock[bI][bJ].y);
+                            if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) {
+                                // YUV444, full chroma
+                                uPlane[i + (j * uRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, yuvBlock[bI][bJ].u);
+                                vPlane[i + (j * vRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, yuvBlock[bI][bJ].v);
+                            }
+                        }
+                    }
+                }
+
+                // Populate any subsampled channels with averages from the 2x2 block
+                if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+                    // Do nothing on chroma planes.
+                } else if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420) {
+                    // YUV420, average 4 samples (2x2)
+
+                    float sumU = 0.0f;
+                    float sumV = 0.0f;
+                    for (int bJ = 0; bJ < blockH; ++bJ) {
+                        for (int bI = 0; bI < blockW; ++bI) {
+                            sumU += yuvBlock[bI][bJ].u;
+                            sumV += yuvBlock[bI][bJ].v;
+                        }
+                    }
+                    float totalSamples = (float)(blockW * blockH);
+                    float avgU = sumU / totalSamples;
+                    float avgV = sumV / totalSamples;
+
+                    const int chromaShiftX = 1;
+                    const int chromaShiftY = 1;
+                    int uvI = outerI >> chromaShiftX;
+                    int uvJ = outerJ >> chromaShiftY;
+                    if (state.yuv.channelBytes > 1) {
+                        uint16_t * pU = (uint16_t *)&uPlane[(uvI * 2) + (uvJ * uRowBytes)];
+                        *pU = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgU);
+                        uint16_t * pV = (uint16_t *)&vPlane[(uvI * 2) + (uvJ * vRowBytes)];
+                        *pV = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgV);
+                    } else {
+                        uPlane[uvI + (uvJ * uRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgU);
+                        vPlane[uvI + (uvJ * vRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgV);
+                    }
+                } else if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV422) {
+                    // YUV422, average 2 samples (1x2), twice
+
+                    for (int bJ = 0; bJ < blockH; ++bJ) {
+                        float sumU = 0.0f;
+                        float sumV = 0.0f;
+                        for (int bI = 0; bI < blockW; ++bI) {
+                            sumU += yuvBlock[bI][bJ].u;
+                            sumV += yuvBlock[bI][bJ].v;
+                        }
+                        float totalSamples = (float)blockW;
+                        float avgU = sumU / totalSamples;
+                        float avgV = sumV / totalSamples;
+
+                        const int chromaShiftX = 1;
+                        int uvI = outerI >> chromaShiftX;
+                        int uvJ = outerJ + bJ;
+                        if (state.yuv.channelBytes > 1) {
+                            uint16_t * pU = (uint16_t *)&uPlane[(uvI * 2) + (uvJ * uRowBytes)];
+                            *pU = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgU);
+                            uint16_t * pV = (uint16_t *)&vPlane[(uvI * 2) + (uvJ * vRowBytes)];
+                            *pV = (uint16_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgV);
+                        } else {
+                            uPlane[uvI + (uvJ * uRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgU);
+                            vPlane[uvI + (uvJ * vRowBytes)] = (uint8_t)avifYUVColorSpaceInfoUVToUNorm(&state.yuv, avgV);
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    if (image->alphaPlane && image->alphaRowBytes) {
+        avifAlphaParams params;
+
+        params.width = image->width;
+        params.height = image->height;
+        params.dstDepth = image->depth;
+        params.dstPlane = image->alphaPlane;
+        params.dstRowBytes = image->alphaRowBytes;
+        params.dstOffsetBytes = 0;
+        params.dstPixelBytes = state.yuv.channelBytes;
+
+        if (avifRGBFormatHasAlpha(rgb->format) && !rgb->ignoreAlpha) {
+            params.srcDepth = rgb->depth;
+            params.srcPlane = rgb->pixels;
+            params.srcRowBytes = rgb->rowBytes;
+            params.srcOffsetBytes = state.rgb.offsetBytesA;
+            params.srcPixelBytes = state.rgb.pixelBytes;
+
+            avifReformatAlpha(&params);
+        } else {
+            // libyuv does not fill alpha when converting from RGB to YUV so
+            // fill it regardless of the value of convertedWithLibYUV.
+            avifFillAlpha(&params);
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Allocates and fills look-up tables for going from YUV limited/full unorm -> full range RGB FP32.
+// Review this when implementing YCgCo limited range support.
+static avifBool avifCreateYUVToRGBLookUpTables(float ** unormFloatTableY, float ** unormFloatTableUV, uint32_t depth, const avifReformatState * state)
+{
+    const size_t cpCount = (size_t)1 << depth;
+
+    assert(unormFloatTableY);
+    *unormFloatTableY = (float *)avifAlloc(cpCount * sizeof(float));
+    AVIF_CHECK(*unormFloatTableY);
+    for (uint32_t cp = 0; cp < cpCount; ++cp) {
+        (*unormFloatTableY)[cp] = ((float)cp - state->yuv.biasY) / state->yuv.rangeY;
+    }
+
+    if (unormFloatTableUV) {
+        if (state->yuv.mode == AVIF_REFORMAT_MODE_IDENTITY) {
+            // Just reuse the luma table since the chroma values are the same.
+            *unormFloatTableUV = *unormFloatTableY;
+        } else {
+            *unormFloatTableUV = (float *)avifAlloc(cpCount * sizeof(float));
+            if (!*unormFloatTableUV) {
+                avifFree(*unormFloatTableY);
+                *unormFloatTableY = NULL;
+                return AVIF_FALSE;
+            }
+            for (uint32_t cp = 0; cp < cpCount; ++cp) {
+                (*unormFloatTableUV)[cp] = ((float)cp - state->yuv.biasUV) / state->yuv.rangeUV;
+            }
+        }
+    }
+    return AVIF_TRUE;
+}
+
+// Frees look-up tables allocated with avifCreateYUVToRGBLookUpTables().
+static void avifFreeYUVToRGBLookUpTables(float ** unormFloatTableY, float ** unormFloatTableUV)
+{
+    if (unormFloatTableUV) {
+        if (*unormFloatTableUV != *unormFloatTableY) {
+            avifFree(*unormFloatTableUV);
+        }
+        *unormFloatTableUV = NULL;
+    }
+
+    avifFree(*unormFloatTableY);
+    *unormFloatTableY = NULL;
+}
+
+#define RGB565(R, G, B) ((uint16_t)(((B) >> 3) | (((G) >> 2) << 5) | (((R) >> 3) << 11)))
+
+static void avifStoreRGB8Pixel(avifRGBFormat format, uint8_t R, uint8_t G, uint8_t B, uint8_t * ptrR, uint8_t * ptrG, uint8_t * ptrB)
+{
+    if (format == AVIF_RGB_FORMAT_RGB_565) {
+        // References for RGB565 color conversion:
+        // * https://docs.microsoft.com/en-us/windows/win32/directshow/working-with-16-bit-rgb
+        // * https://chromium.googlesource.com/libyuv/libyuv/+/9892d70c965678381d2a70a1c9002d1cf136ee78/source/row_common.cc#2362
+        *(uint16_t *)ptrR = RGB565(R, G, B);
+        return;
+    }
+    *ptrR = R;
+    *ptrG = G;
+    *ptrB = B;
+}
+
+static void avifGetRGB565(const uint8_t * ptrR, uint8_t * R, uint8_t * G, uint8_t * B)
+{
+    // References for RGB565 color conversion:
+    // * https://docs.microsoft.com/en-us/windows/win32/directshow/working-with-16-bit-rgb
+    // * https://chromium.googlesource.com/libyuv/libyuv/+/331c361581896292fb46c8c6905e41262b7ca95f/source/row_common.cc#185
+    const uint16_t rgb656 = ((const uint16_t *)ptrR)[0];
+    const uint16_t r5 = (rgb656 & 0xF800) >> 11;
+    const uint16_t g6 = (rgb656 & 0x07E0) >> 5;
+    const uint16_t b5 = (rgb656 & 0x001F);
+    *R = (uint8_t)((r5 << 3) | (r5 >> 2));
+    *G = (uint8_t)((g6 << 2) | (g6 >> 4));
+    *B = (uint8_t)((b5 << 3) | (b5 >> 2));
+}
+
+// Note: This function handles alpha (un)multiply.
+static avifResult avifImageYUVAnyToRGBAnySlow(const avifImage * image,
+                                              avifRGBImage * rgb,
+                                              const avifReformatState * state,
+                                              avifAlphaMultiplyMode alphaMultiplyMode)
+{
+    // Aliases for some state
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    float * unormFloatTableY = NULL;
+    float * unormFloatTableUV = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+    const uint32_t yuvChannelBytes = state->yuv.channelBytes;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+
+    // Aliases for plane data
+    const uint8_t * yPlane = image->yuvPlanes[AVIF_CHAN_Y];
+    const uint8_t * uPlane = image->yuvPlanes[AVIF_CHAN_U];
+    const uint8_t * vPlane = image->yuvPlanes[AVIF_CHAN_V];
+    const uint8_t * aPlane = image->alphaPlane;
+    const uint32_t yRowBytes = image->yuvRowBytes[AVIF_CHAN_Y];
+    const uint32_t uRowBytes = image->yuvRowBytes[AVIF_CHAN_U];
+    const uint32_t vRowBytes = image->yuvRowBytes[AVIF_CHAN_V];
+    const uint32_t aRowBytes = image->alphaRowBytes;
+
+    // Various observations and limits
+    const avifBool hasColor = (uPlane && vPlane && (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV400));
+    const uint16_t yuvMaxChannel = (uint16_t)state->yuv.maxChannel;
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+
+    // If toRGBAlphaMode is active (not no-op), assert that the alpha plane is present. The end of
+    // the avifPrepareReformatState() function should ensure this, but this assert makes it clear
+    // to clang's analyzer.
+    assert((alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_NO_OP) || aPlane);
+
+    for (uint32_t j = 0; j < image->height; ++j) {
+        // uvJ is used only when hasColor is true.
+        const uint32_t uvJ = hasColor ? (j >> state->yuv.formatInfo.chromaShiftY) : 0;
+        const uint8_t * ptrY8 = &yPlane[j * yRowBytes];
+        const uint8_t * ptrU8 = uPlane ? &uPlane[(uvJ * uRowBytes)] : NULL;
+        const uint8_t * ptrV8 = vPlane ? &vPlane[(uvJ * vRowBytes)] : NULL;
+        const uint8_t * ptrA8 = aPlane ? &aPlane[j * aRowBytes] : NULL;
+        const uint16_t * ptrY16 = (const uint16_t *)ptrY8;
+        const uint16_t * ptrU16 = (const uint16_t *)ptrU8;
+        const uint16_t * ptrV16 = (const uint16_t *)ptrV8;
+        const uint16_t * ptrA16 = (const uint16_t *)ptrA8;
+
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            float Y, Cb = 0.5f, Cr = 0.5f;
+
+            // Calculate Y
+            uint16_t unormY;
+            if (image->depth == 8) {
+                unormY = ptrY8[i];
+            } else {
+                // clamp incoming data to protect against bad LUT lookups
+                unormY = AVIF_MIN(ptrY16[i], yuvMaxChannel);
+            }
+            Y = unormFloatTableY[unormY];
+
+            // Calculate Cb and Cr
+            if (hasColor) {
+                const uint32_t uvI = i >> state->yuv.formatInfo.chromaShiftX;
+                if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) {
+                    uint16_t unormU, unormV;
+
+                    if (image->depth == 8) {
+                        unormU = ptrU8[uvI];
+                        unormV = ptrV8[uvI];
+                    } else {
+                        // clamp incoming data to protect against bad LUT lookups
+                        unormU = AVIF_MIN(ptrU16[uvI], yuvMaxChannel);
+                        unormV = AVIF_MIN(ptrV16[uvI], yuvMaxChannel);
+                    }
+
+                    Cb = unormFloatTableUV[unormU];
+                    Cr = unormFloatTableUV[unormV];
+                } else {
+                    // Upsample to 444:
+                    //
+                    // *   *   *   *
+                    //   A       B
+                    // *   1   2   *
+                    //
+                    // *   3   4   *
+                    //   C       D
+                    // *   *   *   *
+                    //
+                    // When converting from YUV420 to RGB, for any given "high-resolution" RGB
+                    // coordinate (1,2,3,4,*), there are up to four "low-resolution" UV samples
+                    // (A,B,C,D) that are "nearest" to the pixel. For RGB pixel #1, A is the closest
+                    // UV sample, B and C are "adjacent" to it on the same row and column, and D is
+                    // the diagonal. For RGB pixel 3, C is the closest UV sample, A and D are
+                    // adjacent, and B is the diagonal. Sometimes the adjacent pixel on the same row
+                    // is to the left or right, and sometimes the adjacent pixel on the same column
+                    // is up or down. For any edge or corner, there might only be only one or two
+                    // samples nearby, so they'll be duplicated.
+                    //
+                    // The following code attempts to find all four nearest UV samples and put them
+                    // in the following unormU and unormV grid as follows:
+                    //
+                    // unorm[0][0] = closest         ( weights: bilinear: 9/16, nearest: 1 )
+                    // unorm[1][0] = adjacent col    ( weights: bilinear: 3/16, nearest: 0 )
+                    // unorm[0][1] = adjacent row    ( weights: bilinear: 3/16, nearest: 0 )
+                    // unorm[1][1] = diagonal        ( weights: bilinear: 1/16, nearest: 0 )
+                    //
+                    // It then weights them according to the requested upsampling set in avifRGBImage.
+
+                    uint16_t unormU[2][2], unormV[2][2];
+
+                    // How many bytes to add to a uint8_t pointer index to get to the adjacent (lesser) sample in a given direction
+                    int uAdjCol, vAdjCol, uAdjRow, vAdjRow;
+                    if ((i == 0) || ((i == (image->width - 1)) && ((i % 2) != 0))) {
+                        uAdjCol = 0;
+                        vAdjCol = 0;
+                    } else {
+                        if ((i % 2) != 0) {
+                            uAdjCol = yuvChannelBytes;
+                            vAdjCol = yuvChannelBytes;
+                        } else {
+                            uAdjCol = -1 * yuvChannelBytes;
+                            vAdjCol = -1 * yuvChannelBytes;
+                        }
+                    }
+
+                    // For YUV422, uvJ will always be a fresh value (always corresponds to j), so
+                    // we'll simply duplicate the sample as if we were on the top or bottom row and
+                    // it'll behave as plain old linear (1D) upsampling, which is all we want.
+                    if ((j == 0) || ((j == (image->height - 1)) && ((j % 2) != 0)) || (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV422)) {
+                        uAdjRow = 0;
+                        vAdjRow = 0;
+                    } else {
+                        if ((j % 2) != 0) {
+                            uAdjRow = (int)uRowBytes;
+                            vAdjRow = (int)vRowBytes;
+                        } else {
+                            uAdjRow = -1 * (int)uRowBytes;
+                            vAdjRow = -1 * (int)vRowBytes;
+                        }
+                    }
+
+                    if (image->depth == 8) {
+                        unormU[0][0] = uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes)];
+                        unormV[0][0] = vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes)];
+                        unormU[1][0] = uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjCol];
+                        unormV[1][0] = vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjCol];
+                        unormU[0][1] = uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjRow];
+                        unormV[0][1] = vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjRow];
+                        unormU[1][1] = uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjCol + uAdjRow];
+                        unormV[1][1] = vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjCol + vAdjRow];
+                    } else {
+                        unormU[0][0] = *((const uint16_t *)&uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes)]);
+                        unormV[0][0] = *((const uint16_t *)&vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes)]);
+                        unormU[1][0] = *((const uint16_t *)&uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjCol]);
+                        unormV[1][0] = *((const uint16_t *)&vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjCol]);
+                        unormU[0][1] = *((const uint16_t *)&uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjRow]);
+                        unormV[0][1] = *((const uint16_t *)&vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjRow]);
+                        unormU[1][1] = *((const uint16_t *)&uPlane[(uvJ * uRowBytes) + (uvI * yuvChannelBytes) + uAdjCol + uAdjRow]);
+                        unormV[1][1] = *((const uint16_t *)&vPlane[(uvJ * vRowBytes) + (uvI * yuvChannelBytes) + vAdjCol + vAdjRow]);
+
+                        // clamp incoming data to protect against bad LUT lookups
+                        for (int bJ = 0; bJ < 2; ++bJ) {
+                            for (int bI = 0; bI < 2; ++bI) {
+                                unormU[bI][bJ] = AVIF_MIN(unormU[bI][bJ], yuvMaxChannel);
+                                unormV[bI][bJ] = AVIF_MIN(unormV[bI][bJ], yuvMaxChannel);
+                            }
+                        }
+                    }
+
+                    if ((rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_FASTEST) ||
+                        (rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_NEAREST)) {
+                        // Nearest neighbor; ignore all UVs but the closest one
+                        Cb = unormFloatTableUV[unormU[0][0]];
+                        Cr = unormFloatTableUV[unormV[0][0]];
+                    } else {
+                        // Bilinear filtering with weights
+                        Cb = (unormFloatTableUV[unormU[0][0]] * (9.0f / 16.0f)) + (unormFloatTableUV[unormU[1][0]] * (3.0f / 16.0f)) +
+                             (unormFloatTableUV[unormU[0][1]] * (3.0f / 16.0f)) + (unormFloatTableUV[unormU[1][1]] * (1.0f / 16.0f));
+                        Cr = (unormFloatTableUV[unormV[0][0]] * (9.0f / 16.0f)) + (unormFloatTableUV[unormV[1][0]] * (3.0f / 16.0f)) +
+                             (unormFloatTableUV[unormV[0][1]] * (3.0f / 16.0f)) + (unormFloatTableUV[unormV[1][1]] * (1.0f / 16.0f));
+                    }
+                }
+            }
+
+            float R, G, B;
+            if (hasColor) {
+                if (state->yuv.mode == AVIF_REFORMAT_MODE_IDENTITY) {
+                    // Identity (GBR): Formulas 41,42,43 from https://www.itu.int/rec/T-REC-H.273-201612-S
+                    G = Y;
+                    B = Cb;
+                    R = Cr;
+                } else if (state->yuv.mode == AVIF_REFORMAT_MODE_YCGCO) {
+                    // YCgCo: Formulas 47,48,49,50 from https://www.itu.int/rec/T-REC-H.273-201612-S
+                    const float t = Y - Cb;
+                    G = Y + Cb;
+                    B = t - Cr;
+                    R = t + Cr;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_YCGCO_R)
+                } else if (state->yuv.mode == AVIF_REFORMAT_MODE_YCGCO_RE || state->yuv.mode == AVIF_REFORMAT_MODE_YCGCO_RO) {
+                    // YCgCoRe/YCgCoRo: Formulas 62,63,64,65 from https://www.itu.int/rec/T-REC-H.273-202407-P
+                    const int YY = unormY;
+                    const int Cg = (int)avifRoundf(Cb * yuvMaxChannel);
+                    const int Co = (int)avifRoundf(Cr * yuvMaxChannel);
+                    const int t = YY - (Cg >> 1);
+                    G = (float)AVIF_CLAMP(t + Cg, 0, state->rgb.maxChannel);
+                    B = (float)AVIF_CLAMP(t - (Co >> 1), 0, state->rgb.maxChannel);
+                    R = (float)AVIF_CLAMP(B + Co, 0, state->rgb.maxChannel);
+                    G /= rgbMaxChannelF;
+                    B /= rgbMaxChannelF;
+                    R /= rgbMaxChannelF;
+#endif
+                } else {
+                    // Normal YUV
+                    R = Y + (2 * (1 - kr)) * Cr;
+                    B = Y + (2 * (1 - kb)) * Cb;
+                    G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+                }
+            } else {
+                // Monochrome: just populate all channels with luma (state->yuv.mode is irrelevant)
+                R = Y;
+                G = Y;
+                B = Y;
+            }
+
+            float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            if (alphaMultiplyMode != AVIF_ALPHA_MULTIPLY_MODE_NO_OP) {
+                // Calculate A
+                uint16_t unormA;
+                if (image->depth == 8) {
+                    unormA = ptrA8[i];
+                } else {
+                    unormA = AVIF_MIN(ptrA16[i], yuvMaxChannel);
+                }
+                const float A = unormA / ((float)state->yuv.maxChannel);
+                const float Ac = AVIF_CLAMP(A, 0.0f, 1.0f);
+
+                if (alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY) {
+                    if (Ac == 0.0f) {
+                        Rc = 0.0f;
+                        Gc = 0.0f;
+                        Bc = 0.0f;
+                    } else if (Ac < 1.0f) {
+                        Rc *= Ac;
+                        Gc *= Ac;
+                        Bc *= Ac;
+                    }
+                } else {
+                    // alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY
+                    if (Ac == 0.0f) {
+                        Rc = 0.0f;
+                        Gc = 0.0f;
+                        Bc = 0.0f;
+                    } else if (Ac < 1.0f) {
+                        Rc /= Ac;
+                        Gc /= Ac;
+                        Bc /= Ac;
+                        Rc = AVIF_MIN(Rc, 1.0f);
+                        Gc = AVIF_MIN(Gc, 1.0f);
+                        Bc = AVIF_MIN(Bc, 1.0f);
+                    }
+                }
+            }
+
+            if (rgb->depth == 8) {
+                avifStoreRGB8Pixel(rgb->format,
+                                   (uint8_t)(0.5f + (Rc * rgbMaxChannelF)),
+                                   (uint8_t)(0.5f + (Gc * rgbMaxChannelF)),
+                                   (uint8_t)(0.5f + (Bc * rgbMaxChannelF)),
+                                   ptrR,
+                                   ptrG,
+                                   ptrB);
+            } else {
+                *((uint16_t *)ptrR) = (uint16_t)(0.5f + (Rc * rgbMaxChannelF));
+                *((uint16_t *)ptrG) = (uint16_t)(0.5f + (Gc * rgbMaxChannelF));
+                *((uint16_t *)ptrB) = (uint16_t)(0.5f + (Bc * rgbMaxChannelF));
+            }
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV16ToRGB16Color(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    float * unormFloatTableUV = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const uint16_t yuvMaxChannel = (uint16_t)state->yuv.maxChannel;
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint32_t uvJ = j >> state->yuv.formatInfo.chromaShiftY;
+        const uint16_t * const ptrY = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        const uint16_t * const ptrU = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_U][(uvJ * image->yuvRowBytes[AVIF_CHAN_U])];
+        const uint16_t * const ptrV = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_V][(uvJ * image->yuvRowBytes[AVIF_CHAN_V])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            uint32_t uvI = i >> state->yuv.formatInfo.chromaShiftX;
+
+            // clamp incoming data to protect against bad LUT lookups
+            const uint16_t unormY = AVIF_MIN(ptrY[i], yuvMaxChannel);
+            const uint16_t unormU = AVIF_MIN(ptrU[uvI], yuvMaxChannel);
+            const uint16_t unormV = AVIF_MIN(ptrV[uvI], yuvMaxChannel);
+
+            // Convert unorm to float
+            const float Y = unormFloatTableY[unormY];
+            const float Cb = unormFloatTableUV[unormU];
+            const float Cr = unormFloatTableUV[unormV];
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            *((uint16_t *)ptrR) = (uint16_t)(0.5f + (Rc * rgbMaxChannelF));
+            *((uint16_t *)ptrG) = (uint16_t)(0.5f + (Gc * rgbMaxChannelF));
+            *((uint16_t *)ptrB) = (uint16_t)(0.5f + (Bc * rgbMaxChannelF));
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV16ToRGB16Mono(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, NULL, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const uint16_t maxChannel = (uint16_t)state->yuv.maxChannel;
+    const float maxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint16_t * const ptrY = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            // clamp incoming data to protect against bad LUT lookups
+            const uint16_t unormY = AVIF_MIN(ptrY[i], maxChannel);
+
+            // Convert unorm to float
+            const float Y = unormFloatTableY[unormY];
+            const float Cb = 0.0f;
+            const float Cr = 0.0f;
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            *((uint16_t *)ptrR) = (uint16_t)(0.5f + (Rc * maxChannelF));
+            *((uint16_t *)ptrG) = (uint16_t)(0.5f + (Gc * maxChannelF));
+            *((uint16_t *)ptrB) = (uint16_t)(0.5f + (Bc * maxChannelF));
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, NULL);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV16ToRGB8Color(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    float * unormFloatTableUV = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const uint16_t yuvMaxChannel = (uint16_t)state->yuv.maxChannel;
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint32_t uvJ = j >> state->yuv.formatInfo.chromaShiftY;
+        const uint16_t * const ptrY = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        const uint16_t * const ptrU = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_U][(uvJ * image->yuvRowBytes[AVIF_CHAN_U])];
+        const uint16_t * const ptrV = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_V][(uvJ * image->yuvRowBytes[AVIF_CHAN_V])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            uint32_t uvI = i >> state->yuv.formatInfo.chromaShiftX;
+
+            // clamp incoming data to protect against bad LUT lookups
+            const uint16_t unormY = AVIF_MIN(ptrY[i], yuvMaxChannel);
+            const uint16_t unormU = AVIF_MIN(ptrU[uvI], yuvMaxChannel);
+            const uint16_t unormV = AVIF_MIN(ptrV[uvI], yuvMaxChannel);
+
+            // Convert unorm to float
+            const float Y = unormFloatTableY[unormY];
+            const float Cb = unormFloatTableUV[unormU];
+            const float Cr = unormFloatTableUV[unormV];
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            avifStoreRGB8Pixel(rgb->format,
+                               (uint8_t)(0.5f + (Rc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Gc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Bc * rgbMaxChannelF)),
+                               ptrR,
+                               ptrG,
+                               ptrB);
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV16ToRGB8Mono(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, NULL, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const uint16_t yuvMaxChannel = (uint16_t)state->yuv.maxChannel;
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint16_t * const ptrY = (uint16_t *)&image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            // clamp incoming data to protect against bad LUT lookups
+            const uint16_t unormY = AVIF_MIN(ptrY[i], yuvMaxChannel);
+
+            // Convert unorm to float
+            const float Y = unormFloatTableY[unormY];
+            const float Cb = 0.0f;
+            const float Cr = 0.0f;
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            avifStoreRGB8Pixel(rgb->format,
+                               (uint8_t)(0.5f + (Rc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Gc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Bc * rgbMaxChannelF)),
+                               ptrR,
+                               ptrG,
+                               ptrB);
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, NULL);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV8ToRGB16Color(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    float * unormFloatTableUV = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint32_t uvJ = j >> state->yuv.formatInfo.chromaShiftY;
+        const uint8_t * const ptrY = &image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        const uint8_t * const ptrU = &image->yuvPlanes[AVIF_CHAN_U][(uvJ * image->yuvRowBytes[AVIF_CHAN_U])];
+        const uint8_t * const ptrV = &image->yuvPlanes[AVIF_CHAN_V][(uvJ * image->yuvRowBytes[AVIF_CHAN_V])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            uint32_t uvI = i >> state->yuv.formatInfo.chromaShiftX;
+
+            // Convert unorm to float (no clamp necessary, the full uint8_t range is a legal lookup)
+            const float Y = unormFloatTableY[ptrY[i]];
+            const float Cb = unormFloatTableUV[ptrU[uvI]];
+            const float Cr = unormFloatTableUV[ptrV[uvI]];
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            *((uint16_t *)ptrR) = (uint16_t)(0.5f + (Rc * rgbMaxChannelF));
+            *((uint16_t *)ptrG) = (uint16_t)(0.5f + (Gc * rgbMaxChannelF));
+            *((uint16_t *)ptrB) = (uint16_t)(0.5f + (Bc * rgbMaxChannelF));
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV8ToRGB16Mono(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, NULL, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint8_t * const ptrY = &image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            // Convert unorm to float (no clamp necessary, the full uint8_t range is a legal lookup)
+            const float Y = unormFloatTableY[ptrY[i]];
+            const float Cb = 0.0f;
+            const float Cr = 0.0f;
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            *((uint16_t *)ptrR) = (uint16_t)(0.5f + (Rc * rgbMaxChannelF));
+            *((uint16_t *)ptrG) = (uint16_t)(0.5f + (Gc * rgbMaxChannelF));
+            *((uint16_t *)ptrB) = (uint16_t)(0.5f + (Bc * rgbMaxChannelF));
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, NULL);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageIdentity8ToRGB8ColorFullRange(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint8_t * const ptrY = &image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        const uint8_t * const ptrU = &image->yuvPlanes[AVIF_CHAN_U][(j * image->yuvRowBytes[AVIF_CHAN_U])];
+        const uint8_t * const ptrV = &image->yuvPlanes[AVIF_CHAN_V][(j * image->yuvRowBytes[AVIF_CHAN_V])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        // This is intentionally a per-row conditional instead of a per-pixel
+        // conditional. This makes the "else" path (much more common than the
+        // "if" path) much faster than having a per-pixel branch.
+        if (rgb->format == AVIF_RGB_FORMAT_RGB_565) {
+            for (uint32_t i = 0; i < image->width; ++i) {
+                *(uint16_t *)ptrR = RGB565(ptrV[i], ptrY[i], ptrU[i]);
+                ptrR += rgbPixelBytes;
+            }
+        } else {
+            for (uint32_t i = 0; i < image->width; ++i) {
+                *ptrR = ptrV[i];
+                *ptrG = ptrY[i];
+                *ptrB = ptrU[i];
+                ptrR += rgbPixelBytes;
+                ptrG += rgbPixelBytes;
+                ptrB += rgbPixelBytes;
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV8ToRGB8Color(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    float * unormFloatTableUV = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint32_t uvJ = j >> state->yuv.formatInfo.chromaShiftY;
+        const uint8_t * const ptrY = &image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        const uint8_t * const ptrU = &image->yuvPlanes[AVIF_CHAN_U][(uvJ * image->yuvRowBytes[AVIF_CHAN_U])];
+        const uint8_t * const ptrV = &image->yuvPlanes[AVIF_CHAN_V][(uvJ * image->yuvRowBytes[AVIF_CHAN_V])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            uint32_t uvI = i >> state->yuv.formatInfo.chromaShiftX;
+
+            // Convert unorm to float (no clamp necessary, the full uint8_t range is a legal lookup)
+            const float Y = unormFloatTableY[ptrY[i]];
+            const float Cb = unormFloatTableUV[ptrU[uvI]];
+            const float Cr = unormFloatTableUV[ptrV[uvI]];
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            avifStoreRGB8Pixel(rgb->format,
+                               (uint8_t)(0.5f + (Rc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Gc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Bc * rgbMaxChannelF)),
+                               ptrR,
+                               ptrG,
+                               ptrB);
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, &unormFloatTableUV);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUV8ToRGB8Mono(const avifImage * image, avifRGBImage * rgb, avifReformatState * state)
+{
+    const float kr = state->yuv.kr;
+    const float kg = state->yuv.kg;
+    const float kb = state->yuv.kb;
+    const uint32_t rgbPixelBytes = state->rgb.pixelBytes;
+    float * unormFloatTableY = NULL;
+    AVIF_CHECKERR(avifCreateYUVToRGBLookUpTables(&unormFloatTableY, NULL, image->depth, state), AVIF_RESULT_OUT_OF_MEMORY);
+
+    const float rgbMaxChannelF = state->rgb.maxChannelF;
+    for (uint32_t j = 0; j < image->height; ++j) {
+        const uint8_t * const ptrY = &image->yuvPlanes[AVIF_CHAN_Y][(j * image->yuvRowBytes[AVIF_CHAN_Y])];
+        uint8_t * ptrR = &rgb->pixels[state->rgb.offsetBytesR + (j * rgb->rowBytes)];
+        uint8_t * ptrG = &rgb->pixels[state->rgb.offsetBytesG + (j * rgb->rowBytes)];
+        uint8_t * ptrB = &rgb->pixels[state->rgb.offsetBytesB + (j * rgb->rowBytes)];
+
+        for (uint32_t i = 0; i < image->width; ++i) {
+            // Convert unorm to float (no clamp necessary, the full uint8_t range is a legal lookup)
+            const float Y = unormFloatTableY[ptrY[i]];
+            const float Cb = 0.0f;
+            const float Cr = 0.0f;
+
+            const float R = Y + (2 * (1 - kr)) * Cr;
+            const float B = Y + (2 * (1 - kb)) * Cb;
+            const float G = Y - ((2 * ((kr * (1 - kr) * Cr) + (kb * (1 - kb) * Cb))) / kg);
+            const float Rc = AVIF_CLAMP(R, 0.0f, 1.0f);
+            const float Gc = AVIF_CLAMP(G, 0.0f, 1.0f);
+            const float Bc = AVIF_CLAMP(B, 0.0f, 1.0f);
+
+            avifStoreRGB8Pixel(rgb->format,
+                               (uint8_t)(0.5f + (Rc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Gc * rgbMaxChannelF)),
+                               (uint8_t)(0.5f + (Bc * rgbMaxChannelF)),
+                               ptrR,
+                               ptrG,
+                               ptrB);
+
+            ptrR += rgbPixelBytes;
+            ptrG += rgbPixelBytes;
+            ptrB += rgbPixelBytes;
+        }
+    }
+    avifFreeYUVToRGBLookUpTables(&unormFloatTableY, NULL);
+    return AVIF_RESULT_OK;
+}
+
+// This constant comes from libyuv. For details, see here:
+// https://chromium.googlesource.com/libyuv/libyuv/+/2f87e9a7/source/row_common.cc#3537
+#define F16_MULTIPLIER 1.9259299444e-34f
+
+typedef union avifF16
+{
+    float f;
+    uint32_t u32;
+} avifF16;
+
+static avifResult avifRGBImageToF16(avifRGBImage * rgb)
+{
+    avifResult libyuvResult = AVIF_RESULT_NOT_IMPLEMENTED;
+    if (!rgb->avoidLibYUV) {
+        libyuvResult = avifRGBImageToF16LibYUV(rgb);
+    }
+    if (libyuvResult != AVIF_RESULT_NOT_IMPLEMENTED) {
+        return libyuvResult;
+    }
+    const uint32_t channelCount = avifRGBFormatChannelCount(rgb->format);
+    const float scale = 1.0f / ((1 << rgb->depth) - 1);
+    const float multiplier = F16_MULTIPLIER * scale;
+    uint16_t * pixelRowBase = (uint16_t *)rgb->pixels;
+    const uint32_t stride = rgb->rowBytes >> 1;
+    for (uint32_t j = 0; j < rgb->height; ++j) {
+        uint16_t * pixel = pixelRowBase;
+        for (uint32_t i = 0; i < rgb->width * channelCount; ++i, ++pixel) {
+            avifF16 f16;
+            f16.f = *pixel * multiplier;
+            *pixel = (uint16_t)(f16.u32 >> 13);
+        }
+        pixelRowBase += stride;
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifImageYUVToRGBImpl(const avifImage * image, avifRGBImage * rgb, avifReformatState * state, avifAlphaMultiplyMode alphaMultiplyMode)
+{
+    avifBool convertedWithLibYUV = AVIF_FALSE;
+    // Reformat alpha, if user asks for it, or (un)multiply processing needs it.
+    avifBool reformatAlpha = avifRGBFormatHasAlpha(rgb->format) &&
+                             (!rgb->ignoreAlpha || (alphaMultiplyMode != AVIF_ALPHA_MULTIPLY_MODE_NO_OP));
+    // This value is used only when reformatAlpha is true.
+    avifBool alphaReformattedWithLibYUV = AVIF_FALSE;
+    if (!rgb->avoidLibYUV && ((alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_NO_OP) || avifRGBFormatHasAlpha(rgb->format))) {
+        avifResult libyuvResult = avifImageYUVToRGBLibYUV(image, rgb, reformatAlpha, &alphaReformattedWithLibYUV);
+        if (libyuvResult == AVIF_RESULT_OK) {
+            convertedWithLibYUV = AVIF_TRUE;
+        } else {
+            if (libyuvResult != AVIF_RESULT_NOT_IMPLEMENTED) {
+                return libyuvResult;
+            }
+        }
+    }
+
+    if (reformatAlpha && !alphaReformattedWithLibYUV) {
+        avifAlphaParams params;
+
+        params.width = rgb->width;
+        params.height = rgb->height;
+        params.dstDepth = rgb->depth;
+        params.dstPlane = rgb->pixels;
+        params.dstRowBytes = rgb->rowBytes;
+        params.dstOffsetBytes = state->rgb.offsetBytesA;
+        params.dstPixelBytes = state->rgb.pixelBytes;
+
+        if (image->alphaPlane && image->alphaRowBytes) {
+            params.srcDepth = image->depth;
+            params.srcPlane = image->alphaPlane;
+            params.srcRowBytes = image->alphaRowBytes;
+            params.srcOffsetBytes = 0;
+            params.srcPixelBytes = state->yuv.channelBytes;
+
+            avifReformatAlpha(&params);
+        } else {
+            avifFillAlpha(&params);
+        }
+    }
+
+    if (!convertedWithLibYUV) {
+        // libyuv is either unavailable or unable to perform the specific conversion required here.
+        // Look over the available built-in "fast" routines for YUV->RGB conversion and see if one
+        // fits the current combination, or as a last resort, call avifImageYUVAnyToRGBAnySlow(),
+        // which handles every possibly YUV->RGB combination, but very slowly (in comparison).
+
+        avifResult convertResult = AVIF_RESULT_NOT_IMPLEMENTED;
+
+        const avifBool hasColor =
+            (image->yuvRowBytes[AVIF_CHAN_U] && image->yuvRowBytes[AVIF_CHAN_V] && (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV400));
+
+        if ((!hasColor || (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) ||
+             ((rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_FASTEST) || (rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_NEAREST))) &&
+            (alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_NO_OP || avifRGBFormatHasAlpha(rgb->format))) {
+            // Explanations on the above conditional:
+            // * None of these fast paths currently support bilinear upsampling, so avoid all of them
+            //   unless the YUV data isn't subsampled or they explicitly requested AVIF_CHROMA_UPSAMPLING_NEAREST.
+            // * None of these fast paths currently handle alpha (un)multiply, so avoid all of them
+            //   if we can't do alpha (un)multiply as a separated post step (destination format doesn't have alpha).
+
+            if (state->yuv.mode == AVIF_REFORMAT_MODE_IDENTITY) {
+                if ((image->depth == 8) && (rgb->depth == 8) && (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) &&
+                    (image->yuvRange == AVIF_RANGE_FULL)) {
+                    convertResult = avifImageIdentity8ToRGB8ColorFullRange(image, rgb, state);
+                }
+
+                // TODO: Add more fast paths for identity
+            } else if (state->yuv.mode == AVIF_REFORMAT_MODE_YUV_COEFFICIENTS) {
+                if (image->depth > 8) {
+                    // yuv:u16
+
+                    if (rgb->depth > 8) {
+                        // yuv:u16, rgb:u16
+
+                        if (hasColor) {
+                            convertResult = avifImageYUV16ToRGB16Color(image, rgb, state);
+                        } else {
+                            convertResult = avifImageYUV16ToRGB16Mono(image, rgb, state);
+                        }
+                    } else {
+                        // yuv:u16, rgb:u8
+
+                        if (hasColor) {
+                            convertResult = avifImageYUV16ToRGB8Color(image, rgb, state);
+                        } else {
+                            convertResult = avifImageYUV16ToRGB8Mono(image, rgb, state);
+                        }
+                    }
+                } else {
+                    // yuv:u8
+
+                    if (rgb->depth > 8) {
+                        // yuv:u8, rgb:u16
+
+                        if (hasColor) {
+                            convertResult = avifImageYUV8ToRGB16Color(image, rgb, state);
+                        } else {
+                            convertResult = avifImageYUV8ToRGB16Mono(image, rgb, state);
+                        }
+                    } else {
+                        // yuv:u8, rgb:u8
+
+                        if (hasColor) {
+                            convertResult = avifImageYUV8ToRGB8Color(image, rgb, state);
+                        } else {
+                            convertResult = avifImageYUV8ToRGB8Mono(image, rgb, state);
+                        }
+                    }
+                }
+            }
+        }
+
+        if (convertResult == AVIF_RESULT_NOT_IMPLEMENTED) {
+            // If we get here, there is no fast path for this combination. Time to be slow!
+            convertResult = avifImageYUVAnyToRGBAnySlow(image, rgb, state, alphaMultiplyMode);
+
+            // The slow path also handles alpha (un)multiply, so forget the operation here.
+            alphaMultiplyMode = AVIF_ALPHA_MULTIPLY_MODE_NO_OP;
+        }
+
+        if (convertResult != AVIF_RESULT_OK) {
+            return convertResult;
+        }
+    }
+
+    // Process alpha premultiplication, if necessary
+    if (alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY) {
+        avifResult result = avifRGBImagePremultiplyAlpha(rgb);
+        if (result != AVIF_RESULT_OK) {
+            return result;
+        }
+    } else if (alphaMultiplyMode == AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY) {
+        avifResult result = avifRGBImageUnpremultiplyAlpha(rgb);
+        if (result != AVIF_RESULT_OK) {
+            return result;
+        }
+    }
+
+    // Convert pixels to half floats (F16), if necessary.
+    if (rgb->isFloat) {
+        return avifRGBImageToF16(rgb);
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+typedef struct
+{
+#if defined(_WIN32)
+    HANDLE thread;
+#else
+    pthread_t thread;
+#endif
+    avifImage image;
+    avifRGBImage rgb;
+    avifReformatState * state;
+    avifAlphaMultiplyMode alphaMultiplyMode;
+    avifResult result;
+    avifBool threadCreated;
+} YUVToRGBThreadData;
+
+#if defined(_WIN32)
+static unsigned int __stdcall avifImageYUVToRGBThreadWorker(void * arg)
+#else
+static void * avifImageYUVToRGBThreadWorker(void * arg)
+#endif
+{
+    YUVToRGBThreadData * data = (YUVToRGBThreadData *)arg;
+    data->result = avifImageYUVToRGBImpl(&data->image, &data->rgb, data->state, data->alphaMultiplyMode);
+#if defined(_WIN32)
+    return 0;
+#else
+    return NULL;
+#endif
+}
+
+static avifBool avifCreateYUVToRGBThread(YUVToRGBThreadData * tdata)
+{
+#if defined(_WIN32)
+    tdata->thread = (HANDLE)_beginthreadex(/*security=*/NULL,
+                                           /*stack_size=*/0,
+                                           &avifImageYUVToRGBThreadWorker,
+                                           tdata,
+                                           /*initflag=*/0,
+                                           /*thrdaddr=*/NULL);
+    return tdata->thread != NULL;
+#else
+    // TODO: Set the thread name for ease of debugging.
+    return pthread_create(&tdata->thread, NULL, &avifImageYUVToRGBThreadWorker, tdata) == 0;
+#endif
+}
+
+static avifBool avifJoinYUVToRGBThread(YUVToRGBThreadData * tdata)
+{
+#if defined(_WIN32)
+    return WaitForSingleObject(tdata->thread, INFINITE) == WAIT_OBJECT_0 && CloseHandle(tdata->thread) != 0;
+#else
+    return pthread_join(tdata->thread, NULL) == 0;
+#endif
+}
+
+avifResult avifImageYUVToRGB(const avifImage * image, avifRGBImage * rgb)
+{
+    // It is okay for rgb->maxThreads to be equal to zero in order to allow clients to zero initialize the avifRGBImage struct
+    // with memset.
+    if (!image->yuvPlanes[AVIF_CHAN_Y] || rgb->maxThreads < 0) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    avifReformatState state;
+    if (!avifPrepareReformatState(image, rgb, &state)) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    avifAlphaMultiplyMode alphaMultiplyMode = AVIF_ALPHA_MULTIPLY_MODE_NO_OP;
+    if (image->alphaPlane) {
+        if (!avifRGBFormatHasAlpha(rgb->format) || rgb->ignoreAlpha) {
+            // if we are converting some image with alpha into a format without alpha, we should do 'premultiply alpha' before
+            // discarding alpha plane. This has the same effect of rendering this image on a black background, which makes sense.
+            if (!image->alphaPremultiplied) {
+                alphaMultiplyMode = AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY;
+            }
+        } else {
+            if (!image->alphaPremultiplied && rgb->alphaPremultiplied) {
+                alphaMultiplyMode = AVIF_ALPHA_MULTIPLY_MODE_MULTIPLY;
+            } else if (image->alphaPremultiplied && !rgb->alphaPremultiplied) {
+                alphaMultiplyMode = AVIF_ALPHA_MULTIPLY_MODE_UNMULTIPLY;
+            }
+        }
+    }
+
+    // In practice, we rarely need more than 8 threads for YUV to RGB conversion.
+    uint32_t jobs = AVIF_CLAMP(rgb->maxThreads, 1, 8);
+
+    // When yuv format is 420 and chromaUpsampling could be BILINEAR, there is a dependency across the horizontal borders of each
+    // job. So we disallow multithreading in that case.
+    if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 && (rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_AUTOMATIC ||
+                                                         rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_BEST_QUALITY ||
+                                                         rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_BILINEAR)) {
+        jobs = 1;
+    }
+
+    // Each thread worker needs at least 2 Y rows (to account for potential U/V subsampling).
+    if (jobs == 1 || (image->height / 2) < jobs) {
+        return avifImageYUVToRGBImpl(image, rgb, &state, alphaMultiplyMode);
+    }
+
+    const size_t byteCount = sizeof(YUVToRGBThreadData) * jobs;
+    YUVToRGBThreadData * threadData = (YUVToRGBThreadData *)avifAlloc(byteCount);
+    if (!threadData) {
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    memset(threadData, 0, byteCount);
+    uint32_t rowsPerJob = image->height / jobs;
+    if (rowsPerJob % 2) {
+        ++rowsPerJob;
+        jobs = (image->height + rowsPerJob - 1) / rowsPerJob; // ceil
+    }
+    const uint32_t rowsForLastJob = image->height - rowsPerJob * (jobs - 1);
+    uint32_t startRow = 0;
+    uint32_t i;
+    for (i = 0; i < jobs; ++i, startRow += rowsPerJob) {
+        YUVToRGBThreadData * tdata = &threadData[i];
+        const avifCropRect rect = { .x = 0, .y = startRow, .width = image->width, .height = (i == jobs - 1) ? rowsForLastJob : rowsPerJob };
+        if (avifImageSetViewRect(&tdata->image, image, &rect) != AVIF_RESULT_OK) {
+            tdata->result = AVIF_RESULT_REFORMAT_FAILED;
+            break;
+        }
+
+        tdata->rgb = *rgb;
+        tdata->rgb.pixels += startRow * (size_t)rgb->rowBytes;
+        tdata->rgb.height = tdata->image.height;
+
+        tdata->state = &state;
+        tdata->alphaMultiplyMode = alphaMultiplyMode;
+
+        if (i > 0) {
+            tdata->threadCreated = avifCreateYUVToRGBThread(tdata);
+            if (!tdata->threadCreated) {
+                tdata->result = AVIF_RESULT_REFORMAT_FAILED;
+                break;
+            }
+        }
+    }
+    // If above loop ran successfully, run the first job in the current thread.
+    if (i == jobs) {
+        avifImageYUVToRGBThreadWorker(&threadData[0]);
+    }
+    avifResult result = AVIF_RESULT_OK;
+    for (i = 0; i < jobs; ++i) {
+        YUVToRGBThreadData * tdata = &threadData[i];
+        if (tdata->threadCreated && !avifJoinYUVToRGBThread(tdata)) {
+            result = AVIF_RESULT_REFORMAT_FAILED;
+        }
+        if (tdata->result != AVIF_RESULT_OK) {
+            result = tdata->result;
+        }
+    }
+    avifFree(threadData);
+    return result;
+}
+
+// Limited -> Full
+// Plan: subtract limited offset, then multiply by ratio of FULLSIZE/LIMITEDSIZE (rounding), then clamp.
+// RATIO = (FULLY - 0) / (MAXLIMITEDY - MINLIMITEDY)
+// -----------------------------------------
+// ( ( (v - MINLIMITEDY)                    | subtract limited offset
+//     * FULLY                              | multiply numerator of ratio
+//   ) + ((MAXLIMITEDY - MINLIMITEDY) / 2)  | add 0.5 (half of denominator) to round
+// ) / (MAXLIMITEDY - MINLIMITEDY)          | divide by denominator of ratio
+// AVIF_CLAMP(v, 0, FULLY)                  | clamp to full range
+// -----------------------------------------
+#define LIMITED_TO_FULL(MINLIMITEDY, MAXLIMITEDY, FULLY)                                                 \
+    v = (((v - MINLIMITEDY) * FULLY) + ((MAXLIMITEDY - MINLIMITEDY) / 2)) / (MAXLIMITEDY - MINLIMITEDY); \
+    v = AVIF_CLAMP(v, 0, FULLY)
+
+// Full -> Limited
+// Plan: multiply by ratio of LIMITEDSIZE/FULLSIZE (rounding), then add limited offset, then clamp.
+// RATIO = (MAXLIMITEDY - MINLIMITEDY) / (FULLY - 0)
+// -----------------------------------------
+// ( ( (v * (MAXLIMITEDY - MINLIMITEDY))    | multiply numerator of ratio
+//     + (FULLY / 2)                        | add 0.5 (half of denominator) to round
+//   ) / FULLY                              | divide by denominator of ratio
+// ) + MINLIMITEDY                          | add limited offset
+//  AVIF_CLAMP(v, MINLIMITEDY, MAXLIMITEDY) | clamp to limited range
+// -----------------------------------------
+#define FULL_TO_LIMITED(MINLIMITEDY, MAXLIMITEDY, FULLY)                           \
+    v = (((v * (MAXLIMITEDY - MINLIMITEDY)) + (FULLY / 2)) / FULLY) + MINLIMITEDY; \
+    v = AVIF_CLAMP(v, MINLIMITEDY, MAXLIMITEDY)
+
+int avifLimitedToFullY(uint32_t depth, int v)
+{
+    switch (depth) {
+        case 8:
+            LIMITED_TO_FULL(16, 235, 255);
+            break;
+        case 10:
+            LIMITED_TO_FULL(64, 940, 1023);
+            break;
+        case 12:
+            LIMITED_TO_FULL(256, 3760, 4095);
+            break;
+    }
+    return v;
+}
+
+int avifLimitedToFullUV(uint32_t depth, int v)
+{
+    switch (depth) {
+        case 8:
+            LIMITED_TO_FULL(16, 240, 255);
+            break;
+        case 10:
+            LIMITED_TO_FULL(64, 960, 1023);
+            break;
+        case 12:
+            LIMITED_TO_FULL(256, 3840, 4095);
+            break;
+    }
+    return v;
+}
+
+int avifFullToLimitedY(uint32_t depth, int v)
+{
+    switch (depth) {
+        case 8:
+            FULL_TO_LIMITED(16, 235, 255);
+            break;
+        case 10:
+            FULL_TO_LIMITED(64, 940, 1023);
+            break;
+        case 12:
+            FULL_TO_LIMITED(256, 3760, 4095);
+            break;
+    }
+    return v;
+}
+
+int avifFullToLimitedUV(uint32_t depth, int v)
+{
+    switch (depth) {
+        case 8:
+            FULL_TO_LIMITED(16, 240, 255);
+            break;
+        case 10:
+            FULL_TO_LIMITED(64, 960, 1023);
+            break;
+        case 12:
+            FULL_TO_LIMITED(256, 3840, 4095);
+            break;
+    }
+    return v;
+}
+
+static inline uint16_t avifFloatToF16(float v)
+{
+    avifF16 f16;
+    f16.f = v * F16_MULTIPLIER;
+    return (uint16_t)(f16.u32 >> 13);
+}
+
+static inline float avifF16ToFloat(uint16_t v)
+{
+    avifF16 f16;
+    f16.u32 = v << 13;
+    return f16.f / F16_MULTIPLIER;
+}
+
+void avifGetRGBAPixel(const avifRGBImage * src, uint32_t x, uint32_t y, const avifRGBColorSpaceInfo * info, float rgbaPixel[4])
+{
+    assert(src != NULL);
+    assert(!src->isFloat || src->depth == 16);
+    assert(src->format != AVIF_RGB_FORMAT_RGB_565 || src->depth == 8);
+
+    const uint8_t * const srcPixel = &src->pixels[y * src->rowBytes + x * info->pixelBytes];
+    if (info->channelBytes > 1) {
+        uint16_t r = *((const uint16_t *)(&srcPixel[info->offsetBytesR]));
+        uint16_t g = *((const uint16_t *)(&srcPixel[info->offsetBytesG]));
+        uint16_t b = *((const uint16_t *)(&srcPixel[info->offsetBytesB]));
+        uint16_t a = avifRGBFormatHasAlpha(src->format) ? *((const uint16_t *)(&srcPixel[info->offsetBytesA])) : (uint16_t)info->maxChannel;
+        if (src->isFloat) {
+            rgbaPixel[0] = avifF16ToFloat(r);
+            rgbaPixel[1] = avifF16ToFloat(g);
+            rgbaPixel[2] = avifF16ToFloat(b);
+            rgbaPixel[3] = avifRGBFormatHasAlpha(src->format) ? avifF16ToFloat(a) : 1.0f;
+        } else {
+            rgbaPixel[0] = r / info->maxChannelF;
+            rgbaPixel[1] = g / info->maxChannelF;
+            rgbaPixel[2] = b / info->maxChannelF;
+            rgbaPixel[3] = a / info->maxChannelF;
+        }
+    } else {
+        if (src->format == AVIF_RGB_FORMAT_RGB_565) {
+            uint8_t r, g, b;
+            avifGetRGB565(&srcPixel[info->offsetBytesR], &r, &g, &b);
+            rgbaPixel[0] = r / info->maxChannelF;
+            rgbaPixel[1] = g / info->maxChannelF;
+            rgbaPixel[2] = b / info->maxChannelF;
+            rgbaPixel[3] = 1.0f;
+        } else {
+            rgbaPixel[0] = srcPixel[info->offsetBytesR] / info->maxChannelF;
+            rgbaPixel[1] = srcPixel[info->offsetBytesG] / info->maxChannelF;
+            rgbaPixel[2] = srcPixel[info->offsetBytesB] / info->maxChannelF;
+            rgbaPixel[3] = avifRGBFormatHasAlpha(src->format) ? (srcPixel[info->offsetBytesA] / info->maxChannelF) : 1.0f;
+        }
+    }
+}
+
+void avifSetRGBAPixel(const avifRGBImage * dst, uint32_t x, uint32_t y, const avifRGBColorSpaceInfo * info, const float rgbaPixel[4])
+{
+    assert(dst != NULL);
+    assert(!dst->isFloat || dst->depth == 16);
+    assert(dst->format != AVIF_RGB_FORMAT_RGB_565 || dst->depth == 8);
+    assert(rgbaPixel[0] >= 0.0f && rgbaPixel[0] <= 1.0f);
+    assert(rgbaPixel[1] >= 0.0f && rgbaPixel[1] <= 1.0f);
+    assert(rgbaPixel[2] >= 0.0f && rgbaPixel[2] <= 1.0f);
+
+    uint8_t * const dstPixel = &dst->pixels[y * dst->rowBytes + x * info->pixelBytes];
+
+    uint8_t * const ptrR = &dstPixel[info->offsetBytesR];
+    uint8_t * const ptrG = &dstPixel[info->offsetBytesG];
+    uint8_t * const ptrB = &dstPixel[info->offsetBytesB];
+    uint8_t * const ptrA = avifRGBFormatHasAlpha(dst->format) ? &dstPixel[info->offsetBytesA] : NULL;
+    if (dst->depth > 8) {
+        if (dst->isFloat) {
+            *((uint16_t *)ptrR) = avifFloatToF16(rgbaPixel[0]);
+            *((uint16_t *)ptrG) = avifFloatToF16(rgbaPixel[1]);
+            *((uint16_t *)ptrB) = avifFloatToF16(rgbaPixel[2]);
+            if (ptrA) {
+                *((uint16_t *)ptrA) = avifFloatToF16(rgbaPixel[3]);
+            }
+        } else {
+            *((uint16_t *)ptrR) = (uint16_t)(0.5f + (rgbaPixel[0] * info->maxChannelF));
+            *((uint16_t *)ptrG) = (uint16_t)(0.5f + (rgbaPixel[1] * info->maxChannelF));
+            *((uint16_t *)ptrB) = (uint16_t)(0.5f + (rgbaPixel[2] * info->maxChannelF));
+            if (ptrA) {
+                *((uint16_t *)ptrA) = (uint16_t)(0.5f + (rgbaPixel[3] * info->maxChannelF));
+            }
+        }
+    } else {
+        avifStoreRGB8Pixel(dst->format,
+                           (uint8_t)(0.5f + (rgbaPixel[0] * info->maxChannelF)),
+                           (uint8_t)(0.5f + (rgbaPixel[1] * info->maxChannelF)),
+                           (uint8_t)(0.5f + (rgbaPixel[2] * info->maxChannelF)),
+                           ptrR,
+                           ptrG,
+                           ptrB);
+        if (ptrA) {
+            *ptrA = (uint8_t)(0.5f + (rgbaPixel[3] * info->maxChannelF));
+        }
+    }
+}
diff --git a/third_party/libavif/src/src/reformat_libsharpyuv.c b/third_party/libavif/src/src/reformat_libsharpyuv.c
new file mode 100644
index 0000000000..a6bd523b0b
--- /dev/null
+++ b/third_party/libavif/src/src/reformat_libsharpyuv.c
@@ -0,0 +1,84 @@
+// Copyright 2022 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#if defined(AVIF_LIBSHARPYUV_ENABLED)
+#include <limits.h>
+#include <sharpyuv/sharpyuv.h>
+#include <sharpyuv/sharpyuv_csp.h>
+
+avifResult avifImageRGBToYUVLibSharpYUV(avifImage * image, const avifRGBImage * rgb, const avifReformatState * state)
+{
+    // The width, height, and stride parameters of SharpYuvConvertWithOptions()
+    // and SharpYuvConvert() are all of the int type.
+    if (rgb->width > INT_MAX || rgb->height > INT_MAX || rgb->rowBytes > INT_MAX || image->yuvRowBytes[AVIF_CHAN_Y] > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    const SharpYuvColorSpace colorSpace = {
+        state->yuv.kr, state->yuv.kb, image->depth, (state->yuv.range == AVIF_RANGE_LIMITED) ? kSharpYuvRangeLimited : kSharpYuvRangeFull
+    };
+
+    SharpYuvConversionMatrix matrix;
+    // Fills in 'matrix' for the given YUVColorSpace.
+    SharpYuvComputeConversionMatrix(&colorSpace, &matrix);
+#if SHARPYUV_VERSION >= SHARPYUV_MAKE_VERSION(0, 4, 0)
+    SharpYuvOptions options;
+    SharpYuvOptionsInit(&matrix, &options);
+    if (image->transferCharacteristics == AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+        // Set to sRGB for backward compatibility.
+        options.transfer_type = kSharpYuvTransferFunctionSrgb;
+    } else {
+        options.transfer_type = (SharpYuvTransferFunctionType)image->transferCharacteristics;
+    }
+    const int sharpyuvRes = SharpYuvConvertWithOptions(&rgb->pixels[state->rgb.offsetBytesR],
+                                                       &rgb->pixels[state->rgb.offsetBytesG],
+                                                       &rgb->pixels[state->rgb.offsetBytesB],
+                                                       state->rgb.pixelBytes,
+                                                       rgb->rowBytes,
+                                                       rgb->depth,
+                                                       image->yuvPlanes[AVIF_CHAN_Y],
+                                                       image->yuvRowBytes[AVIF_CHAN_Y],
+                                                       image->yuvPlanes[AVIF_CHAN_U],
+                                                       image->yuvRowBytes[AVIF_CHAN_U],
+                                                       image->yuvPlanes[AVIF_CHAN_V],
+                                                       image->yuvRowBytes[AVIF_CHAN_V],
+                                                       image->depth,
+                                                       rgb->width,
+                                                       rgb->height,
+                                                       &options);
+#else
+    const int sharpyuvRes = SharpYuvConvert(&rgb->pixels[state->rgb.offsetBytesR],
+                                            &rgb->pixels[state->rgb.offsetBytesG],
+                                            &rgb->pixels[state->rgb.offsetBytesB],
+                                            state->rgb.pixelBytes,
+                                            rgb->rowBytes,
+                                            rgb->depth,
+                                            image->yuvPlanes[AVIF_CHAN_Y],
+                                            image->yuvRowBytes[AVIF_CHAN_Y],
+                                            image->yuvPlanes[AVIF_CHAN_U],
+                                            image->yuvRowBytes[AVIF_CHAN_U],
+                                            image->yuvPlanes[AVIF_CHAN_V],
+                                            image->yuvRowBytes[AVIF_CHAN_V],
+                                            image->depth,
+                                            rgb->width,
+                                            rgb->height,
+                                            &matrix);
+#endif // SHARPYUV_VERSION >= SHARPYUV_MAKE_VERSION(0, 4, 0)
+    if (!sharpyuvRes) {
+        return AVIF_RESULT_REFORMAT_FAILED;
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+#else
+
+avifResult avifImageRGBToYUVLibSharpYUV(avifImage * image, const avifRGBImage * rgb, const avifReformatState * state)
+{
+    (void)image;
+    (void)rgb;
+    (void)state;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+#endif // defined(AVIF_LIBSHARPYUV_ENABLED)
diff --git a/third_party/libavif/src/src/reformat_libyuv.c b/third_party/libavif/src/src/reformat_libyuv.c
new file mode 100644
index 0000000000..cfd7e295ba
--- /dev/null
+++ b/third_party/libavif/src/src/reformat_libyuv.c
@@ -0,0 +1,1171 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#if !defined(AVIF_LIBYUV_ENABLED)
+
+// No libyuv!
+avifResult avifImageRGBToYUVLibYUV(avifImage * image, const avifRGBImage * rgb)
+{
+    (void)image;
+    (void)rgb;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+avifResult avifImageYUVToRGBLibYUV(const avifImage * image, avifRGBImage * rgb, avifBool reformatAlpha, avifBool * alphaReformattedWithLibYUV)
+{
+    (void)image;
+    (void)rgb;
+    (void)reformatAlpha;
+    *alphaReformattedWithLibYUV = AVIF_FALSE;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+avifResult avifRGBImagePremultiplyAlphaLibYUV(avifRGBImage * rgb)
+{
+    (void)rgb;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+avifResult avifRGBImageUnpremultiplyAlphaLibYUV(avifRGBImage * rgb)
+{
+    (void)rgb;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+avifResult avifRGBImageToF16LibYUV(avifRGBImage * rgb)
+{
+    (void)rgb;
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+unsigned int avifLibYUVVersion(void)
+{
+    return 0;
+}
+
+#else
+
+#include <assert.h>
+#include <limits.h>
+#include <string.h>
+
+#if defined(__clang__)
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wstrict-prototypes" // "this function declaration is not a prototype"
+// The newline at the end of libyuv/version.h was accidentally deleted in version 1792 and restored
+// in version 1813:
+// https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3183182
+// https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3527834
+#pragma clang diagnostic ignored "-Wnewline-eof"       // "no newline at end of file"
+#endif
+#include <libyuv.h>
+#if defined(__clang__)
+#pragma clang diagnostic pop
+#endif
+
+// libyuv is a C++ library and defines custom types (struct, enum, etc) in the libyuv namespace when the libyuv header files are
+// included by C++ code. When accessed from a C library like libavif, via a function pointer, this leads to signature mismatches
+// in the CFI sanitizers since libyuv itself, compiled as C++ code, has the types within the namespace and the C code has the
+// types without the namespace. The same thing happens with clang's undefined behavior sanitizer as well when invoked with
+// -fsanitize=function. So we suppress both of these sanitizers in functions that call libyuv functions via a pointer.
+// For a simpler example of this bug, please see: https://github.com/vigneshvg/cpp_c_potential_cfi_bug.
+// For more details on clang's CFI see: https://clang.llvm.org/docs/ControlFlowIntegrity.html.
+// For more details on clang's UBSan see: https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html
+#if defined(__clang__)
+#define IGNORE_CFI_ICALL __attribute__((no_sanitize("cfi-icall", "function")))
+#else
+#define IGNORE_CFI_ICALL
+#endif
+
+//--------------------------------------------------------------------------------------------------
+// libyuv API availability management
+
+// These defines are used to create a NULL reference to libyuv functions that
+// did not exist prior to a particular version of libyuv.
+// Versions prior to 1755 are considered too old and not used (see CMakeLists.txt).
+#if LIBYUV_VERSION < 1844
+// I444ToRGB24Matrix() and I422ToRGB24MatrixFilter() were added in libyuv version 1844.
+//
+// Note: Between the following two commits, libyuv version jumped from 1841 to 1844, down to 1843,
+// and back to 1844. See https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3906082 and
+// https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3906091.
+#define I444ToRGB24Matrix NULL
+#define I422ToRGB24MatrixFilter NULL
+#endif
+#if LIBYUV_VERSION < 1841
+// I420ToRGB24MatrixFilter() was added in libyuv version 1841.
+// See https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3900298.
+#define I420ToRGB24MatrixFilter NULL
+#endif
+#if LIBYUV_VERSION < 1840
+#define ABGRToJ400 NULL
+#endif
+#if LIBYUV_VERSION < 1838
+#define I422ToRGB565Matrix NULL
+#endif
+#if LIBYUV_VERSION < 1813
+#define I422ToARGBMatrixFilter NULL
+#define I420ToARGBMatrixFilter NULL
+#define I210ToARGBMatrixFilter NULL
+#define I010ToARGBMatrixFilter NULL
+#define I420AlphaToARGBMatrixFilter NULL
+#define I422AlphaToARGBMatrixFilter NULL
+#define I010AlphaToARGBMatrixFilter NULL
+#define I210AlphaToARGBMatrixFilter NULL
+#endif
+#if LIBYUV_VERSION < 1782
+#define RAWToJ420 NULL
+#endif
+#if LIBYUV_VERSION < 1781
+#define I012ToARGBMatrix NULL
+#endif
+#if LIBYUV_VERSION < 1780
+#define I410ToARGBMatrix NULL
+#define I410AlphaToARGBMatrix NULL
+#define I210AlphaToARGBMatrix NULL
+#define I010AlphaToARGBMatrix NULL
+#endif
+#if LIBYUV_VERSION < 1771
+#define I422AlphaToARGBMatrix NULL
+#define I444AlphaToARGBMatrix NULL
+#endif
+#if LIBYUV_VERSION < 1756
+#define I400ToARGBMatrix NULL
+#endif
+
+// Two-step replacement for the conversions to 8-bit BT.601 YUV which are missing from libyuv.
+static int avifReorderARGBThenConvertToYUV(int (*ReorderARGB)(const uint8_t *, int, uint8_t *, int, int, int),
+                                           int (*ConvertToYUV)(const uint8_t *, int, uint8_t *, int, uint8_t *, int, uint8_t *, int, int, int),
+                                           const uint8_t * src_abgr,
+                                           int src_stride_abgr,
+                                           uint8_t * dst_y,
+                                           int dst_stride_y,
+                                           uint8_t * dst_u,
+                                           int dst_stride_u,
+                                           uint8_t * dst_v,
+                                           int dst_stride_v,
+                                           avifPixelFormat dst_format,
+                                           int width,
+                                           int height)
+{
+    // Only the vertically subsampled formats need to be processed by luma row pairs.
+    avifPixelFormatInfo format_info;
+    avifGetPixelFormatInfo(dst_format, &format_info);
+    const int min_num_rows = (format_info.chromaShiftY == 1) ? 2 : 1;
+
+    // A temporary buffer is needed to call ReorderARGB().
+    uint8_t * src_argb;
+    const int src_stride_argb = width * 4;
+    const int soft_allocation_limit = 16384; // Arbitrarily chosen trade-off between CPU and memory footprints.
+    int num_allocated_rows;
+    if ((height == 1) || ((int64_t)src_stride_argb * height <= soft_allocation_limit)) {
+        // Process the whole buffer in one go.
+        num_allocated_rows = height;
+    } else {
+        if ((int64_t)src_stride_argb * min_num_rows > INT_MAX) {
+            return -1;
+        }
+        // The last row of an odd number of RGB rows to be converted to vertically subsampled YUV is treated
+        // differently by libyuv, so make sure all steps but the last one process a multiple of min_num_rows rows.
+        // Try to process the highest multiple of min_num_rows rows possible in a single step without
+        // allocating more than soft_allocation_limit, unless min_num_rows rows need more than that.
+        num_allocated_rows = AVIF_MAX(1, soft_allocation_limit / (src_stride_argb * min_num_rows)) * min_num_rows;
+    }
+    src_argb = (uint8_t *)avifAlloc(num_allocated_rows * src_stride_argb);
+    if (!src_argb) {
+        return -1;
+    }
+
+    for (int y = 0; y < height; y += num_allocated_rows) {
+        const int num_rows = AVIF_MIN(num_allocated_rows, height - y);
+        if (ReorderARGB(src_abgr, src_stride_abgr, src_argb, src_stride_argb, width, num_rows) ||
+            ConvertToYUV(src_argb, src_stride_argb, dst_y, dst_stride_y, dst_u, dst_stride_u, dst_v, dst_stride_v, width, num_rows)) {
+            avifFree(src_argb);
+            return -1;
+        }
+        src_abgr += (size_t)num_rows * src_stride_abgr;
+        dst_y += (size_t)num_rows * dst_stride_y;
+        // Either chroma is not vertically subsampled, num_rows is even, or this is the last iteration.
+        dst_u += (size_t)(num_rows >> format_info.chromaShiftY) * dst_stride_u;
+        dst_v += (size_t)(num_rows >> format_info.chromaShiftY) * dst_stride_v;
+    }
+    avifFree(src_argb);
+    return 0;
+}
+
+#define AVIF_DEFINE_CONVERSION(NAME, REORDER_ARGB, CONVERT_TO_YUV, YUV_FORMAT) \
+    static int NAME(const uint8_t * src_abgr,                                  \
+                    int src_stride_abgr,                                       \
+                    uint8_t * dst_y,                                           \
+                    int dst_stride_y,                                          \
+                    uint8_t * dst_u,                                           \
+                    int dst_stride_u,                                          \
+                    uint8_t * dst_v,                                           \
+                    int dst_stride_v,                                          \
+                    int width,                                                 \
+                    int height)                                                \
+    {                                                                          \
+        return avifReorderARGBThenConvertToYUV(REORDER_ARGB,                   \
+                                               CONVERT_TO_YUV,                 \
+                                               src_abgr,                       \
+                                               src_stride_abgr,                \
+                                               dst_y,                          \
+                                               dst_stride_y,                   \
+                                               dst_u,                          \
+                                               dst_stride_u,                   \
+                                               dst_v,                          \
+                                               dst_stride_v,                   \
+                                               YUV_FORMAT,                     \
+                                               width,                          \
+                                               height);                        \
+    }
+
+#if LIBYUV_VERSION < 1840
+// AVIF_RGB_FORMAT_RGBA
+AVIF_DEFINE_CONVERSION(ABGRToJ422, ABGRToARGB, ARGBToJ422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(ABGRToJ420, ABGRToARGB, ARGBToJ420, AVIF_PIXEL_FORMAT_YUV420)
+#endif
+
+// These are not yet implemented in libyuv so they cannot be guarded by a version check.
+// The "avif" prefix avoids any redefinition if they are available in libyuv one day.
+// AVIF_RGB_FORMAT_RGB
+AVIF_DEFINE_CONVERSION(avifRAWToI444, RAWToARGB, ARGBToI444, AVIF_PIXEL_FORMAT_YUV444)
+AVIF_DEFINE_CONVERSION(avifRAWToI422, RAWToARGB, ARGBToI422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifRAWToJ422, RAWToARGB, ARGBToJ422, AVIF_PIXEL_FORMAT_YUV422)
+// AVIF_RGB_FORMAT_RGBA
+AVIF_DEFINE_CONVERSION(avifABGRToI444, ABGRToARGB, ARGBToI444, AVIF_PIXEL_FORMAT_YUV444)
+AVIF_DEFINE_CONVERSION(avifABGRToI422, ABGRToARGB, ARGBToI422, AVIF_PIXEL_FORMAT_YUV422)
+// AVIF_RGB_FORMAT_ARGB
+AVIF_DEFINE_CONVERSION(avifBGRAToI444, BGRAToARGB, ARGBToI444, AVIF_PIXEL_FORMAT_YUV444)
+AVIF_DEFINE_CONVERSION(avifBGRAToI422, BGRAToARGB, ARGBToI422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifBGRAToJ422, BGRAToARGB, ARGBToJ422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifBGRAToJ420, BGRAToARGB, ARGBToJ420, AVIF_PIXEL_FORMAT_YUV420)
+// AVIF_RGB_FORMAT_BGR
+AVIF_DEFINE_CONVERSION(avifRGB24ToI444, RGB24ToARGB, ARGBToI444, AVIF_PIXEL_FORMAT_YUV444)
+AVIF_DEFINE_CONVERSION(avifRGB24ToI422, RGB24ToARGB, ARGBToI422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifRGB24ToJ422, RGB24ToARGB, ARGBToJ422, AVIF_PIXEL_FORMAT_YUV422)
+// AVIF_RGB_FORMAT_ABGR
+AVIF_DEFINE_CONVERSION(avifRGBAToI444, RGBAToARGB, ARGBToI444, AVIF_PIXEL_FORMAT_YUV444)
+AVIF_DEFINE_CONVERSION(avifRGBAToI422, RGBAToARGB, ARGBToI422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifRGBAToJ422, RGBAToARGB, ARGBToJ422, AVIF_PIXEL_FORMAT_YUV422)
+AVIF_DEFINE_CONVERSION(avifRGBAToJ420, RGBAToARGB, ARGBToJ420, AVIF_PIXEL_FORMAT_YUV420)
+
+//--------------------------------------------------------------------------------------------------
+// RGB to YUV
+
+static avifResult avifImageRGBToYUVLibYUV8bpc(avifImage * image, const avifRGBImage * rgb);
+
+avifResult avifImageRGBToYUVLibYUV(avifImage * image, const avifRGBImage * rgb)
+{
+    // The width, height, and stride parameters of libyuv functions are all of the int type.
+    if (image->width > INT_MAX || image->height > INT_MAX || image->yuvRowBytes[AVIF_CHAN_Y] > INT_MAX || rgb->rowBytes > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    if ((image->depth == 8) && (rgb->depth == 8)) {
+        return avifImageRGBToYUVLibYUV8bpc(image, rgb);
+    }
+
+    // This function didn't do anything; use the built-in conversion.
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+
+avifResult avifImageRGBToYUVLibYUV8bpc(avifImage * image, const avifRGBImage * rgb)
+{
+    assert((image->depth == 8) && (rgb->depth == 8));
+    // libavif uses byte-order when describing pixel formats, such that the R in RGBA is the lowest address,
+    // similar to PNG. libyuv orders in word-order, so libavif's RGBA would be referred to in libyuv as ABGR.
+
+    // libyuv only handles BT.601 for RGB to YUV, and not all range/order/subsampling combinations.
+    // BT.470BG has the same coefficients as BT.601.
+    if ((image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_BT470BG) || (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_BT601)) {
+        if (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+            // Lookup table for RGB To Y (monochrome).
+            typedef int (*RGBtoY)(const uint8_t *, int, uint8_t *, int, int, int);
+            // First dimension is for avifRange.
+            RGBtoY lutRgbToY[2][AVIF_RGB_FORMAT_COUNT] = { // AVIF_RANGE_LIMITED
+                                                           {
+                                                               //          // AVIF_RGB_FORMAT_
+                                                               NULL,       // RGB
+                                                               NULL,       // RGBA
+                                                               NULL,       // ARGB
+                                                               NULL,       // BGR
+                                                               ARGBToI400, // BGRA
+                                                               NULL,       // ABGR
+                                                               NULL,       // RGB_565
+                                                           },
+                                                           // AVIF_RANGE_FULL
+                                                           {
+                                                               //           // AVIF_RGB_FORMAT_
+                                                               RAWToJ400,   // RGB
+                                                               ABGRToJ400,  // RGBA
+                                                               NULL,        // ARGB
+                                                               RGB24ToJ400, // BGR
+                                                               ARGBToJ400,  // BGRA
+                                                               RGBAToJ400,  // ABGR
+                                                               NULL         // RGB_565
+                                                           }
+            };
+            RGBtoY rgbToY = lutRgbToY[image->yuvRange][rgb->format];
+            if (rgbToY != NULL) {
+                if (rgbToY(rgb->pixels,
+                           rgb->rowBytes,
+                           image->yuvPlanes[AVIF_CHAN_Y],
+                           image->yuvRowBytes[AVIF_CHAN_Y],
+                           image->width,
+                           image->height) != 0) {
+                    return AVIF_RESULT_REFORMAT_FAILED;
+                }
+                return AVIF_RESULT_OK;
+            }
+        } else {
+            // Lookup table for RGB To YUV Matrix (average filter).
+            typedef int (*RGBtoYUV)(const uint8_t *, int, uint8_t *, int, uint8_t *, int, uint8_t *, int, int, int);
+            // First dimension is for avifRange.
+            RGBtoYUV lutRgbToYuv[2][AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+                // AVIF_RANGE_LIMITED
+                {
+                    // { NONE,    YUV444,    YUV422,    YUV420,    YUV400 }        // AVIF_RGB_FORMAT_
+                    { NULL, avifRAWToI444, avifRAWToI422, RAWToI420, NULL },       // RGB
+                    { NULL, avifABGRToI444, avifABGRToI422, ABGRToI420, NULL },    // RGBA
+                    { NULL, avifBGRAToI444, avifBGRAToI422, BGRAToI420, NULL },    // ARGB
+                    { NULL, avifRGB24ToI444, avifRGB24ToI422, RGB24ToI420, NULL }, // BGR
+                    { NULL, ARGBToI444, ARGBToI422, ARGBToI420, NULL },            // BGRA
+                    { NULL, avifRGBAToI444, avifRGBAToI422, RGBAToI420, NULL },    // ABGR
+                    { NULL, NULL, NULL, NULL, NULL }                               // RGB_565
+                },
+                // AVIF_RANGE_FULL
+                {
+                    // { NONE, YUV444, YUV422,   YUV420,   YUV400 }       // AVIF_RGB_FORMAT_
+                    { NULL, NULL, avifRAWToJ422, RAWToJ420, NULL },       // RGB
+                    { NULL, NULL, ABGRToJ422, ABGRToJ420, NULL },         // RGBA
+                    { NULL, NULL, avifBGRAToJ422, avifBGRAToJ420, NULL }, // ARGB
+                    { NULL, NULL, avifRGB24ToJ422, RGB24ToJ420, NULL },   // BGR
+                    { NULL, NULL, ARGBToJ422, ARGBToJ420, NULL },         // BGRA
+                    { NULL, NULL, avifRGBAToJ422, avifRGBAToJ420, NULL }, // ABGR
+                    { NULL, NULL, NULL, NULL, NULL }                      // RGB_565
+                }
+            };
+            RGBtoYUV rgbToYuv = lutRgbToYuv[image->yuvRange][rgb->format][image->yuvFormat];
+            if (rgbToYuv != NULL) {
+                if (rgbToYuv(rgb->pixels,
+                             rgb->rowBytes,
+                             image->yuvPlanes[AVIF_CHAN_Y],
+                             image->yuvRowBytes[AVIF_CHAN_Y],
+                             image->yuvPlanes[AVIF_CHAN_U],
+                             image->yuvRowBytes[AVIF_CHAN_U],
+                             image->yuvPlanes[AVIF_CHAN_V],
+                             image->yuvRowBytes[AVIF_CHAN_V],
+                             image->width,
+                             image->height) != 0) {
+                    return AVIF_RESULT_REFORMAT_FAILED;
+                }
+                return AVIF_RESULT_OK;
+            }
+        }
+    }
+    // TODO: Use SplitRGBPlane() for AVIF_MATRIX_COEFFICIENTS_IDENTITY if faster than the built-in implementation
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+
+//--------------------------------------------------------------------------------------------------
+// YUV to RGB
+
+// Note about the libyuv look up tables used for YUV-to-RGB conversion:
+// libavif uses byte-order when describing pixel formats, such that the R in RGBA is the lowest address, similar to PNG. libyuv
+// orders in word-order, so libavif's RGBA would be referred to in libyuv as ABGR.  In addition, swapping U and V in any of the
+// calls, along with using the Yvu matrix instead of Yuv matrix, swaps B and R in these orderings as well.
+//
+// libavif format            libyuv Func      UV matrix (and UV argument ordering)
+// --------------------      -------------    ------------------------------------
+// For 8-bit YUV:
+// AVIF_RGB_FORMAT_RGB       *ToRGB24Matrix   matrixYVU
+// AVIF_RGB_FORMAT_RGBA      *ToARGBMatrix    matrixYVU
+// AVIF_RGB_FORMAT_ARGB      *ToRGBAMatrix    matrixYVU
+// AVIF_RGB_FORMAT_BGR       *ToRGB24Matrix   matrixYUV
+// AVIF_RGB_FORMAT_BGRA      *ToARGBMatrix    matrixYUV
+// AVIF_RGB_FORMAT_ABGR      *ToRGBAMatrix    matrixYUV
+// AVIF_RGB_FORMAT_RGB_565   *ToRGB565Matrix  matrixYUV
+//
+// For 10-bit and 12-bit YUV:
+// AVIF_RGB_FORMAT_RGB       n/a              n/a
+// AVIF_RGB_FORMAT_RGBA      *ToARGBMatrix    matrixYVU
+// AVIF_RGB_FORMAT_ARGB      n/a              n/a
+// AVIF_RGB_FORMAT_BGR       n/a              n/a
+// AVIF_RGB_FORMAT_BGRA      *ToARGBMatrix    matrixYUV
+// AVIF_RGB_FORMAT_ABGR      n/a              n/a
+// AVIF_RGB_FORMAT_RGB_565   n/a              n/a
+
+// Lookup table for isYVU. If the entry in this table is AVIF_TRUE, then it
+// means that we are using a libyuv function with R and B channels swapped,
+// which requires U and V planes also be swapped.
+static const avifBool lutIsYVU[AVIF_RGB_FORMAT_COUNT] = {
+    //          // AVIF_RGB_FORMAT_
+    AVIF_TRUE,  // RGB
+    AVIF_TRUE,  // RGBA
+    AVIF_TRUE,  // ARGB
+    AVIF_FALSE, // BGR
+    AVIF_FALSE, // BGRA
+    AVIF_FALSE, // ABGR
+    AVIF_FALSE, // RGB_565
+};
+
+typedef int (*YUV400ToRGBMatrix)(const uint8_t *, int, uint8_t *, int, const struct YuvConstants *, int, int);
+typedef int (*YUVToRGBMatrixFilter)(const uint8_t *,
+                                    int,
+                                    const uint8_t *,
+                                    int,
+                                    const uint8_t *,
+                                    int,
+                                    uint8_t *,
+                                    int,
+                                    const struct YuvConstants *,
+                                    int,
+                                    int,
+                                    enum FilterMode);
+typedef int (*YUVAToRGBMatrixFilter)(const uint8_t *,
+                                     int,
+                                     const uint8_t *,
+                                     int,
+                                     const uint8_t *,
+                                     int,
+                                     const uint8_t *,
+                                     int,
+                                     uint8_t *,
+                                     int,
+                                     const struct YuvConstants *,
+                                     int,
+                                     int,
+                                     int,
+                                     enum FilterMode);
+typedef int (*YUVToRGBMatrix)(const uint8_t *, int, const uint8_t *, int, const uint8_t *, int, uint8_t *, int, const struct YuvConstants *, int, int);
+typedef int (*YUVAToRGBMatrix)(const uint8_t *,
+                               int,
+                               const uint8_t *,
+                               int,
+                               const uint8_t *,
+                               int,
+                               const uint8_t *,
+                               int,
+                               uint8_t *,
+                               int,
+                               const struct YuvConstants *,
+                               int,
+                               int,
+                               int);
+typedef int (*YUVToRGBMatrixFilterHighBitDepth)(const uint16_t *,
+                                                int,
+                                                const uint16_t *,
+                                                int,
+                                                const uint16_t *,
+                                                int,
+                                                uint8_t *,
+                                                int,
+                                                const struct YuvConstants *,
+                                                int,
+                                                int,
+                                                enum FilterMode);
+typedef int (*YUVAToRGBMatrixFilterHighBitDepth)(const uint16_t *,
+                                                 int,
+                                                 const uint16_t *,
+                                                 int,
+                                                 const uint16_t *,
+                                                 int,
+                                                 const uint16_t *,
+                                                 int,
+                                                 uint8_t *,
+                                                 int,
+                                                 const struct YuvConstants *,
+                                                 int,
+                                                 int,
+                                                 int,
+                                                 enum FilterMode);
+typedef int (*YUVToRGBMatrixHighBitDepth)(const uint16_t *,
+                                          int,
+                                          const uint16_t *,
+                                          int,
+                                          const uint16_t *,
+                                          int,
+                                          uint8_t *,
+                                          int,
+                                          const struct YuvConstants *,
+                                          int,
+                                          int);
+typedef int (*YUVAToRGBMatrixHighBitDepth)(const uint16_t *,
+                                           int,
+                                           const uint16_t *,
+                                           int,
+                                           const uint16_t *,
+                                           int,
+                                           const uint16_t *,
+                                           int,
+                                           uint8_t *,
+                                           int,
+                                           const struct YuvConstants *,
+                                           int,
+                                           int,
+                                           int);
+
+// At most one pointer in this struct will be not-NULL.
+typedef struct
+{
+    YUV400ToRGBMatrix yuv400ToRgbMatrix;
+    YUVToRGBMatrixFilter yuvToRgbMatrixFilter;
+    YUVAToRGBMatrixFilter yuvaToRgbMatrixFilter;
+    YUVToRGBMatrix yuvToRgbMatrix;
+    YUVAToRGBMatrix yuvaToRgbMatrix;
+    YUVToRGBMatrixFilterHighBitDepth yuvToRgbMatrixFilterHighBitDepth;
+    YUVAToRGBMatrixFilterHighBitDepth yuvaToRgbMatrixFilterHighBitDepth;
+    YUVToRGBMatrixHighBitDepth yuvToRgbMatrixHighBitDepth;
+    YUVAToRGBMatrixHighBitDepth yuvaToRgbMatrixHighBitDepth;
+} LibyuvConversionFunction;
+
+// Only allow nearest-neighbor filter if explicitly specified or left as default.
+static avifBool nearestNeighborFilterAllowed(int chromaUpsampling)
+{
+    return chromaUpsampling != AVIF_CHROMA_UPSAMPLING_BILINEAR && chromaUpsampling != AVIF_CHROMA_UPSAMPLING_BEST_QUALITY;
+}
+
+// Returns AVIF_TRUE if the given yuvFormat and yuvDepth can be converted to 8-bit RGB using libyuv, AVIF_FALSE otherwise. When
+// AVIF_TRUE is returned, exactly one function pointers will be populated with the appropriate conversion function. If
+// alphaPreferred is set to AVIF_TRUE, then a function that can also copy the alpha channel will be preferred if available.
+static avifBool getLibYUVConversionFunction(avifPixelFormat yuvFormat,
+                                            int yuvDepth,
+                                            avifRGBImage * rgb,
+                                            avifBool alphaPreferred,
+                                            LibyuvConversionFunction * lcf)
+{
+    // Lookup table for 8-bit YUV400 to 8-bit RGB Matrix.
+    static const YUV400ToRGBMatrix lutYuv400ToRgbMatrix[AVIF_RGB_FORMAT_COUNT] = {
+        //                // AVIF_RGB_FORMAT_
+        NULL,             // RGB
+        I400ToARGBMatrix, // RGBA
+        NULL,             // ARGB
+        NULL,             // BGR
+        I400ToARGBMatrix, // BGRA
+        NULL,             // ABGR
+        NULL,             // RGB_565
+    };
+
+    // Lookup table for 8-bit YUV To 8-bit RGB Matrix (with filter).
+    static const YUVToRGBMatrixFilter lutYuvToRgbMatrixFilter[AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+        { NULL, NULL, I422ToRGB24MatrixFilter, I420ToRGB24MatrixFilter, NULL }, // RGB
+        { NULL, NULL, I422ToARGBMatrixFilter, I420ToARGBMatrixFilter, NULL },   // RGBA
+        { NULL, NULL, NULL, NULL, NULL },                                       // ARGB
+        { NULL, NULL, I422ToRGB24MatrixFilter, I420ToRGB24MatrixFilter, NULL }, // BGR
+        { NULL, NULL, I422ToARGBMatrixFilter, I420ToARGBMatrixFilter, NULL },   // BGRA
+        { NULL, NULL, NULL, NULL, NULL },                                       // ABGR
+        { NULL, NULL, NULL, NULL, NULL },                                       // RGB_565
+    };
+
+    // Lookup table for 8-bit YUVA To 8-bit RGB Matrix (with filter).
+    static const YUVAToRGBMatrixFilter lutYuvaToRgbMatrixFilter[AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+        { NULL, NULL, NULL, NULL, NULL },                                               // RGB
+        { NULL, NULL, I422AlphaToARGBMatrixFilter, I420AlphaToARGBMatrixFilter, NULL }, // RGBA
+        { NULL, NULL, NULL, NULL, NULL },                                               // ARGB
+        { NULL, NULL, NULL, NULL, NULL },                                               // BGR
+        { NULL, NULL, I422AlphaToARGBMatrixFilter, I420AlphaToARGBMatrixFilter, NULL }, // BGRA
+        { NULL, NULL, NULL, NULL, NULL },                                               // ABGR
+        { NULL, NULL, NULL, NULL, NULL },                                               // RGB_565
+    };
+
+    // Lookup table for 8-bit YUV To 8-bit RGB Matrix (4:4:4 or nearest-neighbor filter).
+    static const YUVToRGBMatrix lutYuvToRgbMatrix[AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+        { NULL, I444ToRGB24Matrix, NULL, I420ToRGB24Matrix, NULL },           // RGB
+        { NULL, I444ToARGBMatrix, I422ToARGBMatrix, I420ToARGBMatrix, NULL }, // RGBA
+        { NULL, NULL, I422ToRGBAMatrix, I420ToRGBAMatrix, NULL },             // ARGB
+        { NULL, I444ToRGB24Matrix, NULL, I420ToRGB24Matrix, NULL },           // BGR
+        { NULL, I444ToARGBMatrix, I422ToARGBMatrix, I420ToARGBMatrix, NULL }, // BGRA
+        { NULL, NULL, I422ToRGBAMatrix, I420ToRGBAMatrix, NULL },             // ABGR
+        { NULL, NULL, I422ToRGB565Matrix, I420ToRGB565Matrix, NULL },         // RGB_565
+    };
+
+    // Lookup table for 8-bit YUVA To 8-bit RGB Matrix (4:4:4 or nearest-neighbor filter).
+    static const YUVAToRGBMatrix lutYuvaToRgbMatrix[AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+        { NULL, NULL, NULL, NULL, NULL },                                                    // RGB
+        { NULL, I444AlphaToARGBMatrix, I422AlphaToARGBMatrix, I420AlphaToARGBMatrix, NULL }, // RGBA
+        { NULL, NULL, NULL, NULL, NULL },                                                    // ARGB
+        { NULL, NULL, NULL, NULL, NULL },                                                    // BGR
+        { NULL, I444AlphaToARGBMatrix, I422AlphaToARGBMatrix, I420AlphaToARGBMatrix, NULL }, // BGRA
+        { NULL, NULL, NULL, NULL, NULL },                                                    // ABGR
+        { NULL, NULL, NULL, NULL, NULL },                                                    // RGB_565
+    };
+
+    // Lookup table for YUV To RGB Matrix (with filter).  First dimension is for the YUV bit depth.
+    static const YUVToRGBMatrixFilterHighBitDepth lutYuvToRgbMatrixFilterHighBitDepth[2][AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // 10bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL },                                     // RGB
+            { NULL, NULL, I210ToARGBMatrixFilter, I010ToARGBMatrixFilter, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL },                                     // ARGB
+            { NULL, NULL, NULL, NULL, NULL },                                     // BGR
+            { NULL, NULL, I210ToARGBMatrixFilter, I010ToARGBMatrixFilter, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL },                                     // ABGR
+            { NULL, NULL, NULL, NULL, NULL },                                     // RGB_565
+        },
+        // 12bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 } // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL }, // RGB
+            { NULL, NULL, NULL, NULL, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL }, // ARGB
+            { NULL, NULL, NULL, NULL, NULL }, // BGR
+            { NULL, NULL, NULL, NULL, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL }, // ABGR
+            { NULL, NULL, NULL, NULL, NULL }, // RGB_565
+        },
+    };
+
+    // Lookup table for YUVA To RGB Matrix (with filter).  First dimension is for the YUV bit depth.
+    static const YUVAToRGBMatrixFilterHighBitDepth lutYuvaToRgbMatrixFilterHighBitDepth[2][AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // 10bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL },                                               // RGB
+            { NULL, NULL, I210AlphaToARGBMatrixFilter, I010AlphaToARGBMatrixFilter, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL },                                               // ARGB
+            { NULL, NULL, NULL, NULL, NULL },                                               // BGR
+            { NULL, NULL, I210AlphaToARGBMatrixFilter, I010AlphaToARGBMatrixFilter, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL },                                               // ABGR
+            { NULL, NULL, NULL, NULL, NULL },                                               // RGB_565
+        },
+        // 12bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 } // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL }, // RGB
+            { NULL, NULL, NULL, NULL, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL }, // ARGB
+            { NULL, NULL, NULL, NULL, NULL }, // BGR
+            { NULL, NULL, NULL, NULL, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL }, // ABGR
+            { NULL, NULL, NULL, NULL, NULL }, // RGB_565
+        },
+    };
+
+    // Lookup table for YUV To RGB Matrix (4:4:4 or nearest-neighbor filter).  First dimension is for the YUV bit depth.
+    static const YUVToRGBMatrixHighBitDepth lutYuvToRgbMatrixHighBitDepth[2][AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // 10bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL },                                     // RGB
+            { NULL, I410ToARGBMatrix, I210ToARGBMatrix, I010ToARGBMatrix, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL },                                     // ARGB
+            { NULL, NULL, NULL, NULL, NULL },                                     // BGR
+            { NULL, I410ToARGBMatrix, I210ToARGBMatrix, I010ToARGBMatrix, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL },                                     // ABGR
+            { NULL, NULL, NULL, NULL, NULL },                                     // RGB_565
+        },
+        // 12bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }   // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL },             // RGB
+            { NULL, NULL, NULL, I012ToARGBMatrix, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL },             // ARGB
+            { NULL, NULL, NULL, NULL, NULL },             // BGR
+            { NULL, NULL, NULL, I012ToARGBMatrix, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL },             // ABGR
+            { NULL, NULL, NULL, NULL, NULL },             // RGB_565
+        },
+    };
+
+    // Lookup table for YUVA To RGB Matrix (4:4:4 or nearest-neighbor filter).  First dimension is for the YUV bit depth.
+    static const YUVAToRGBMatrixHighBitDepth lutYuvaToRgbMatrixHighBitDepth[2][AVIF_RGB_FORMAT_COUNT][AVIF_PIXEL_FORMAT_COUNT] = {
+        // 10bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }                           // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL },                                                    // RGB
+            { NULL, I410AlphaToARGBMatrix, I210AlphaToARGBMatrix, I010AlphaToARGBMatrix, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL },                                                    // ARGB
+            { NULL, NULL, NULL, NULL, NULL },                                                    // BGR
+            { NULL, I410AlphaToARGBMatrix, I210AlphaToARGBMatrix, I010AlphaToARGBMatrix, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL },                                                    // ABGR
+            { NULL, NULL, NULL, NULL, NULL },                                                    // RGB_565
+        },
+        // 12bpc
+        {
+            // { NONE, YUV444, YUV422, YUV420, YUV400 }   // AVIF_RGB_FORMAT_
+            { NULL, NULL, NULL, NULL, NULL }, // RGB
+            { NULL, NULL, NULL, NULL, NULL }, // RGBA
+            { NULL, NULL, NULL, NULL, NULL }, // ARGB
+            { NULL, NULL, NULL, NULL, NULL }, // BGR
+            { NULL, NULL, NULL, NULL, NULL }, // BGRA
+            { NULL, NULL, NULL, NULL, NULL }, // ABGR
+            { NULL, NULL, NULL, NULL, NULL }, // RGB_565
+        },
+    };
+
+    memset(lcf, 0, sizeof(*lcf));
+    assert(rgb->depth == 8);
+    if (yuvDepth > 8) {
+        assert(yuvDepth == 10 || yuvDepth == 12);
+        int depthIndex = (yuvDepth == 10) ? 0 : 1;
+        if (yuvFormat != AVIF_PIXEL_FORMAT_YUV444) {
+            if (alphaPreferred) {
+                lcf->yuvaToRgbMatrixFilterHighBitDepth = lutYuvaToRgbMatrixFilterHighBitDepth[depthIndex][rgb->format][yuvFormat];
+                if (lcf->yuvaToRgbMatrixFilterHighBitDepth != NULL) {
+                    return AVIF_TRUE;
+                }
+            }
+            lcf->yuvToRgbMatrixFilterHighBitDepth = lutYuvToRgbMatrixFilterHighBitDepth[depthIndex][rgb->format][yuvFormat];
+            if (lcf->yuvToRgbMatrixFilterHighBitDepth != NULL) {
+                return AVIF_TRUE;
+            }
+        }
+        if (yuvFormat == AVIF_PIXEL_FORMAT_YUV444 || nearestNeighborFilterAllowed(rgb->chromaUpsampling)) {
+            if (alphaPreferred) {
+                lcf->yuvaToRgbMatrixHighBitDepth = lutYuvaToRgbMatrixHighBitDepth[depthIndex][rgb->format][yuvFormat];
+                if (lcf->yuvaToRgbMatrixHighBitDepth != NULL) {
+                    return AVIF_TRUE;
+                }
+            }
+            lcf->yuvToRgbMatrixHighBitDepth = lutYuvToRgbMatrixHighBitDepth[depthIndex][rgb->format][yuvFormat];
+            if (lcf->yuvToRgbMatrixHighBitDepth != NULL) {
+                return AVIF_TRUE;
+            }
+        }
+        // Fallthrough is intentional. No high bitdepth libyuv function was found. Check if there is an 8-bit libyuv function which
+        // can used with a downshift.
+    }
+    if (yuvFormat == AVIF_PIXEL_FORMAT_YUV400) {
+        lcf->yuv400ToRgbMatrix = lutYuv400ToRgbMatrix[rgb->format];
+        return lcf->yuv400ToRgbMatrix != NULL;
+    }
+    if (yuvFormat != AVIF_PIXEL_FORMAT_YUV444) {
+        if (alphaPreferred) {
+            lcf->yuvaToRgbMatrixFilter = lutYuvaToRgbMatrixFilter[rgb->format][yuvFormat];
+            if (lcf->yuvaToRgbMatrixFilter != NULL) {
+                return AVIF_TRUE;
+            }
+        }
+        lcf->yuvToRgbMatrixFilter = lutYuvToRgbMatrixFilter[rgb->format][yuvFormat];
+        if (lcf->yuvToRgbMatrixFilter != NULL) {
+            return AVIF_TRUE;
+        }
+        if (!nearestNeighborFilterAllowed(rgb->chromaUpsampling)) {
+            return AVIF_FALSE;
+        }
+    }
+    if (alphaPreferred) {
+        lcf->yuvaToRgbMatrix = lutYuvaToRgbMatrix[rgb->format][yuvFormat];
+        if (lcf->yuvaToRgbMatrix != NULL) {
+            return AVIF_TRUE;
+        }
+    }
+    lcf->yuvToRgbMatrix = lutYuvToRgbMatrix[rgb->format][yuvFormat];
+    return lcf->yuvToRgbMatrix != NULL;
+}
+
+static void getLibYUVConstants(const avifImage * image, const struct YuvConstants ** matrixYUV, const struct YuvConstants ** matrixYVU)
+{
+    // Allow the identity matrix to be used with YUV 4:0:0. Replace the identity matrix with
+    // MatrixCoefficients 6 (BT.601).
+    const avifBool yuv400WithIdentityMatrix = (image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400) &&
+                                              (image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_IDENTITY);
+    const avifMatrixCoefficients matrixCoefficients = yuv400WithIdentityMatrix ? AVIF_MATRIX_COEFFICIENTS_BT601 : image->matrixCoefficients;
+    if (image->yuvRange == AVIF_RANGE_FULL) {
+        switch (matrixCoefficients) {
+            // BT.709 full range YuvConstants were added in libyuv version 1772.
+            // See https://chromium-review.googlesource.com/c/libyuv/libyuv/+/2646472.
+            case AVIF_MATRIX_COEFFICIENTS_BT709:
+#if LIBYUV_VERSION >= 1772
+                *matrixYUV = &kYuvF709Constants;
+                *matrixYVU = &kYvuF709Constants;
+#endif
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_BT470BG:
+            case AVIF_MATRIX_COEFFICIENTS_BT601:
+            case AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED:
+                *matrixYUV = &kYuvJPEGConstants;
+                *matrixYVU = &kYvuJPEGConstants;
+                break;
+            // BT.2020 full range YuvConstants were added in libyuv version 1775.
+            // See https://chromium-review.googlesource.com/c/libyuv/libyuv/+/2678859.
+            case AVIF_MATRIX_COEFFICIENTS_BT2020_NCL:
+#if LIBYUV_VERSION >= 1775
+                *matrixYUV = &kYuvV2020Constants;
+                *matrixYVU = &kYvuV2020Constants;
+#endif
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_NCL:
+                switch (image->colorPrimaries) {
+                    case AVIF_COLOR_PRIMARIES_BT709:
+                    case AVIF_COLOR_PRIMARIES_UNSPECIFIED:
+#if LIBYUV_VERSION >= 1772
+                        *matrixYUV = &kYuvF709Constants;
+                        *matrixYVU = &kYvuF709Constants;
+#endif
+                        break;
+                    case AVIF_COLOR_PRIMARIES_BT470BG:
+                    case AVIF_COLOR_PRIMARIES_BT601:
+                        *matrixYUV = &kYuvJPEGConstants;
+                        *matrixYVU = &kYvuJPEGConstants;
+                        break;
+                    case AVIF_COLOR_PRIMARIES_BT2020:
+#if LIBYUV_VERSION >= 1775
+                        *matrixYUV = &kYuvV2020Constants;
+                        *matrixYVU = &kYvuV2020Constants;
+#endif
+                        break;
+
+                    case AVIF_COLOR_PRIMARIES_UNKNOWN:
+                    case AVIF_COLOR_PRIMARIES_BT470M:
+                    case AVIF_COLOR_PRIMARIES_SMPTE240:
+                    case AVIF_COLOR_PRIMARIES_GENERIC_FILM:
+                    case AVIF_COLOR_PRIMARIES_XYZ:
+                    case AVIF_COLOR_PRIMARIES_SMPTE431:
+                    case AVIF_COLOR_PRIMARIES_SMPTE432:
+                    case AVIF_COLOR_PRIMARIES_EBU3213:
+                        break;
+                }
+                break;
+
+            case AVIF_MATRIX_COEFFICIENTS_IDENTITY:
+            case AVIF_MATRIX_COEFFICIENTS_FCC:
+            case AVIF_MATRIX_COEFFICIENTS_SMPTE240:
+            case AVIF_MATRIX_COEFFICIENTS_YCGCO:
+            case AVIF_MATRIX_COEFFICIENTS_BT2020_CL:
+            case AVIF_MATRIX_COEFFICIENTS_SMPTE2085:
+            case AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL:
+            case AVIF_MATRIX_COEFFICIENTS_ICTCP:
+                break;
+        }
+    } else { // image->yuvRange == AVIF_RANGE_LIMITED
+        switch (matrixCoefficients) {
+            case AVIF_MATRIX_COEFFICIENTS_BT709:
+                *matrixYUV = &kYuvH709Constants;
+                *matrixYVU = &kYvuH709Constants;
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_BT470BG:
+            case AVIF_MATRIX_COEFFICIENTS_BT601:
+            case AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED:
+                *matrixYUV = &kYuvI601Constants;
+                *matrixYVU = &kYvuI601Constants;
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_BT2020_NCL:
+                *matrixYUV = &kYuv2020Constants;
+                *matrixYVU = &kYvu2020Constants;
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_NCL:
+                switch (image->colorPrimaries) {
+                    case AVIF_COLOR_PRIMARIES_BT709:
+                    case AVIF_COLOR_PRIMARIES_UNSPECIFIED:
+                        *matrixYUV = &kYuvH709Constants;
+                        *matrixYVU = &kYvuH709Constants;
+                        break;
+                    case AVIF_COLOR_PRIMARIES_BT470BG:
+                    case AVIF_COLOR_PRIMARIES_BT601:
+                        *matrixYUV = &kYuvI601Constants;
+                        *matrixYVU = &kYvuI601Constants;
+                        break;
+                    case AVIF_COLOR_PRIMARIES_BT2020:
+                        *matrixYUV = &kYuv2020Constants;
+                        *matrixYVU = &kYvu2020Constants;
+                        break;
+
+                    case AVIF_COLOR_PRIMARIES_UNKNOWN:
+                    case AVIF_COLOR_PRIMARIES_BT470M:
+                    case AVIF_COLOR_PRIMARIES_SMPTE240:
+                    case AVIF_COLOR_PRIMARIES_GENERIC_FILM:
+                    case AVIF_COLOR_PRIMARIES_XYZ:
+                    case AVIF_COLOR_PRIMARIES_SMPTE431:
+                    case AVIF_COLOR_PRIMARIES_SMPTE432:
+                    case AVIF_COLOR_PRIMARIES_EBU3213:
+                        break;
+                }
+                break;
+            case AVIF_MATRIX_COEFFICIENTS_IDENTITY:
+            case AVIF_MATRIX_COEFFICIENTS_FCC:
+            case AVIF_MATRIX_COEFFICIENTS_SMPTE240:
+            case AVIF_MATRIX_COEFFICIENTS_YCGCO:
+            case AVIF_MATRIX_COEFFICIENTS_BT2020_CL:
+            case AVIF_MATRIX_COEFFICIENTS_SMPTE2085:
+            case AVIF_MATRIX_COEFFICIENTS_CHROMA_DERIVED_CL:
+            case AVIF_MATRIX_COEFFICIENTS_ICTCP:
+                break;
+        }
+    }
+}
+
+static avifResult avifImageDownshiftTo8bpc(const avifImage * image, avifImage * image8, avifBool downshiftAlpha)
+{
+    avifImageSetDefaults(image8);
+    avifImageCopyNoAlloc(image8, image);
+    image8->depth = 8;
+    // downshiftAlpha will be true only if the image has an alpha plane. So it is safe to pass AVIF_PLANES_ALL here in that case.
+    assert(!downshiftAlpha || image->alphaPlane);
+    AVIF_CHECKRES(avifImageAllocatePlanes(image8, downshiftAlpha ? AVIF_PLANES_ALL : AVIF_PLANES_YUV));
+    // 16384 for 10-bit and 4096 for 12-bit.
+    const int scale = 1 << (24 - image->depth);
+    for (int plane = AVIF_CHAN_Y; plane <= (downshiftAlpha ? AVIF_CHAN_A : AVIF_CHAN_V); ++plane) {
+        const uint32_t planeWidth = avifImagePlaneWidth(image, plane);
+        if (planeWidth == 0) {
+            continue;
+        }
+        Convert16To8Plane((const uint16_t *)avifImagePlane(image, plane),
+                          avifImagePlaneRowBytes(image, plane) / 2,
+                          avifImagePlane(image8, plane),
+                          avifImagePlaneRowBytes(image8, plane),
+                          scale,
+                          planeWidth,
+                          avifImagePlaneHeight(image, plane));
+    }
+    return AVIF_RESULT_OK;
+}
+
+IGNORE_CFI_ICALL avifResult avifImageYUVToRGBLibYUV(const avifImage * image, avifRGBImage * rgb, avifBool reformatAlpha, avifBool * alphaReformattedWithLibYUV)
+{
+    *alphaReformattedWithLibYUV = AVIF_FALSE;
+    // The width, height, and stride parameters of libyuv functions are all of the int type.
+    if (image->width > INT_MAX || image->height > INT_MAX || image->yuvRowBytes[AVIF_CHAN_Y] > INT_MAX || rgb->rowBytes > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (rgb->depth != 8 || (image->depth != 8 && image->depth != 10 && image->depth != 12)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    // Find the correct libyuv YuvConstants, based on range and CP/MC
+    const struct YuvConstants * matrixYUV = NULL;
+    const struct YuvConstants * matrixYVU = NULL;
+    getLibYUVConstants(image, &matrixYUV, &matrixYVU);
+    if (!matrixYVU) {
+        // No YuvConstants exist for the current image; use the built-in YUV conversion
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    LibyuvConversionFunction lcf;
+    const avifBool alphaPreferred = reformatAlpha && image->alphaPlane && image->alphaRowBytes;
+    if (!getLibYUVConversionFunction(image->yuvFormat, image->depth, rgb, alphaPreferred, &lcf)) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (!image->alphaPlane || !image->alphaRowBytes) {
+        // If the image does not have an alpha plane, then libyuv always prefills the output RGB image with opaque alpha values.
+        *alphaReformattedWithLibYUV = AVIF_TRUE;
+    }
+    avifBool isYVU = lutIsYVU[rgb->format];
+    const struct YuvConstants * matrix = isYVU ? matrixYVU : matrixYUV;
+    int libyuvResult = -1;
+    int uPlaneIndex = isYVU ? AVIF_CHAN_V : AVIF_CHAN_U;
+    int vPlaneIndex = isYVU ? AVIF_CHAN_U : AVIF_CHAN_V;
+    const enum FilterMode filter =
+        ((rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_FASTEST) || (rgb->chromaUpsampling == AVIF_CHROMA_UPSAMPLING_NEAREST))
+            ? kFilterNone
+            : kFilterBilinear;
+    if (lcf.yuvToRgbMatrixFilterHighBitDepth != NULL) {
+        libyuvResult = lcf.yuvToRgbMatrixFilterHighBitDepth((const uint16_t *)image->yuvPlanes[AVIF_CHAN_Y],
+                                                            image->yuvRowBytes[AVIF_CHAN_Y] / 2,
+                                                            (const uint16_t *)image->yuvPlanes[uPlaneIndex],
+                                                            image->yuvRowBytes[uPlaneIndex] / 2,
+                                                            (const uint16_t *)image->yuvPlanes[vPlaneIndex],
+                                                            image->yuvRowBytes[vPlaneIndex] / 2,
+                                                            rgb->pixels,
+                                                            rgb->rowBytes,
+                                                            matrix,
+                                                            image->width,
+                                                            image->height,
+                                                            filter);
+    } else if (lcf.yuvaToRgbMatrixFilterHighBitDepth != NULL) {
+        libyuvResult = lcf.yuvaToRgbMatrixFilterHighBitDepth((const uint16_t *)image->yuvPlanes[AVIF_CHAN_Y],
+                                                             image->yuvRowBytes[AVIF_CHAN_Y] / 2,
+                                                             (const uint16_t *)image->yuvPlanes[uPlaneIndex],
+                                                             image->yuvRowBytes[uPlaneIndex] / 2,
+                                                             (const uint16_t *)image->yuvPlanes[vPlaneIndex],
+                                                             image->yuvRowBytes[vPlaneIndex] / 2,
+                                                             (const uint16_t *)image->alphaPlane,
+                                                             image->alphaRowBytes / 2,
+                                                             rgb->pixels,
+                                                             rgb->rowBytes,
+                                                             matrix,
+                                                             image->width,
+                                                             image->height,
+                                                             /*attenuate=*/0,
+                                                             filter);
+        *alphaReformattedWithLibYUV = AVIF_TRUE;
+    } else if (lcf.yuvToRgbMatrixHighBitDepth != NULL) {
+        libyuvResult = lcf.yuvToRgbMatrixHighBitDepth((const uint16_t *)image->yuvPlanes[AVIF_CHAN_Y],
+                                                      image->yuvRowBytes[AVIF_CHAN_Y] / 2,
+                                                      (const uint16_t *)image->yuvPlanes[uPlaneIndex],
+                                                      image->yuvRowBytes[uPlaneIndex] / 2,
+                                                      (const uint16_t *)image->yuvPlanes[vPlaneIndex],
+                                                      image->yuvRowBytes[vPlaneIndex] / 2,
+                                                      rgb->pixels,
+                                                      rgb->rowBytes,
+                                                      matrix,
+                                                      image->width,
+                                                      image->height);
+    } else if (lcf.yuvaToRgbMatrixHighBitDepth != NULL) {
+        libyuvResult = lcf.yuvaToRgbMatrixHighBitDepth((const uint16_t *)image->yuvPlanes[AVIF_CHAN_Y],
+                                                       image->yuvRowBytes[AVIF_CHAN_Y] / 2,
+                                                       (const uint16_t *)image->yuvPlanes[uPlaneIndex],
+                                                       image->yuvRowBytes[uPlaneIndex] / 2,
+                                                       (const uint16_t *)image->yuvPlanes[vPlaneIndex],
+                                                       image->yuvRowBytes[vPlaneIndex] / 2,
+                                                       (const uint16_t *)image->alphaPlane,
+                                                       image->alphaRowBytes / 2,
+                                                       rgb->pixels,
+                                                       rgb->rowBytes,
+                                                       matrix,
+                                                       image->width,
+                                                       image->height,
+                                                       /*attentuate=*/0);
+        *alphaReformattedWithLibYUV = AVIF_TRUE;
+    } else {
+        avifImage image8;
+        avifBool inputIsHighBitDepth = image->depth > 8;
+        if (inputIsHighBitDepth) {
+            const avifBool downshiftAlpha = (lcf.yuvaToRgbMatrixFilter != NULL || lcf.yuvaToRgbMatrix != NULL);
+            AVIF_CHECKRES(avifImageDownshiftTo8bpc(image, &image8, downshiftAlpha));
+            image = &image8;
+        }
+        if (lcf.yuv400ToRgbMatrix != NULL) {
+            libyuvResult = lcf.yuv400ToRgbMatrix(image->yuvPlanes[AVIF_CHAN_Y],
+                                                 image->yuvRowBytes[AVIF_CHAN_Y],
+                                                 rgb->pixels,
+                                                 rgb->rowBytes,
+                                                 matrix,
+                                                 image->width,
+                                                 image->height);
+        } else if (lcf.yuvToRgbMatrixFilter != NULL) {
+            libyuvResult = lcf.yuvToRgbMatrixFilter(image->yuvPlanes[AVIF_CHAN_Y],
+                                                    image->yuvRowBytes[AVIF_CHAN_Y],
+                                                    image->yuvPlanes[uPlaneIndex],
+                                                    image->yuvRowBytes[uPlaneIndex],
+                                                    image->yuvPlanes[vPlaneIndex],
+                                                    image->yuvRowBytes[vPlaneIndex],
+                                                    rgb->pixels,
+                                                    rgb->rowBytes,
+                                                    matrix,
+                                                    image->width,
+                                                    image->height,
+                                                    filter);
+        } else if (lcf.yuvaToRgbMatrixFilter != NULL) {
+            libyuvResult = lcf.yuvaToRgbMatrixFilter(image->yuvPlanes[AVIF_CHAN_Y],
+                                                     image->yuvRowBytes[AVIF_CHAN_Y],
+                                                     image->yuvPlanes[uPlaneIndex],
+                                                     image->yuvRowBytes[uPlaneIndex],
+                                                     image->yuvPlanes[vPlaneIndex],
+                                                     image->yuvRowBytes[vPlaneIndex],
+                                                     image->alphaPlane,
+                                                     image->alphaRowBytes,
+                                                     rgb->pixels,
+                                                     rgb->rowBytes,
+                                                     matrix,
+                                                     image->width,
+                                                     image->height,
+                                                     /*attenuate=*/0,
+                                                     filter);
+            *alphaReformattedWithLibYUV = AVIF_TRUE;
+        } else if (lcf.yuvToRgbMatrix != NULL) {
+            libyuvResult = lcf.yuvToRgbMatrix(image->yuvPlanes[AVIF_CHAN_Y],
+                                              image->yuvRowBytes[AVIF_CHAN_Y],
+                                              image->yuvPlanes[uPlaneIndex],
+                                              image->yuvRowBytes[uPlaneIndex],
+                                              image->yuvPlanes[vPlaneIndex],
+                                              image->yuvRowBytes[vPlaneIndex],
+                                              rgb->pixels,
+                                              rgb->rowBytes,
+                                              matrix,
+                                              image->width,
+                                              image->height);
+        } else if (lcf.yuvaToRgbMatrix != NULL) {
+            libyuvResult = lcf.yuvaToRgbMatrix(image->yuvPlanes[AVIF_CHAN_Y],
+                                               image->yuvRowBytes[AVIF_CHAN_Y],
+                                               image->yuvPlanes[uPlaneIndex],
+                                               image->yuvRowBytes[uPlaneIndex],
+                                               image->yuvPlanes[vPlaneIndex],
+                                               image->yuvRowBytes[vPlaneIndex],
+                                               image->alphaPlane,
+                                               image->alphaRowBytes,
+                                               rgb->pixels,
+                                               rgb->rowBytes,
+                                               matrix,
+                                               image->width,
+                                               image->height,
+                                               /*attenuate=*/0);
+            *alphaReformattedWithLibYUV = AVIF_TRUE;
+        }
+        if (inputIsHighBitDepth) {
+            avifImageFreePlanes(&image8, AVIF_PLANES_ALL);
+            image = NULL;
+        }
+    }
+    return (libyuvResult != 0) ? AVIF_RESULT_REFORMAT_FAILED : AVIF_RESULT_OK;
+}
+
+//--------------------------------------------------------------------------------------------------
+
+avifResult avifRGBImagePremultiplyAlphaLibYUV(avifRGBImage * rgb)
+{
+    // See if the current settings can be accomplished with libyuv, and use it (if possible).
+
+    // The width, height, and stride parameters of libyuv functions are all of the int type.
+    if (rgb->width > INT_MAX || rgb->height > INT_MAX || rgb->rowBytes > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (rgb->depth != 8) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // libavif uses byte-order when describing pixel formats, such that the R in RGBA is the lowest address,
+    // similar to PNG. libyuv orders in word-order, so libavif's RGBA would be referred to in libyuv as ABGR.
+
+    // Order of RGB doesn't matter here.
+    if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+        if (ARGBAttenuate(rgb->pixels, rgb->rowBytes, rgb->pixels, rgb->rowBytes, rgb->width, rgb->height) != 0) {
+            return AVIF_RESULT_REFORMAT_FAILED;
+        }
+        return AVIF_RESULT_OK;
+    }
+
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+
+avifResult avifRGBImageUnpremultiplyAlphaLibYUV(avifRGBImage * rgb)
+{
+    // See if the current settings can be accomplished with libyuv, and use it (if possible).
+
+    // The width, height, and stride parameters of libyuv functions are all of the int type.
+    if (rgb->width > INT_MAX || rgb->height > INT_MAX || rgb->rowBytes > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    if (rgb->depth != 8) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    // libavif uses byte-order when describing pixel formats, such that the R in RGBA is the lowest address,
+    // similar to PNG. libyuv orders in word-order, so libavif's RGBA would be referred to in libyuv as ABGR.
+
+    if (rgb->format == AVIF_RGB_FORMAT_RGBA || rgb->format == AVIF_RGB_FORMAT_BGRA) {
+        if (ARGBUnattenuate(rgb->pixels, rgb->rowBytes, rgb->pixels, rgb->rowBytes, rgb->width, rgb->height) != 0) {
+            return AVIF_RESULT_REFORMAT_FAILED;
+        }
+        return AVIF_RESULT_OK;
+    }
+
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+
+avifResult avifRGBImageToF16LibYUV(avifRGBImage * rgb)
+{
+    // The width, height, and stride parameters of libyuv functions are all of the int type.
+    if (rgb->width > INT_MAX || rgb->height > INT_MAX || rgb->rowBytes > INT_MAX) {
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+    const float scale = 1.0f / ((1 << rgb->depth) - 1);
+    // Note: HalfFloatPlane requires the stride to be in bytes.
+    const int result = HalfFloatPlane((const uint16_t *)rgb->pixels,
+                                      rgb->rowBytes,
+                                      (uint16_t *)rgb->pixels,
+                                      rgb->rowBytes,
+                                      scale,
+                                      rgb->width * avifRGBFormatChannelCount(rgb->format),
+                                      rgb->height);
+    return (result == 0) ? AVIF_RESULT_OK : AVIF_RESULT_INVALID_ARGUMENT;
+}
+
+unsigned int avifLibYUVVersion(void)
+{
+    return (unsigned int)LIBYUV_VERSION;
+}
+
+#endif
diff --git a/third_party/libavif/src/src/sampletransform.c b/third_party/libavif/src/src/sampletransform.c
new file mode 100644
index 0000000000..5210366b0f
--- /dev/null
+++ b/third_party/libavif/src/src/sampletransform.c
@@ -0,0 +1,401 @@
+// Copyright 2024 Google LLC
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <stdint.h>
+#include <string.h>
+
+//------------------------------------------------------------------------------
+// Convenience functions
+
+avifBool avifSampleTransformExpressionIsValid(const avifSampleTransformExpression * tokens, uint32_t numInputImageItems)
+{
+    uint32_t stackSize = 0;
+    for (uint32_t t = 0; t < tokens->count; ++t) {
+        const avifSampleTransformToken * token = &tokens->tokens[t];
+        AVIF_CHECK(token->type < AVIF_SAMPLE_TRANSFORM_RESERVED);
+        if (token->type == AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX) {
+            // inputImageItemIndex is 1-based.
+            AVIF_CHECK(token->inputImageItemIndex != 0);
+            AVIF_CHECK(token->inputImageItemIndex <= numInputImageItems);
+        }
+        if (token->type == AVIF_SAMPLE_TRANSFORM_CONSTANT || token->type == AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX) {
+            ++stackSize;
+        } else if (token->type == AVIF_SAMPLE_TRANSFORM_NEGATE || token->type == AVIF_SAMPLE_TRANSFORM_ABSOLUTE ||
+                   token->type == AVIF_SAMPLE_TRANSFORM_NOT || token->type == AVIF_SAMPLE_TRANSFORM_MSB) {
+            AVIF_CHECK(stackSize >= 1);
+            // Pop one and push one.
+        } else {
+            AVIF_CHECK(stackSize >= 2);
+            --stackSize; // Pop two and push one.
+        }
+    }
+    AVIF_CHECK(stackSize == 1);
+    return AVIF_TRUE;
+}
+
+avifBool avifSampleTransformExpressionIsEquivalentTo(const avifSampleTransformExpression * a, const avifSampleTransformExpression * b)
+{
+    if (a->count != b->count) {
+        return AVIF_FALSE;
+    }
+
+    for (uint32_t t = 0; t < a->count; ++t) {
+        const avifSampleTransformToken * aToken = &a->tokens[t];
+        const avifSampleTransformToken * bToken = &b->tokens[t];
+        if (aToken->type != bToken->type || (aToken->type == AVIF_SAMPLE_TRANSFORM_CONSTANT && aToken->constant != bToken->constant)) {
+            return AVIF_FALSE;
+        }
+        // For AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX, no need to compare inputImageItemIndex
+        // because these are variables in the expression.
+    }
+    return AVIF_TRUE;
+}
+
+//------------------------------------------------------------------------------
+// Recipe to expression
+
+static avifBool avifPushConstant(avifSampleTransformExpression * expression, int32_t constant)
+{
+    avifSampleTransformToken * token = (avifSampleTransformToken *)avifArrayPush(expression);
+    if (token == NULL) {
+        return AVIF_FALSE;
+    }
+    token->type = AVIF_SAMPLE_TRANSFORM_CONSTANT;
+    token->constant = constant;
+    return AVIF_TRUE;
+}
+static avifBool avifPushInputImageItem(avifSampleTransformExpression * expression, uint8_t inputImageItemIndex)
+{
+    avifSampleTransformToken * token = (avifSampleTransformToken *)avifArrayPush(expression);
+    if (token == NULL) {
+        return AVIF_FALSE;
+    }
+    token->type = AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX;
+    token->inputImageItemIndex = inputImageItemIndex;
+    return AVIF_TRUE;
+}
+static avifBool avifPushOperator(avifSampleTransformExpression * expression, avifSampleTransformTokenType operator)
+{
+    avifSampleTransformToken * token = (avifSampleTransformToken *)avifArrayPush(expression);
+    if (token == NULL) {
+        return AVIF_FALSE;
+    }
+    token->type = (uint8_t) operator;
+    return AVIF_TRUE;
+}
+
+avifResult avifSampleTransformRecipeToExpression(avifSampleTransformRecipe recipe, avifSampleTransformExpression * expression)
+{
+    // Postfix (or Reverse Polish) notation. Brackets to highlight sub-expressions.
+
+    if (recipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B) {
+        // reference_count is two: two 8-bit input images.
+        //   (base_sample << 8) | hidden_sample
+        // Note: base_sample is encoded losslessly. hidden_sample is encoded lossily or losslessly.
+        AVIF_CHECKERR(avifArrayCreate(expression, sizeof(avifSampleTransformToken), 5), AVIF_RESULT_OUT_OF_MEMORY);
+
+        {
+            // The base image represents the 8 most significant bits of the reconstructed, bit-depth-extended output image.
+            // Left shift the base image (which is also the primary item, or the auxiliary alpha item of the primary item)
+            // by 8 bits. This is equivalent to multiplying by 2^8.
+            AVIF_ASSERT_OR_RETURN(avifPushConstant(expression, 256));
+            AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 1));
+            AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_PRODUCT));
+        }
+        {
+            // The second image represents the 8 least significant bits of the reconstructed, bit-depth-extended output image.
+            AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 2));
+        }
+        AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_OR));
+        return AVIF_RESULT_OK;
+    }
+
+    if (recipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B) {
+        // reference_count is two: one 12-bit input image and one 8-bit input image (because AV1 does not support 4-bit samples).
+        //   (base_sample << 4) | (hidden_sample >> 4)
+        // Note: base_sample is encoded losslessly. hidden_sample is encoded lossily or losslessly.
+        AVIF_CHECKERR(avifArrayCreate(expression, sizeof(avifSampleTransformToken), 7), AVIF_RESULT_OUT_OF_MEMORY);
+
+        {
+            // The base image represents the 12 most significant bits of the reconstructed, bit-depth-extended output image.
+            // Left shift the base image (which is also the primary item, or the auxiliary alpha item of the primary item)
+            // by 4 bits. This is equivalent to multiplying by 2^4.
+            AVIF_ASSERT_OR_RETURN(avifPushConstant(expression, 16));
+            AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 1));
+            AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_PRODUCT));
+        }
+        {
+            // The second image represents the 4 least significant bits of the reconstructed, bit-depth-extended output image.
+            AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 2));
+            AVIF_ASSERT_OR_RETURN(avifPushConstant(expression, 16));
+            AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_DIVIDE));
+        }
+        AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_SUM));
+        return AVIF_RESULT_OK;
+    }
+
+    if (recipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B) {
+        // reference_count is two: one 12-bit input image and one 8-bit input image.
+        //   (base_sample << 4) + hidden_sample
+        // Note: Both base_sample and hidden_sample are encoded lossily or losslessly. hidden_sample overlaps
+        //       with base_sample by 4 bits to alleviate the loss caused by the quantization of base_sample.
+        AVIF_CHECKERR(avifArrayCreate(expression, sizeof(avifSampleTransformToken), 7), AVIF_RESULT_OUT_OF_MEMORY);
+
+        // The base image represents the 12 most significant bits of the reconstructed, bit-depth-extended output image.
+        // Left shift the base image (which is also the primary item, or the auxiliary alpha item of the primary item)
+        // by 4 bits. This is equivalent to multiplying by 2^4.
+        AVIF_ASSERT_OR_RETURN(avifPushConstant(expression, 16));
+        AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 1));
+        AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_PRODUCT));
+
+        // The second image represents the offset to apply to the shifted base image to retrieve
+        // the original image, with some loss due to quantization.
+        AVIF_ASSERT_OR_RETURN(avifPushInputImageItem(expression, 2));
+        AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_SUM));
+
+        // The second image is offset by 128 to have unsigned values to encode.
+        // Correct that last to always work with unsigned values in the operations above.
+        AVIF_ASSERT_OR_RETURN(avifPushConstant(expression, 128));
+        AVIF_ASSERT_OR_RETURN(avifPushOperator(expression, AVIF_SAMPLE_TRANSFORM_DIFFERENCE));
+        // Sample values are clamped to [0:1<<depth[ at that point.
+        return AVIF_RESULT_OK;
+    }
+
+    return AVIF_RESULT_INVALID_ARGUMENT;
+}
+
+avifResult avifSampleTransformExpressionToRecipe(const avifSampleTransformExpression * expression, avifSampleTransformRecipe * recipe)
+{
+    *recipe = AVIF_SAMPLE_TRANSFORM_NONE;
+    const avifSampleTransformRecipe kAllRecipes[] = { AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B,
+                                                      AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B,
+                                                      AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B };
+    for (size_t i = 0; i < sizeof(kAllRecipes) / sizeof(kAllRecipes[0]); ++i) {
+        avifSampleTransformRecipe candidateRecipe = kAllRecipes[i];
+        avifSampleTransformExpression candidateExpression = { 0 };
+        AVIF_CHECKRES(avifSampleTransformRecipeToExpression(candidateRecipe, &candidateExpression));
+        const avifBool equivalence = avifSampleTransformExpressionIsEquivalentTo(expression, &candidateExpression);
+        avifArrayDestroy(&candidateExpression);
+        if (equivalence) {
+            *recipe = candidateRecipe;
+            return AVIF_RESULT_OK;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+//------------------------------------------------------------------------------
+// Operators
+
+static int32_t avifSampleTransformClamp32b(int64_t value)
+{
+    return value <= INT32_MIN ? INT32_MIN : value >= INT32_MAX ? INT32_MAX : (int32_t)value;
+}
+
+static int32_t avifSampleTransformOperation32bOneOperand(int32_t operand, uint8_t operator)
+{
+    switch (operator) {
+        case AVIF_SAMPLE_TRANSFORM_NEGATE:
+            return avifSampleTransformClamp32b(-(int64_t)operand);
+        case AVIF_SAMPLE_TRANSFORM_ABSOLUTE:
+            return operand >= 0 ? operand : avifSampleTransformClamp32b(-(int64_t)operand);
+        case AVIF_SAMPLE_TRANSFORM_NOT:
+            return ~operand;
+        case AVIF_SAMPLE_TRANSFORM_MSB: {
+            if (operand <= 0) {
+                return 0;
+            }
+            int32_t log2 = 0;
+            operand >>= 1;
+            for (; operand != 0; ++log2) {
+                operand >>= 1;
+            }
+            return log2;
+        }
+        default:
+            assert(AVIF_FALSE);
+    }
+    return 0;
+}
+
+static int32_t avifSampleTransformOperation32bTwoOperands(int32_t leftOperand, int32_t rightOperand, uint8_t operator)
+{
+    switch (operator) {
+        case AVIF_SAMPLE_TRANSFORM_SUM:
+            return avifSampleTransformClamp32b(leftOperand + rightOperand);
+        case AVIF_SAMPLE_TRANSFORM_DIFFERENCE:
+            return avifSampleTransformClamp32b(leftOperand - rightOperand);
+        case AVIF_SAMPLE_TRANSFORM_PRODUCT:
+            return avifSampleTransformClamp32b(leftOperand * rightOperand);
+        case AVIF_SAMPLE_TRANSFORM_DIVIDE:
+            return rightOperand == 0 ? leftOperand : leftOperand / rightOperand;
+        case AVIF_SAMPLE_TRANSFORM_AND:
+            return leftOperand & rightOperand;
+        case AVIF_SAMPLE_TRANSFORM_OR:
+            return leftOperand | rightOperand;
+        case AVIF_SAMPLE_TRANSFORM_XOR:
+            return leftOperand ^ rightOperand;
+        case AVIF_SAMPLE_TRANSFORM_POW: {
+            if (leftOperand == 0 || leftOperand == 1) {
+                return leftOperand;
+            }
+            const uint32_t exponent = rightOperand > 0 ? (uint32_t)rightOperand : (uint32_t) - (int64_t)rightOperand;
+            if (exponent == 0) {
+                return 1;
+            }
+            if (exponent == 1) {
+                return leftOperand;
+            }
+            if (leftOperand == -1) {
+                return (exponent % 2 == 0) ? 1 : -1;
+            }
+
+            int64_t result = leftOperand;
+            for (uint32_t i = 1; i < exponent; ++i) {
+                result *= leftOperand;
+                if (result <= INT32_MIN) {
+                    return INT32_MIN;
+                } else if (result >= INT32_MAX) {
+                    return INT32_MAX;
+                }
+            }
+            return (int32_t)result;
+        }
+        case AVIF_SAMPLE_TRANSFORM_MIN:
+            return leftOperand <= rightOperand ? leftOperand : rightOperand;
+        case AVIF_SAMPLE_TRANSFORM_MAX:
+            return leftOperand <= rightOperand ? rightOperand : leftOperand;
+        default:
+            assert(AVIF_FALSE);
+    }
+    return 0;
+}
+
+//------------------------------------------------------------------------------
+// Expression
+
+AVIF_ARRAY_DECLARE(avifSampleTransformStack32b, int32_t, elements);
+
+static avifResult avifImageApplyExpression32b(avifImage * dstImage,
+                                              const avifSampleTransformExpression * expression,
+                                              const avifImage * inputImageItems[],
+                                              avifPlanesFlags planes,
+                                              int32_t * stack,
+                                              uint32_t stackCapacity)
+{
+    // This slow path could be avoided by recognizing the recipe thanks to avifSampleTransformExpressionToRecipe()
+    // and having a dedicated optimized implementation for each recipe.
+
+    const int32_t minValue = 0;
+    const int32_t maxValue = (1 << dstImage->depth) - 1;
+
+    const avifBool skipColor = !(planes & AVIF_PLANES_YUV);
+    const avifBool skipAlpha = !(planes & AVIF_PLANES_A);
+    for (int c = AVIF_CHAN_Y; c <= AVIF_CHAN_A; ++c) {
+        const avifBool alpha = c == AVIF_CHAN_A;
+        if ((skipColor && !alpha) || (skipAlpha && alpha)) {
+            continue;
+        }
+
+        const uint32_t planeWidth = avifImagePlaneWidth(dstImage, c);
+        const uint32_t planeHeight = avifImagePlaneHeight(dstImage, c);
+        for (uint32_t y = 0; y < planeHeight; ++y) {
+            for (uint32_t x = 0; x < planeWidth; ++x) {
+                uint32_t stackSize = 0;
+                for (uint32_t t = 0; t < expression->count; ++t) {
+                    const avifSampleTransformToken * token = &expression->tokens[t];
+                    if (token->type == AVIF_SAMPLE_TRANSFORM_CONSTANT) {
+                        AVIF_ASSERT_OR_RETURN(stackSize < stackCapacity);
+                        stack[stackSize++] = token->constant;
+                    } else if (token->type == AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX) {
+                        const avifImage * image = inputImageItems[token->inputImageItemIndex - 1]; // 1-based
+                        const uint8_t * row = avifImagePlane(image, c) + avifImagePlaneRowBytes(image, c) * y;
+                        AVIF_ASSERT_OR_RETURN(stackSize < stackCapacity);
+                        stack[stackSize++] = avifImageUsesU16(image) ? ((const uint16_t *)row)[x] : row[x];
+                    } else if (token->type == AVIF_SAMPLE_TRANSFORM_NEGATE || token->type == AVIF_SAMPLE_TRANSFORM_ABSOLUTE ||
+                               token->type == AVIF_SAMPLE_TRANSFORM_NOT || token->type == AVIF_SAMPLE_TRANSFORM_MSB) {
+                        AVIF_ASSERT_OR_RETURN(stackSize >= 1);
+                        stack[stackSize - 1] = avifSampleTransformOperation32bOneOperand(stack[stackSize - 1], token->type);
+                        // Pop one and push one.
+                    } else {
+                        AVIF_ASSERT_OR_RETURN(stackSize >= 2);
+                        stack[stackSize - 2] =
+                            avifSampleTransformOperation32bTwoOperands(stack[stackSize - 2], stack[stackSize - 1], token->type);
+                        stackSize--; // Pop two and push one.
+                    }
+                }
+                AVIF_ASSERT_OR_RETURN(stackSize == 1);
+                // Fit to 'pixi'-defined range. TODO(yguyon): Take avifRange into account.
+                stack[0] = AVIF_CLAMP(stack[0], minValue, maxValue);
+
+                uint8_t * row = avifImagePlane(dstImage, c) + avifImagePlaneRowBytes(dstImage, c) * y;
+                if (avifImageUsesU16(dstImage)) {
+                    ((uint16_t *)row)[x] = (uint16_t)stack[0];
+                } else {
+                    row[x] = (uint8_t)stack[0];
+                }
+            }
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifImageApplyExpression(avifImage * dstImage,
+                                    avifSampleTransformBitDepth bitDepth,
+                                    const avifSampleTransformExpression * expression,
+                                    uint8_t numInputImageItems,
+                                    const avifImage * inputImageItems[],
+                                    avifPlanesFlags planes)
+{
+    // Check that the expression is valid.
+    AVIF_ASSERT_OR_RETURN(avifSampleTransformExpressionIsValid(expression, numInputImageItems));
+    const avifBool skipColor = !(planes & AVIF_PLANES_YUV);
+    const avifBool skipAlpha = !(planes & AVIF_PLANES_A);
+    for (int c = AVIF_CHAN_Y; c <= AVIF_CHAN_A; ++c) {
+        const avifBool alpha = c == AVIF_CHAN_A;
+        if ((skipColor && !alpha) || (skipAlpha && alpha)) {
+            continue;
+        }
+
+        const uint32_t planeWidth = avifImagePlaneWidth(dstImage, c);
+        const uint32_t planeHeight = avifImagePlaneHeight(dstImage, c);
+        for (uint32_t i = 0; i < numInputImageItems; ++i) {
+            AVIF_CHECKERR(avifImagePlaneWidth(inputImageItems[i], c) == planeWidth, AVIF_RESULT_BMFF_PARSE_FAILED);
+            AVIF_CHECKERR(avifImagePlaneHeight(inputImageItems[i], c) == planeHeight, AVIF_RESULT_BMFF_PARSE_FAILED);
+        }
+    }
+
+    // Then apply it. This part should not fail except for memory shortage reasons.
+    if (bitDepth == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32) {
+        uint32_t stackCapacity = expression->count / 2 + 1;
+        int32_t * stack = avifAlloc(stackCapacity * sizeof(int32_t));
+        AVIF_CHECKERR(stack != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        const avifResult result = avifImageApplyExpression32b(dstImage, expression, inputImageItems, planes, stack, stackCapacity);
+        avifFree(stack);
+        return result;
+    }
+    return AVIF_RESULT_NOT_IMPLEMENTED;
+}
+
+avifResult avifImageApplyOperations(avifImage * dstImage,
+                                    avifSampleTransformBitDepth bitDepth,
+                                    uint32_t numTokens,
+                                    const avifSampleTransformToken tokens[],
+                                    uint8_t numInputImageItems,
+                                    const avifImage * inputImageItems[],
+                                    avifPlanesFlags planes)
+{
+    avifSampleTransformExpression expression = { 0 };
+    AVIF_CHECKERR(avifArrayCreate(&expression, sizeof(avifSampleTransformToken), numTokens), AVIF_RESULT_OUT_OF_MEMORY);
+    for (uint32_t t = 0; t < numTokens; ++t) {
+        avifSampleTransformToken * token = (avifSampleTransformToken *)avifArrayPush(&expression);
+        AVIF_ASSERT_OR_RETURN(token != NULL);
+        *token = tokens[t];
+    }
+    const avifResult result = avifImageApplyExpression(dstImage, bitDepth, &expression, numInputImageItems, inputImageItems, planes);
+    avifArrayDestroy(&expression);
+    return result;
+}
diff --git a/third_party/libavif/src/src/scale.c b/third_party/libavif/src/src/scale.c
new file mode 100644
index 0000000000..3d64774a3c
--- /dev/null
+++ b/third_party/libavif/src/src/scale.c
@@ -0,0 +1,200 @@
+// Copyright 2021 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+#include <limits.h>
+
+#if defined(__clang__)
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wstrict-prototypes" // "this function declaration is not a prototype"
+// The newline at the end of libyuv/version.h was accidentally deleted in version 1792 and restored
+// in version 1813:
+// https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3183182
+// https://chromium-review.googlesource.com/c/libyuv/libyuv/+/3527834
+#pragma clang diagnostic ignored "-Wnewline-eof" // "no newline at end of file"
+#endif
+#include <libyuv.h>
+#if defined(__clang__)
+#pragma clang diagnostic pop
+#endif
+
+// This should be configurable and/or smarter. kFilterBox has the highest quality but is the slowest.
+#define AVIF_LIBYUV_FILTER_MODE kFilterBox
+
+avifResult avifImageScaleWithLimit(avifImage * image,
+                                   uint32_t dstWidth,
+                                   uint32_t dstHeight,
+                                   uint32_t imageSizeLimit,
+                                   uint32_t imageDimensionLimit,
+                                   avifDiagnostics * diag)
+{
+    if ((image->width == dstWidth) && (image->height == dstHeight)) {
+        // Nothing to do
+        return AVIF_RESULT_OK;
+    }
+
+    if ((dstWidth == 0) || (dstHeight == 0)) {
+        avifDiagnosticsPrintf(diag, "avifImageScaleWithLimit requested invalid dst dimensions [%ux%u]", dstWidth, dstHeight);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    if (avifDimensionsTooLarge(dstWidth, dstHeight, imageSizeLimit, imageDimensionLimit)) {
+        avifDiagnosticsPrintf(diag, "avifImageScaleWithLimit requested dst dimensions that are too large [%ux%u]", dstWidth, dstHeight);
+        return AVIF_RESULT_NOT_IMPLEMENTED;
+    }
+
+    uint8_t * srcYUVPlanes[AVIF_PLANE_COUNT_YUV];
+    uint32_t srcYUVRowBytes[AVIF_PLANE_COUNT_YUV];
+    for (int i = 0; i < AVIF_PLANE_COUNT_YUV; ++i) {
+        srcYUVPlanes[i] = image->yuvPlanes[i];
+        image->yuvPlanes[i] = NULL;
+        srcYUVRowBytes[i] = image->yuvRowBytes[i];
+        image->yuvRowBytes[i] = 0;
+    }
+    const avifBool srcImageOwnsYUVPlanes = image->imageOwnsYUVPlanes;
+    image->imageOwnsYUVPlanes = AVIF_FALSE;
+
+    uint8_t * srcAlphaPlane = image->alphaPlane;
+    image->alphaPlane = NULL;
+    uint32_t srcAlphaRowBytes = image->alphaRowBytes;
+    image->alphaRowBytes = 0;
+    const avifBool srcImageOwnsAlphaPlane = image->imageOwnsAlphaPlane;
+    image->imageOwnsAlphaPlane = AVIF_FALSE;
+
+    const uint32_t srcWidth = image->width;
+    const uint32_t srcHeight = image->height;
+    const uint32_t srcUVWidth = avifImagePlaneWidth(image, AVIF_CHAN_U);
+    const uint32_t srcUVHeight = avifImagePlaneHeight(image, AVIF_CHAN_U);
+    image->width = dstWidth;
+    image->height = dstHeight;
+
+    avifResult result = AVIF_RESULT_OK;
+    if (srcYUVPlanes[0] || srcAlphaPlane) {
+        // A simple conservative check to avoid integer overflows in libyuv's ScalePlane() and
+        // ScalePlane_12() functions.
+        if (srcWidth > 16384) {
+            avifDiagnosticsPrintf(diag, "avifImageScaleWithLimit requested invalid width scale for libyuv [%u -> %u]", srcWidth, dstWidth);
+            result = AVIF_RESULT_NOT_IMPLEMENTED;
+            goto cleanup;
+        }
+        if (srcHeight > 16384) {
+            avifDiagnosticsPrintf(diag, "avifImageScaleWithLimit requested invalid height scale for libyuv [%u -> %u]", srcHeight, dstHeight);
+            result = AVIF_RESULT_NOT_IMPLEMENTED;
+            goto cleanup;
+        }
+    }
+
+    if (srcYUVPlanes[0]) {
+        const avifResult allocationResult = avifImageAllocatePlanes(image, AVIF_PLANES_YUV);
+        if (allocationResult != AVIF_RESULT_OK) {
+            avifDiagnosticsPrintf(diag, "Allocation of YUV planes failed: %s", avifResultToString(allocationResult));
+            result = AVIF_RESULT_OUT_OF_MEMORY;
+            goto cleanup;
+        }
+
+        for (int i = 0; i < AVIF_PLANE_COUNT_YUV; ++i) {
+            if (!srcYUVPlanes[i]) {
+                continue;
+            }
+
+            const uint32_t srcW = (i == AVIF_CHAN_Y) ? srcWidth : srcUVWidth;
+            const uint32_t srcH = (i == AVIF_CHAN_Y) ? srcHeight : srcUVHeight;
+            const uint32_t dstW = avifImagePlaneWidth(image, i);
+            const uint32_t dstH = avifImagePlaneHeight(image, i);
+            if (image->depth > 8) {
+                uint16_t * const srcPlane = (uint16_t *)srcYUVPlanes[i];
+                const uint32_t srcStride = srcYUVRowBytes[i] / 2;
+                uint16_t * const dstPlane = (uint16_t *)image->yuvPlanes[i];
+                const uint32_t dstStride = image->yuvRowBytes[i] / 2;
+#if LIBYUV_VERSION >= 1880
+                const int failure =
+                    ScalePlane_12(srcPlane, srcStride, srcW, srcH, dstPlane, dstStride, dstW, dstH, AVIF_LIBYUV_FILTER_MODE);
+                if (failure) {
+                    avifDiagnosticsPrintf(diag, "ScalePlane_12() failed (%d)", failure);
+                    result = (failure == 1) ? AVIF_RESULT_OUT_OF_MEMORY : AVIF_RESULT_UNKNOWN_ERROR;
+                    goto cleanup;
+                }
+#elif LIBYUV_VERSION >= 1774
+                ScalePlane_12(srcPlane, srcStride, srcW, srcH, dstPlane, dstStride, dstW, dstH, AVIF_LIBYUV_FILTER_MODE);
+#else
+                ScalePlane_16(srcPlane, srcStride, srcW, srcH, dstPlane, dstStride, dstW, dstH, AVIF_LIBYUV_FILTER_MODE);
+#endif
+            } else {
+                uint8_t * const srcPlane = srcYUVPlanes[i];
+                const uint32_t srcStride = srcYUVRowBytes[i];
+                uint8_t * const dstPlane = image->yuvPlanes[i];
+                const uint32_t dstStride = image->yuvRowBytes[i];
+#if LIBYUV_VERSION >= 1880
+                const int failure = ScalePlane(srcPlane, srcStride, srcW, srcH, dstPlane, dstStride, dstW, dstH, AVIF_LIBYUV_FILTER_MODE);
+                if (failure) {
+                    avifDiagnosticsPrintf(diag, "ScalePlane() failed (%d)", failure);
+                    result = (failure == 1) ? AVIF_RESULT_OUT_OF_MEMORY : AVIF_RESULT_UNKNOWN_ERROR;
+                    goto cleanup;
+                }
+#else
+                ScalePlane(srcPlane, srcStride, srcW, srcH, dstPlane, dstStride, dstW, dstH, AVIF_LIBYUV_FILTER_MODE);
+#endif
+            }
+        }
+    }
+
+    if (srcAlphaPlane) {
+        const avifResult allocationResult = avifImageAllocatePlanes(image, AVIF_PLANES_A);
+        if (allocationResult != AVIF_RESULT_OK) {
+            avifDiagnosticsPrintf(diag, "Allocation of alpha plane failed: %s", avifResultToString(allocationResult));
+            return AVIF_RESULT_OUT_OF_MEMORY;
+        }
+
+        if (image->depth > 8) {
+            uint16_t * const srcPlane = (uint16_t *)srcAlphaPlane;
+            const uint32_t srcStride = srcAlphaRowBytes / 2;
+            uint16_t * const dstPlane = (uint16_t *)image->alphaPlane;
+            const uint32_t dstStride = image->alphaRowBytes / 2;
+#if LIBYUV_VERSION >= 1880
+            const int failure =
+                ScalePlane_12(srcPlane, srcStride, srcWidth, srcHeight, dstPlane, dstStride, dstWidth, dstHeight, AVIF_LIBYUV_FILTER_MODE);
+            if (failure) {
+                avifDiagnosticsPrintf(diag, "ScalePlane_12() failed (%d)", failure);
+                result = (failure == 1) ? AVIF_RESULT_OUT_OF_MEMORY : AVIF_RESULT_UNKNOWN_ERROR;
+                goto cleanup;
+            }
+#elif LIBYUV_VERSION >= 1774
+            ScalePlane_12(srcPlane, srcStride, srcWidth, srcHeight, dstPlane, dstStride, dstWidth, dstHeight, AVIF_LIBYUV_FILTER_MODE);
+#else
+            ScalePlane_16(srcPlane, srcStride, srcWidth, srcHeight, dstPlane, dstStride, dstWidth, dstHeight, AVIF_LIBYUV_FILTER_MODE);
+#endif
+        } else {
+            uint8_t * const srcPlane = srcAlphaPlane;
+            const uint32_t srcStride = srcAlphaRowBytes;
+            uint8_t * const dstPlane = image->alphaPlane;
+            const uint32_t dstStride = image->alphaRowBytes;
+#if LIBYUV_VERSION >= 1880
+            const int failure =
+                ScalePlane(srcPlane, srcStride, srcWidth, srcHeight, dstPlane, dstStride, dstWidth, dstHeight, AVIF_LIBYUV_FILTER_MODE);
+            if (failure) {
+                avifDiagnosticsPrintf(diag, "ScalePlane() failed (%d)", failure);
+                result = (failure == 1) ? AVIF_RESULT_OUT_OF_MEMORY : AVIF_RESULT_UNKNOWN_ERROR;
+                goto cleanup;
+            }
+#else
+            ScalePlane(srcPlane, srcStride, srcWidth, srcHeight, dstPlane, dstStride, dstWidth, dstHeight, AVIF_LIBYUV_FILTER_MODE);
+#endif
+        }
+    }
+
+cleanup:
+    if (srcYUVPlanes[0] && srcImageOwnsYUVPlanes) {
+        for (int i = 0; i < AVIF_PLANE_COUNT_YUV; ++i) {
+            avifFree(srcYUVPlanes[i]);
+        }
+    }
+    if (srcAlphaPlane && srcImageOwnsAlphaPlane) {
+        avifFree(srcAlphaPlane);
+    }
+    return result;
+}
+
+avifResult avifImageScale(avifImage * image, uint32_t dstWidth, uint32_t dstHeight, avifDiagnostics * diag)
+{
+    avifDiagnosticsClearError(diag);
+    return avifImageScaleWithLimit(image, dstWidth, dstHeight, AVIF_DEFAULT_IMAGE_SIZE_LIMIT, AVIF_DEFAULT_IMAGE_DIMENSION_LIMIT, diag);
+}
diff --git a/third_party/libavif/src/src/stream.c b/third_party/libavif/src/src/stream.c
new file mode 100644
index 0000000000..b9b8488965
--- /dev/null
+++ b/third_party/libavif/src/src/stream.c
@@ -0,0 +1,509 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <inttypes.h>
+#include <stdlib.h>
+#include <string.h>
+
+// ---------------------------------------------------------------------------
+// avifROStream
+
+const uint8_t * avifROStreamCurrent(avifROStream * stream)
+{
+    return stream->raw->data + stream->offset;
+}
+
+void avifROStreamStart(avifROStream * stream, avifROData * raw, avifDiagnostics * diag, const char * diagContext)
+{
+    stream->raw = raw;
+    stream->offset = 0;
+    stream->numUsedBitsInPartialByte = 0;
+    stream->diag = diag;
+    stream->diagContext = diagContext;
+
+    // If diag is non-NULL, diagContext must also be non-NULL
+    assert(!stream->diag || stream->diagContext);
+}
+
+avifBool avifROStreamHasBytesLeft(const avifROStream * stream, size_t byteCount)
+{
+    return byteCount <= (stream->raw->size - stream->offset);
+}
+
+size_t avifROStreamRemainingBytes(const avifROStream * stream)
+{
+    return stream->raw->size - stream->offset;
+}
+
+size_t avifROStreamOffset(const avifROStream * stream)
+{
+    return stream->offset;
+}
+
+void avifROStreamSetOffset(avifROStream * stream, size_t offset)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    stream->offset = offset;
+    if (stream->offset > stream->raw->size) {
+        stream->offset = stream->raw->size;
+    }
+}
+
+avifBool avifROStreamSkip(avifROStream * stream, size_t byteCount)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    if (!avifROStreamHasBytesLeft(stream, byteCount)) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Failed to skip %zu bytes, truncated data?", stream->diagContext, byteCount);
+        return AVIF_FALSE;
+    }
+    stream->offset += byteCount;
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamRead(avifROStream * stream, uint8_t * data, size_t size)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    if (!avifROStreamHasBytesLeft(stream, size)) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Failed to read %zu bytes, truncated data?", stream->diagContext, size);
+        return AVIF_FALSE;
+    }
+
+    memcpy(data, stream->raw->data + stream->offset, size);
+    stream->offset += size;
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadUX8(avifROStream * stream, uint64_t * v, uint64_t factor)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    if (factor == 0) {
+        // Don't read anything, just set to 0
+        *v = 0;
+    } else if (factor == 1) {
+        uint8_t tmp;
+        AVIF_CHECK(avifROStreamRead(stream, &tmp, 1));
+        *v = tmp;
+    } else if (factor == 2) {
+        uint16_t tmp;
+        AVIF_CHECK(avifROStreamReadU16(stream, &tmp));
+        *v = tmp;
+    } else if (factor == 4) {
+        uint32_t tmp;
+        AVIF_CHECK(avifROStreamReadU32(stream, &tmp));
+        *v = tmp;
+    } else if (factor == 8) {
+        uint64_t tmp;
+        AVIF_CHECK(avifROStreamReadU64(stream, &tmp));
+        *v = tmp;
+    } else {
+        // Unsupported factor
+        avifDiagnosticsPrintf(stream->diag, "%s: Failed to read UX8 value; Unsupported UX8 factor [%" PRIu64 "]", stream->diagContext, factor);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadU16(avifROStream * stream, uint16_t * v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECK(avifROStreamRead(stream, (uint8_t *)v, sizeof(uint16_t)));
+    *v = avifNTOHS(*v);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadU16Endianness(avifROStream * stream, uint16_t * v, avifBool littleEndian)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECK(avifROStreamRead(stream, (uint8_t *)v, sizeof(uint16_t)));
+    *v = littleEndian ? avifCTOHS(*v) : avifNTOHS(*v);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadU32(avifROStream * stream, uint32_t * v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECK(avifROStreamRead(stream, (uint8_t *)v, sizeof(uint32_t)));
+    *v = avifNTOHL(*v);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadU32Endianness(avifROStream * stream, uint32_t * v, avifBool littleEndian)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECK(avifROStreamRead(stream, (uint8_t *)v, sizeof(uint32_t)));
+    *v = littleEndian ? avifCTOHL(*v) : avifNTOHL(*v);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadU64(avifROStream * stream, uint64_t * v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECK(avifROStreamRead(stream, (uint8_t *)v, sizeof(uint64_t)));
+    *v = avifNTOH64(*v);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamSkipBits(avifROStream * stream, size_t bitCount)
+{
+    if (stream->numUsedBitsInPartialByte != 0) {
+        assert(stream->numUsedBitsInPartialByte < 8);
+        const size_t padding = AVIF_MIN(8 - stream->numUsedBitsInPartialByte, bitCount);
+        stream->numUsedBitsInPartialByte = (stream->numUsedBitsInPartialByte + padding) % 8;
+        bitCount -= padding;
+        if (bitCount == 0) {
+            return AVIF_TRUE;
+        }
+    }
+    const size_t num_bytes = (bitCount + 7) / 8;
+    AVIF_CHECK(avifROStreamSkip(stream, num_bytes));
+    stream->numUsedBitsInPartialByte = bitCount % 8;
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadBitsU8(avifROStream * stream, uint8_t * v, size_t bitCount)
+{
+    AVIF_CHECK(bitCount <= sizeof(*v) * 8);
+    uint32_t vU32;
+    AVIF_CHECK(avifROStreamReadBitsU32(stream, &vU32, bitCount));
+    *v = (uint8_t)vU32;
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadBitsU16(avifROStream * stream, uint16_t * v, size_t bitCount)
+{
+    AVIF_CHECK(bitCount <= sizeof(*v) * 8);
+    uint32_t vU32;
+    AVIF_CHECK(avifROStreamReadBitsU32(stream, &vU32, bitCount));
+    *v = (uint16_t)vU32;
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadBitsU32(avifROStream * stream, uint32_t * v, size_t bitCount)
+{
+    AVIF_CHECK(bitCount <= sizeof(*v) * 8);
+    *v = 0;
+    while (bitCount) {
+        if (stream->numUsedBitsInPartialByte == 0) {
+            AVIF_CHECK(avifROStreamSkip(stream, sizeof(uint8_t))); // Book a new partial byte in the stream.
+        }
+        assert(stream->offset > 0);
+        const uint8_t * packedBits = stream->raw->data + stream->offset - 1;
+
+        const size_t numBits = AVIF_MIN(bitCount, 8 - stream->numUsedBitsInPartialByte);
+        stream->numUsedBitsInPartialByte += numBits;
+        bitCount -= numBits;
+        // The stream bits are packed starting with the most significant bit of the first input byte.
+        // This way, packed bits can be found in the same order in the bit stream.
+        const uint32_t bits = (*packedBits >> (8 - stream->numUsedBitsInPartialByte)) & ((1 << numBits) - 1);
+        // The value bits are ordered from the most significant bit to the least significant bit.
+        // In the case where avifROStreamReadBitsU32() is used to parse the unsigned integer value *v
+        // over multiple aligned bytes, this order corresponds to big endianness.
+        *v |= bits << bitCount;
+
+        if (stream->numUsedBitsInPartialByte == 8) {
+            // Start a new partial byte the next time a bit is needed.
+            stream->numUsedBitsInPartialByte = 0;
+        }
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadString(avifROStream * stream, char * output, size_t outputSize)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+
+    // Check for the presence of a null terminator in the stream.
+    size_t remainingBytes = avifROStreamRemainingBytes(stream);
+    const uint8_t * p = avifROStreamCurrent(stream);
+    avifBool foundNullTerminator = AVIF_FALSE;
+    for (size_t i = 0; i < remainingBytes; ++i) {
+        if (p[i] == 0) {
+            foundNullTerminator = AVIF_TRUE;
+            break;
+        }
+    }
+    if (!foundNullTerminator) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Failed to find a NULL terminator when reading a string", stream->diagContext);
+        return AVIF_FALSE;
+    }
+
+    const char * streamString = (const char *)p;
+    size_t stringLen = strlen(streamString);
+    stream->offset += stringLen + 1; // update the stream to have read the "whole string" in
+
+    if (output && outputSize) {
+        // clamp to our output buffer
+        if (stringLen >= outputSize) {
+            stringLen = outputSize - 1;
+        }
+        memcpy(output, streamString, stringLen);
+        output[stringLen] = 0;
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadBoxHeaderPartial(avifROStream * stream, avifBoxHeader * header, avifBool topLevel)
+{
+    // Section 4.2.2 of ISO/IEC 14496-12.
+    size_t startOffset = stream->offset;
+
+    uint32_t smallSize;
+    AVIF_CHECK(avifROStreamReadU32(stream, &smallSize));   // unsigned int(32) size;
+    AVIF_CHECK(avifROStreamRead(stream, header->type, 4)); // unsigned int(32) type = boxtype;
+
+    uint64_t size = smallSize;
+    if (size == 1) {
+        AVIF_CHECK(avifROStreamReadU64(stream, &size)); // unsigned int(64) largesize;
+    }
+
+    if (!memcmp(header->type, "uuid", 4)) {
+        AVIF_CHECK(avifROStreamSkip(stream, 16)); // unsigned int(8) usertype[16] = extended_type;
+    }
+
+    size_t bytesRead = stream->offset - startOffset;
+    if (size == 0) {
+        // Section 4.2.2 of ISO/IEC 14496-12.
+        //   if size is 0, then this box shall be in a top-level box (i.e. not contained in another
+        //   box), and be the last box in its 'file', and its payload extends to the end of that
+        //   enclosing 'file'. This is normally only used for a MediaDataBox ('mdat').
+        if (!topLevel) {
+            avifDiagnosticsPrintf(stream->diag, "%s: Non-top-level box with size 0", stream->diagContext);
+            return AVIF_FALSE;
+        }
+
+        // The given stream may be incomplete and there is no guarantee that sizeHint is available and accurate.
+        // Otherwise size could be set to avifROStreamRemainingBytes(stream) + (stream->offset - startOffset) right now.
+
+        // Wait for avifIOReadFunc() to return AVIF_RESULT_OK.
+        header->isSizeZeroBox = AVIF_TRUE;
+        header->size = 0;
+        return AVIF_TRUE;
+    }
+
+    if ((size < bytesRead) || ((size - bytesRead) > SIZE_MAX)) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Header size overflow check failure", stream->diagContext);
+        return AVIF_FALSE;
+    }
+    header->isSizeZeroBox = AVIF_FALSE;
+    header->size = (size_t)(size - bytesRead);
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadBoxHeader(avifROStream * stream, avifBoxHeader * header)
+{
+    AVIF_CHECK(avifROStreamReadBoxHeaderPartial(stream, header, /*topLevel=*/AVIF_FALSE));
+    if (header->size > avifROStreamRemainingBytes(stream)) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Child box too large, possibly truncated data", stream->diagContext);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadVersionAndFlags(avifROStream * stream, uint8_t * version, uint32_t * flags)
+{
+    uint8_t versionAndFlags[4];
+    AVIF_CHECK(avifROStreamRead(stream, versionAndFlags, 4));
+    if (version) {
+        *version = versionAndFlags[0];
+    }
+    if (flags) {
+        *flags = (versionAndFlags[1] << 16) + (versionAndFlags[2] << 8) + (versionAndFlags[3] << 0);
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifROStreamReadAndEnforceVersion(avifROStream * stream, uint8_t enforcedVersion)
+{
+    uint8_t version;
+    AVIF_CHECK(avifROStreamReadVersionAndFlags(stream, &version, NULL));
+    if (version != enforcedVersion) {
+        avifDiagnosticsPrintf(stream->diag, "%s: Expecting box version %u, got version %u", stream->diagContext, enforcedVersion, version);
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+// ---------------------------------------------------------------------------
+// avifRWStream
+
+#define AVIF_STREAM_BUFFER_INCREMENT (1024 * 1024)
+static avifResult makeRoom(avifRWStream * stream, size_t size)
+{
+    size_t neededSize = stream->offset + size;
+    size_t newSize = stream->raw->size;
+    while (newSize < neededSize) {
+        newSize += AVIF_STREAM_BUFFER_INCREMENT;
+    }
+    return avifRWDataRealloc(stream->raw, newSize);
+}
+
+void avifRWStreamStart(avifRWStream * stream, avifRWData * raw)
+{
+    stream->raw = raw;
+    stream->offset = 0;
+    stream->numUsedBitsInPartialByte = 0;
+}
+
+size_t avifRWStreamOffset(const avifRWStream * stream)
+{
+    return stream->offset;
+}
+
+void avifRWStreamSetOffset(avifRWStream * stream, size_t offset)
+{
+    stream->offset = offset;
+    if (stream->offset > stream->raw->size) {
+        stream->offset = stream->raw->size;
+    }
+}
+
+void avifRWStreamFinishWrite(avifRWStream * stream)
+{
+    if (stream->raw->size != stream->offset) {
+        if (stream->offset) {
+            stream->raw->size = stream->offset;
+        } else {
+            avifRWDataFree(stream->raw);
+        }
+    }
+}
+
+avifResult avifRWStreamWrite(avifRWStream * stream, const void * data, size_t size)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    if (size) {
+        AVIF_CHECKRES(makeRoom(stream, size));
+        memcpy(stream->raw->data + stream->offset, data, size);
+        stream->offset += size;
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteChars(avifRWStream * stream, const char * chars, size_t size)
+{
+    return avifRWStreamWrite(stream, chars, size);
+}
+
+avifResult avifRWStreamWriteFullBox(avifRWStream * stream, const char * type, size_t contentSize, int version, uint32_t flags, avifBoxMarker * marker)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    if (marker) {
+        *marker = stream->offset;
+    }
+    size_t headerSize = sizeof(uint32_t) + 4 /* size of type */;
+    if (version != -1) {
+        headerSize += 4;
+    }
+
+    AVIF_CHECKRES(makeRoom(stream, headerSize));
+    memset(stream->raw->data + stream->offset, 0, headerSize);
+    uint32_t noSize = avifHTONL((uint32_t)(headerSize + contentSize));
+    memcpy(stream->raw->data + stream->offset, &noSize, sizeof(uint32_t));
+    memcpy(stream->raw->data + stream->offset + 4, type, 4);
+    if (version != -1) {
+        stream->raw->data[stream->offset + 8] = (uint8_t)version;
+        stream->raw->data[stream->offset + 9] = (uint8_t)((flags >> 16) & 0xff);
+        stream->raw->data[stream->offset + 10] = (uint8_t)((flags >> 8) & 0xff);
+        stream->raw->data[stream->offset + 11] = (uint8_t)((flags >> 0) & 0xff);
+    }
+    stream->offset += headerSize;
+
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteBox(avifRWStream * stream, const char * type, size_t contentSize, avifBoxMarker * marker)
+{
+    return avifRWStreamWriteFullBox(stream, type, contentSize, -1, 0, marker);
+}
+
+void avifRWStreamFinishBox(avifRWStream * stream, avifBoxMarker marker)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    uint32_t noSize = avifHTONL((uint32_t)(stream->offset - marker));
+    memcpy(stream->raw->data + marker, &noSize, sizeof(uint32_t));
+}
+
+avifResult avifRWStreamWriteU8(avifRWStream * stream, uint8_t v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECKRES(makeRoom(stream, 1));
+    stream->raw->data[stream->offset] = v;
+    stream->offset += 1;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteU16(avifRWStream * stream, uint16_t v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    const size_t size = sizeof(uint16_t);
+    AVIF_CHECKRES(makeRoom(stream, size));
+    v = avifHTONS(v);
+    memcpy(stream->raw->data + stream->offset, &v, size);
+    stream->offset += size;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteU32(avifRWStream * stream, uint32_t v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    const size_t size = sizeof(uint32_t);
+    AVIF_CHECKRES(makeRoom(stream, size));
+    v = avifHTONL(v);
+    memcpy(stream->raw->data + stream->offset, &v, size);
+    stream->offset += size;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteU64(avifRWStream * stream, uint64_t v)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    const size_t size = sizeof(uint64_t);
+    AVIF_CHECKRES(makeRoom(stream, size));
+    v = avifHTON64(v);
+    memcpy(stream->raw->data + stream->offset, &v, size);
+    stream->offset += size;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteZeros(avifRWStream * stream, size_t byteCount)
+{
+    assert(stream->numUsedBitsInPartialByte == 0); // Byte alignment is required.
+    AVIF_CHECKRES(makeRoom(stream, byteCount));
+    memset(stream->raw->data + stream->offset, 0, byteCount);
+    stream->offset += byteCount;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifRWStreamWriteBits(avifRWStream * stream, uint32_t v, size_t bitCount)
+{
+    AVIF_CHECKERR(bitCount >= 32 || (v >> bitCount) == 0, AVIF_RESULT_INVALID_ARGUMENT);
+    while (bitCount) {
+        if (stream->numUsedBitsInPartialByte == 0) {
+            AVIF_CHECKRES(makeRoom(stream, 1)); // Book a new partial byte in the stream.
+            stream->raw->data[stream->offset] = 0;
+            stream->offset += 1;
+        }
+        assert(stream->offset > 0);
+        uint8_t * packedBits = stream->raw->data + stream->offset - 1;
+
+        const size_t numBits = AVIF_MIN(bitCount, 8 - stream->numUsedBitsInPartialByte);
+        stream->numUsedBitsInPartialByte += numBits;
+        bitCount -= numBits;
+        // Order the input bits from the most significant bit to the least significant bit.
+        // In the case where avifRWStreamWriteBits() is used to write the unsigned integer value v
+        // over multiple aligned bytes, this order corresponds to big endianness.
+        const uint32_t bits = (v >> bitCount) & ((1 << numBits) - 1);
+        // Pack bits starting with the most significant bit of the first output byte.
+        // This way, packed bits can be found in the same order in the bit stream.
+        *packedBits |= bits << (8 - stream->numUsedBitsInPartialByte);
+
+        if (stream->numUsedBitsInPartialByte == 8) {
+            // Start a new partial byte the next time a bit is needed.
+            stream->numUsedBitsInPartialByte = 0;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
diff --git a/third_party/libavif/src/src/utils.c b/third_party/libavif/src/src/utils.c
new file mode 100644
index 0000000000..8578d30631
--- /dev/null
+++ b/third_party/libavif/src/src/utils.c
@@ -0,0 +1,288 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <math.h>
+#include <string.h>
+
+float avifRoundf(float v)
+{
+    return floorf(v + 0.5f);
+}
+
+// Thanks, Rob Pike! https://commandcenter.blogspot.nl/2012/04/byte-order-fallacy.html
+
+uint16_t avifHTONS(uint16_t s)
+{
+    uint16_t result = 0;
+    uint8_t * data = (uint8_t *)&result;
+    data[0] = (s >> 8) & 0xff;
+    data[1] = (s >> 0) & 0xff;
+    return result;
+}
+
+uint16_t avifNTOHS(uint16_t s)
+{
+    const uint8_t * data = (const uint8_t *)&s;
+    return (uint16_t)((data[1] << 0) | (data[0] << 8));
+}
+
+uint16_t avifCTOHS(uint16_t s)
+{
+    const uint8_t * data = (const uint8_t *)&s;
+    return (uint16_t)((data[0] << 0) | (data[1] << 8));
+}
+
+uint32_t avifHTONL(uint32_t l)
+{
+    uint32_t result = 0;
+    uint8_t * data = (uint8_t *)&result;
+    data[0] = (l >> 24) & 0xff;
+    data[1] = (l >> 16) & 0xff;
+    data[2] = (l >> 8) & 0xff;
+    data[3] = (l >> 0) & 0xff;
+    return result;
+}
+
+uint32_t avifNTOHL(uint32_t l)
+{
+    const uint8_t * data = (const uint8_t *)&l;
+    return ((uint32_t)data[3] << 0) | ((uint32_t)data[2] << 8) | ((uint32_t)data[1] << 16) | ((uint32_t)data[0] << 24);
+}
+
+uint32_t avifCTOHL(uint32_t l)
+{
+    const uint8_t * data = (const uint8_t *)&l;
+    return ((uint32_t)data[0] << 0) | ((uint32_t)data[1] << 8) | ((uint32_t)data[2] << 16) | ((uint32_t)data[3] << 24);
+}
+
+uint64_t avifHTON64(uint64_t l)
+{
+    uint64_t result = 0;
+    uint8_t * data = (uint8_t *)&result;
+    data[0] = (l >> 56) & 0xff;
+    data[1] = (l >> 48) & 0xff;
+    data[2] = (l >> 40) & 0xff;
+    data[3] = (l >> 32) & 0xff;
+    data[4] = (l >> 24) & 0xff;
+    data[5] = (l >> 16) & 0xff;
+    data[6] = (l >> 8) & 0xff;
+    data[7] = (l >> 0) & 0xff;
+    return result;
+}
+
+uint64_t avifNTOH64(uint64_t l)
+{
+    const uint8_t * data = (const uint8_t *)&l;
+    return ((uint64_t)data[7] << 0) | ((uint64_t)data[6] << 8) | ((uint64_t)data[5] << 16) | ((uint64_t)data[4] << 24) |
+           ((uint64_t)data[3] << 32) | ((uint64_t)data[2] << 40) | ((uint64_t)data[1] << 48) | ((uint64_t)data[0] << 56);
+}
+
+AVIF_ARRAY_DECLARE(avifArrayInternal, uint8_t, ptr);
+
+// On error, this function must set arr->ptr to NULL and both arr->count and arr->capacity to 0.
+avifBool avifArrayCreate(void * arrayStruct, uint32_t elementSize, uint32_t initialCapacity)
+{
+    avifArrayInternal * arr = (avifArrayInternal *)arrayStruct;
+    arr->elementSize = elementSize ? elementSize : 1;
+    arr->count = 0;
+    arr->capacity = initialCapacity;
+    size_t byteCount = (size_t)arr->elementSize * arr->capacity;
+    arr->ptr = (uint8_t *)avifAlloc(byteCount);
+    if (!arr->ptr) {
+        arr->capacity = 0;
+        return AVIF_FALSE;
+    }
+    memset(arr->ptr, 0, byteCount);
+    return AVIF_TRUE;
+}
+
+void * avifArrayPush(void * arrayStruct)
+{
+    avifArrayInternal * arr = (avifArrayInternal *)arrayStruct;
+    if (arr->count == arr->capacity) {
+        uint8_t * oldPtr = arr->ptr;
+        size_t oldByteCount = (size_t)arr->elementSize * arr->capacity;
+        arr->ptr = (uint8_t *)avifAlloc(oldByteCount * 2);
+        if (arr->ptr == NULL) {
+            return NULL;
+        }
+        memset(arr->ptr + oldByteCount, 0, oldByteCount);
+        memcpy(arr->ptr, oldPtr, oldByteCount);
+        arr->capacity *= 2;
+        avifFree(oldPtr);
+    }
+    ++arr->count;
+    return &arr->ptr[(arr->count - 1) * (size_t)arr->elementSize];
+}
+
+void avifArrayPop(void * arrayStruct)
+{
+    avifArrayInternal * arr = (avifArrayInternal *)arrayStruct;
+    assert(arr->count > 0);
+    --arr->count;
+    memset(&arr->ptr[arr->count * (size_t)arr->elementSize], 0, arr->elementSize);
+}
+
+void avifArrayDestroy(void * arrayStruct)
+{
+    avifArrayInternal * arr = (avifArrayInternal *)arrayStruct;
+    if (arr->ptr) {
+        avifFree(arr->ptr);
+        arr->ptr = NULL;
+    }
+    memset(arr, 0, sizeof(avifArrayInternal));
+}
+
+// |a| and |b| hold int32_t values. The int64_t type is used so that we can negate INT32_MIN without
+// overflowing int32_t.
+static int64_t calcGCD(int64_t a, int64_t b)
+{
+    if (a < 0) {
+        a *= -1;
+    }
+    if (b < 0) {
+        b *= -1;
+    }
+    while (b != 0) {
+        int64_t r = a % b;
+        a = b;
+        b = r;
+    }
+    return a;
+}
+
+void avifFractionSimplify(avifFraction * f)
+{
+    int64_t gcd = calcGCD(f->n, f->d);
+    if (gcd > 1) {
+        f->n = (int32_t)(f->n / gcd);
+        f->d = (int32_t)(f->d / gcd);
+    }
+}
+
+static avifBool overflowsInt32(int64_t x)
+{
+    return (x < INT32_MIN) || (x > INT32_MAX);
+}
+
+avifBool avifFractionCD(avifFraction * a, avifFraction * b)
+{
+    avifFractionSimplify(a);
+    avifFractionSimplify(b);
+    if (a->d != b->d) {
+        const int64_t ad = a->d;
+        const int64_t bd = b->d;
+        const int64_t anNew = a->n * bd;
+        const int64_t adNew = a->d * bd;
+        const int64_t bnNew = b->n * ad;
+        const int64_t bdNew = b->d * ad;
+        if (overflowsInt32(anNew) || overflowsInt32(adNew) || overflowsInt32(bnNew) || overflowsInt32(bdNew)) {
+            return AVIF_FALSE;
+        }
+        a->n = (int32_t)anNew;
+        a->d = (int32_t)adNew;
+        b->n = (int32_t)bnNew;
+        b->d = (int32_t)bdNew;
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifFractionAdd(avifFraction a, avifFraction b, avifFraction * result)
+{
+    if (!avifFractionCD(&a, &b)) {
+        return AVIF_FALSE;
+    }
+
+    const int64_t resultN = (int64_t)a.n + b.n;
+    if (overflowsInt32(resultN)) {
+        return AVIF_FALSE;
+    }
+    result->n = (int32_t)resultN;
+    result->d = a.d;
+
+    avifFractionSimplify(result);
+    return AVIF_TRUE;
+}
+
+avifBool avifFractionSub(avifFraction a, avifFraction b, avifFraction * result)
+{
+    if (!avifFractionCD(&a, &b)) {
+        return AVIF_FALSE;
+    }
+
+    const int64_t resultN = (int64_t)a.n - b.n;
+    if (overflowsInt32(resultN)) {
+        return AVIF_FALSE;
+    }
+    result->n = (int32_t)resultN;
+    result->d = a.d;
+
+    avifFractionSimplify(result);
+    return AVIF_TRUE;
+}
+
+static avifBool avifDoubleToUnsignedFractionImpl(double v, uint32_t maxNumerator, uint32_t * numerator, uint32_t * denominator)
+{
+    if (isnan(v) || v < 0 || v > maxNumerator) {
+        return AVIF_FALSE;
+    }
+
+    // Maximum denominator: makes sure that the numerator is <= maxNumerator and the denominator is <= UINT32_MAX.
+    const uint32_t maxD = (v <= 1) ? UINT32_MAX : (uint32_t)floor(maxNumerator / v);
+
+    // Find the best approximation of v as a fraction using continued fractions, see
+    // https://en.wikipedia.org/wiki/Continued_fraction
+    *denominator = 1;
+    uint32_t previousD = 0;
+    double currentV = v - floor(v);
+    int iter = 0;
+    // Set a maximum number of iterations to be safe. Most numbers should
+    // converge in less than ~20 iterations.
+    // The golden ratio is the worst case and takes 39 iterations.
+    const int maxIter = 39;
+    while (iter < maxIter) {
+        const double numeratorDouble = (double)(*denominator) * v;
+        assert(numeratorDouble <= maxNumerator);
+        *numerator = (uint32_t)round(numeratorDouble);
+        if (fabs(numeratorDouble - (*numerator)) == 0.0) {
+            return AVIF_TRUE;
+        }
+        currentV = 1.0 / currentV;
+        const double newD = previousD + floor(currentV) * (*denominator);
+        if (newD > (double)maxD) {
+            // This is the best we can do with a denominator <= max_d.
+            return AVIF_TRUE;
+        }
+        previousD = *denominator;
+        assert(newD <= UINT32_MAX);
+        *denominator = (uint32_t)newD;
+        currentV -= floor(currentV);
+        ++iter;
+    }
+    // Maximum number of iterations reached, return what we've found.
+    // For max_iter >= 39 we shouldn't get here. max_iter can be set
+    // to a lower value to speed up the algorithm if needed.
+    *numerator = (uint32_t)round((double)(*denominator) * v);
+    return AVIF_TRUE;
+}
+
+avifBool avifDoubleToSignedFraction(double v, avifSignedFraction * fraction)
+{
+    uint32_t positive_numerator;
+    if (!avifDoubleToUnsignedFractionImpl(fabs(v), INT32_MAX, &positive_numerator, &fraction->d)) {
+        return AVIF_FALSE;
+    }
+    fraction->n = (int32_t)positive_numerator;
+    if (v < 0) {
+        fraction->n *= -1;
+    }
+    return AVIF_TRUE;
+}
+
+avifBool avifDoubleToUnsignedFraction(double v, avifUnsignedFraction * fraction)
+{
+    return avifDoubleToUnsignedFractionImpl(v, UINT32_MAX, &fraction->n, &fraction->d);
+}
diff --git a/third_party/libavif/src/src/write.c b/third_party/libavif/src/src/write.c
new file mode 100644
index 0000000000..cf4e1c7932
--- /dev/null
+++ b/third_party/libavif/src/src/write.c
@@ -0,0 +1,3854 @@
+// Copyright 2019 Joe Drago. All rights reserved.
+// SPDX-License-Identifier: BSD-2-Clause
+
+#include "avif/internal.h"
+
+#include <assert.h>
+#include <string.h>
+#include <time.h>
+
+#define MAX_ASSOCIATIONS 16
+struct ipmaArray
+{
+    uint8_t associations[MAX_ASSOCIATIONS];
+    avifBool essential[MAX_ASSOCIATIONS];
+    uint8_t count;
+};
+
+// Used to store offsets in meta boxes which need to point at mdat offsets that
+// aren't known yet. When an item's mdat payload is written, all registered fixups
+// will have this now-known offset "fixed up".
+typedef struct avifOffsetFixup
+{
+    size_t offset;
+} avifOffsetFixup;
+AVIF_ARRAY_DECLARE(avifOffsetFixupArray, avifOffsetFixup, fixup);
+
+static const char alphaURN[] = AVIF_URN_ALPHA0;
+static const size_t alphaURNSize = sizeof(alphaURN);
+
+static const char xmpContentType[] = AVIF_CONTENT_TYPE_XMP;
+static const size_t xmpContentTypeSize = sizeof(xmpContentType);
+
+static avifResult writeCodecConfig(avifRWStream * s, const avifCodecConfigurationBox * cfg);
+static avifResult writeConfigBox(avifRWStream * s, const avifCodecConfigurationBox * cfg, const char * configPropName);
+
+// ---------------------------------------------------------------------------
+// avifSetTileConfiguration
+
+static int floorLog2(uint32_t n)
+{
+    assert(n > 0);
+    int count = 0;
+    while (n != 0) {
+        ++count;
+        n >>= 1;
+    }
+    return count - 1;
+}
+
+// Splits tilesLog2 into *tileDim1Log2 and *tileDim2Log2, considering the ratio of dim1 to dim2.
+//
+// Precondition:
+//     dim1 >= dim2
+// Postcondition:
+//     tilesLog2 == *tileDim1Log2 + *tileDim2Log2
+//     *tileDim1Log2 >= *tileDim2Log2
+static void splitTilesLog2(uint32_t dim1, uint32_t dim2, int tilesLog2, int * tileDim1Log2, int * tileDim2Log2)
+{
+    assert(dim1 >= dim2);
+    uint32_t ratio = dim1 / dim2;
+    int diffLog2 = floorLog2(ratio);
+    int subtract = tilesLog2 - diffLog2;
+    if (subtract < 0) {
+        subtract = 0;
+    }
+    *tileDim2Log2 = subtract / 2;
+    *tileDim1Log2 = tilesLog2 - *tileDim2Log2;
+    assert(*tileDim1Log2 >= *tileDim2Log2);
+}
+
+// Set the tile configuration: the number of tiles and the tile size.
+//
+// Tiles improve encoding and decoding speeds when multiple threads are available. However, for
+// image coding, the total tile boundary length affects the compression efficiency because intra
+// prediction can't go across tile boundaries. So the more tiles there are in an image, the worse
+// the compression ratio is. For a given number of tiles, making the tile size close to a square
+// tends to reduce the total tile boundary length inside the image. Use more tiles along the longer
+// dimension of the image to make the tile size closer to a square.
+void avifSetTileConfiguration(int threads, uint32_t width, uint32_t height, int * tileRowsLog2, int * tileColsLog2)
+{
+    *tileRowsLog2 = 0;
+    *tileColsLog2 = 0;
+    if (threads > 1) {
+        // Avoid small tiles because they are particularly bad for image coding.
+        //
+        // Use no more tiles than the number of threads. Aim for one tile per thread. Using more
+        // than one thread inside one tile could be less efficient. Using more tiles than the
+        // number of threads would result in a compression penalty without much benefit.
+        const uint32_t kMinTileArea = 512 * 512;
+        const uint32_t kMaxTiles = 32;
+        uint32_t imageArea = width * height;
+        uint32_t tiles = (imageArea + kMinTileArea - 1) / kMinTileArea;
+        if (tiles > kMaxTiles) {
+            tiles = kMaxTiles;
+        }
+        if (tiles > (uint32_t)threads) {
+            tiles = threads;
+        }
+        int tilesLog2 = floorLog2(tiles);
+        // If the image's width is greater than the height, use more tile columns than tile rows.
+        if (width >= height) {
+            splitTilesLog2(width, height, tilesLog2, tileColsLog2, tileRowsLog2);
+        } else {
+            splitTilesLog2(height, width, tilesLog2, tileRowsLog2, tileColsLog2);
+        }
+    }
+}
+
+// ---------------------------------------------------------------------------
+// avifCodecEncodeOutput
+
+avifCodecEncodeOutput * avifCodecEncodeOutputCreate(void)
+{
+    avifCodecEncodeOutput * encodeOutput = (avifCodecEncodeOutput *)avifAlloc(sizeof(avifCodecEncodeOutput));
+    if (encodeOutput == NULL) {
+        return NULL;
+    }
+    memset(encodeOutput, 0, sizeof(avifCodecEncodeOutput));
+    if (!avifArrayCreate(&encodeOutput->samples, sizeof(avifEncodeSample), 1)) {
+        avifCodecEncodeOutputDestroy(encodeOutput);
+        return NULL;
+    }
+    return encodeOutput;
+}
+
+avifResult avifCodecEncodeOutputAddSample(avifCodecEncodeOutput * encodeOutput, const uint8_t * data, size_t len, avifBool sync)
+{
+    avifEncodeSample * sample = (avifEncodeSample *)avifArrayPush(&encodeOutput->samples);
+    AVIF_CHECKERR(sample, AVIF_RESULT_OUT_OF_MEMORY);
+    const avifResult result = avifRWDataSet(&sample->data, data, len);
+    if (result != AVIF_RESULT_OK) {
+        avifArrayPop(&encodeOutput->samples);
+        return result;
+    }
+    sample->sync = sync;
+    return AVIF_RESULT_OK;
+}
+
+void avifCodecEncodeOutputDestroy(avifCodecEncodeOutput * encodeOutput)
+{
+    for (uint32_t sampleIndex = 0; sampleIndex < encodeOutput->samples.count; ++sampleIndex) {
+        avifRWDataFree(&encodeOutput->samples.sample[sampleIndex].data);
+    }
+    avifArrayDestroy(&encodeOutput->samples);
+    avifFree(encodeOutput);
+}
+
+// ---------------------------------------------------------------------------
+// avifEncoderItem
+
+// one "item" worth for encoder
+typedef struct avifEncoderItem
+{
+    uint16_t id;
+    uint8_t type[4];                      // 4-character 'item_type' field in the 'infe' (item info entry) box
+    avifCodec * codec;                    // only present on image items
+    avifCodecEncodeOutput * encodeOutput; // AV1 sample data
+    avifRWData metadataPayload;           // Exif/XMP data
+    avifCodecConfigurationBox av1C;       // Harvested in avifEncoderFinish(), if encodeOutput has samples
+                                          // TODO(yguyon): Rename or add av2C
+    uint32_t cellIndex;                   // Which row-major cell index corresponds to this item. only present on image items
+    avifItemCategory itemCategory;        // Category of item being encoded
+    avifBool hiddenImage;                 // A hidden image item has (flags & 1) equal to 1 in its ItemInfoEntry.
+
+    const char * infeName;
+    size_t infeNameSize;
+    const char * infeContentType;
+    size_t infeContentTypeSize;
+    avifOffsetFixupArray mdatFixups;
+
+    uint16_t irefToID; // if non-zero, make an iref from this id -> irefToID
+    const char * irefType;
+
+    uint32_t gridCols; // if non-zero (legal range [1-256]), this is a grid item
+    uint32_t gridRows; // if non-zero (legal range [1-256]), this is a grid item
+
+    // the reconstructed image of a grid item will be trimmed to these dimensions (only present on grid items)
+    uint32_t gridWidth;
+    uint32_t gridHeight;
+
+    uint32_t extraLayerCount; // if non-zero (legal range [1-(AVIF_MAX_AV1_LAYER_COUNT-1)]), this is a layered AV1 image
+
+    uint16_t dimgFromID; // if non-zero, make an iref from dimgFromID -> this id
+
+    struct ipmaArray ipma;
+} avifEncoderItem;
+AVIF_ARRAY_DECLARE(avifEncoderItemArray, avifEncoderItem, item);
+
+// ---------------------------------------------------------------------------
+// avifEncoderItemReference
+
+// pointer to one "item" interested in
+typedef avifEncoderItem * avifEncoderItemReference;
+AVIF_ARRAY_DECLARE(avifEncoderItemReferenceArray, avifEncoderItemReference, ref);
+
+// ---------------------------------------------------------------------------
+// avifEncoderFrame
+
+typedef struct avifEncoderFrame
+{
+    uint64_t durationInTimescales;
+} avifEncoderFrame;
+AVIF_ARRAY_DECLARE(avifEncoderFrameArray, avifEncoderFrame, frame);
+
+// ---------------------------------------------------------------------------
+// avifEncoderData
+
+AVIF_ARRAY_DECLARE(avifEncoderItemIdArray, uint16_t, itemID);
+
+typedef struct avifEncoderData
+{
+    avifEncoderItemArray items;
+    avifEncoderFrameArray frames;
+    // Map the encoder settings quality and qualityAlpha to quantizer and quantizerAlpha
+    int quantizer;
+    int quantizerAlpha;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    int quantizerGainMap;
+#endif
+    // tileRowsLog2 and tileColsLog2 are the actual tiling values after automatic tiling is handled
+    int tileRowsLog2;
+    int tileColsLog2;
+    avifEncoder lastEncoder;
+    // lastQuantizer and lastQuantizerAlpha are the quantizer and quantizerAlpha values used last
+    // time
+    int lastQuantizer;
+    int lastQuantizerAlpha;
+    // lastTileRowsLog2 and lastTileColsLog2 are the actual tiling values used last time
+    int lastTileRowsLog2;
+    int lastTileColsLog2;
+    avifImage * imageMetadata;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    // For convenience, holds metadata derived from the avifGainMap struct (when present) about the
+    // altenate image
+    avifImage * altImageMetadata;
+#endif
+    uint16_t lastItemID;
+    uint16_t primaryItemID;
+    avifEncoderItemIdArray alternativeItemIDs; // list of item ids for an 'altr' box (group of alternatives to each other)
+    avifBool singleImage; // if true, the AVIF_ADD_IMAGE_FLAG_SINGLE flag was set on the first call to avifEncoderAddImage()
+    avifBool alphaPresent;
+    size_t gainMapSizeBytes;
+    // Fields specific to AV1/AV2
+    const char * imageItemType;  // "av01" for AV1 ("av02" for AV2 if AVIF_CODEC_AVM)
+    const char * configPropName; // "av1C" for AV1 ("av2C" for AV2 if AVIF_CODEC_AVM)
+} avifEncoderData;
+
+static void avifEncoderDataDestroy(avifEncoderData * data);
+
+// Returns NULL if a memory allocation failed.
+static avifEncoderData * avifEncoderDataCreate(void)
+{
+    avifEncoderData * data = (avifEncoderData *)avifAlloc(sizeof(avifEncoderData));
+    if (!data) {
+        return NULL;
+    }
+    memset(data, 0, sizeof(avifEncoderData));
+    data->imageMetadata = avifImageCreateEmpty();
+    if (!data->imageMetadata) {
+        goto error;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    data->altImageMetadata = avifImageCreateEmpty();
+    if (!data->altImageMetadata) {
+        goto error;
+    }
+#endif
+    if (!avifArrayCreate(&data->items, sizeof(avifEncoderItem), 8)) {
+        goto error;
+    }
+    if (!avifArrayCreate(&data->frames, sizeof(avifEncoderFrame), 1)) {
+        goto error;
+    }
+    if (!avifArrayCreate(&data->alternativeItemIDs, sizeof(uint16_t), 1)) {
+        goto error;
+    }
+    return data;
+
+error:
+    avifEncoderDataDestroy(data);
+    return NULL;
+}
+
+static avifEncoderItem * avifEncoderDataCreateItem(avifEncoderData * data, const char * type, const char * infeName, size_t infeNameSize, uint32_t cellIndex)
+{
+    avifEncoderItem * item = (avifEncoderItem *)avifArrayPush(&data->items);
+    if (item == NULL) {
+        return NULL;
+    }
+    ++data->lastItemID;
+    item->id = data->lastItemID;
+    memcpy(item->type, type, sizeof(item->type));
+    item->infeName = infeName;
+    item->infeNameSize = infeNameSize;
+    item->encodeOutput = avifCodecEncodeOutputCreate();
+    if (item->encodeOutput == NULL) {
+        goto error;
+    }
+    item->cellIndex = cellIndex;
+    if (!avifArrayCreate(&item->mdatFixups, sizeof(avifOffsetFixup), 4)) {
+        goto error;
+    }
+    return item;
+
+error:
+    if (item->encodeOutput != NULL) {
+        avifCodecEncodeOutputDestroy(item->encodeOutput);
+    }
+    --data->lastItemID;
+    avifArrayPop(&data->items);
+    return NULL;
+}
+
+static avifEncoderItem * avifEncoderDataFindItemByID(avifEncoderData * data, uint16_t id)
+{
+    for (uint32_t itemIndex = 0; itemIndex < data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &data->items.item[itemIndex];
+        if (item->id == id) {
+            return item;
+        }
+    }
+    return NULL;
+}
+
+static void avifEncoderDataDestroy(avifEncoderData * data)
+{
+    for (uint32_t i = 0; i < data->items.count; ++i) {
+        avifEncoderItem * item = &data->items.item[i];
+        if (item->codec) {
+            avifCodecDestroy(item->codec);
+        }
+        avifCodecEncodeOutputDestroy(item->encodeOutput);
+        avifRWDataFree(&item->metadataPayload);
+        avifArrayDestroy(&item->mdatFixups);
+    }
+    if (data->imageMetadata) {
+        avifImageDestroy(data->imageMetadata);
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (data->altImageMetadata) {
+        avifImageDestroy(data->altImageMetadata);
+    }
+#endif
+    avifArrayDestroy(&data->items);
+    avifArrayDestroy(&data->frames);
+    avifArrayDestroy(&data->alternativeItemIDs);
+    avifFree(data);
+}
+
+static avifResult avifEncoderItemAddMdatFixup(avifEncoderItem * item, const avifRWStream * s)
+{
+    avifOffsetFixup * fixup = (avifOffsetFixup *)avifArrayPush(&item->mdatFixups);
+    AVIF_CHECKERR(fixup != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    fixup->offset = avifRWStreamOffset(s);
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+// avifItemPropertyDedup - Provides ipco deduplication
+
+typedef struct avifItemProperty
+{
+    uint8_t index;
+    size_t offset;
+    size_t size;
+} avifItemProperty;
+AVIF_ARRAY_DECLARE(avifItemPropertyArray, avifItemProperty, property);
+
+typedef struct avifItemPropertyDedup
+{
+    avifItemPropertyArray properties;
+    avifRWStream s;    // Temporary stream for each new property, checked against already-written boxes for deduplications
+    avifRWData buffer; // Temporary storage for 's'
+    uint8_t nextIndex; // 1-indexed, incremented every time another unique property is finished
+} avifItemPropertyDedup;
+
+static avifItemPropertyDedup * avifItemPropertyDedupCreate(void)
+{
+    avifItemPropertyDedup * dedup = (avifItemPropertyDedup *)avifAlloc(sizeof(avifItemPropertyDedup));
+    if (dedup == NULL) {
+        return NULL;
+    }
+    memset(dedup, 0, sizeof(avifItemPropertyDedup));
+    if (!avifArrayCreate(&dedup->properties, sizeof(avifItemProperty), 8)) {
+        avifFree(dedup);
+        return NULL;
+    }
+    if (avifRWDataRealloc(&dedup->buffer, 2048) != AVIF_RESULT_OK) {
+        avifArrayDestroy(&dedup->properties);
+        avifFree(dedup);
+        return NULL;
+    }
+    return dedup;
+}
+
+static void avifItemPropertyDedupDestroy(avifItemPropertyDedup * dedup)
+{
+    avifArrayDestroy(&dedup->properties);
+    avifRWDataFree(&dedup->buffer);
+    avifFree(dedup);
+}
+
+// Resets the dedup's temporary write stream in preparation for a single item property's worth of writing
+static void avifItemPropertyDedupStart(avifItemPropertyDedup * dedup)
+{
+    avifRWStreamStart(&dedup->s, &dedup->buffer);
+}
+
+// This compares the newly written item property (in the dedup's temporary storage buffer) to
+// already-written properties (whose offsets/sizes in outputStream are recorded in the dedup). If a
+// match is found, the previous property's index is used. If this new property is unique, it is
+// assigned the next available property index, written to the output stream, and its offset/size in
+// the output stream is recorded in the dedup for future comparisons.
+//
+// On success, this function adds to the given ipma box a property association linking the reused
+// or newly created property with the item.
+static avifResult avifItemPropertyDedupFinish(avifItemPropertyDedup * dedup, avifRWStream * outputStream, struct ipmaArray * ipma, avifBool essential)
+{
+    uint8_t propertyIndex = 0;
+    const size_t newPropertySize = avifRWStreamOffset(&dedup->s);
+
+    for (size_t i = 0; i < dedup->properties.count; ++i) {
+        avifItemProperty * property = &dedup->properties.property[i];
+        if ((property->size == newPropertySize) &&
+            !memcmp(&outputStream->raw->data[property->offset], dedup->buffer.data, newPropertySize)) {
+            // We've already written this exact property, reuse it
+            propertyIndex = property->index;
+            AVIF_ASSERT_OR_RETURN(propertyIndex != 0);
+            break;
+        }
+    }
+
+    if (propertyIndex == 0) {
+        // Write a new property, and remember its location in the output stream for future deduplication
+        avifItemProperty * property = (avifItemProperty *)avifArrayPush(&dedup->properties);
+        AVIF_CHECKERR(property != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+        property->index = ++dedup->nextIndex; // preincrement so the first new index is 1 (as ipma is 1-indexed)
+        property->size = newPropertySize;
+        property->offset = avifRWStreamOffset(outputStream);
+        AVIF_CHECKRES(avifRWStreamWrite(outputStream, dedup->buffer.data, newPropertySize));
+        propertyIndex = property->index;
+    }
+
+    AVIF_CHECKERR(ipma->count < MAX_ASSOCIATIONS, AVIF_RESULT_UNKNOWN_ERROR);
+    ipma->associations[ipma->count] = propertyIndex;
+    ipma->essential[ipma->count] = essential;
+    ++ipma->count;
+    return AVIF_RESULT_OK;
+}
+
+// ---------------------------------------------------------------------------
+
+static const avifScalingMode noScaling = { { 1, 1 }, { 1, 1 } };
+
+avifEncoder * avifEncoderCreate(void)
+{
+    avifEncoder * encoder = (avifEncoder *)avifAlloc(sizeof(avifEncoder));
+    if (!encoder) {
+        return NULL;
+    }
+    memset(encoder, 0, sizeof(avifEncoder));
+    encoder->codecChoice = AVIF_CODEC_CHOICE_AUTO;
+    encoder->maxThreads = 1;
+    encoder->speed = AVIF_SPEED_DEFAULT;
+    encoder->keyframeInterval = 0;
+    encoder->timescale = 1;
+    encoder->repetitionCount = AVIF_REPETITION_COUNT_INFINITE;
+    encoder->quality = AVIF_QUALITY_DEFAULT;
+    encoder->qualityAlpha = AVIF_QUALITY_DEFAULT;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    encoder->qualityGainMap = AVIF_QUALITY_DEFAULT;
+#endif
+    encoder->minQuantizer = AVIF_QUANTIZER_BEST_QUALITY;
+    encoder->maxQuantizer = AVIF_QUANTIZER_WORST_QUALITY;
+    encoder->minQuantizerAlpha = AVIF_QUANTIZER_BEST_QUALITY;
+    encoder->maxQuantizerAlpha = AVIF_QUANTIZER_WORST_QUALITY;
+    encoder->tileRowsLog2 = 0;
+    encoder->tileColsLog2 = 0;
+    encoder->autoTiling = AVIF_FALSE;
+    encoder->scalingMode = noScaling;
+    encoder->data = avifEncoderDataCreate();
+    encoder->csOptions = avifCodecSpecificOptionsCreate();
+    if (!encoder->data || !encoder->csOptions) {
+        avifEncoderDestroy(encoder);
+        return NULL;
+    }
+    encoder->headerFormat = AVIF_HEADER_FULL;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    encoder->sampleTransformRecipe = AVIF_SAMPLE_TRANSFORM_NONE;
+#endif
+    return encoder;
+}
+
+void avifEncoderDestroy(avifEncoder * encoder)
+{
+    if (encoder->csOptions) {
+        avifCodecSpecificOptionsDestroy(encoder->csOptions);
+    }
+    if (encoder->data) {
+        avifEncoderDataDestroy(encoder->data);
+    }
+    avifFree(encoder);
+}
+
+avifResult avifEncoderSetCodecSpecificOption(avifEncoder * encoder, const char * key, const char * value)
+{
+    return avifCodecSpecificOptionsSet(encoder->csOptions, key, value);
+}
+
+static void avifEncoderBackupSettings(avifEncoder * encoder)
+{
+    avifEncoder * lastEncoder = &encoder->data->lastEncoder;
+
+    // lastEncoder->data is only used to mark that lastEncoder is initialized. lastEncoder->data
+    // must not be dereferenced.
+    lastEncoder->data = encoder->data;
+    lastEncoder->codecChoice = encoder->codecChoice;
+    lastEncoder->maxThreads = encoder->maxThreads;
+    lastEncoder->speed = encoder->speed;
+    lastEncoder->keyframeInterval = encoder->keyframeInterval;
+    lastEncoder->timescale = encoder->timescale;
+    lastEncoder->repetitionCount = encoder->repetitionCount;
+    lastEncoder->extraLayerCount = encoder->extraLayerCount;
+    lastEncoder->minQuantizer = encoder->minQuantizer;
+    lastEncoder->maxQuantizer = encoder->maxQuantizer;
+    lastEncoder->minQuantizerAlpha = encoder->minQuantizerAlpha;
+    lastEncoder->maxQuantizerAlpha = encoder->maxQuantizerAlpha;
+    encoder->data->lastQuantizer = encoder->data->quantizer;
+    encoder->data->lastQuantizerAlpha = encoder->data->quantizerAlpha;
+    encoder->data->lastTileRowsLog2 = encoder->data->tileRowsLog2;
+    encoder->data->lastTileColsLog2 = encoder->data->tileColsLog2;
+    lastEncoder->scalingMode = encoder->scalingMode;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    lastEncoder->sampleTransformRecipe = encoder->sampleTransformRecipe;
+#endif
+}
+
+// This function detects changes made on avifEncoder. It returns true on success (i.e., if every
+// change is valid), or false on failure (i.e., if any setting that can't change was changed). It
+// reports a bitwise-OR of detected changes in encoderChanges.
+static avifBool avifEncoderDetectChanges(const avifEncoder * encoder, avifEncoderChanges * encoderChanges)
+{
+    const avifEncoder * lastEncoder = &encoder->data->lastEncoder;
+    *encoderChanges = 0;
+
+    if (!lastEncoder->data) {
+        // lastEncoder is not initialized.
+        return AVIF_TRUE;
+    }
+
+    if ((lastEncoder->codecChoice != encoder->codecChoice) || (lastEncoder->maxThreads != encoder->maxThreads) ||
+        (lastEncoder->speed != encoder->speed) || (lastEncoder->keyframeInterval != encoder->keyframeInterval) ||
+        (lastEncoder->timescale != encoder->timescale) || (lastEncoder->repetitionCount != encoder->repetitionCount) ||
+        (lastEncoder->extraLayerCount != encoder->extraLayerCount)) {
+        return AVIF_FALSE;
+    }
+
+    if (encoder->data->lastQuantizer != encoder->data->quantizer) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_QUANTIZER;
+    }
+    if (encoder->data->lastQuantizerAlpha != encoder->data->quantizerAlpha) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_QUANTIZER_ALPHA;
+    }
+    if (lastEncoder->minQuantizer != encoder->minQuantizer) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_MIN_QUANTIZER;
+    }
+    if (lastEncoder->maxQuantizer != encoder->maxQuantizer) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_MAX_QUANTIZER;
+    }
+    if (lastEncoder->minQuantizerAlpha != encoder->minQuantizerAlpha) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_MIN_QUANTIZER_ALPHA;
+    }
+    if (lastEncoder->maxQuantizerAlpha != encoder->maxQuantizerAlpha) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_MAX_QUANTIZER_ALPHA;
+    }
+    if (encoder->data->lastTileRowsLog2 != encoder->data->tileRowsLog2) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_TILE_ROWS_LOG2;
+    }
+    if (encoder->data->lastTileColsLog2 != encoder->data->tileColsLog2) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_TILE_COLS_LOG2;
+    }
+    if (memcmp(&lastEncoder->scalingMode, &encoder->scalingMode, sizeof(avifScalingMode)) != 0) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_SCALING_MODE;
+    }
+    if (encoder->csOptions->count > 0) {
+        *encoderChanges |= AVIF_ENCODER_CHANGE_CODEC_SPECIFIC;
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (lastEncoder->sampleTransformRecipe != encoder->sampleTransformRecipe) {
+        return AVIF_FALSE;
+    }
+#endif
+
+    return AVIF_TRUE;
+}
+
+// Same as 'avifEncoderWriteColorProperties' but for the colr nclx box only.
+static avifResult avifEncoderWriteNclxProperty(avifRWStream * dedupStream,
+                                               avifRWStream * outputStream,
+                                               const avifImage * imageMetadata,
+                                               struct ipmaArray * ipma,
+                                               avifItemPropertyDedup * dedup)
+{
+    if (dedup) {
+        avifItemPropertyDedupStart(dedup);
+    }
+    avifBoxMarker colr;
+    AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "colr", AVIF_BOX_SIZE_TBD, &colr));
+    AVIF_CHECKRES(avifRWStreamWriteChars(dedupStream, "nclx", 4));                   // unsigned int(32) colour_type;
+    AVIF_CHECKRES(avifRWStreamWriteU16(dedupStream, imageMetadata->colorPrimaries)); // unsigned int(16) colour_primaries;
+    AVIF_CHECKRES(avifRWStreamWriteU16(dedupStream, imageMetadata->transferCharacteristics)); // unsigned int(16) transfer_characteristics;
+    AVIF_CHECKRES(avifRWStreamWriteU16(dedupStream, imageMetadata->matrixCoefficients)); // unsigned int(16) matrix_coefficients;
+    AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, (imageMetadata->yuvRange == AVIF_RANGE_FULL) ? 1 : 0, /*bitCount=*/1)); // unsigned int(1) full_range_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, 0, /*bitCount=*/7)); // unsigned int(7) reserved = 0;
+    avifRWStreamFinishBox(dedupStream, colr);
+    if (dedup) {
+        AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_FALSE));
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Subset of avifEncoderWriteColorProperties() for the properties pasp, clap, irot, imir.
+static avifResult avifEncoderWriteExtendedColorProperties(avifRWStream * dedupStream,
+                                                          avifRWStream * outputStream,
+                                                          const avifImage * imageMetadata,
+                                                          struct ipmaArray * ipma,
+                                                          avifItemPropertyDedup * dedup);
+
+// This function is used in two codepaths:
+// * writing color *item* properties
+// * writing color *track* properties
+//
+// Item properties must have property associations with them and can be deduplicated (by reusing
+// these associations), so this function leverages the ipma and dedup arguments to do this.
+//
+// Track properties, however, are implicitly associated by the track in which they are contained, so
+// there is no need to build a property association box (ipma), and no way to deduplicate/reuse a
+// property. In this case, the ipma and dedup properties should/will be set to NULL, and this
+// function will avoid using them.
+static avifResult avifEncoderWriteColorProperties(avifRWStream * outputStream,
+                                                  const avifImage * imageMetadata,
+                                                  struct ipmaArray * ipma,
+                                                  avifItemPropertyDedup * dedup)
+{
+    // outputStream is the final bitstream that will be output by the libavif encoder API.
+    // dedupStream is either equal to outputStream or to &dedup->s which is a temporary stream used
+    // to store parts of the final bitstream; these parts may be discarded if they are a duplicate
+    // of an already stored property.
+    avifRWStream * dedupStream = outputStream;
+    if (dedup) {
+        AVIF_ASSERT_OR_RETURN(ipma);
+
+        // Use the dedup's temporary stream for box writes.
+        dedupStream = &dedup->s;
+    }
+
+    if (imageMetadata->icc.size > 0) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker colr;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "colr", AVIF_BOX_SIZE_TBD, &colr));
+        AVIF_CHECKRES(avifRWStreamWriteChars(dedupStream, "prof", 4)); // unsigned int(32) colour_type;
+        AVIF_CHECKRES(avifRWStreamWrite(dedupStream, imageMetadata->icc.data, imageMetadata->icc.size));
+        avifRWStreamFinishBox(dedupStream, colr);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_FALSE));
+        }
+    }
+
+    // HEIF 6.5.5.1, from Amendment 3 allows multiple colr boxes: "at most one for a given value of colour type"
+    // Therefore, *always* writing an nclx box, even if an a prof box was already written above.
+    AVIF_CHECKRES(avifEncoderWriteNclxProperty(dedupStream, outputStream, imageMetadata, ipma, dedup));
+
+    return avifEncoderWriteExtendedColorProperties(dedupStream, outputStream, imageMetadata, ipma, dedup);
+}
+
+static avifResult avifEncoderWriteContentLightLevelInformation(avifRWStream * outputStream,
+                                                               const avifContentLightLevelInformationBox * clli)
+{
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, clli->maxCLL, 16));  // unsigned int(16) max_content_light_level;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, clli->maxPALL, 16)); // unsigned int(16) max_pic_average_light_level;
+    return AVIF_RESULT_OK;
+}
+
+// Same as 'avifEncoderWriteColorProperties' but for properties related to High Dynamic Range only.
+static avifResult avifEncoderWriteHDRProperties(avifRWStream * dedupStream,
+                                                avifRWStream * outputStream,
+                                                const avifImage * imageMetadata,
+                                                struct ipmaArray * ipma,
+                                                avifItemPropertyDedup * dedup)
+{
+    // Write Content Light Level Information, if present
+    if (imageMetadata->clli.maxCLL || imageMetadata->clli.maxPALL) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker clli;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "clli", AVIF_BOX_SIZE_TBD, &clli));
+        AVIF_CHECKRES(avifEncoderWriteContentLightLevelInformation(dedupStream, &imageMetadata->clli));
+        avifRWStreamFinishBox(dedupStream, clli);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_FALSE));
+        }
+    }
+
+    // TODO(maryla): add other HDR boxes: mdcv, cclv, etc. (in avifEncoderWriteMiniHDRProperties() too)
+
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI) && defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+static avifResult avifEncoderWriteMiniHDRProperties(avifRWStream * outputStream, const avifImage * imageMetadata)
+{
+    const avifBool hasClli = imageMetadata->clli.maxCLL != 0 || imageMetadata->clli.maxPALL != 0;
+    const avifBool hasMdcv = AVIF_FALSE;
+    const avifBool hasCclv = AVIF_FALSE;
+    const avifBool hasAmve = AVIF_FALSE;
+    const avifBool hasReve = AVIF_FALSE;
+    const avifBool hasNdwt = AVIF_FALSE;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasClli, 1)); // bit(1) clli_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasMdcv, 1)); // bit(1) mdcv_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasCclv, 1)); // bit(1) cclv_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasAmve, 1)); // bit(1) amve_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasReve, 1)); // bit(1) reve_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(outputStream, hasNdwt, 1)); // bit(1) ndwt_flag;
+
+    if (hasClli) {
+        // ContentLightLevel clli;
+        AVIF_CHECKRES(avifEncoderWriteContentLightLevelInformation(outputStream, &imageMetadata->clli));
+    }
+    if (hasMdcv) {
+        // MasteringDisplayColourVolume mdcv;
+    }
+    if (hasCclv) {
+        // ContentColourVolume cclv;
+    }
+    if (hasAmve) {
+        // AmbientViewingEnvironment amve;
+    }
+    if (hasReve) {
+        // ReferenceViewingEnvironment reve;
+    }
+    if (hasNdwt) {
+        // NominalDiffuseWhite ndwt;
+    }
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI && AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+static avifResult avifEncoderWriteExtendedColorProperties(avifRWStream * dedupStream,
+                                                          avifRWStream * outputStream,
+                                                          const avifImage * imageMetadata,
+                                                          struct ipmaArray * ipma,
+                                                          avifItemPropertyDedup * dedup)
+{
+    // Write (Optional) Transformations
+    if (imageMetadata->transformFlags & AVIF_TRANSFORM_PASP) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker pasp;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "pasp", AVIF_BOX_SIZE_TBD, &pasp));
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->pasp.hSpacing)); // unsigned int(32) hSpacing;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->pasp.vSpacing)); // unsigned int(32) vSpacing;
+        avifRWStreamFinishBox(dedupStream, pasp);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_FALSE));
+        }
+    }
+    if (imageMetadata->transformFlags & AVIF_TRANSFORM_CLAP) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker clap;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "clap", AVIF_BOX_SIZE_TBD, &clap));
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.widthN));    // unsigned int(32) cleanApertureWidthN;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.widthD));    // unsigned int(32) cleanApertureWidthD;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.heightN));   // unsigned int(32) cleanApertureHeightN;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.heightD));   // unsigned int(32) cleanApertureHeightD;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.horizOffN)); // unsigned int(32) horizOffN;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.horizOffD)); // unsigned int(32) horizOffD;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.vertOffN));  // unsigned int(32) vertOffN;
+        AVIF_CHECKRES(avifRWStreamWriteU32(dedupStream, imageMetadata->clap.vertOffD));  // unsigned int(32) vertOffD;
+        avifRWStreamFinishBox(dedupStream, clap);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_TRUE));
+        }
+    }
+    if (imageMetadata->transformFlags & AVIF_TRANSFORM_IROT) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker irot;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "irot", AVIF_BOX_SIZE_TBD, &irot));
+        AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, 0, /*bitCount=*/6)); // unsigned int (6) reserved = 0;
+        AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, imageMetadata->irot.angle & 0x3, /*bitCount=*/2)); // unsigned int (2) angle;
+        avifRWStreamFinishBox(dedupStream, irot);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_TRUE));
+        }
+    }
+    if (imageMetadata->transformFlags & AVIF_TRANSFORM_IMIR) {
+        if (dedup) {
+            avifItemPropertyDedupStart(dedup);
+        }
+        avifBoxMarker imir;
+        AVIF_CHECKRES(avifRWStreamWriteBox(dedupStream, "imir", AVIF_BOX_SIZE_TBD, &imir));
+        AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, 0, /*bitCount=*/7)); // unsigned int(7) reserved = 0;
+        AVIF_CHECKRES(avifRWStreamWriteBits(dedupStream, imageMetadata->imir.axis ? 1 : 0, /*bitCount=*/1)); // unsigned int(1) axis;
+        avifRWStreamFinishBox(dedupStream, imir);
+        if (dedup) {
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, outputStream, ipma, AVIF_TRUE));
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifRWStreamWriteHandlerBox(avifRWStream * s, const char handlerType[4])
+{
+    avifBoxMarker hdlr;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "hdlr", AVIF_BOX_SIZE_TBD, 0, 0, &hdlr));
+    AVIF_CHECKRES(avifRWStreamWriteU32(s, 0));                // unsigned int(32) pre_defined = 0;
+    AVIF_CHECKRES(avifRWStreamWriteChars(s, handlerType, 4)); // unsigned int(32) handler_type;
+    AVIF_CHECKRES(avifRWStreamWriteZeros(s, 12));             // const unsigned int(32)[3] reserved = 0;
+    AVIF_CHECKRES(avifRWStreamWriteChars(s, "", 1));          // string name; (writing null terminator)
+    avifRWStreamFinishBox(s, hdlr);
+    return AVIF_RESULT_OK;
+}
+
+// Write unassociated metadata items (EXIF, XMP) to a small meta box inside of a trak box.
+// These items are implicitly associated with the track they are contained within.
+static avifResult avifEncoderWriteTrackMetaBox(avifEncoder * encoder, avifRWStream * s)
+{
+    // Count how many non-image items (such as EXIF/XMP) are being written
+    uint32_t metadataItemCount = 0;
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if (memcmp(item->type, encoder->data->imageItemType, 4) != 0) {
+            ++metadataItemCount;
+        }
+    }
+    if (metadataItemCount == 0) {
+        // Don't even bother writing the trak meta box
+        return AVIF_RESULT_OK;
+    }
+
+    avifBoxMarker meta;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "meta", AVIF_BOX_SIZE_TBD, 0, 0, &meta));
+
+    AVIF_CHECKRES(avifRWStreamWriteHandlerBox(s, "pict"));
+
+    avifBoxMarker iloc;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "iloc", AVIF_BOX_SIZE_TBD, 0, 0, &iloc));
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 4, /*bitCount=*/4));          // unsigned int(4) offset_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 4, /*bitCount=*/4));          // unsigned int(4) length_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, /*bitCount=*/4));          // unsigned int(4) base_offset_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, /*bitCount=*/4));          // unsigned int(4) reserved;
+    AVIF_CHECKRES(avifRWStreamWriteU16(s, (uint16_t)metadataItemCount)); // unsigned int(16) item_count;
+    for (uint32_t trakItemIndex = 0; trakItemIndex < encoder->data->items.count; ++trakItemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[trakItemIndex];
+        if (memcmp(item->type, encoder->data->imageItemType, 4) == 0) {
+            // Skip over all non-metadata items
+            continue;
+        }
+
+        AVIF_CHECKRES(avifRWStreamWriteU16(s, item->id));          // unsigned int(16) item_ID;
+        AVIF_CHECKRES(avifRWStreamWriteU16(s, 0));                 // unsigned int(16) data_reference_index;
+        AVIF_CHECKRES(avifRWStreamWriteU16(s, 1));                 // unsigned int(16) extent_count;
+        AVIF_CHECKRES(avifEncoderItemAddMdatFixup(item, s));       //
+        AVIF_CHECKRES(avifRWStreamWriteU32(s, 0 /* set later */)); // unsigned int(offset_size*8) extent_offset;
+        AVIF_CHECKRES(avifRWStreamWriteU32(s, (uint32_t)item->metadataPayload.size)); // unsigned int(length_size*8) extent_length;
+    }
+    avifRWStreamFinishBox(s, iloc);
+
+    avifBoxMarker iinf;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "iinf", AVIF_BOX_SIZE_TBD, 0, 0, &iinf));
+    AVIF_CHECKRES(avifRWStreamWriteU16(s, (uint16_t)metadataItemCount)); //  unsigned int(16) entry_count;
+    for (uint32_t trakItemIndex = 0; trakItemIndex < encoder->data->items.count; ++trakItemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[trakItemIndex];
+        if (memcmp(item->type, encoder->data->imageItemType, 4) == 0) {
+            continue;
+        }
+
+        AVIF_ASSERT_OR_RETURN(!item->hiddenImage);
+        avifBoxMarker infe;
+        AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "infe", AVIF_BOX_SIZE_TBD, 2, 0, &infe));
+        AVIF_CHECKRES(avifRWStreamWriteU16(s, item->id));                             // unsigned int(16) item_ID;
+        AVIF_CHECKRES(avifRWStreamWriteU16(s, 0));                                    // unsigned int(16) item_protection_index;
+        AVIF_CHECKRES(avifRWStreamWrite(s, item->type, 4));                           // unsigned int(32) item_type;
+        AVIF_CHECKRES(avifRWStreamWriteChars(s, item->infeName, item->infeNameSize)); // string item_name; (writing null terminator)
+        if (item->infeContentType && item->infeContentTypeSize) { // string content_type; (writing null terminator)
+            AVIF_CHECKRES(avifRWStreamWriteChars(s, item->infeContentType, item->infeContentTypeSize));
+        }
+        avifRWStreamFinishBox(s, infe);
+    }
+    avifRWStreamFinishBox(s, iinf);
+
+    avifRWStreamFinishBox(s, meta);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifWriteGridPayload(avifRWData * data, uint32_t gridCols, uint32_t gridRows, uint32_t gridWidth, uint32_t gridHeight)
+{
+    // ISO/IEC 23008-12 6.6.2.3.2
+    // aligned(8) class ImageGrid {
+    //     unsigned int(8) version = 0;
+    //     unsigned int(8) flags;
+    //     FieldLength = ((flags & 1) + 1) * 16;
+    //     unsigned int(8) rows_minus_one;
+    //     unsigned int(8) columns_minus_one;
+    //     unsigned int(FieldLength) output_width;
+    //     unsigned int(FieldLength) output_height;
+    // }
+
+    uint8_t gridFlags = ((gridWidth > 65535) || (gridHeight > 65535)) ? 1 : 0;
+
+    avifRWStream s;
+    avifRWStreamStart(&s, data);
+    AVIF_CHECKRES(avifRWStreamWriteU8(&s, 0));                       // unsigned int(8) version = 0;
+    AVIF_CHECKRES(avifRWStreamWriteU8(&s, gridFlags));               // unsigned int(8) flags;
+    AVIF_CHECKRES(avifRWStreamWriteU8(&s, (uint8_t)(gridRows - 1))); // unsigned int(8) rows_minus_one;
+    AVIF_CHECKRES(avifRWStreamWriteU8(&s, (uint8_t)(gridCols - 1))); // unsigned int(8) columns_minus_one;
+    if (gridFlags & 1) {
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, gridWidth));  // unsigned int(FieldLength) output_width;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, gridHeight)); // unsigned int(FieldLength) output_height;
+    } else {
+        uint16_t tmpWidth = (uint16_t)gridWidth;
+        uint16_t tmpHeight = (uint16_t)gridHeight;
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, tmpWidth));  // unsigned int(FieldLength) output_width;
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, tmpHeight)); // unsigned int(FieldLength) output_height;
+    }
+    avifRWStreamFinishWrite(&s);
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+
+static avifBool avifGainMapIdenticalChannels(const avifGainMap * gainMap)
+{
+    return gainMap->gainMapMin[0].n == gainMap->gainMapMin[1].n && gainMap->gainMapMin[0].n == gainMap->gainMapMin[2].n &&
+           gainMap->gainMapMin[0].d == gainMap->gainMapMin[1].d && gainMap->gainMapMin[0].d == gainMap->gainMapMin[2].d &&
+           gainMap->gainMapMax[0].n == gainMap->gainMapMax[1].n && gainMap->gainMapMax[0].n == gainMap->gainMapMax[2].n &&
+           gainMap->gainMapMax[0].d == gainMap->gainMapMax[1].d && gainMap->gainMapMax[0].d == gainMap->gainMapMax[2].d &&
+           gainMap->gainMapGamma[0].n == gainMap->gainMapGamma[1].n && gainMap->gainMapGamma[0].n == gainMap->gainMapGamma[2].n &&
+           gainMap->gainMapGamma[0].d == gainMap->gainMapGamma[1].d && gainMap->gainMapGamma[0].d == gainMap->gainMapGamma[2].d &&
+           gainMap->baseOffset[0].n == gainMap->baseOffset[1].n && gainMap->baseOffset[0].n == gainMap->baseOffset[2].n &&
+           gainMap->baseOffset[0].d == gainMap->baseOffset[1].d && gainMap->baseOffset[0].d == gainMap->baseOffset[2].d &&
+           gainMap->alternateOffset[0].n == gainMap->alternateOffset[1].n &&
+           gainMap->alternateOffset[0].n == gainMap->alternateOffset[2].n &&
+           gainMap->alternateOffset[0].d == gainMap->alternateOffset[1].d &&
+           gainMap->alternateOffset[0].d == gainMap->alternateOffset[2].d;
+}
+
+// Returns the number of bytes written by avifWriteGainmapMetadata().
+static avifBool avifGainMapMetadataSize(const avifGainMap * gainMap)
+{
+    const uint8_t channelCount = avifGainMapIdenticalChannels(gainMap) ? 1u : 3u;
+    return sizeof(uint16_t) * 2 + sizeof(uint8_t) + sizeof(uint32_t) * 4 + channelCount * sizeof(uint32_t) * 10;
+}
+
+static avifResult avifWriteGainmapMetadata(avifRWStream * s, const avifGainMap * gainMap, avifDiagnostics * diag)
+{
+    AVIF_CHECKRES(avifGainMapValidateMetadata(gainMap, diag));
+    const size_t offset = avifRWStreamOffset(s);
+
+    // GainMapMetadata syntax as per clause C.2.2 of ISO 21496-1:
+
+    // GainMapVersion syntax as per clause C.2.2 of ISO 21496-1:
+    const uint16_t minimumVersion = 0;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, minimumVersion, 16)); // unsigned int(16) minimum_version;
+    const uint16_t writerVersion = 0;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, writerVersion, 16)); // unsigned int(16) writer_version;
+
+    if (minimumVersion == 0) {
+        const uint8_t channelCount = avifGainMapIdenticalChannels(gainMap) ? 1u : 3u;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, channelCount == 3, 1));          // unsigned int(1) is_multichannel;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->useBaseColorSpace, 1)); // unsigned int(1) use_base_colour_space;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, 6));                          // unsigned int(6) reserved;
+
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->baseHdrHeadroom.n, 32)); // unsigned int(32) base_hdr_headroom_numerator;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->baseHdrHeadroom.d, 32)); // unsigned int(32) base_hdr_headroom_denominator;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->alternateHdrHeadroom.n, 32)); // unsigned int(32) alternate_hdr_headroom_numerator;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->alternateHdrHeadroom.d, 32)); // unsigned int(32) alternate_hdr_headroom_denominator;
+
+        // GainMapChannel channels[channel_count];
+        for (int c = 0; c < channelCount; ++c) {
+            // GainMapChannel syntax as per clause C.2.2 of ISO 21496-1:
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)gainMap->gainMapMin[c].n, 32)); // int(32) gain_map_min_numerator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->gainMapMin[c].d, 32)); // unsigned int(32) gain_map_min_denominator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)gainMap->gainMapMax[c].n, 32)); // int(32) gain_map_max_numerator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->gainMapMax[c].d, 32));   // unsigned int(32) gain_map_max_denominator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->gainMapGamma[c].n, 32)); // unsigned int(32) gamma_numerator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->gainMapGamma[c].d, 32)); // unsigned int(32) gamma_denominator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)gainMap->baseOffset[c].n, 32)); // int(32) base_offset_numerator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->baseOffset[c].d, 32)); // unsigned int(32) base_offset_denominator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)gainMap->alternateOffset[c].n, 32)); // int(32) alternate_offset_numerator;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainMap->alternateOffset[c].d, 32)); // unsigned int(32) alternate_offset_denominator;
+        }
+    }
+
+    AVIF_ASSERT_OR_RETURN(avifRWStreamOffset(s) == offset + avifGainMapMetadataSize(gainMap));
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifWriteToneMappedImagePayload(avifRWData * data, const avifGainMap * gainMap, avifDiagnostics * diag)
+{
+    avifRWStream s;
+    avifRWStreamStart(&s, data);
+    // ToneMapImage syntax as per section 6.6.2.4.2 of ISO/IEC23008-12:2024
+    // amendment "Support for tone map derived image items and other improvements":
+    const uint8_t version = 0;
+    AVIF_CHECKRES(avifRWStreamWriteU8(&s, version)); // unsigned int(8) version = 0;
+    if (version == 0) {
+        AVIF_CHECKRES(avifWriteGainmapMetadata(&s, gainMap, diag)); // GainMapMetadata;
+    }
+    avifRWStreamFinishWrite(&s);
+    return AVIF_RESULT_OK;
+}
+
+size_t avifEncoderGetGainMapSizeBytes(avifEncoder * encoder)
+{
+    return encoder->data->gainMapSizeBytes;
+}
+
+// Sets altImageMetadata's metadata values to represent the "alternate" image as if applying the gain map to the base image.
+static avifResult avifImageCopyAltImageMetadata(avifImage * altImageMetadata, const avifImage * imageWithGainMap)
+{
+    altImageMetadata->width = imageWithGainMap->width;
+    altImageMetadata->height = imageWithGainMap->height;
+    AVIF_CHECKRES(avifRWDataSet(&altImageMetadata->icc, imageWithGainMap->gainMap->altICC.data, imageWithGainMap->gainMap->altICC.size));
+    altImageMetadata->colorPrimaries = imageWithGainMap->gainMap->altColorPrimaries;
+    altImageMetadata->transferCharacteristics = imageWithGainMap->gainMap->altTransferCharacteristics;
+    altImageMetadata->matrixCoefficients = imageWithGainMap->gainMap->altMatrixCoefficients;
+    altImageMetadata->yuvRange = imageWithGainMap->gainMap->altYUVRange;
+    altImageMetadata->depth = imageWithGainMap->gainMap->altDepth
+                                  ? imageWithGainMap->gainMap->altDepth
+                                  : AVIF_MAX(imageWithGainMap->depth, imageWithGainMap->gainMap->image->depth);
+    altImageMetadata->yuvFormat = (imageWithGainMap->gainMap->altPlaneCount == 1) ? AVIF_PIXEL_FORMAT_YUV400 : AVIF_PIXEL_FORMAT_YUV444;
+    altImageMetadata->clli = imageWithGainMap->gainMap->altCLLI;
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+static avifResult avifEncoderWriteSampleTransformTokens(avifRWStream * s, const avifSampleTransformExpression * expression)
+{
+    AVIF_ASSERT_OR_RETURN(expression->count <= 256);
+    AVIF_CHECKRES(avifRWStreamWriteU8(s, (uint8_t)expression->count)); // unsigned int(8) token_count;
+
+    for (uint32_t t = 0; t < expression->count; ++t) {
+        const avifSampleTransformToken * token = &expression->tokens[t];
+        AVIF_CHECKRES(avifRWStreamWriteU8(s, token->type)); // unsigned int(8) token;
+
+        if (token->type == AVIF_SAMPLE_TRANSFORM_CONSTANT) {
+            // TODO(yguyon): Verify two's complement representation is guaranteed here.
+            const uint32_t constant = *(const uint32_t *)&token->constant;
+            AVIF_CHECKRES(avifRWStreamWriteU32(s, constant)); // signed int(1<<(bit_depth+3)) constant;
+        } else if (token->type == AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX) {
+            AVIF_CHECKRES(avifRWStreamWriteU8(s, token->inputImageItemIndex)); // unsigned int(8) input_image_item_index;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderWriteSampleTransformPayload(avifEncoder * encoder, avifRWData * data)
+{
+    avifRWStream s;
+    avifRWStreamStart(&s, data);
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, 0, /*bitCount=*/6)); // unsigned int(6) version = 0;
+    // AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32 is necessary because the two input images
+    // once combined use 16-bit unsigned values, but intermediate results are stored in signed integers.
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32, /*bitCount=*/2)); // unsigned int(2) bit_depth;
+
+    avifSampleTransformExpression expression = { 0 };
+    AVIF_CHECKRES(avifSampleTransformRecipeToExpression(encoder->sampleTransformRecipe, &expression));
+    const avifResult result = avifEncoderWriteSampleTransformTokens(&s, &expression);
+    avifArrayDestroy(&expression);
+    if (result != AVIF_RESULT_OK) {
+        avifDiagnosticsPrintf(&encoder->diag, "Failed to write sample transform metadata for recipe %d", (int)encoder->sampleTransformRecipe);
+        return result;
+    }
+
+    avifRWStreamFinishWrite(&s);
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+static avifResult avifEncoderDataCreateExifItem(avifEncoderData * data, const avifRWData * exif)
+{
+    size_t exifTiffHeaderOffset;
+    const avifResult result = avifGetExifTiffHeaderOffset(exif->data, exif->size, &exifTiffHeaderOffset);
+    if (result != AVIF_RESULT_OK) {
+        // Couldn't find the TIFF header
+        return result;
+    }
+
+    avifEncoderItem * exifItem = avifEncoderDataCreateItem(data, "Exif", "Exif", 5, 0);
+    if (!exifItem) {
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    exifItem->irefToID = data->primaryItemID;
+    exifItem->irefType = "cdsc";
+
+    const uint32_t offset32bit = avifHTONL((uint32_t)exifTiffHeaderOffset);
+    AVIF_CHECKRES(avifRWDataRealloc(&exifItem->metadataPayload, sizeof(offset32bit) + exif->size));
+    memcpy(exifItem->metadataPayload.data, &offset32bit, sizeof(offset32bit));
+    memcpy(exifItem->metadataPayload.data + sizeof(offset32bit), exif->data, exif->size);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderDataCreateXMPItem(avifEncoderData * data, const avifRWData * xmp)
+{
+    avifEncoderItem * xmpItem = avifEncoderDataCreateItem(data, "mime", "XMP", 4, 0);
+    if (!xmpItem) {
+        return AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    xmpItem->irefToID = data->primaryItemID;
+    xmpItem->irefType = "cdsc";
+
+    xmpItem->infeContentType = xmpContentType;
+    xmpItem->infeContentTypeSize = xmpContentTypeSize;
+    AVIF_CHECKRES(avifRWDataSet(&xmpItem->metadataPayload, xmp->data, xmp->size));
+    return AVIF_RESULT_OK;
+}
+
+// Same as avifImageCopy() but pads the dstImage with border pixel values to reach dstWidth and dstHeight.
+static avifResult avifImageCopyAndPad(avifImage * const dstImage, const avifImage * srcImage, uint32_t dstWidth, uint32_t dstHeight)
+{
+    AVIF_ASSERT_OR_RETURN(dstImage);
+    AVIF_ASSERT_OR_RETURN(!dstImage->width && !dstImage->height); // dstImage is not set yet.
+    AVIF_ASSERT_OR_RETURN(dstWidth >= srcImage->width);
+    AVIF_ASSERT_OR_RETURN(dstHeight >= srcImage->height);
+
+    // Copy all fields but do not allocate the planes.
+    AVIF_CHECKRES(avifImageCopy(dstImage, srcImage, (avifPlanesFlag)0));
+    dstImage->width = dstWidth;
+    dstImage->height = dstHeight;
+
+    if (srcImage->yuvPlanes[AVIF_CHAN_Y]) {
+        AVIF_CHECKRES(avifImageAllocatePlanes(dstImage, AVIF_PLANES_YUV));
+    }
+    if (srcImage->alphaPlane) {
+        AVIF_CHECKRES(avifImageAllocatePlanes(dstImage, AVIF_PLANES_A));
+    }
+    const avifBool usesU16 = avifImageUsesU16(srcImage);
+    for (int plane = AVIF_CHAN_Y; plane <= AVIF_CHAN_A; ++plane) {
+        const uint8_t * srcRow = avifImagePlane(srcImage, plane);
+        const uint32_t srcRowBytes = avifImagePlaneRowBytes(srcImage, plane);
+        const uint32_t srcPlaneWidth = avifImagePlaneWidth(srcImage, plane);
+        const uint32_t srcPlaneHeight = avifImagePlaneHeight(srcImage, plane); // 0 for A if no alpha and 0 for UV if 4:0:0.
+        const size_t srcPlaneWidthBytes = (size_t)srcPlaneWidth << usesU16;
+
+        uint8_t * dstRow = avifImagePlane(dstImage, plane);
+        const uint32_t dstRowBytes = avifImagePlaneRowBytes(dstImage, plane);
+        const uint32_t dstPlaneWidth = avifImagePlaneWidth(dstImage, plane);
+        const uint32_t dstPlaneHeight = avifImagePlaneHeight(dstImage, plane); // 0 for A if no alpha and 0 for UV if 4:0:0.
+        const size_t dstPlaneWidthBytes = (size_t)dstPlaneWidth << usesU16;
+
+        for (uint32_t j = 0; j < srcPlaneHeight; ++j) {
+            memcpy(dstRow, srcRow, srcPlaneWidthBytes);
+
+            // Pad columns.
+            if (dstPlaneWidth > srcPlaneWidth) {
+                if (usesU16) {
+                    uint16_t * dstRow16 = (uint16_t *)dstRow;
+                    for (uint32_t x = srcPlaneWidth; x < dstPlaneWidth; ++x) {
+                        dstRow16[x] = dstRow16[srcPlaneWidth - 1];
+                    }
+                } else {
+                    memset(&dstRow[srcPlaneWidth], dstRow[srcPlaneWidth - 1], dstPlaneWidth - srcPlaneWidth);
+                }
+            }
+            srcRow += srcRowBytes;
+            dstRow += dstRowBytes;
+        }
+
+        // Pad rows.
+        for (uint32_t j = srcPlaneHeight; j < dstPlaneHeight; ++j) {
+            memcpy(dstRow, dstRow - dstRowBytes, dstPlaneWidthBytes);
+            dstRow += dstRowBytes;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static int avifQualityToQuantizer(int quality, int minQuantizer, int maxQuantizer)
+{
+    int quantizer;
+    if (quality == AVIF_QUALITY_DEFAULT) {
+        // In older libavif releases, avifEncoder didn't have the quality and qualityAlpha fields.
+        // Supply a default value for quantizer.
+        quantizer = (minQuantizer + maxQuantizer) / 2;
+        quantizer = AVIF_CLAMP(quantizer, 0, 63);
+    } else {
+        quality = AVIF_CLAMP(quality, 0, 100);
+        quantizer = ((100 - quality) * 63 + 50) / 100;
+    }
+    return quantizer;
+}
+
+static const char infeNameColor[] = "Color";
+static const char infeNameAlpha[] = "Alpha";
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+static const char infeNameGainMap[] = "GMap";
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+static const char infeNameSampleTransform[] = "SampleTransform";
+#endif
+
+static const char * getInfeName(avifItemCategory itemCategory)
+{
+    if (avifIsAlpha(itemCategory)) {
+        return infeNameAlpha;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (itemCategory == AVIF_ITEM_GAIN_MAP) {
+        return infeNameGainMap;
+    }
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (itemCategory >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY && itemCategory <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY) {
+        return infeNameSampleTransform;
+    }
+#endif
+    return infeNameColor;
+}
+
+// Adds the items for a single cell or a grid of cells. Outputs the topLevelItemID which is
+// the only item if there is exactly one cell, or the grid item for multiple cells.
+// Note: The topLevelItemID output argument has the type uint16_t* instead of avifEncoderItem** because
+//       the avifEncoderItem pointer may be invalidated by a call to avifEncoderDataCreateItem().
+static avifResult avifEncoderAddImageItems(avifEncoder * encoder,
+                                           uint32_t gridCols,
+                                           uint32_t gridRows,
+                                           uint32_t gridWidth,
+                                           uint32_t gridHeight,
+                                           avifItemCategory itemCategory,
+                                           uint16_t * topLevelItemID)
+{
+    const uint32_t cellCount = gridCols * gridRows;
+    const char * infeName = getInfeName(itemCategory);
+    const size_t infeNameSize = strlen(infeName) + 1;
+
+    if (cellCount > 1) {
+        avifEncoderItem * gridItem = avifEncoderDataCreateItem(encoder->data, "grid", infeName, infeNameSize, 0);
+        AVIF_CHECKRES(avifWriteGridPayload(&gridItem->metadataPayload, gridCols, gridRows, gridWidth, gridHeight));
+        gridItem->itemCategory = itemCategory;
+        gridItem->gridCols = gridCols;
+        gridItem->gridRows = gridRows;
+        gridItem->gridWidth = gridWidth;
+        gridItem->gridHeight = gridHeight;
+        *topLevelItemID = gridItem->id;
+    }
+
+    for (uint32_t cellIndex = 0; cellIndex < cellCount; ++cellIndex) {
+        avifEncoderItem * item =
+            avifEncoderDataCreateItem(encoder->data, encoder->data->imageItemType, infeName, infeNameSize, cellIndex);
+        AVIF_CHECKERR(item, AVIF_RESULT_OUT_OF_MEMORY);
+        AVIF_CHECKRES(avifCodecCreate(encoder->codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE, &item->codec));
+        item->codec->csOptions = encoder->csOptions;
+        item->codec->diag = &encoder->diag;
+        item->itemCategory = itemCategory;
+        item->extraLayerCount = encoder->extraLayerCount;
+
+        if (cellCount > 1) {
+            item->dimgFromID = *topLevelItemID;
+            item->hiddenImage = AVIF_TRUE;
+        } else {
+            *topLevelItemID = item->id;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+static avifResult avifEncoderCreateBitDepthExtensionItems(avifEncoder * encoder,
+                                                          uint32_t gridCols,
+                                                          uint32_t gridRows,
+                                                          uint32_t gridWidth,
+                                                          uint32_t gridHeight,
+                                                          uint16_t colorItemID)
+{
+    AVIF_ASSERT_OR_RETURN(encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B ||
+                          encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B ||
+                          encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B);
+
+    // There are multiple possible ISOBMFF box hierarchies for translucent images,
+    // using 'sato' (Sample Transform) derived image items:
+    //  - a primary 'sato' item uses a main color coded item and a hidden color coded item; each color coded
+    //    item has an auxiliary alpha coded item; the main color coded item and the 'sato' item are in
+    //    an 'altr' group (backward-compatible, implemented)
+    //  - a primary 'sato' item uses a main color coded item and a hidden color coded item; the primary
+    //    'sato' item has an auxiliary alpha 'sato' item using two alpha coded items (backward-incompatible)
+    // Likewise, there are multiple possible ISOBMFF box hierarchies for bit-depth-extended grids,
+    // using 'sato' (Sample Transform) derived image items:
+    //  - a primary color 'grid', an auxiliary alpha 'grid', a hidden color 'grid', a hidden auxiliary alpha 'grid'
+    //    and a 'sato' using the two color 'grid's as input items in this order; the primary color item
+    //    and the 'sato' item being in an 'altr' group (backward-compatible, implemented)
+    //  - a primary 'grid' of 'sato' cells and an auxiliary alpha 'grid' of 'sato' cells (backward-incompatible)
+    avifEncoderItem * sampleTransformItem = avifEncoderDataCreateItem(encoder->data,
+                                                                      "sato",
+                                                                      infeNameSampleTransform,
+                                                                      /*infeNameSize=*/strlen(infeNameSampleTransform) + 1,
+                                                                      /*cellIndex=*/0);
+    AVIF_CHECKRES(avifEncoderWriteSampleTransformPayload(encoder, &sampleTransformItem->metadataPayload));
+    sampleTransformItem->itemCategory = AVIF_ITEM_SAMPLE_TRANSFORM;
+    uint16_t sampleTransformItemID = sampleTransformItem->id;
+    // 'altr' group
+    AVIF_ASSERT_OR_RETURN(encoder->data->alternativeItemIDs.count == 0);
+    uint16_t * alternativeItemID = (uint16_t *)avifArrayPush(&encoder->data->alternativeItemIDs);
+    AVIF_CHECKERR(alternativeItemID != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    *alternativeItemID = sampleTransformItem->id;
+    alternativeItemID = (uint16_t *)avifArrayPush(&encoder->data->alternativeItemIDs);
+    AVIF_CHECKERR(alternativeItemID != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    *alternativeItemID = colorItemID;
+
+    uint16_t bitDepthExtensionColorItemId;
+    AVIF_CHECKRES(
+        avifEncoderAddImageItems(encoder, gridCols, gridRows, gridWidth, gridHeight, AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR, &bitDepthExtensionColorItemId));
+    avifEncoderItem * bitDepthExtensionColorItem = avifEncoderDataFindItemByID(encoder->data, bitDepthExtensionColorItemId);
+    assert(bitDepthExtensionColorItem);
+    bitDepthExtensionColorItem->hiddenImage = AVIF_TRUE;
+
+    // Set the color and bit depth extension items' dimgFromID value to point to the sample transform item.
+    // The color item shall be first, and the bit depth extension item second. avifEncoderFinish() writes the
+    // dimg item references in item id order, so as long as colorItemID < bitDepthExtensionColorItemId, the order
+    // will be correct.
+    AVIF_ASSERT_OR_RETURN(colorItemID < bitDepthExtensionColorItemId);
+    avifEncoderItem * colorItem = avifEncoderDataFindItemByID(encoder->data, colorItemID);
+    AVIF_ASSERT_OR_RETURN(colorItem != NULL);
+    AVIF_ASSERT_OR_RETURN(colorItem->dimgFromID == 0); // Our internal API only allows one dimg value per item.
+    colorItem->dimgFromID = sampleTransformItemID;
+    bitDepthExtensionColorItem->dimgFromID = sampleTransformItemID;
+
+    if (encoder->data->alphaPresent) {
+        uint16_t bitDepthExtensionAlphaItemId;
+        AVIF_CHECKRES(
+            avifEncoderAddImageItems(encoder, gridCols, gridRows, gridWidth, gridHeight, AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA, &bitDepthExtensionAlphaItemId));
+        avifEncoderItem * bitDepthExtensionAlphaItem = avifEncoderDataFindItemByID(encoder->data, bitDepthExtensionAlphaItemId);
+        assert(bitDepthExtensionAlphaItem);
+        bitDepthExtensionAlphaItem->irefType = "auxl";
+        bitDepthExtensionAlphaItem->irefToID = bitDepthExtensionColorItemId;
+        if (encoder->data->imageMetadata->alphaPremultiplied) {
+            // The reference may have changed; fetch it again.
+            bitDepthExtensionColorItem = avifEncoderDataFindItemByID(encoder->data, bitDepthExtensionColorItemId);
+            assert(bitDepthExtensionColorItem);
+            bitDepthExtensionColorItem->irefType = "prem";
+            bitDepthExtensionColorItem->irefToID = bitDepthExtensionAlphaItemId;
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+// Same as avifImageApplyExpression() but for the expression (inputImageItem [op] constant).
+// Convenience function.
+static avifResult avifImageApplyImgOpConst(avifImage * result,
+                                           const avifImage * inputImageItem,
+                                           avifSampleTransformTokenType op,
+                                           int32_t constant,
+                                           avifPlanesFlags planes)
+{
+    // Postfix notation.
+    const avifSampleTransformToken tokens[] = { { AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX, 0, /*inputImageItemIndex=*/1 },
+                                                { AVIF_SAMPLE_TRANSFORM_CONSTANT, constant, 0 },
+                                                { (uint8_t)op, 0, 0 } };
+    return avifImageApplyOperations(result, AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32, /*numTokens=*/3, tokens, /*numInputImageItems=*/1, &inputImageItem, planes);
+}
+
+static avifResult avifImageCreateAllocate(avifImage ** sampleTransformedImage, const avifImage * reference, uint32_t numBits, avifPlanesFlag planes)
+{
+    *sampleTransformedImage = avifImageCreate(reference->width, reference->height, numBits, reference->yuvFormat);
+    AVIF_CHECKERR(*sampleTransformedImage != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    return avifImageAllocatePlanes(*sampleTransformedImage, planes);
+}
+
+// Finds the encoded base image and decodes it. Callers of this function must free
+// *codec and *decodedBaseImage if not null, whether the function succeeds or not.
+static avifResult avifEncoderDecodeSatoBaseImage(avifEncoder * encoder,
+                                                 const avifImage * original,
+                                                 uint32_t numBits,
+                                                 avifPlanesFlag planes,
+                                                 avifCodec ** codec,
+                                                 avifImage ** decodedBaseImage)
+{
+    avifDecodeSample sample;
+    memset(&sample, 0, sizeof(sample));
+    sample.spatialID = AVIF_SPATIAL_ID_UNSET;
+
+    // Find the encoded bytes of the base image item.
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if ((item->itemCategory != AVIF_ITEM_COLOR || planes != AVIF_PLANES_YUV) &&
+            (item->itemCategory != AVIF_ITEM_ALPHA || planes != AVIF_PLANES_A)) {
+            continue;
+        }
+
+        AVIF_ASSERT_OR_RETURN(item->encodeOutput != NULL); // TODO: Support grids?
+        AVIF_ASSERT_OR_RETURN(item->encodeOutput->samples.count == 1);
+        AVIF_ASSERT_OR_RETURN(item->encodeOutput->samples.sample[0].data.size != 0);
+        AVIF_ASSERT_OR_RETURN(sample.data.size == 0); // There should be only one base item.
+        sample.data.data = item->encodeOutput->samples.sample[0].data.data;
+        sample.data.size = item->encodeOutput->samples.sample[0].data.size;
+    }
+    AVIF_ASSERT_OR_RETURN(sample.data.size != 0); // There should be at least one base item.
+
+    AVIF_CHECKRES(avifCodecCreate(AVIF_CODEC_CHOICE_AUTO, AVIF_CODEC_FLAG_CAN_DECODE, codec));
+    (*codec)->diag = &encoder->diag;
+    (*codec)->maxThreads = encoder->maxThreads;
+    (*codec)->imageSizeLimit = AVIF_DEFAULT_IMAGE_SIZE_LIMIT;
+    AVIF_CHECKRES(avifImageCreateAllocate(decodedBaseImage, original, numBits, planes));
+    avifBool isLimitedRangeAlpha = AVIF_FALSE; // Ignored.
+    AVIF_CHECKERR((*codec)->getNextImage(*codec, &sample, planes == AVIF_PLANES_A, &isLimitedRangeAlpha, *decodedBaseImage),
+                  AVIF_RESULT_ENCODE_SAMPLE_TRANSFORM_FAILED);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderCreateSatoImage(avifEncoder * encoder,
+                                             const avifEncoderItem * item,
+                                             avifBool itemWillBeEncodedLosslessly,
+                                             const avifImage * image,
+                                             avifImage ** sampleTransformedImage)
+{
+    const avifPlanesFlag planes = avifIsAlpha(item->itemCategory) ? AVIF_PLANES_A : AVIF_PLANES_YUV;
+    // The first image item used as input to the 'sato' Sample Transform derived image item.
+    avifBool isBase = item->itemCategory == AVIF_ITEM_COLOR || item->itemCategory == AVIF_ITEM_ALPHA;
+    if (!isBase) {
+        // The second image item used as input to the 'sato' Sample Transform derived image item.
+        AVIF_ASSERT_OR_RETURN(item->itemCategory >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY &&
+                              item->itemCategory <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY);
+    }
+
+    if (encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B) {
+        if (isBase) {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 8, planes));
+            AVIF_CHECKRES(avifImageApplyImgOpConst(*sampleTransformedImage, image, AVIF_SAMPLE_TRANSFORM_DIVIDE, 256, planes));
+        } else {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 8, planes));
+            AVIF_CHECKRES(avifImageApplyImgOpConst(*sampleTransformedImage, image, AVIF_SAMPLE_TRANSFORM_AND, 255, planes));
+        }
+    } else if (encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B) {
+        if (isBase) {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 12, planes));
+            AVIF_CHECKRES(avifImageApplyImgOpConst(*sampleTransformedImage, image, AVIF_SAMPLE_TRANSFORM_DIVIDE, 16, planes));
+        } else {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 8, planes));
+            AVIF_CHECKRES(avifImageApplyImgOpConst(*sampleTransformedImage, image, AVIF_SAMPLE_TRANSFORM_AND, 15, planes));
+            // AVIF only supports 8, 10 or 12-bit image items. Scale the samples to fit the range.
+            // Note: The samples could be encoded as is without being shifted left before encoding,
+            //       but they would not be shifted right after decoding either. Right shifting after
+            //       decoding provides a guarantee on the range of values and on the lack of integer
+            //       overflow, so it is safer to do these extra steps.
+            //       It also makes more sense from a compression point-of-view to use the full range.
+            // Transform in-place.
+            AVIF_CHECKRES(
+                avifImageApplyImgOpConst(*sampleTransformedImage, *sampleTransformedImage, AVIF_SAMPLE_TRANSFORM_PRODUCT, 16, planes));
+            if (!itemWillBeEncodedLosslessly) {
+                // Small loss at encoding could be amplified by the truncation caused by the right
+                // shift after decoding. Offset sample values now, before encoding, to round rather
+                // than floor the samples shifted after decoding.
+                // Note: Samples were just left shifted by numShiftedBits, so adding less than
+                //       (1<<numShiftedBits) will not trigger any integer overflow.
+                // Transform in-place.
+                AVIF_CHECKRES(
+                    avifImageApplyImgOpConst(*sampleTransformedImage, *sampleTransformedImage, AVIF_SAMPLE_TRANSFORM_SUM, 7, planes));
+            }
+        }
+    } else {
+        AVIF_CHECKERR(encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B,
+                      AVIF_RESULT_NOT_IMPLEMENTED);
+        if (isBase) {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 12, planes));
+            AVIF_CHECKRES(avifImageApplyImgOpConst(*sampleTransformedImage, image, AVIF_SAMPLE_TRANSFORM_DIVIDE, 16, planes));
+        } else {
+            AVIF_CHECKRES(avifImageCreateAllocate(sampleTransformedImage, image, 8, planes));
+            avifCodec * codec = NULL;
+            avifImage * decodedBaseImage = NULL;
+            avifResult result = avifEncoderDecodeSatoBaseImage(encoder, image, 12, planes, &codec, &decodedBaseImage);
+            if (result == AVIF_RESULT_OK) {
+                // decoded = main*16+hidden-128 so hidden = clamp_8b(original-main*16+128). Postfix notation.
+                const avifSampleTransformToken tokens[] = { { AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX, 0, /*inputImageItemIndex=*/1 },
+                                                            { AVIF_SAMPLE_TRANSFORM_INPUT_IMAGE_ITEM_INDEX, 0, /*inputImageItemIndex=*/2 },
+                                                            { AVIF_SAMPLE_TRANSFORM_CONSTANT, /*constant=*/16, 0 },
+                                                            { AVIF_SAMPLE_TRANSFORM_PRODUCT, 0, 0 },
+                                                            { AVIF_SAMPLE_TRANSFORM_DIFFERENCE, 0, 0 },
+                                                            { AVIF_SAMPLE_TRANSFORM_CONSTANT, /*constant=*/128, 0 },
+                                                            { AVIF_SAMPLE_TRANSFORM_SUM, 0, 0 } };
+                // image is "original" (index 1) and decodedBaseImage is "main" (index 2) in the formula above.
+                const avifImage * inputImageItems[] = { image, decodedBaseImage };
+                result = avifImageApplyOperations(*sampleTransformedImage,
+                                                  AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_32,
+                                                  /*numTokens=*/7,
+                                                  tokens,
+                                                  /*numInputImageItems=*/2,
+                                                  inputImageItems,
+                                                  planes);
+            }
+            if (decodedBaseImage) {
+                avifImageDestroy(decodedBaseImage);
+            }
+            if (codec) {
+                avifCodecDestroy(codec);
+            }
+            AVIF_CHECKRES(result);
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderCreateBitDepthExtensionImage(avifEncoder * encoder,
+                                                          const avifEncoderItem * item,
+                                                          avifBool itemWillBeEncodedLosslessly,
+                                                          const avifImage * image,
+                                                          avifImage ** sampleTransformedImage)
+{
+    AVIF_ASSERT_OR_RETURN(image->depth == 16); // Other bit depths could be supported but for now it is 16-bit only.
+    *sampleTransformedImage = NULL;
+    const avifResult result = avifEncoderCreateSatoImage(encoder, item, itemWillBeEncodedLosslessly, image, sampleTransformedImage);
+    if (result != AVIF_RESULT_OK && *sampleTransformedImage != NULL) {
+        avifImageDestroy(*sampleTransformedImage);
+    }
+    return result;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+static avifCodecType avifEncoderGetCodecType(const avifEncoder * encoder)
+{
+    // TODO(yguyon): Rework when AVIF_CODEC_CHOICE_AUTO can be AVM
+    assert((encoder->codecChoice != AVIF_CODEC_CHOICE_AUTO) ||
+           (strcmp(avifCodecName(encoder->codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE), "avm") != 0));
+    return avifCodecTypeFromChoice(encoder->codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE);
+}
+
+// This function is called after every color frame is encoded. It returns AVIF_TRUE if a keyframe needs to be forced for the next
+// alpha frame to be encoded, AVIF_FALSE otherwise.
+static avifBool avifEncoderDataShouldForceKeyframeForAlpha(const avifEncoderData * data,
+                                                           const avifEncoderItem * colorItem,
+                                                           avifAddImageFlags addImageFlags)
+{
+    if (!data->alphaPresent) {
+        // There is no alpha plane.
+        return AVIF_FALSE;
+    }
+    if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+        // Not an animated image.
+        return AVIF_FALSE;
+    }
+    if (data->frames.count == 0) {
+        // data->frames.count is the number of frames that have been encoded so far by previous calls to avifEncoderAddImage. If
+        // this is the first frame, there is no need to force keyframe.
+        return AVIF_FALSE;
+    }
+    const uint32_t colorFramesOutputSoFar = colorItem->encodeOutput->samples.count;
+    const avifBool isLaggedOutput = (data->frames.count + 1) != colorFramesOutputSoFar;
+    if (isLaggedOutput) {
+        // If the encoder is operating with lag, then there is no way to determine if the last encoded frame was a keyframe until
+        // the encoder outputs it (after the lag). So do not force keyframe for alpha channel in this case.
+        return AVIF_FALSE;
+    }
+    return colorItem->encodeOutput->samples.sample[colorFramesOutputSoFar - 1].sync;
+}
+
+static avifResult avifGetErrorForItemCategory(avifItemCategory itemCategory)
+{
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (itemCategory == AVIF_ITEM_GAIN_MAP) {
+        return AVIF_RESULT_ENCODE_GAIN_MAP_FAILED;
+    }
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (itemCategory == AVIF_ITEM_SAMPLE_TRANSFORM ||
+        (itemCategory >= AVIF_SAMPLE_TRANSFORM_MIN_CATEGORY && itemCategory <= AVIF_SAMPLE_TRANSFORM_MAX_CATEGORY)) {
+        return AVIF_RESULT_ENCODE_SAMPLE_TRANSFORM_FAILED;
+    }
+#endif
+    return avifIsAlpha(itemCategory) ? AVIF_RESULT_ENCODE_ALPHA_FAILED : AVIF_RESULT_ENCODE_COLOR_FAILED;
+}
+
+static uint32_t avifGridWidth(uint32_t gridCols, const avifImage * firstCell, const avifImage * bottomRightCell)
+{
+    return (gridCols - 1) * firstCell->width + bottomRightCell->width;
+}
+
+static uint32_t avifGridHeight(uint32_t gridRows, const avifImage * firstCell, const avifImage * bottomRightCell)
+{
+    return (gridRows - 1) * firstCell->height + bottomRightCell->height;
+}
+
+static avifResult avifValidateGrid(uint32_t gridCols,
+                                   uint32_t gridRows,
+                                   const avifImage * const * cellImages,
+                                   avifBool validateGainMap,
+                                   avifDiagnostics * diag)
+{
+    const uint32_t cellCount = gridCols * gridRows;
+    const avifImage * firstCell = cellImages[0];
+    const avifImage * bottomRightCell = cellImages[cellCount - 1];
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (validateGainMap) {
+        AVIF_ASSERT_OR_RETURN(firstCell->gainMap && firstCell->gainMap->image);
+        firstCell = firstCell->gainMap->image;
+        AVIF_ASSERT_OR_RETURN(bottomRightCell->gainMap && bottomRightCell->gainMap->image);
+        bottomRightCell = bottomRightCell->gainMap->image;
+    }
+#endif
+    const uint32_t tileWidth = firstCell->width;
+    const uint32_t tileHeight = firstCell->height;
+    const uint32_t gridWidth = avifGridWidth(gridCols, firstCell, bottomRightCell);
+    const uint32_t gridHeight = avifGridHeight(gridRows, firstCell, bottomRightCell);
+    for (uint32_t cellIndex = 0; cellIndex < cellCount; ++cellIndex) {
+        const avifImage * cellImage = cellImages[cellIndex];
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (validateGainMap) {
+            AVIF_ASSERT_OR_RETURN(cellImage->gainMap && cellImage->gainMap->image);
+            cellImage = cellImage->gainMap->image;
+        }
+#endif
+        const uint32_t expectedCellWidth = ((cellIndex + 1) % gridCols) ? tileWidth : bottomRightCell->width;
+        const uint32_t expectedCellHeight = (cellIndex < (cellCount - gridCols)) ? tileHeight : bottomRightCell->height;
+        if ((cellImage->width != expectedCellWidth) || (cellImage->height != expectedCellHeight)) {
+            avifDiagnosticsPrintf(diag,
+                                  "%s cell %u has invalid dimensions: expected %ux%u found %ux%u",
+                                  validateGainMap ? "gain map" : "image",
+                                  cellIndex,
+                                  expectedCellWidth,
+                                  expectedCellHeight,
+                                  cellImage->width,
+                                  cellImage->height);
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+
+        // MIAF (ISO 23000-22:2019), Section 7.3.11.4.1:
+        //   All input images of a grid image item shall use the same coding format, chroma sampling format, and the
+        //   same decoder configuration (see 7.3.6.2).
+        if ((cellImage->depth != firstCell->depth) || (cellImage->yuvFormat != firstCell->yuvFormat) ||
+            (cellImage->yuvRange != firstCell->yuvRange) || (cellImage->colorPrimaries != firstCell->colorPrimaries) ||
+            (cellImage->transferCharacteristics != firstCell->transferCharacteristics) ||
+            (cellImage->matrixCoefficients != firstCell->matrixCoefficients) || (!!cellImage->alphaPlane != !!firstCell->alphaPlane) ||
+            (cellImage->alphaPremultiplied != firstCell->alphaPremultiplied)) {
+            avifDiagnosticsPrintf(diag,
+                                  "all grid cells should have the same value for: depth, yuvFormat, yuvRange, colorPrimaries, "
+                                  "transferCharacteristics, matrixCoefficients, alphaPlane presence, alphaPremultiplied");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+
+        if (!cellImage->yuvPlanes[AVIF_CHAN_Y]) {
+            return AVIF_RESULT_NO_CONTENT;
+        }
+    }
+
+    if ((bottomRightCell->width > tileWidth) || (bottomRightCell->height > tileHeight)) {
+        avifDiagnosticsPrintf(diag,
+                              "the last %s cell can be smaller but not larger than the other cells which are %ux%u, found %ux%u",
+                              validateGainMap ? "gain map" : "image",
+                              tileWidth,
+                              tileHeight,
+                              bottomRightCell->width,
+                              bottomRightCell->height);
+        return AVIF_RESULT_INVALID_IMAGE_GRID;
+    }
+    if ((cellCount > 1) && !avifAreGridDimensionsValid(firstCell->yuvFormat, gridWidth, gridHeight, tileWidth, tileHeight, diag)) {
+        return AVIF_RESULT_INVALID_IMAGE_GRID;
+    }
+
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderAddImageInternal(avifEncoder * encoder,
+                                              uint32_t gridCols,
+                                              uint32_t gridRows,
+                                              const avifImage * const * cellImages,
+                                              uint64_t durationInTimescales,
+                                              avifAddImageFlags addImageFlags)
+{
+    // -----------------------------------------------------------------------
+    // Verify encoding is possible
+
+    if (!avifCodecName(encoder->codecChoice, AVIF_CODEC_FLAG_CAN_ENCODE)) {
+        return AVIF_RESULT_NO_CODEC_AVAILABLE;
+    }
+
+    if (encoder->extraLayerCount >= AVIF_MAX_AV1_LAYER_COUNT) {
+        avifDiagnosticsPrintf(&encoder->diag, "extraLayerCount [%u] must be less than %d", encoder->extraLayerCount, AVIF_MAX_AV1_LAYER_COUNT);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+
+    // -----------------------------------------------------------------------
+    // Validate images
+
+    const uint32_t cellCount = gridCols * gridRows;
+    if (cellCount == 0) {
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+
+    const avifImage * firstCell = cellImages[0];
+    const avifImage * bottomRightCell = cellImages[cellCount - 1];
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    AVIF_CHECKERR(firstCell->depth == 8 || firstCell->depth == 10 || firstCell->depth == 12 ||
+                      (firstCell->depth == 16 && encoder->sampleTransformRecipe != AVIF_SAMPLE_TRANSFORM_NONE),
+                  AVIF_RESULT_UNSUPPORTED_DEPTH);
+#else
+    AVIF_CHECKERR(firstCell->depth == 8 || firstCell->depth == 10 || firstCell->depth == 12, AVIF_RESULT_UNSUPPORTED_DEPTH);
+#endif
+    AVIF_CHECKERR(firstCell->yuvFormat != AVIF_PIXEL_FORMAT_NONE, AVIF_RESULT_NO_YUV_FORMAT_SELECTED);
+    if (!firstCell->width || !firstCell->height || !bottomRightCell->width || !bottomRightCell->height) {
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    AVIF_CHECKRES(avifValidateGrid(gridCols, gridRows, cellImages, /*validateGainMap=*/AVIF_FALSE, &encoder->diag));
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    const avifBool hasGainMap = (firstCell->gainMap && firstCell->gainMap->image != NULL);
+
+    // Check that either all cells have a gain map, or none of them do.
+    // If a gain map is present, check that they all have the same gain map metadata.
+    for (uint32_t cellIndex = 0; cellIndex < cellCount; ++cellIndex) {
+        const avifImage * cellImage = cellImages[cellIndex];
+        const avifBool cellHasGainMap = (cellImage->gainMap && cellImage->gainMap->image);
+        if (cellHasGainMap != hasGainMap) {
+            avifDiagnosticsPrintf(&encoder->diag, "cells should either all have a gain map image, or none of them should, found a mix");
+            return AVIF_RESULT_INVALID_IMAGE_GRID;
+        }
+        if (hasGainMap) {
+            const avifGainMap * firstGainMap = firstCell->gainMap;
+            const avifGainMap * cellGainMap = cellImage->gainMap;
+            if (cellGainMap->altICC.size != firstGainMap->altICC.size ||
+                memcmp(cellGainMap->altICC.data, firstGainMap->altICC.data, cellGainMap->altICC.size) != 0 ||
+                cellGainMap->altColorPrimaries != firstGainMap->altColorPrimaries ||
+                cellGainMap->altTransferCharacteristics != firstGainMap->altTransferCharacteristics ||
+                cellGainMap->altMatrixCoefficients != firstGainMap->altMatrixCoefficients ||
+                cellGainMap->altYUVRange != firstGainMap->altYUVRange || cellGainMap->altDepth != firstGainMap->altDepth ||
+                cellGainMap->altPlaneCount != firstGainMap->altPlaneCount || cellGainMap->altCLLI.maxCLL != firstGainMap->altCLLI.maxCLL ||
+                cellGainMap->altCLLI.maxPALL != firstGainMap->altCLLI.maxPALL) {
+                avifDiagnosticsPrintf(&encoder->diag, "all cells should have the same alternate image metadata in the gain map");
+                return AVIF_RESULT_INVALID_IMAGE_GRID;
+            }
+            if (cellGainMap->baseHdrHeadroom.n != firstGainMap->baseHdrHeadroom.n ||
+                cellGainMap->baseHdrHeadroom.d != firstGainMap->baseHdrHeadroom.d ||
+                cellGainMap->alternateHdrHeadroom.n != firstGainMap->alternateHdrHeadroom.n ||
+                cellGainMap->alternateHdrHeadroom.d != firstGainMap->alternateHdrHeadroom.d) {
+                avifDiagnosticsPrintf(&encoder->diag, "all cells should have the same gain map metadata");
+                return AVIF_RESULT_INVALID_IMAGE_GRID;
+            }
+            for (int c = 0; c < 3; ++c) {
+                if (cellGainMap->gainMapMin[c].n != firstGainMap->gainMapMin[c].n ||
+                    cellGainMap->gainMapMin[c].d != firstGainMap->gainMapMin[c].d ||
+                    cellGainMap->gainMapMax[c].n != firstGainMap->gainMapMax[c].n ||
+                    cellGainMap->gainMapMax[c].d != firstGainMap->gainMapMax[c].d ||
+                    cellGainMap->gainMapGamma[c].n != firstGainMap->gainMapGamma[c].n ||
+                    cellGainMap->gainMapGamma[c].d != firstGainMap->gainMapGamma[c].d ||
+                    cellGainMap->baseOffset[c].n != firstGainMap->baseOffset[c].n ||
+                    cellGainMap->baseOffset[c].d != firstGainMap->baseOffset[c].d ||
+                    cellGainMap->alternateOffset[c].n != firstGainMap->alternateOffset[c].n ||
+                    cellGainMap->alternateOffset[c].d != firstGainMap->alternateOffset[c].d) {
+                    avifDiagnosticsPrintf(&encoder->diag, "all cells should have the same gain map metadata");
+                    return AVIF_RESULT_INVALID_IMAGE_GRID;
+                }
+            }
+        }
+    }
+
+    if (hasGainMap) {
+        // AVIF supports 16-bit images through sample transforms used as bit depth extensions,
+        // but this is not implemented for gain maps for now. Stick to at most 12 bits.
+        // TODO(yguyon): Implement 16-bit gain maps.
+        AVIF_CHECKERR(firstCell->gainMap->image->depth == 8 || firstCell->gainMap->image->depth == 10 ||
+                          firstCell->gainMap->image->depth == 12,
+                      AVIF_RESULT_UNSUPPORTED_DEPTH);
+        AVIF_CHECKERR(firstCell->gainMap->image->yuvFormat != AVIF_PIXEL_FORMAT_NONE, AVIF_RESULT_NO_YUV_FORMAT_SELECTED);
+        AVIF_CHECKRES(avifValidateGrid(gridCols, gridRows, cellImages, /*validateGainMap=*/AVIF_TRUE, &encoder->diag));
+        if (firstCell->gainMap->image->colorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED ||
+            firstCell->gainMap->image->transferCharacteristics != AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+            avifDiagnosticsPrintf(&encoder->diag, "the gain map image must have colorPrimaries = 2 and transferCharacteristics = 2");
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+    // -----------------------------------------------------------------------
+    // Validate flags
+
+    if (encoder->data->singleImage) {
+        // The previous call to avifEncoderAddImage() set AVIF_ADD_IMAGE_FLAG_SINGLE.
+        // avifEncoderAddImage() cannot be called again for this encode.
+        return AVIF_RESULT_ENCODE_COLOR_FAILED;
+    }
+
+    if (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE) {
+        encoder->data->singleImage = AVIF_TRUE;
+
+        if (encoder->extraLayerCount > 0) {
+            // AVIF_ADD_IMAGE_FLAG_SINGLE may not be set for layered image.
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+
+        if (encoder->data->items.count > 0) {
+            // AVIF_ADD_IMAGE_FLAG_SINGLE may only be set on the first and only image.
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+    }
+
+    // -----------------------------------------------------------------------
+    // Choose AV1 or AV2
+
+    const avifCodecType codecType = avifEncoderGetCodecType(encoder);
+    switch (codecType) {
+        case AVIF_CODEC_TYPE_AV1:
+            encoder->data->imageItemType = "av01";
+            encoder->data->configPropName = "av1C";
+            break;
+#if defined(AVIF_CODEC_AVM)
+        case AVIF_CODEC_TYPE_AV2:
+            encoder->data->imageItemType = "av02";
+            encoder->data->configPropName = "av2C";
+            break;
+#endif
+        default:
+            return AVIF_RESULT_NO_CODEC_AVAILABLE;
+    }
+
+    // -----------------------------------------------------------------------
+    // Map quality and qualityAlpha to quantizer and quantizerAlpha
+    encoder->data->quantizer = avifQualityToQuantizer(encoder->quality, encoder->minQuantizer, encoder->maxQuantizer);
+    encoder->data->quantizerAlpha = avifQualityToQuantizer(encoder->qualityAlpha, encoder->minQuantizerAlpha, encoder->maxQuantizerAlpha);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    encoder->data->quantizerGainMap =
+        avifQualityToQuantizer(encoder->qualityGainMap, AVIF_QUANTIZER_BEST_QUALITY, AVIF_QUANTIZER_WORST_QUALITY);
+#endif
+
+    // -----------------------------------------------------------------------
+    // Handle automatic tiling
+
+    encoder->data->tileRowsLog2 = AVIF_CLAMP(encoder->tileRowsLog2, 0, 6);
+    encoder->data->tileColsLog2 = AVIF_CLAMP(encoder->tileColsLog2, 0, 6);
+    if (encoder->autoTiling) {
+        // Use as many tiles as allowed by the minimum tile area requirement and impose a maximum
+        // of 8 tiles.
+        const int threads = 8;
+        avifSetTileConfiguration(threads, firstCell->width, firstCell->height, &encoder->data->tileRowsLog2, &encoder->data->tileColsLog2);
+    }
+
+    // -----------------------------------------------------------------------
+    // All encoder settings are known now. Detect changes.
+
+    avifEncoderChanges encoderChanges;
+    if (!avifEncoderDetectChanges(encoder, &encoderChanges)) {
+        return AVIF_RESULT_CANNOT_CHANGE_SETTING;
+    }
+    avifEncoderBackupSettings(encoder);
+
+    // -----------------------------------------------------------------------
+
+    if (durationInTimescales == 0) {
+        durationInTimescales = 1;
+    }
+
+    if (encoder->data->items.count == 0) {
+        // Make a copy of the first image's metadata (sans pixels) for future writing/validation
+        AVIF_CHECKRES(avifImageCopy(encoder->data->imageMetadata, firstCell, 0));
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (hasGainMap) {
+            AVIF_CHECKRES(avifImageCopyAltImageMetadata(encoder->data->altImageMetadata, encoder->data->imageMetadata));
+        }
+#endif
+
+        // Prepare all AV1 items
+        uint16_t colorItemID;
+        const uint32_t gridWidth = avifGridWidth(gridCols, firstCell, bottomRightCell);
+        const uint32_t gridHeight = avifGridHeight(gridRows, firstCell, bottomRightCell);
+        AVIF_CHECKRES(avifEncoderAddImageItems(encoder, gridCols, gridRows, gridWidth, gridHeight, AVIF_ITEM_COLOR, &colorItemID));
+        encoder->data->primaryItemID = colorItemID;
+
+        encoder->data->alphaPresent = (firstCell->alphaPlane != NULL);
+        if (encoder->data->alphaPresent && (addImageFlags & AVIF_ADD_IMAGE_FLAG_SINGLE)) {
+            // If encoding a single image in which the alpha plane exists but is entirely opaque,
+            // simply skip writing an alpha AV1 payload entirely, as it'll be interpreted as opaque
+            // and is less bytes.
+            //
+            // However, if encoding an image sequence, the first frame's alpha plane being entirely
+            // opaque could be a false positive for removing the alpha AV1 payload, as it might simply
+            // be a fade out later in the sequence. This is why avifImageIsOpaque() is only called
+            // when encoding a single image.
+
+            encoder->data->alphaPresent = AVIF_FALSE;
+            for (uint32_t cellIndex = 0; cellIndex < cellCount; ++cellIndex) {
+                const avifImage * cellImage = cellImages[cellIndex];
+                if (!avifImageIsOpaque(cellImage)) {
+                    encoder->data->alphaPresent = AVIF_TRUE;
+                    break;
+                }
+            }
+        }
+
+        if (encoder->data->alphaPresent) {
+            uint16_t alphaItemID;
+            AVIF_CHECKRES(avifEncoderAddImageItems(encoder, gridCols, gridRows, gridWidth, gridHeight, AVIF_ITEM_ALPHA, &alphaItemID));
+            avifEncoderItem * alphaItem = avifEncoderDataFindItemByID(encoder->data, alphaItemID);
+            AVIF_ASSERT_OR_RETURN(alphaItem);
+            alphaItem->irefType = "auxl";
+            alphaItem->irefToID = colorItemID;
+            if (encoder->data->imageMetadata->alphaPremultiplied) {
+                avifEncoderItem * colorItem = avifEncoderDataFindItemByID(encoder->data, colorItemID);
+                AVIF_ASSERT_OR_RETURN(colorItem);
+                colorItem->irefType = "prem";
+                colorItem->irefToID = alphaItemID;
+            }
+        }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (firstCell->gainMap && firstCell->gainMap->image) {
+            avifEncoderItem * toneMappedItem = avifEncoderDataCreateItem(encoder->data,
+                                                                         "tmap",
+                                                                         infeNameGainMap,
+                                                                         /*infeNameSize=*/strlen(infeNameGainMap) + 1,
+                                                                         /*cellIndex=*/0);
+            AVIF_CHECKRES(avifWriteToneMappedImagePayload(&toneMappedItem->metadataPayload, firstCell->gainMap, &encoder->diag));
+            // Even though the 'tmap' item is related to the gain map, it represents a color image and its metadata is more similar to the color item.
+            toneMappedItem->itemCategory = AVIF_ITEM_COLOR;
+            uint16_t toneMappedItemID = toneMappedItem->id;
+
+            AVIF_ASSERT_OR_RETURN(encoder->data->alternativeItemIDs.count == 0);
+            uint16_t * alternativeItemID = (uint16_t *)avifArrayPush(&encoder->data->alternativeItemIDs);
+            AVIF_CHECKERR(alternativeItemID != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            *alternativeItemID = toneMappedItemID;
+
+            alternativeItemID = (uint16_t *)avifArrayPush(&encoder->data->alternativeItemIDs);
+            AVIF_CHECKERR(alternativeItemID != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+            *alternativeItemID = colorItemID;
+
+            const uint32_t gainMapGridWidth =
+                avifGridWidth(gridCols, cellImages[0]->gainMap->image, cellImages[gridCols * gridRows - 1]->gainMap->image);
+            const uint32_t gainMapGridHeight =
+                avifGridHeight(gridRows, cellImages[0]->gainMap->image, cellImages[gridCols * gridRows - 1]->gainMap->image);
+
+            uint16_t gainMapItemID;
+            AVIF_CHECKRES(
+                avifEncoderAddImageItems(encoder, gridCols, gridRows, gainMapGridWidth, gainMapGridHeight, AVIF_ITEM_GAIN_MAP, &gainMapItemID));
+            avifEncoderItem * gainMapItem = avifEncoderDataFindItemByID(encoder->data, gainMapItemID);
+            AVIF_ASSERT_OR_RETURN(gainMapItem);
+            gainMapItem->hiddenImage = AVIF_TRUE;
+
+            // Set the color item and gain map item's dimgFromID value to point to the tone mapped item.
+            // The color item shall be first, and the gain map second. avifEncoderFinish() writes the
+            // dimg item references in item id order, so as long as colorItemID < gainMapItemID, the order
+            // will be correct.
+            AVIF_ASSERT_OR_RETURN(colorItemID < gainMapItemID);
+            avifEncoderItem * colorItem = avifEncoderDataFindItemByID(encoder->data, colorItemID);
+            AVIF_ASSERT_OR_RETURN(colorItem);
+            AVIF_ASSERT_OR_RETURN(colorItem->dimgFromID == 0); // Our internal API only allows one dimg value per item.
+            colorItem->dimgFromID = toneMappedItemID;
+            gainMapItem->dimgFromID = toneMappedItemID;
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        if (encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B ||
+            encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B ||
+            encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B) {
+            // For now, only 16-bit depth is supported.
+            AVIF_ASSERT_OR_RETURN(firstCell->depth == 16);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            AVIF_CHECKERR(!firstCell->gainMap, AVIF_RESULT_NOT_IMPLEMENTED); // TODO(yguyon): Implement 16-bit HDR
+#endif
+            AVIF_CHECKRES(avifEncoderCreateBitDepthExtensionItems(encoder, gridCols, gridRows, gridWidth, gridHeight, colorItemID));
+        } else {
+            AVIF_CHECKERR(encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_NONE, AVIF_RESULT_NOT_IMPLEMENTED);
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+        // -----------------------------------------------------------------------
+        // Create metadata items (Exif, XMP)
+
+        if (firstCell->exif.size > 0) {
+            const avifResult result = avifEncoderDataCreateExifItem(encoder->data, &firstCell->exif);
+            if (result != AVIF_RESULT_OK) {
+                return result;
+            }
+        }
+
+        if (firstCell->xmp.size > 0) {
+            const avifResult result = avifEncoderDataCreateXMPItem(encoder->data, &firstCell->xmp);
+            if (result != AVIF_RESULT_OK) {
+                return result;
+            }
+        }
+    } else {
+        // Another frame in an image sequence, or layer in a layered image
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (hasGainMap) {
+            avifDiagnosticsPrintf(&encoder->diag, "gain maps are not supported for image sequences or layered images");
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+#endif
+
+        const avifImage * imageMetadata = encoder->data->imageMetadata;
+        // Image metadata that are copied to the configuration property and nclx boxes are not allowed to change.
+        // If the first image in the sequence had an alpha plane (even if fully opaque), all
+        // subsequent images must have alpha as well.
+        if ((imageMetadata->depth != firstCell->depth) || (imageMetadata->yuvFormat != firstCell->yuvFormat) ||
+            (imageMetadata->yuvRange != firstCell->yuvRange) ||
+            (imageMetadata->yuvChromaSamplePosition != firstCell->yuvChromaSamplePosition) ||
+            (imageMetadata->colorPrimaries != firstCell->colorPrimaries) ||
+            (imageMetadata->transferCharacteristics != firstCell->transferCharacteristics) ||
+            (imageMetadata->matrixCoefficients != firstCell->matrixCoefficients) ||
+            (imageMetadata->alphaPremultiplied != firstCell->alphaPremultiplied) ||
+            (encoder->data->alphaPresent && !firstCell->alphaPlane)) {
+            return AVIF_RESULT_INCOMPATIBLE_IMAGE;
+        }
+    }
+
+    if (encoder->data->frames.count == 1) {
+        // We will be writing an image sequence. When writing the AV1SampleEntry (derived from
+        // VisualSampleEntry) in the stsd box, we need to cast imageMetadata->width and
+        // imageMetadata->height to uint16_t:
+        //     class VisualSampleEntry(codingname) extends SampleEntry (codingname){
+        //        ...
+        //        unsigned int(16) width;
+        //        unsigned int(16) height;
+        //        ...
+        //     }
+        // Check whether it is safe to cast width and height to uint16_t. The maximum width and
+        // height of an AV1 frame are 65536, which just exceeds uint16_t.
+        AVIF_ASSERT_OR_RETURN(encoder->data->items.count > 0);
+        const avifImage * imageMetadata = encoder->data->imageMetadata;
+        AVIF_CHECKERR(imageMetadata->width <= 65535 && imageMetadata->height <= 65535, AVIF_RESULT_INVALID_ARGUMENT);
+    }
+
+    // -----------------------------------------------------------------------
+    // Encode AV1 OBUs
+
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if (item->codec) {
+            const avifImage * cellImage = cellImages[item->cellIndex];
+            avifImage * cellImagePlaceholder = NULL; // May be used as a temporary, modified cellImage. Left as NULL otherwise.
+            const avifImage * firstCellImage = firstCell;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+            if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+                AVIF_ASSERT_OR_RETURN(cellImage->gainMap && cellImage->gainMap->image);
+                cellImage = cellImage->gainMap->image;
+                AVIF_ASSERT_OR_RETURN(firstCell->gainMap && firstCell->gainMap->image);
+                firstCellImage = firstCell->gainMap->image;
+            }
+#endif
+
+            if ((cellImage->width != firstCellImage->width) || (cellImage->height != firstCellImage->height)) {
+                // Pad the right-most and/or bottom-most tiles so that all tiles share the same dimensions.
+                cellImagePlaceholder = avifImageCreateEmpty();
+                AVIF_CHECKERR(cellImagePlaceholder, AVIF_RESULT_OUT_OF_MEMORY);
+                const avifResult result =
+                    avifImageCopyAndPad(cellImagePlaceholder, cellImage, firstCellImage->width, firstCellImage->height);
+                if (result != AVIF_RESULT_OK) {
+                    avifImageDestroy(cellImagePlaceholder);
+                    return result;
+                }
+                cellImage = cellImagePlaceholder;
+            }
+
+            const avifBool isAlpha = avifIsAlpha(item->itemCategory);
+            int quantizer = isAlpha ? encoder->data->quantizerAlpha
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+                            : (item->itemCategory == AVIF_ITEM_GAIN_MAP) ? encoder->data->quantizerGainMap
+#endif
+                                                                         : encoder->data->quantizer;
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+            // Remember original quantizer values in case they change, to reset them afterwards.
+            int * encoderMinQuantizer = isAlpha ? &encoder->minQuantizerAlpha : &encoder->minQuantizer;
+            int * encoderMaxQuantizer = isAlpha ? &encoder->maxQuantizerAlpha : &encoder->maxQuantizer;
+            const int originalMinQuantizer = *encoderMinQuantizer;
+            const int originalMaxQuantizer = *encoderMaxQuantizer;
+
+            if (encoder->sampleTransformRecipe != AVIF_SAMPLE_TRANSFORM_NONE) {
+                if ((encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B ||
+                     encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B) &&
+                    (item->itemCategory == AVIF_ITEM_COLOR || item->itemCategory == AVIF_ITEM_ALPHA)) {
+                    // Encoding the least significant bits of a sample does not make any sense if the
+                    // other bits are lossily compressed. Encode the most significant bits losslessly.
+                    quantizer = AVIF_QUANTIZER_LOSSLESS;
+                    *encoderMinQuantizer = AVIF_QUANTIZER_LOSSLESS;
+                    *encoderMaxQuantizer = AVIF_QUANTIZER_LOSSLESS;
+                    if (!avifEncoderDetectChanges(encoder, &encoderChanges)) {
+                        assert(AVIF_FALSE);
+                    }
+                }
+
+                // Replace cellImage by the first or second input to the AVIF_ITEM_SAMPLE_TRANSFORM derived image item.
+                const avifBool itemWillBeEncodedLosslessly = (quantizer == AVIF_QUANTIZER_LOSSLESS);
+                avifImage * sampleTransformedImage = NULL;
+                if (cellImagePlaceholder) {
+                    avifImageDestroy(cellImagePlaceholder); // Replaced by sampleTransformedImage.
+                    cellImagePlaceholder = NULL;
+                }
+                AVIF_CHECKRES(
+                    avifEncoderCreateBitDepthExtensionImage(encoder, item, itemWillBeEncodedLosslessly, cellImage, &sampleTransformedImage));
+                cellImagePlaceholder = sampleTransformedImage; // Transfer ownership.
+                cellImage = cellImagePlaceholder;
+            }
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+
+            // If alpha channel is present, set disableLaggedOutput to AVIF_TRUE. If the encoder supports it, this enables
+            // avifEncoderDataShouldForceKeyframeForAlpha to force a keyframe in the alpha channel whenever a keyframe has been
+            // encoded in the color channel for animated images.
+            avifResult encodeResult = item->codec->encodeImage(item->codec,
+                                                               encoder,
+                                                               cellImage,
+                                                               isAlpha,
+                                                               encoder->data->tileRowsLog2,
+                                                               encoder->data->tileColsLog2,
+                                                               quantizer,
+                                                               encoderChanges,
+                                                               /*disableLaggedOutput=*/encoder->data->alphaPresent,
+                                                               addImageFlags,
+                                                               item->encodeOutput);
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+            // Revert quality settings if they changed.
+            if (*encoderMinQuantizer != originalMinQuantizer || *encoderMaxQuantizer != originalMaxQuantizer) {
+                avifEncoderBackupSettings(encoder); // Remember last encoding settings for next avifEncoderDetectChanges().
+                *encoderMinQuantizer = originalMinQuantizer;
+                *encoderMaxQuantizer = originalMaxQuantizer;
+            }
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+            if (cellImagePlaceholder) {
+                avifImageDestroy(cellImagePlaceholder);
+            }
+            if (encodeResult == AVIF_RESULT_UNKNOWN_ERROR) {
+                encodeResult = avifGetErrorForItemCategory(item->itemCategory);
+            }
+            AVIF_CHECKRES(encodeResult);
+            if (itemIndex == 0 && avifEncoderDataShouldForceKeyframeForAlpha(encoder->data, item, addImageFlags)) {
+                addImageFlags |= AVIF_ADD_IMAGE_FLAG_FORCE_KEYFRAME;
+            }
+        }
+    }
+
+    avifCodecSpecificOptionsClear(encoder->csOptions);
+    avifEncoderFrame * frame = (avifEncoderFrame *)avifArrayPush(&encoder->data->frames);
+    AVIF_CHECKERR(frame != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    frame->durationInTimescales = durationInTimescales;
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifEncoderAddImage(avifEncoder * encoder, const avifImage * image, uint64_t durationInTimescales, avifAddImageFlags addImageFlags)
+{
+    avifDiagnosticsClearError(&encoder->diag);
+    return avifEncoderAddImageInternal(encoder, 1, 1, &image, durationInTimescales, addImageFlags);
+}
+
+avifResult avifEncoderAddImageGrid(avifEncoder * encoder,
+                                   uint32_t gridCols,
+                                   uint32_t gridRows,
+                                   const avifImage * const * cellImages,
+                                   avifAddImageFlags addImageFlags)
+{
+    avifDiagnosticsClearError(&encoder->diag);
+    if ((gridCols == 0) || (gridCols > 256) || (gridRows == 0) || (gridRows > 256)) {
+        return AVIF_RESULT_INVALID_IMAGE_GRID;
+    }
+    if (encoder->extraLayerCount == 0) {
+        addImageFlags |= AVIF_ADD_IMAGE_FLAG_SINGLE; // image grids cannot be image sequences
+    }
+    return avifEncoderAddImageInternal(encoder, gridCols, gridRows, cellImages, 1, addImageFlags);
+}
+
+static size_t avifEncoderFindExistingChunk(avifRWStream * s, size_t mdatStartOffset, const uint8_t * data, size_t size)
+{
+    const size_t mdatCurrentOffset = avifRWStreamOffset(s);
+    const size_t mdatSearchSize = mdatCurrentOffset - mdatStartOffset;
+    if (mdatSearchSize < size) {
+        return 0;
+    }
+    const size_t mdatEndSearchOffset = mdatCurrentOffset - size;
+    for (size_t searchOffset = mdatStartOffset; searchOffset <= mdatEndSearchOffset; ++searchOffset) {
+        if (!memcmp(data, &s->raw->data[searchOffset], size)) {
+            return searchOffset;
+        }
+    }
+    return 0;
+}
+
+static avifResult avifEncoderWriteMediaDataBox(avifEncoder * encoder,
+                                               avifRWStream * s,
+                                               avifEncoderItemReferenceArray * layeredColorItems,
+                                               avifEncoderItemReferenceArray * layeredAlphaItems)
+{
+    encoder->ioStats.colorOBUSize = 0;
+    encoder->ioStats.alphaOBUSize = 0;
+    encoder->data->gainMapSizeBytes = 0;
+
+    avifBoxMarker mdat;
+    AVIF_CHECKRES(avifRWStreamWriteBox(s, "mdat", AVIF_BOX_SIZE_TBD, &mdat));
+    const size_t mdatStartOffset = avifRWStreamOffset(s);
+    for (uint32_t itemPasses = 0; itemPasses < 3; ++itemPasses) {
+        // Use multiple passes to pack in the following order:
+        //   * Pass 0: metadata (Exif/XMP/gain map metadata)
+        //   * Pass 1: alpha, gain map image (AV1)
+        //   * Pass 2: all other item data (AV1 color)
+        //
+        // See here for the discussion on alpha coming before color:
+        // https://github.com/AOMediaCodec/libavif/issues/287
+        //
+        // Exif and XMP are packed first as they're required to be fully available
+        // by avifDecoderParse() before it returns AVIF_RESULT_OK, unless ignoreXMP
+        // and ignoreExif are enabled.
+        //
+        const avifBool metadataPass = (itemPasses == 0);
+        const avifBool alphaAndGainMapPass = (itemPasses == 1);
+
+        for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+            avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+            if ((item->metadataPayload.size == 0) && (item->encodeOutput->samples.count == 0)) {
+                // this item has nothing for the mdat box
+                continue;
+            }
+            const avifBool isMetadata = !memcmp(item->type, "mime", 4) || !memcmp(item->type, "Exif", 4) ||
+                                        !memcmp(item->type, "tmap", 4);
+            if (metadataPass != isMetadata) {
+                // only process metadata (XMP/Exif) payloads when metadataPass is true
+                continue;
+            }
+            const avifBool isAlpha = avifIsAlpha(item->itemCategory);
+            const avifBool isAlphaOrGainMap = isAlpha
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+                                              || item->itemCategory == AVIF_ITEM_GAIN_MAP
+#endif
+                ;
+            if (alphaAndGainMapPass != isAlphaOrGainMap) {
+                // only process alpha payloads when alphaPass is true
+                continue;
+            }
+
+            if ((encoder->extraLayerCount > 0) && (item->encodeOutput->samples.count > 0)) {
+                // Interleave - Pick out AV1 items and interleave them later.
+                // We always interleave all AV1 items for layered images.
+                AVIF_ASSERT_OR_RETURN(item->encodeOutput->samples.count == item->mdatFixups.count);
+
+                avifEncoderItemReference * ref =
+                    (avifEncoderItemReference *)avifArrayPush(isAlpha ? layeredAlphaItems : layeredColorItems);
+                AVIF_CHECKERR(ref != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+                *ref = item;
+                continue;
+            }
+
+            size_t chunkOffset = 0;
+
+            // Deduplication - See if an identical chunk to this has already been written.
+            // Doing it when item->encodeOutput->samples.count > 1 would require contiguous memory.
+            if (item->encodeOutput->samples.count == 1) {
+                avifEncodeSample * sample = &item->encodeOutput->samples.sample[0];
+                chunkOffset = avifEncoderFindExistingChunk(s, mdatStartOffset, sample->data.data, sample->data.size);
+            } else if (item->encodeOutput->samples.count == 0) {
+                chunkOffset = avifEncoderFindExistingChunk(s, mdatStartOffset, item->metadataPayload.data, item->metadataPayload.size);
+            }
+
+            if (!chunkOffset) {
+                // We've never seen this chunk before; write it out
+                chunkOffset = avifRWStreamOffset(s);
+                if (item->encodeOutput->samples.count > 0) {
+                    for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                        avifEncodeSample * sample = &item->encodeOutput->samples.sample[sampleIndex];
+                        AVIF_CHECKRES(avifRWStreamWrite(s, sample->data.data, sample->data.size));
+
+                        if (isAlpha) {
+                            encoder->ioStats.alphaOBUSize += sample->data.size;
+                        } else if (item->itemCategory == AVIF_ITEM_COLOR) {
+                            encoder->ioStats.colorOBUSize += sample->data.size;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+                        } else if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+                            encoder->data->gainMapSizeBytes += sample->data.size;
+#endif
+                        }
+                    }
+                } else {
+                    AVIF_CHECKRES(avifRWStreamWrite(s, item->metadataPayload.data, item->metadataPayload.size));
+                }
+            }
+
+            for (uint32_t fixupIndex = 0; fixupIndex < item->mdatFixups.count; ++fixupIndex) {
+                avifOffsetFixup * fixup = &item->mdatFixups.fixup[fixupIndex];
+                size_t prevOffset = avifRWStreamOffset(s);
+                avifRWStreamSetOffset(s, fixup->offset);
+                AVIF_CHECKRES(avifRWStreamWriteU32(s, (uint32_t)chunkOffset));
+                avifRWStreamSetOffset(s, prevOffset);
+            }
+        }
+    }
+
+    uint32_t layeredItemCount = AVIF_MAX(layeredColorItems->count, layeredAlphaItems->count);
+    if (layeredItemCount > 0) {
+        // Interleave samples of all AV1 items.
+        // We first write the first layer of all items,
+        // in which we write first layer of each cell,
+        // in which we write alpha first and then color.
+        avifBool hasMoreSample;
+        uint32_t layerIndex = 0;
+        do {
+            hasMoreSample = AVIF_FALSE;
+            for (uint32_t itemIndex = 0; itemIndex < layeredItemCount; ++itemIndex) {
+                for (int samplePass = 0; samplePass < 2; ++samplePass) {
+                    // Alpha coming before color
+                    avifEncoderItemReferenceArray * currentItems = (samplePass == 0) ? layeredAlphaItems : layeredColorItems;
+                    if (itemIndex >= currentItems->count) {
+                        continue;
+                    }
+
+                    // TODO: Offer the ability for a user to specify which grid cell should be written first.
+                    avifEncoderItem * item = currentItems->ref[itemIndex];
+                    if (item->encodeOutput->samples.count <= layerIndex) {
+                        // We've already written all samples of this item
+                        continue;
+                    } else if (item->encodeOutput->samples.count > layerIndex + 1) {
+                        hasMoreSample = AVIF_TRUE;
+                    }
+                    avifRWData * data = &item->encodeOutput->samples.sample[layerIndex].data;
+                    size_t chunkOffset = avifEncoderFindExistingChunk(s, mdatStartOffset, data->data, data->size);
+                    if (!chunkOffset) {
+                        // We've never seen this chunk before; write it out
+                        chunkOffset = avifRWStreamOffset(s);
+                        AVIF_CHECKRES(avifRWStreamWrite(s, data->data, data->size));
+                        if (samplePass == 0) {
+                            encoder->ioStats.alphaOBUSize += data->size;
+                        } else {
+                            encoder->ioStats.colorOBUSize += data->size;
+                        }
+                    }
+
+                    size_t prevOffset = avifRWStreamOffset(s);
+                    avifRWStreamSetOffset(s, item->mdatFixups.fixup[layerIndex].offset);
+                    AVIF_CHECKRES(avifRWStreamWriteU32(s, (uint32_t)chunkOffset));
+                    avifRWStreamSetOffset(s, prevOffset);
+                }
+            }
+            ++layerIndex;
+        } while (hasMoreSample);
+
+        AVIF_ASSERT_OR_RETURN(layerIndex <= AVIF_MAX_AV1_LAYER_COUNT);
+    }
+    avifRWStreamFinishBox(s, mdat);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifWriteAltrGroup(avifRWStream * s, uint32_t groupID, const avifEncoderItemIdArray * itemIDs)
+{
+    avifBoxMarker grpl;
+    AVIF_CHECKRES(avifRWStreamWriteBox(s, "grpl", AVIF_BOX_SIZE_TBD, &grpl));
+
+    avifBoxMarker altr;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(s, "altr", AVIF_BOX_SIZE_TBD, 0, 0, &altr));
+
+    AVIF_CHECKRES(avifRWStreamWriteU32(s, groupID));                  // unsigned int(32) group_id;
+    AVIF_CHECKRES(avifRWStreamWriteU32(s, (uint32_t)itemIDs->count)); // unsigned int(32) num_entities_in_group;
+    for (uint32_t i = 0; i < itemIDs->count; ++i) {
+        AVIF_CHECKRES(avifRWStreamWriteU32(s, (uint32_t)itemIDs->itemID[i])); // unsigned int(32) entity_id;
+    }
+
+    avifRWStreamFinishBox(s, altr);
+
+    avifRWStreamFinishBox(s, grpl);
+
+    return AVIF_RESULT_OK;
+}
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+// Returns true if the image can be encoded with a MinimizedImageBox instead of a full regular MetaBox.
+static avifBool avifEncoderIsMiniCompatible(const avifEncoder * encoder)
+{
+    // The MinimizedImageBox ("mif3" brand) only supports non-layered, still images.
+    if (encoder->extraLayerCount || (encoder->data->frames.count != 1)) {
+        return AVIF_FALSE;
+    }
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+    if (encoder->sampleTransformRecipe != AVIF_SAMPLE_TRANSFORM_NONE) {
+        return AVIF_FALSE;
+    }
+#endif
+
+    // Check for maximum field values and maximum chunk sizes.
+
+    // width_minus1 and height_minus1
+    if (encoder->data->imageMetadata->width > (1 << 15) || encoder->data->imageMetadata->height > (1 << 15)) {
+        return AVIF_FALSE;
+    }
+    // icc_data_size_minus1, exif_data_size_minus1 and xmp_data_size_minus1
+    if (encoder->data->imageMetadata->icc.size > (1 << 20) || encoder->data->imageMetadata->exif.size > (1 << 20) ||
+        encoder->data->imageMetadata->xmp.size > (1 << 20)) {
+        return AVIF_FALSE;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    // gainmap_width_minus1 and gainmap_height_minus1
+    if (encoder->data->imageMetadata->gainMap != NULL && encoder->data->imageMetadata->gainMap->image != NULL &&
+        (encoder->data->imageMetadata->gainMap->image->width > (1 << 15) ||
+         encoder->data->imageMetadata->gainMap->image->height > (1 << 15))) {
+        return AVIF_FALSE;
+    }
+    // tmap_icc_data_size_minus1
+    if (encoder->data->altImageMetadata->icc.size > (1 << 20)) {
+        return AVIF_FALSE;
+    }
+    // gainmap_metadata_size
+    if (encoder->data->imageMetadata->gainMap != NULL && avifGainMapMetadataSize(encoder->data->imageMetadata->gainMap) >= (1 << 20)) {
+        return AVIF_FALSE;
+    }
+#endif
+
+    // 4:4:4, 4:2:2, 4:2:0 and 4:0:0 are supported by a MinimizedImageBox.
+    // chroma_subsampling
+    if (encoder->data->imageMetadata->yuvFormat != AVIF_PIXEL_FORMAT_YUV444 &&
+        encoder->data->imageMetadata->yuvFormat != AVIF_PIXEL_FORMAT_YUV422 &&
+        encoder->data->imageMetadata->yuvFormat != AVIF_PIXEL_FORMAT_YUV420 &&
+        encoder->data->imageMetadata->yuvFormat != AVIF_PIXEL_FORMAT_YUV400) {
+        return AVIF_FALSE;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    // gainmap_chroma_subsampling
+    if (encoder->data->imageMetadata->gainMap != NULL && encoder->data->imageMetadata->gainMap->image != NULL &&
+        (encoder->data->imageMetadata->gainMap->image->yuvFormat != AVIF_PIXEL_FORMAT_YUV444 &&
+         encoder->data->imageMetadata->gainMap->image->yuvFormat != AVIF_PIXEL_FORMAT_YUV422 &&
+         encoder->data->imageMetadata->gainMap->image->yuvFormat != AVIF_PIXEL_FORMAT_YUV420 &&
+         encoder->data->imageMetadata->gainMap->image->yuvFormat != AVIF_PIXEL_FORMAT_YUV400)) {
+        return AVIF_FALSE;
+    }
+#endif
+
+    // colour_primaries, transfer_characteristics and matrix_coefficients
+    if (encoder->data->imageMetadata->colorPrimaries > 255 || encoder->data->imageMetadata->transferCharacteristics > 255 ||
+        encoder->data->imageMetadata->matrixCoefficients > 255) {
+        return AVIF_FALSE;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    // gainmap_colour_primaries, gainmap_transfer_characteristics and gainmap_matrix_coefficients
+    if (encoder->data->imageMetadata->gainMap != NULL && encoder->data->imageMetadata->gainMap->image != NULL &&
+        (encoder->data->imageMetadata->gainMap->image->colorPrimaries > 255 ||
+         encoder->data->imageMetadata->gainMap->image->transferCharacteristics > 255 ||
+         encoder->data->imageMetadata->gainMap->image->matrixCoefficients > 255)) {
+        return AVIF_FALSE;
+    }
+    // tmap_colour_primaries, tmap_transfer_characteristics and tmap_matrix_coefficients
+    if (encoder->data->altImageMetadata->colorPrimaries > 255 || encoder->data->altImageMetadata->transferCharacteristics > 255 ||
+        encoder->data->altImageMetadata->matrixCoefficients > 255) {
+        return AVIF_FALSE;
+    }
+#endif
+
+    const avifEncoderItem * colorItem = NULL;
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+
+        // Grids are not supported by a MinimizedImageBox.
+        if (item->gridCols || item->gridRows) {
+            return AVIF_FALSE;
+        }
+
+        if (item->id == encoder->data->primaryItemID) {
+            assert(!colorItem);
+            colorItem = item;
+            // main_item_data_size_minus1
+            if (item->encodeOutput->samples.count != 1 || item->encodeOutput->samples.sample[0].data.size > (1 << 28)) {
+                return AVIF_FALSE;
+            }
+            continue; // The primary item can be stored in the MinimizedImageBox.
+        }
+        if (item->itemCategory == AVIF_ITEM_ALPHA && item->irefToID == encoder->data->primaryItemID) {
+            // alpha_item_data_size
+            if (item->encodeOutput->samples.count != 1 || item->encodeOutput->samples.sample[0].data.size >= (1 << 28)) {
+                return AVIF_FALSE;
+            }
+            continue; // The alpha auxiliary item can be stored in the MinimizedImageBox.
+        }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+            // gainmap_item_data_size
+            if (item->encodeOutput->samples.count != 1 || item->encodeOutput->samples.sample[0].data.size >= (1 << 28)) {
+                return AVIF_FALSE;
+            }
+            continue; // The gainmap input image item can be stored in the MinimizedImageBox.
+        }
+        if (!memcmp(item->type, "tmap", 4)) {
+            assert(item->itemCategory == AVIF_ITEM_COLOR); // Cannot be differentiated from the primary item by its itemCategory.
+            continue; // The tone mapping derived image item can be represented in the MinimizedImageBox.
+        }
+#endif
+        if (!memcmp(item->type, "mime", 4) && !memcmp(item->infeName, "XMP", item->infeNameSize)) {
+            assert(item->metadataPayload.size == encoder->data->imageMetadata->xmp.size);
+            continue; // XMP metadata can be stored in the MinimizedImageBox.
+        }
+        if (!memcmp(item->type, "Exif", 4) && !memcmp(item->infeName, "Exif", item->infeNameSize)) {
+            assert(item->metadataPayload.size == encoder->data->imageMetadata->exif.size + 4);
+            const uint32_t exif_tiff_header_offset = *(uint32_t *)item->metadataPayload.data;
+            if (exif_tiff_header_offset != 0) {
+                return AVIF_FALSE;
+            }
+            continue; // Exif metadata can be stored in the MinimizedImageBox if exif_tiff_header_offset is 0.
+        }
+
+        // Items besides the colorItem, the alphaItem, the gainmap item and Exif/XMP/ICC/HDR
+        // metadata are not directly supported by the MinimizedImageBox.
+        return AVIF_FALSE;
+    }
+    // A primary item is necessary.
+    if (!colorItem) {
+        return AVIF_FALSE;
+    }
+    return AVIF_TRUE;
+}
+
+static avifResult avifEncoderWriteMiniBox(avifEncoder * encoder, avifRWStream * s);
+
+static avifResult avifEncoderWriteFileTypeBoxAndMetaBoxV1(avifEncoder * encoder, avifRWData * output)
+{
+    avifRWStream s;
+    avifRWStreamStart(&s, output);
+
+    avifBoxMarker ftyp;
+    AVIF_CHECKRES(avifRWStreamWriteBox(&s, "ftyp", AVIF_BOX_SIZE_TBD, &ftyp));
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, "mif3", 4)); // unsigned int(32) major_brand;
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, "avif", 4)); // unsigned int(32) minor_version;
+                                                          // unsigned int(32) compatible_brands[];
+    avifRWStreamFinishBox(&s, ftyp);
+
+    AVIF_CHECKRES(avifEncoderWriteMiniBox(encoder, &s));
+
+    avifRWStreamFinishWrite(&s);
+    return AVIF_RESULT_OK;
+}
+
+static avifResult avifEncoderWriteMiniBox(avifEncoder * encoder, avifRWStream * s)
+{
+    const avifEncoderItem * colorItem = NULL;
+    const avifEncoderItem * alphaItem = NULL;
+    const avifEncoderItem * gainmapItem = NULL;
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if (item->id == encoder->data->primaryItemID) {
+            AVIF_ASSERT_OR_RETURN(!colorItem);
+            colorItem = item;
+        } else if (item->itemCategory == AVIF_ITEM_ALPHA && item->irefToID == encoder->data->primaryItemID) {
+            AVIF_ASSERT_OR_RETURN(!alphaItem);
+            alphaItem = item;
+        }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+            AVIF_ASSERT_OR_RETURN(!gainmapItem);
+            gainmapItem = item;
+        }
+#endif
+    }
+
+    AVIF_ASSERT_OR_RETURN(colorItem);
+    const avifRWData * colorData = &colorItem->encodeOutput->samples.sample[0].data;
+    const avifRWData * alphaData = alphaItem ? &alphaItem->encodeOutput->samples.sample[0].data : NULL;
+    const avifRWData * gainmapData = gainmapItem ? &gainmapItem->encodeOutput->samples.sample[0].data : NULL;
+
+    const avifImage * const image = encoder->data->imageMetadata;
+
+    const avifBool hasAlpha = alphaItem != NULL;
+    const avifBool alphaIsPremultiplied = encoder->data->imageMetadata->alphaPremultiplied;
+    const avifBool hasGainmap = gainmapItem != NULL;
+    const avifBool hasHdr = hasGainmap; // libavif only supports gainmap-based HDR encoding for now.
+    const avifBool hasIcc = image->icc.size != 0;
+    const uint32_t chromaSubsampling = image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400   ? 0
+                                       : image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 ? 1
+                                       : image->yuvFormat == AVIF_PIXEL_FORMAT_YUV422 ? 2
+                                                                                      : 3;
+
+    const avifColorPrimaries defaultColorPrimaries = hasIcc ? AVIF_COLOR_PRIMARIES_UNSPECIFIED : AVIF_COLOR_PRIMARIES_BT709;
+    const avifTransferCharacteristics defaultTransferCharacteristics = hasIcc ? AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED
+                                                                              : AVIF_TRANSFER_CHARACTERISTICS_SRGB;
+    const avifMatrixCoefficients defaultMatrixCoefficients = chromaSubsampling == 0 ? AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED
+                                                                                    : AVIF_MATRIX_COEFFICIENTS_BT601;
+    const avifBool hasExplicitCicp = image->colorPrimaries != defaultColorPrimaries ||
+                                     image->transferCharacteristics != defaultTransferCharacteristics ||
+                                     image->matrixCoefficients != defaultMatrixCoefficients;
+
+    const avifBool floatFlag = AVIF_FALSE;
+    const avifBool fullRange = image->yuvRange == AVIF_RANGE_FULL;
+
+    // In AV1, the chroma_sample_position syntax element is not present for the YUV 4:2:2 format.
+    // Assume that AV1 uses the same 4:2:2 chroma sample location as HEVC and VVC (colocated).
+    if (image->yuvFormat != AVIF_PIXEL_FORMAT_YUV420 && image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_UNKNOWN) {
+        avifDiagnosticsPrintf(&encoder->diag,
+                              "YUV chroma sample position %d is only supported with 4:2:0 YUV format in AV1",
+                              image->yuvChromaSamplePosition);
+        return AVIF_RESULT_INVALID_ARGUMENT;
+    }
+    // For the YUV 4:2:0 format, assume centered sample position unless specified otherwise.
+    // This is consistent with the behavior in read.c.
+    const avifBool chromaIsHorizontallyCentered = image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 &&
+                                                  image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_VERTICAL &&
+                                                  image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_COLOCATED;
+    const avifBool chromaIsVerticallyCentered = image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 &&
+                                                image->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_COLOCATED;
+
+    const uint32_t orientationMinus1 = avifImageIrotImirToExifOrientation(image) - 1;
+
+    uint8_t infeType[4];
+    uint8_t codecConfigType[4];
+    avifBool hasExplicitCodecTypes;
+    if (encoder->codecChoice == AVIF_CODEC_CHOICE_AVM) {
+        memcpy(infeType, "av02", 4);
+        memcpy(codecConfigType, "av2C", 4); // Same syntax as 'av1C'.
+        hasExplicitCodecTypes = AVIF_TRUE;
+    } else {
+        memcpy(infeType, "av01", 4);
+        memcpy(codecConfigType, "av1C", 4);
+        // 'av01' and 'av1C' are implied by 'avif' minor_version field of FileTypeBox. No need to write them.
+        hasExplicitCodecTypes = AVIF_FALSE;
+    }
+
+    uint32_t smallDimensionsFlag = image->width <= (1 << 7) && image->height <= (1 << 7);
+    const uint32_t codecConfigSize = 4; // 'av1C' always uses 4 bytes.
+    uint32_t gainmapMetadataSize = 0;
+    const uint32_t fewCodecConfigBytesFlag = codecConfigSize < (1 << 3);
+    uint32_t fewItemDataBytesFlag = colorData->size <= (1 << 15) && (!alphaData || alphaData->size < (1 << 15));
+    uint32_t fewMetadataBytesFlag = image->icc.size <= (1 << 10) && image->exif.size <= (1 << 10) && image->xmp.size <= (1 << 10);
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (hasGainmap) {
+        AVIF_ASSERT_OR_RETURN(image->gainMap != NULL && image->gainMap->image != NULL);
+        gainmapMetadataSize = avifGainMapMetadataSize(image->gainMap);
+        AVIF_ASSERT_OR_RETURN(gainmapData != NULL);
+
+        smallDimensionsFlag &= image->gainMap->image->width <= (1 << 7) && image->gainMap->image->height <= (1 << 7);
+        fewItemDataBytesFlag &= gainmapData->size < (1 << 15);
+        fewMetadataBytesFlag &= encoder->data->altImageMetadata->icc.size <= (1 << 10) && gainmapMetadataSize <= (1 << 10);
+        // image->gainMap->image->icc is ignored.
+    }
+#endif
+
+    avifBoxMarker mini;
+    AVIF_CHECKRES(avifRWStreamWriteBox(s, "mini", AVIF_BOX_SIZE_TBD, &mini));
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, 2)); // bit(2) version = 0;
+
+    // flags
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, hasExplicitCodecTypes, 1)); // bit(1) explicit_codec_types_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, floatFlag, 1));             // bit(1) float_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, fullRange, 1));             // bit(1) full_range_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, alphaItem != 0, 1));        // bit(1) alpha_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, hasExplicitCicp, 1));       // bit(1) explicit_cicp_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, hasHdr, 1));                // bit(1) hdr_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, hasIcc, 1));                // bit(1) icc_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, image->exif.size != 0, 1)); // bit(1) exif_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, image->xmp.size != 0, 1));  // bit(1) xmp_flag;
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, chromaSubsampling, 2)); // bit(2) chroma_subsampling;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, orientationMinus1, 3)); // bit(3) orientation_minus1;
+
+    // Spatial extents
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, smallDimensionsFlag, 1));                         // bit(1) small_dimensions_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, image->width - 1, smallDimensionsFlag ? 7 : 15)); // unsigned int(small_dimensions_flag ? 7 : 15) width_minus1;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, image->height - 1, smallDimensionsFlag ? 7 : 15)); // unsigned int(small_dimensions_flag ? 7 : 15) height_minus1;
+
+    // Pixel information
+    if (chromaSubsampling == 1 || chromaSubsampling == 2) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, chromaIsHorizontallyCentered, 1)); // bit(1) chroma_is_horizontally_centered;
+    }
+    if (chromaSubsampling == 1) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, chromaIsVerticallyCentered, 1)); // bit(1) chroma_is_vertically_centered;
+    }
+
+    if (floatFlag) {
+        // bit(2) bit_depth_log2_minus4;
+        AVIF_ASSERT_OR_RETURN(AVIF_FALSE);
+    } else {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, image->depth > 8, 1)); // bit(1) high_bit_depth_flag;
+        if (image->depth > 8) {
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, image->depth - 9, 3)); // bit(3) bit_depth_minus9;
+        }
+    }
+
+    if (alphaItem) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, alphaIsPremultiplied, 1)); // bit(1) alpha_is_premultiplied;
+    }
+
+    // Colour properties
+    if (hasExplicitCicp) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, image->colorPrimaries, 8));          // bit(8) colour_primaries;
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, image->transferCharacteristics, 8)); // bit(8) transfer_characteristics;
+        if (chromaSubsampling != 0) {
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, image->matrixCoefficients, 8)); // bit(8) matrix_coefficients;
+        } else {
+            AVIF_CHECKERR(image->matrixCoefficients == AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED, AVIF_RESULT_ENCODE_COLOR_FAILED);
+        }
+    }
+
+    if (hasExplicitCodecTypes) {
+        // bit(32) infe_type;
+        for (int i = 0; i < 4; ++i) {
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, infeType[i], 8));
+        }
+        // bit(32) codec_config_type;
+        for (int i = 0; i < 4; ++i) {
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, codecConfigType[i], 8));
+        }
+    }
+
+    // High Dynamic Range properties
+    size_t tmapIccSize = 0;
+    if (hasHdr) {
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, hasGainmap, 1)); // bit(1) gainmap_flag;
+        if (hasGainmap) {
+            const avifImage * tmap = encoder->data->altImageMetadata;
+            const avifImage * gainmap = image->gainMap->image;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->width - 1, smallDimensionsFlag ? 7 : 15)); // unsigned int(small_dimensions_flag ? 7 : 15) gainmap_width_minus1;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->height - 1, smallDimensionsFlag ? 7 : 15)); // unsigned int(small_dimensions_flag ? 7 : 15) gainmap_height_minus1;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->matrixCoefficients, 8)); // bit(8) gainmap_matrix_coefficients;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->yuvRange == AVIF_RANGE_FULL, 1)); // bit(1) gainmap_full_range_flag;
+            const uint32_t gainmapChromaSubsampling = gainmap->yuvFormat == AVIF_PIXEL_FORMAT_YUV400   ? 0
+                                                      : gainmap->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 ? 1
+                                                      : gainmap->yuvFormat == AVIF_PIXEL_FORMAT_YUV422 ? 2
+                                                                                                       : 3;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmapChromaSubsampling, 2)); // bit(1) gainmap_chroma_subsampling;
+            if (gainmapChromaSubsampling == 1 || gainmapChromaSubsampling == 2) {
+                AVIF_CHECKRES(avifRWStreamWriteBits(s,
+                                                    gainmap->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 &&
+                                                        gainmap->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_VERTICAL &&
+                                                        gainmap->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_COLOCATED,
+                                                    1)); // bit(1) gainmap_chroma_is_horizontally_centered;
+            }
+            if (gainmapChromaSubsampling == 1) {
+                AVIF_CHECKRES(avifRWStreamWriteBits(s,
+                                                    gainmap->yuvFormat == AVIF_PIXEL_FORMAT_YUV420 &&
+                                                        gainmap->yuvChromaSamplePosition != AVIF_CHROMA_SAMPLE_POSITION_COLOCATED,
+                                                    1)); // bit(1) gainmap_chroma_is_vertically_centered;
+            }
+
+            const avifBool gainmapFloatFlag = AVIF_FALSE;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmapFloatFlag, 1)); // bit(1) gainmap_float_flag;
+            if (gainmapFloatFlag) {
+                // bit(2) gainmap_bit_depth_log2_minus4;
+                AVIF_ASSERT_OR_RETURN(AVIF_FALSE);
+            } else {
+                AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->depth > 8, 1)); // bit(1) gainmap_high_bit_depth_flag;
+                if (gainmap->depth > 8) {
+                    AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmap->depth - 9, 3)); // bit(3) gainmap_bit_depth_minus9;
+                }
+            }
+
+            tmapIccSize = encoder->data->altImageMetadata->icc.size;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, tmapIccSize != 0, 1)); // bit(1) tmap_icc_flag;
+            const avifBool tmapHasExplicitCicp = tmap->colorPrimaries != AVIF_COLOR_PRIMARIES_BT709 ||
+                                                 tmap->transferCharacteristics != AVIF_TRANSFER_CHARACTERISTICS_SRGB ||
+                                                 tmap->matrixCoefficients != AVIF_MATRIX_COEFFICIENTS_BT601 ||
+                                                 tmap->yuvRange != AVIF_RANGE_FULL;
+            AVIF_CHECKRES(avifRWStreamWriteBits(s, tmapHasExplicitCicp, 1)); // bit(1) tmap_explicit_cicp_flag;
+            if (tmapHasExplicitCicp) {
+                AVIF_CHECKRES(avifRWStreamWriteBits(s, tmap->colorPrimaries, 8));          // bit(8) tmap_colour_primaries;
+                AVIF_CHECKRES(avifRWStreamWriteBits(s, tmap->transferCharacteristics, 8)); // bit(8) tmap_transfer_characteristics;
+                AVIF_CHECKRES(avifRWStreamWriteBits(s, tmap->matrixCoefficients, 8));      // bit(8) tmap_matrix_coefficients;
+                AVIF_CHECKRES(avifRWStreamWriteBits(s, tmap->yuvRange == AVIF_RANGE_FULL, 1)); // bit(8) tmap_full_range_flag;
+            }
+            // gainmap->icc is ignored.
+        }
+
+        AVIF_CHECKRES(avifEncoderWriteMiniHDRProperties(s, image));
+        if (hasGainmap) {
+            AVIF_CHECKRES(avifEncoderWriteMiniHDRProperties(s, encoder->data->altImageMetadata));
+        }
+#endif // AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP
+    }
+
+    // Chunk sizes
+    if (hasIcc || image->exif.size || image->xmp.size || (hasHdr && hasGainmap)) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, fewMetadataBytesFlag, 1)); // bit(1) few_metadata_bytes_flag;
+    }
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, fewCodecConfigBytesFlag, 1)); // bit(1) few_codec_config_bytes_flag;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, fewItemDataBytesFlag, 1));    // bit(1) few_item_data_bytes_flag;
+
+    if (hasIcc) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)image->icc.size - 1, fewMetadataBytesFlag ? 10 : 20)); // unsigned int(few_metadata_bytes_flag ? 10 : 20) icc_data_size_minus1;
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (hasHdr && hasGainmap && tmapIccSize != 0) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)tmapIccSize - 1, fewMetadataBytesFlag ? 10 : 20)); // unsigned int(few_metadata_bytes_flag ? 10 : 20) tmap_icc_data_size_minus1;
+    }
+
+    if (hasHdr && hasGainmap) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, gainmapMetadataSize, fewMetadataBytesFlag ? 10 : 20)); // unsigned int(few_metadata_bytes_flag ? 10 : 20) gainmap_metadata_size;
+    }
+    if (hasHdr && hasGainmap) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)gainmapData->size, fewItemDataBytesFlag ? 15 : 28)); // unsigned int(few_item_data_bytes_flag ? 15 : 28) gainmap_item_data_size;
+    }
+    if (hasHdr && hasGainmap && gainmapData->size != 0) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, codecConfigSize, fewCodecConfigBytesFlag ? 3 : 12)); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) gainmap_item_codec_config_size;
+    }
+#endif
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, codecConfigSize, fewCodecConfigBytesFlag ? 3 : 12)); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) main_item_codec_config_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)colorData->size - 1, fewItemDataBytesFlag ? 15 : 28)); // unsigned int(few_item_data_bytes_flag ? 15 : 28) main_item_data_size_minus1;
+
+    if (hasAlpha) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)alphaData->size, fewItemDataBytesFlag ? 15 : 28)); // unsigned int(few_item_data_bytes_flag ? 15 : 28) alpha_item_data_size;
+    }
+    if (hasAlpha && alphaData->size != 0) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, codecConfigSize, fewCodecConfigBytesFlag ? 3 : 12)); // unsigned int(few_codec_config_bytes_flag ? 3 : 12) alpha_item_codec_config_size;
+    }
+
+    if (image->exif.size) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)image->exif.size - 1, fewMetadataBytesFlag ? 10 : 20)); // unsigned int(few_metadata_bytes_flag ? 10 : 20) exif_data_size_minus_one;
+    }
+    if (image->xmp.size) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, (uint32_t)image->xmp.size - 1, fewMetadataBytesFlag ? 10 : 20)); // unsigned int(few_metadata_bytes_flag ? 10 : 20) xmp_data_size_minus_one;
+    }
+
+    // trailing_bits(); // bit padding till byte alignment
+    if (s->numUsedBitsInPartialByte != 0) {
+        AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, 8 - s->numUsedBitsInPartialByte));
+    }
+    const size_t headerBytes = avifRWStreamOffset(s);
+
+    // Chunks
+    if (hasAlpha && alphaData->size != 0 && codecConfigSize != 0) {
+        AVIF_CHECKRES(writeCodecConfig(s, &alphaItem->av1C)); // unsigned int(8) alpha_item_codec_config[alpha_item_codec_config_size];
+    }
+    if (hasHdr && hasGainmap && codecConfigSize != 0) {
+        AVIF_CHECKRES(writeCodecConfig(s, &gainmapItem->av1C)); // unsigned int(8) gainmap_item_codec_config[gainmap_item_codec_config_size];
+    }
+    if (codecConfigSize > 0) {
+        AVIF_CHECKRES(writeCodecConfig(s, &colorItem->av1C)); // unsigned int(8) main_item_codec_config[main_item_codec_config_size];
+    }
+
+    if (hasIcc) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, image->icc.data, image->icc.size)); // unsigned int(8) icc_data[icc_data_size_minus1 + 1];
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    if (hasHdr && hasGainmap && tmapIccSize != 0) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, encoder->data->altImageMetadata->icc.data, tmapIccSize)); // unsigned int(8) tmap_icc_data[tmap_icc_data_size_minus1 + 1];
+    }
+    if (hasHdr && hasGainmap && gainmapMetadataSize != 0) {
+        AVIF_CHECKRES(avifWriteGainmapMetadata(s, image->gainMap, &encoder->diag)); // unsigned int(8) gainmap_metadata[gainmap_metadata_size];
+    }
+#endif
+
+    if (hasAlpha && alphaData->size != 0) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, alphaData->data, alphaData->size)); // unsigned int(8) alpha_item_data[alpha_item_data_size];
+    }
+    if (hasHdr && hasGainmap && gainmapData->size != 0) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, gainmapData->data, gainmapData->size)); // unsigned int(8) gainmap_item_data[gainmap_item_data_size];
+    }
+
+    AVIF_CHECKRES(avifRWStreamWrite(s, colorData->data, colorData->size)); // unsigned int(8) main_item_data[main_item_data_size_minus1 + 1];
+
+    if (image->exif.size) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, image->exif.data, image->exif.size)); // unsigned int(8) exif_data[exif_data_size_minus1 + 1];
+    }
+    if (image->xmp.size) {
+        AVIF_CHECKRES(avifRWStreamWrite(s, image->xmp.data, image->xmp.size)); // unsigned int(8) xmp_data[xmp_data_size_minus1 + 1];
+    }
+
+    const size_t expectedChunkBytes = (hasAlpha ? codecConfigSize : 0) + (hasGainmap ? codecConfigSize : 0) + codecConfigSize +
+                                      image->icc.size + (hasGainmap ? tmapIccSize : 0) + (hasGainmap ? gainmapMetadataSize : 0) +
+                                      (hasAlpha ? alphaData->size : 0) + (hasGainmap ? gainmapData->size : 0) + colorData->size +
+                                      image->exif.size + image->xmp.size;
+    AVIF_ASSERT_OR_RETURN(avifRWStreamOffset(s) == headerBytes + expectedChunkBytes);
+    avifRWStreamFinishBox(s, mini);
+    return AVIF_RESULT_OK;
+}
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+static avifResult avifRWStreamWriteProperties(avifItemPropertyDedup * const dedup,
+                                              avifRWStream * const s,
+                                              const avifEncoder * const encoder,
+                                              const avifImage * const imageMetadata,
+                                              const avifImage * const altImageMetadata)
+{
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        const avifBool isGrid = (item->gridCols > 0);
+        // Whether there is ipma to write for this item.
+        avifBool hasIpmaToWrite = item->codec || isGrid;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        const avifBool isToneMappedImage = !memcmp(item->type, "tmap", 4);
+        if (isToneMappedImage) {
+            hasIpmaToWrite = AVIF_TRUE;
+        }
+#endif
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        const avifBool isSampleTransformImage = !memcmp(item->type, "sato", 4);
+        if (isSampleTransformImage) {
+            hasIpmaToWrite = AVIF_TRUE;
+        }
+#endif
+        memset(&item->ipma, 0, sizeof(item->ipma));
+        if (!hasIpmaToWrite) {
+            continue;
+        }
+
+        if (item->dimgFromID && (item->extraLayerCount == 0)) {
+            avifEncoderItem * parentItem = avifEncoderDataFindItemByID(encoder->data, item->dimgFromID);
+            if (parentItem && !memcmp(parentItem->type, "grid", 4)) {
+                // All image cells from a grid should share the exact same properties unless they are
+                // layered image which have different al1x, so see if we've already written properties
+                // out for another cell in this grid, and if so, just steal their ipma and move on.
+                // This is a sneaky way to provide iprp deduplication.
+
+                avifBool foundPreviousCell = AVIF_FALSE;
+                for (uint32_t dedupIndex = 0; dedupIndex < itemIndex; ++dedupIndex) {
+                    avifEncoderItem * dedupItem = &encoder->data->items.item[dedupIndex];
+                    if ((item->dimgFromID == dedupItem->dimgFromID) && (dedupItem->extraLayerCount == 0)) {
+                        // We've already written dedup's items out. Steal their ipma indices and move on!
+                        item->ipma = dedupItem->ipma;
+                        foundPreviousCell = AVIF_TRUE;
+                        break;
+                    }
+                }
+                if (foundPreviousCell) {
+                    continue;
+                }
+            }
+        }
+
+        const avifImage * itemMetadata = imageMetadata;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        if (isToneMappedImage) {
+            itemMetadata = altImageMetadata;
+        } else if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+            AVIF_ASSERT_OR_RETURN(itemMetadata->gainMap && itemMetadata->gainMap->image);
+            itemMetadata = itemMetadata->gainMap->image;
+        }
+#else
+        (void)altImageMetadata;
+#endif
+        uint32_t imageWidth = itemMetadata->width;
+        uint32_t imageHeight = itemMetadata->height;
+        if (isGrid) {
+            imageWidth = item->gridWidth;
+            imageHeight = item->gridHeight;
+        }
+
+        // Properties all image items need (coded and derived)
+        // ispe = image spatial extent (width, height)
+        avifItemPropertyDedupStart(dedup);
+        avifBoxMarker ispe;
+        AVIF_CHECKRES(avifRWStreamWriteFullBox(&dedup->s, "ispe", AVIF_BOX_SIZE_TBD, 0, 0, &ispe));
+        AVIF_CHECKRES(avifRWStreamWriteU32(&dedup->s, imageWidth));  // unsigned int(32) image_width;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&dedup->s, imageHeight)); // unsigned int(32) image_height;
+        avifRWStreamFinishBox(&dedup->s, ispe);
+        AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, s, &item->ipma, AVIF_FALSE));
+
+        // pixi = pixel information (depth, channel count)
+        avifBool hasPixi = AVIF_TRUE;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        // Pixi is optional for the 'tmap' item.
+        if (isToneMappedImage && imageMetadata->gainMap->altDepth == 0 && imageMetadata->gainMap->altPlaneCount == 0) {
+            hasPixi = AVIF_FALSE;
+        }
+#endif
+        const avifBool isAlpha = avifIsAlpha(item->itemCategory);
+        uint8_t depth = (uint8_t)itemMetadata->depth;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM)
+        if (encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B ||
+            encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B ||
+            encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_8B_OVERLAP_4B) {
+            if (item->itemCategory == AVIF_ITEM_SAMPLE_TRANSFORM) {
+                AVIF_ASSERT_OR_RETURN(depth == 16); // Only 16-bit depth is supported for now.
+            } else if (encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_8B_8B) {
+                depth = 8;
+            } else {
+                if (item->itemCategory == AVIF_ITEM_COLOR || item->itemCategory == AVIF_ITEM_ALPHA) {
+                    depth = 12;
+                } else {
+                    AVIF_ASSERT_OR_RETURN(item->itemCategory == AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_COLOR ||
+                                          item->itemCategory == AVIF_ITEM_SAMPLE_TRANSFORM_INPUT_0_ALPHA);
+                    // Will be shifted to 4-bit samples at decoding for AVIF_SAMPLE_TRANSFORM_BIT_DEPTH_EXTENSION_12B_4B.
+                    depth = 8;
+                }
+            }
+        } else {
+            AVIF_CHECKERR(encoder->sampleTransformRecipe == AVIF_SAMPLE_TRANSFORM_NONE, AVIF_RESULT_NOT_IMPLEMENTED);
+        }
+        assert(isSampleTransformImage == (item->itemCategory == AVIF_ITEM_SAMPLE_TRANSFORM));
+#endif // AVIF_ENABLE_EXPERIMENTAL_SAMPLE_TRANSFORM
+        if (hasPixi) {
+            avifItemPropertyDedupStart(dedup);
+            uint8_t channelCount = (isAlpha || (itemMetadata->yuvFormat == AVIF_PIXEL_FORMAT_YUV400)) ? 1 : 3;
+            avifBoxMarker pixi;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&dedup->s, "pixi", AVIF_BOX_SIZE_TBD, 0, 0, &pixi));
+            AVIF_CHECKRES(avifRWStreamWriteU8(&dedup->s, channelCount)); // unsigned int (8) num_channels;
+            for (uint8_t chan = 0; chan < channelCount; ++chan) {
+                AVIF_CHECKRES(avifRWStreamWriteU8(&dedup->s, depth)); // unsigned int (8) bits_per_channel;
+            }
+            avifRWStreamFinishBox(&dedup->s, pixi);
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, s, &item->ipma, AVIF_FALSE));
+        }
+
+        // Codec configuration box ('av1C' or 'av2C')
+        if (item->codec) {
+            avifItemPropertyDedupStart(dedup);
+            AVIF_CHECKRES(writeConfigBox(&dedup->s, &item->av1C, encoder->data->configPropName));
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, s, &item->ipma, AVIF_TRUE));
+        }
+
+        if (isAlpha) {
+            // Alpha specific properties
+
+            avifItemPropertyDedupStart(dedup);
+            avifBoxMarker auxC;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&dedup->s, "auxC", AVIF_BOX_SIZE_TBD, 0, 0, &auxC));
+            AVIF_CHECKRES(avifRWStreamWriteChars(&dedup->s, alphaURN, alphaURNSize)); //  string aux_type;
+            avifRWStreamFinishBox(&dedup->s, auxC);
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, s, &item->ipma, AVIF_FALSE));
+        } else if (item->itemCategory == AVIF_ITEM_COLOR) {
+            // Color specific properties
+            // Note the 'tmap' (tone mapped image) item when a gain map is present also has itemCategory AVIF_ITEM_COLOR.
+
+            AVIF_CHECKRES(avifEncoderWriteColorProperties(s, itemMetadata, &item->ipma, dedup));
+            AVIF_CHECKRES(avifEncoderWriteHDRProperties(&dedup->s, s, itemMetadata, &item->ipma, dedup));
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+        } else if (item->itemCategory == AVIF_ITEM_GAIN_MAP) {
+            // Gain map specific properties
+
+            // Write the colr nclx box.
+            AVIF_CHECKRES(avifEncoderWriteNclxProperty(&dedup->s, s, itemMetadata, &item->ipma, dedup));
+
+            // Also write the transformative properties.
+
+            // For the orientation, it could be done in multiple ways:
+            // - Bake the orientation in the base and gain map images.
+            //   This does not allow for orientation changes without recompression.
+            // - Associate 'irot'/'imir' with the 'tmap' derived image item only.
+            //   If so, decoding only the base image would give a different orientation than
+            //   decoding the tone-mapped image.
+            // - Wrap the base image in an 'iden' derived image item and associate 'irot'/'imir'
+            //   with the 'tmap' and 'iden' derived image items. 'iden' is not currently supported
+            //   by libavif, reducing the backward compatibility of this solution.
+            // - Associate 'irot'/'imir' with the base and gain map image items.
+            //   Do not associate 'irot'/'imir' with the 'tmap' derived image item.
+            //   These transformative properties are supposed to be applied at decoding on
+            //   image items before these are used as input to a derived image item.
+            //   libavif uses this pattern at encoding and requires it at decoding.
+            //   As of today, this is forbidden by the AVIF specification:
+            //     https://aomediacodec.github.io/av1-avif/v1.1.0.html#file-constraints
+            //   That rule was written before 'tmap' was proposed and may be relaxed for 'tmap'.
+
+            // 'clap' is treated as 'irot'/'imir', although it could differ between the base and
+            // gain map image items if these have different dimensions.
+            if (imageMetadata->transformFlags & AVIF_TRANSFORM_CLAP) {
+                AVIF_CHECKERR(imageMetadata->width != itemMetadata->width || imageMetadata->height != itemMetadata->height,
+                              AVIF_RESULT_NOT_IMPLEMENTED);
+            }
+
+            // 'pasp' is not a transformative property (despite AVIF_TRANSFORM_PASP being part of
+            // avifTransformFlag) but it is assumed to apply to the gain map in the same way as
+            // the transformative properties above.
+
+            // Based on the explanation above, 'pasp', 'clap', 'irot' and 'imir' have to match between the base and
+            // gain map image items in the container part of the encoded file.
+            // To enforce that, the transformative properties of the gain map cannot be set explicitly in the API.
+            AVIF_CHECKERR(itemMetadata->transformFlags == AVIF_TRANSFORM_NONE, AVIF_RESULT_ENCODE_GAIN_MAP_FAILED);
+            AVIF_CHECKRES(avifEncoderWriteExtendedColorProperties(&dedup->s, s, imageMetadata, &item->ipma, dedup));
+#endif
+        }
+
+        if (item->extraLayerCount > 0) {
+            // Layered Image Indexing Property
+
+            avifItemPropertyDedupStart(dedup);
+            avifBoxMarker a1lx;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&dedup->s, "a1lx", AVIF_BOX_SIZE_TBD, &a1lx));
+            uint32_t layerSize[AVIF_MAX_AV1_LAYER_COUNT - 1] = { 0 };
+            avifBool largeSize = AVIF_FALSE;
+
+            for (uint32_t validLayer = 0; validLayer < item->extraLayerCount; ++validLayer) {
+                uint32_t size = (uint32_t)item->encodeOutput->samples.sample[validLayer].data.size;
+                layerSize[validLayer] = size;
+                if (size > 0xffff) {
+                    largeSize = AVIF_TRUE;
+                }
+            }
+
+            AVIF_CHECKRES(avifRWStreamWriteBits(&dedup->s, 0, /*bitCount=*/7));                 // unsigned int(7) reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteBits(&dedup->s, largeSize ? 1 : 0, /*bitCount=*/1)); // unsigned int(1) large_size;
+
+            // FieldLength = (large_size + 1) * 16;
+            // unsigned int(FieldLength) layer_size[3];
+            for (uint32_t layer = 0; layer < AVIF_MAX_AV1_LAYER_COUNT - 1; ++layer) {
+                if (largeSize) {
+                    AVIF_CHECKRES(avifRWStreamWriteU32(&dedup->s, layerSize[layer]));
+                } else {
+                    AVIF_CHECKRES(avifRWStreamWriteU16(&dedup->s, (uint16_t)layerSize[layer]));
+                }
+            }
+            avifRWStreamFinishBox(&dedup->s, a1lx);
+            AVIF_CHECKRES(avifItemPropertyDedupFinish(dedup, s, &item->ipma, AVIF_FALSE));
+
+            // We don't add an 'lsel' property since many decoders do not support it and will reject the image,
+            // see https://github.com/AOMediaCodec/libavif/pull/2429
+        }
+    }
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifEncoderFinish(avifEncoder * encoder, avifRWData * output)
+{
+    avifDiagnosticsClearError(&encoder->diag);
+    if (encoder->data->items.count == 0) {
+        return AVIF_RESULT_NO_CONTENT;
+    }
+
+    const avifCodecType codecType = avifEncoderGetCodecType(encoder);
+    if (codecType == AVIF_CODEC_TYPE_UNKNOWN) {
+        return AVIF_RESULT_NO_CODEC_AVAILABLE;
+    }
+
+    // -----------------------------------------------------------------------
+    // Finish up encoding
+
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if (item->codec) {
+            if (!item->codec->encodeFinish(item->codec, item->encodeOutput)) {
+                return avifGetErrorForItemCategory(item->itemCategory);
+            }
+
+            if (item->encodeOutput->samples.count != encoder->data->frames.count) {
+                return avifGetErrorForItemCategory(item->itemCategory);
+            }
+
+            if ((item->extraLayerCount > 0) && (item->encodeOutput->samples.count != item->extraLayerCount + 1)) {
+                // Check whether user has sent enough frames to encoder.
+                avifDiagnosticsPrintf(&encoder->diag,
+                                      "Expected %u frames given to avifEncoderAddImage() to encode this layered image according to extraLayerCount, but got %u frames.",
+                                      item->extraLayerCount + 1,
+                                      item->encodeOutput->samples.count);
+                return AVIF_RESULT_INVALID_ARGUMENT;
+            }
+        }
+    }
+
+    // -----------------------------------------------------------------------
+    // Harvest configuration properties from sequence headers
+
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        if (item->encodeOutput->samples.count > 0) {
+            const avifEncodeSample * firstSample = &item->encodeOutput->samples.sample[0];
+            avifSequenceHeader sequenceHeader;
+            AVIF_CHECKERR(avifSequenceHeaderParse(&sequenceHeader, (const avifROData *)&firstSample->data, codecType),
+                          avifGetErrorForItemCategory(item->itemCategory));
+            item->av1C = sequenceHeader.av1C;
+        }
+    }
+
+    // -----------------------------------------------------------------------
+    // Begin write stream
+
+#if defined(AVIF_ENABLE_EXPERIMENTAL_MINI)
+    // Decide whether to go for a reduced MinimizedImageBox or a full regular MetaBox.
+    if ((encoder->headerFormat == AVIF_HEADER_REDUCED) && avifEncoderIsMiniCompatible(encoder)) {
+        AVIF_CHECKRES(avifEncoderWriteFileTypeBoxAndMetaBoxV1(encoder, output));
+        return AVIF_RESULT_OK;
+    }
+#endif // AVIF_ENABLE_EXPERIMENTAL_MINI
+
+    const avifImage * imageMetadata = encoder->data->imageMetadata;
+    // The epoch for creation_time and modification_time is midnight, Jan. 1,
+    // 1904, in UTC time. Add the number of seconds between that epoch and the
+    // Unix epoch.
+    uint64_t now = (uint64_t)time(NULL) + 2082844800;
+
+    avifRWStream s;
+    avifRWStreamStart(&s, output);
+
+    // -----------------------------------------------------------------------
+    // Write ftyp
+
+    // Layered sequence is not supported for now.
+    const avifBool isSequence = (encoder->extraLayerCount == 0) && (encoder->data->frames.count > 1);
+
+    const char * majorBrand = "avif";
+    if (isSequence) {
+        majorBrand = "avis";
+    }
+
+    uint32_t minorVersion = 0;
+#if defined(AVIF_CODEC_AVM)
+    if (codecType == AVIF_CODEC_TYPE_AV2) {
+        // TODO(yguyon): Experimental AV2-AVIF is AVIF version 2 for now (change once it is ratified).
+        minorVersion = 2;
+    }
+#endif
+
+    // According to section 5.2 of AV1 Image File Format specification v1.1.0:
+    //   If the primary item or all the items referenced by the primary item are AV1 image items made only
+    //   of Intra Frames, the brand "avio" should be used in the compatible_brands field of the FileTypeBox.
+    // See https://aomediacodec.github.io/av1-avif/v1.1.0.html#image-and-image-collection-brand.
+    // This rule corresponds to using the "avio" brand in all cases except for layered images, because:
+    //  - Non-layered still images are always Intra Frames, even with grids;
+    //  - Sequences cannot be combined with layers or grids, and the first frame of the sequence
+    //    (referred to by the primary image item) is always an Intra Frame.
+    avifBool useAvioBrand;
+    if (isSequence) {
+        // According to section 5.3 of AV1 Image File Format specification v1.1.0:
+        //   Additionally, if a file contains AV1 image sequences and the brand avio is used in the
+        //   compatible_brands field of the FileTypeBox, the item constraints for this brand shall be met
+        //   and at least one of the AV1 image sequences shall be made only of AV1 Samples marked as sync.
+        // See https://aomediacodec.github.io/av1-avif/v1.1.0.html#image-sequence-brand.
+        useAvioBrand = AVIF_FALSE;
+        for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+            avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+            if (item->encodeOutput->samples.count == 0) {
+                continue; // Not a track.
+            }
+            avifBool onlySyncSamples = AVIF_TRUE;
+            for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                if (!item->encodeOutput->samples.sample[sampleIndex].sync) {
+                    onlySyncSamples = AVIF_FALSE;
+                    break;
+                }
+            }
+            if (onlySyncSamples) {
+                useAvioBrand = AVIF_TRUE; // at least one of the AV1 image sequences is made only of sync samples
+                break;
+            }
+        }
+    } else {
+        // The gpac/ComplianceWarden tool only warns about the lack of the "avio" brand for sequences,
+        // and the specification says the brand "should" be used, not "shall". Leverage that opportunity
+        // to save four bytes for still images.
+        useAvioBrand = AVIF_FALSE; // Should be (encoder->extraLayerCount == 0) to be fully compliant.
+    }
+
+    avifBoxMarker ftyp;
+    AVIF_CHECKRES(avifRWStreamWriteBox(&s, "ftyp", AVIF_BOX_SIZE_TBD, &ftyp));
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, majorBrand, 4));              // unsigned int(32) major_brand;
+    AVIF_CHECKRES(avifRWStreamWriteU32(&s, minorVersion));                 // unsigned int(32) minor_version;
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, "avif", 4));                  // unsigned int(32) compatible_brands[];
+    if (useAvioBrand) {                                                    //
+        AVIF_CHECKRES(avifRWStreamWriteChars(&s, "avio", 4));              // ... compatible_brands[]
+    }                                                                      //
+    if (isSequence) {                                                      //
+        AVIF_CHECKRES(avifRWStreamWriteChars(&s, "avis", 4));              // ... compatible_brands[]
+        AVIF_CHECKRES(avifRWStreamWriteChars(&s, "msf1", 4));              // ... compatible_brands[]
+        AVIF_CHECKRES(avifRWStreamWriteChars(&s, "iso8", 4));              // ... compatible_brands[]
+    }                                                                      //
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, "mif1", 4));                  // ... compatible_brands[]
+    AVIF_CHECKRES(avifRWStreamWriteChars(&s, "miaf", 4));                  // ... compatible_brands[]
+    if ((imageMetadata->depth == 8) || (imageMetadata->depth == 10)) {     //
+        if (imageMetadata->yuvFormat == AVIF_PIXEL_FORMAT_YUV420) {        //
+            AVIF_CHECKRES(avifRWStreamWriteChars(&s, "MA1B", 4));          // ... compatible_brands[]
+        } else if (imageMetadata->yuvFormat == AVIF_PIXEL_FORMAT_YUV444) { //
+            AVIF_CHECKRES(avifRWStreamWriteChars(&s, "MA1A", 4));          // ... compatible_brands[]
+        }
+    }
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        if (!memcmp(encoder->data->items.item[itemIndex].type, "tmap", 4)) {
+            // ISO/IEC 23008-12:2024/AMD 1:2024(E)
+            // This brand enables file players to identify and decode HEIF files containing tone-map derived image
+            // items. When present, this brand shall be among the brands included in the compatible_brands
+            // array of the FileTypeBox.
+            AVIF_CHECKRES(avifRWStreamWriteChars(&s, "tmap", 4)); // ... compatible_brands[]
+            break;
+        }
+    }
+#endif
+    avifRWStreamFinishBox(&s, ftyp);
+
+    // -----------------------------------------------------------------------
+    // Start meta
+
+    avifBoxMarker meta;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "meta", AVIF_BOX_SIZE_TBD, 0, 0, &meta));
+
+    // -----------------------------------------------------------------------
+    // Write hdlr
+
+    AVIF_CHECKRES(avifRWStreamWriteHandlerBox(&s, "pict"));
+
+    // -----------------------------------------------------------------------
+    // Write pitm
+
+    if (encoder->data->primaryItemID != 0) {
+        AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "pitm", sizeof(uint16_t), 0, 0, /*marker=*/NULL));
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, encoder->data->primaryItemID)); //  unsigned int(16) item_ID;
+    }
+
+    // -----------------------------------------------------------------------
+    // Write iloc
+
+    avifBoxMarker iloc;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "iloc", AVIF_BOX_SIZE_TBD, 0, 0, &iloc));
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, 4, /*bitCount=*/4));                   // unsigned int(4) offset_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, 4, /*bitCount=*/4));                   // unsigned int(4) length_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, 0, /*bitCount=*/4));                   // unsigned int(4) base_offset_size;
+    AVIF_CHECKRES(avifRWStreamWriteBits(&s, 0, /*bitCount=*/4));                   // unsigned int(4) reserved;
+    AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)encoder->data->items.count)); // unsigned int(16) item_count;
+
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->id)); // unsigned int(16) item_ID;
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));        // unsigned int(16) data_reference_index;
+
+        // Layered Image, write location for all samples
+        if (item->extraLayerCount > 0) {
+            uint32_t layerCount = item->extraLayerCount + 1;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)layerCount)); // unsigned int(16) extent_count;
+            for (uint32_t i = 0; i < layerCount; ++i) {
+                AVIF_CHECKRES(avifEncoderItemAddMdatFixup(item, &s));
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0 /* set later */)); // unsigned int(offset_size*8) extent_offset;
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)item->encodeOutput->samples.sample[i].data.size)); // unsigned int(length_size*8) extent_length;
+            }
+            continue;
+        }
+
+        uint32_t contentSize = (uint32_t)item->metadataPayload.size;
+        if (item->encodeOutput->samples.count > 0) {
+            // This is choosing sample 0's size as there are two cases here:
+            // * This is a single image, in which case this is correct
+            // * This is an image sequence, but this file should still be a valid single-image avif,
+            //   so there must still be a primary item pointing at a sync sample. Since the first
+            //   frame of the image sequence is guaranteed to be a sync sample, it is chosen here.
+            //
+            // TODO: Offer the ability for a user to specify which frame in the sequence should
+            //       become the primary item's image, and force that frame to be a keyframe.
+            contentSize = (uint32_t)item->encodeOutput->samples.sample[0].data.size;
+        }
+
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, 1));                     // unsigned int(16) extent_count;
+        AVIF_CHECKRES(avifEncoderItemAddMdatFixup(item, &s));           //
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0 /* set later */));     // unsigned int(offset_size*8) extent_offset;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)contentSize)); // unsigned int(length_size*8) extent_length;
+    }
+
+    avifRWStreamFinishBox(&s, iloc);
+
+    // -----------------------------------------------------------------------
+    // Write iinf
+
+    // Section 8.11.6.2 of ISO/IEC 14496-12.
+    avifBoxMarker iinf;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "iinf", AVIF_BOX_SIZE_TBD, 0, 0, &iinf));
+    AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)encoder->data->items.count)); //  unsigned int(16) entry_count;
+
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+
+        uint32_t flags = item->hiddenImage ? 1 : 0;
+        avifBoxMarker infe;
+        AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "infe", AVIF_BOX_SIZE_TBD, 2, flags, &infe));
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->id));                             // unsigned int(16) item_ID;
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                                    // unsigned int(16) item_protection_index;
+        AVIF_CHECKRES(avifRWStreamWrite(&s, item->type, 4));                           // unsigned int(32) item_type;
+        AVIF_CHECKRES(avifRWStreamWriteChars(&s, item->infeName, item->infeNameSize)); // utf8string item_name; (writing null terminator)
+        if (!memcmp(item->type, "mime", 4)) {
+            AVIF_CHECKRES(avifRWStreamWriteChars(&s, item->infeContentType, item->infeContentTypeSize)); // utf8string content_type; (writing null terminator)
+            // utf8string content_encoding; //optional
+        } else if (!memcmp(item->type, "uri ", 4)) {
+            // utf8string item_uri_type;
+            return AVIF_RESULT_NOT_IMPLEMENTED;
+        }
+        avifRWStreamFinishBox(&s, infe);
+    }
+
+    avifRWStreamFinishBox(&s, iinf);
+
+    // -----------------------------------------------------------------------
+    // Write iref boxes
+
+    avifBoxMarker iref = 0;
+    for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+        avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+
+        // Count how many other items refer to this item with dimgFromID
+        uint16_t dimgCount = 0;
+        for (uint32_t dimgIndex = 0; dimgIndex < encoder->data->items.count; ++dimgIndex) {
+            avifEncoderItem * dimgItem = &encoder->data->items.item[dimgIndex];
+            if (dimgItem->dimgFromID == item->id) {
+                ++dimgCount;
+            }
+        }
+
+        if (dimgCount > 0) {
+            if (!iref) {
+                AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "iref", AVIF_BOX_SIZE_TBD, 0, 0, &iref));
+            }
+            avifBoxMarker refType;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "dimg", AVIF_BOX_SIZE_TBD, &refType));
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->id));  // unsigned int(16) from_item_ID;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, dimgCount)); // unsigned int(16) reference_count;
+            for (uint32_t dimgIndex = 0; dimgIndex < encoder->data->items.count; ++dimgIndex) {
+                avifEncoderItem * dimgItem = &encoder->data->items.item[dimgIndex];
+                if (dimgItem->dimgFromID == item->id) {
+                    AVIF_CHECKRES(avifRWStreamWriteU16(&s, dimgItem->id)); // unsigned int(16) to_item_ID;
+                }
+            }
+            avifRWStreamFinishBox(&s, refType);
+        }
+
+        if (item->irefToID != 0) {
+            if (!iref) {
+                AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "iref", AVIF_BOX_SIZE_TBD, 0, 0, &iref));
+            }
+            avifBoxMarker refType;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, item->irefType, AVIF_BOX_SIZE_TBD, &refType));
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->id));       // unsigned int(16) from_item_ID;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 1));              // unsigned int(16) reference_count;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->irefToID)); // unsigned int(16) to_item_ID;
+            avifRWStreamFinishBox(&s, refType);
+        }
+    }
+    if (iref) {
+        avifRWStreamFinishBox(&s, iref);
+    }
+
+    // -----------------------------------------------------------------------
+    // Write iprp -> ipco/ipma
+
+    avifBoxMarker iprp;
+    AVIF_CHECKRES(avifRWStreamWriteBox(&s, "iprp", AVIF_BOX_SIZE_TBD, &iprp));
+
+    avifItemPropertyDedup * dedup = avifItemPropertyDedupCreate();
+    AVIF_CHECKERR(dedup != NULL, AVIF_RESULT_OUT_OF_MEMORY);
+    avifBoxMarker ipco;
+    AVIF_CHECKRES(avifRWStreamWriteBox(&s, "ipco", AVIF_BOX_SIZE_TBD, &ipco));
+    avifImage * altImageMetadata = NULL;
+#if defined(AVIF_ENABLE_EXPERIMENTAL_GAIN_MAP)
+    altImageMetadata = encoder->data->altImageMetadata;
+#endif
+    avifResult result = avifRWStreamWriteProperties(dedup, &s, encoder, imageMetadata, altImageMetadata);
+    avifItemPropertyDedupDestroy(dedup);
+    AVIF_CHECKRES(result);
+    avifRWStreamFinishBox(&s, ipco);
+    dedup = NULL;
+
+    avifBoxMarker ipma;
+    AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "ipma", AVIF_BOX_SIZE_TBD, 0, 0, &ipma));
+    {
+        int ipmaCount = 0;
+        for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+            avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+            if (item->ipma.count > 0) {
+                ++ipmaCount;
+            }
+        }
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, ipmaCount)); // unsigned int(32) entry_count;
+
+        for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+            avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+            if (item->ipma.count == 0) {
+                continue;
+            }
+
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, item->id));        // unsigned int(16) item_ID;
+            AVIF_CHECKRES(avifRWStreamWriteU8(&s, item->ipma.count)); // unsigned int(8) association_count;
+            for (int i = 0; i < item->ipma.count; ++i) {
+                AVIF_CHECKRES(avifRWStreamWriteBits(&s, item->ipma.essential[i] ? 1 : 0, /*bitCount=*/1)); // bit(1) essential;
+                AVIF_CHECKRES(avifRWStreamWriteBits(&s, item->ipma.associations[i], /*bitCount=*/7)); // unsigned int(7) property_index;
+            }
+        }
+    }
+    avifRWStreamFinishBox(&s, ipma);
+
+    avifRWStreamFinishBox(&s, iprp);
+
+    // -----------------------------------------------------------------------
+    // Write grpl/altr box
+
+    if (encoder->data->alternativeItemIDs.count) {
+        // Section 8.18.3.3 of ISO 14496-12 (ISOBMFF) says:
+        //   group_id is a non-negative integer assigned to the particular grouping that shall not be equal to any
+        //   group_id value of any other EntityToGroupBox, any item_ID value of the hierarchy level
+        //   (file, movie. or track) that contains the GroupsListBox, or any track_ID value (when the
+        //   GroupsListBox is contained in the file level).
+        AVIF_ASSERT_OR_RETURN(encoder->data->lastItemID < UINT16_MAX);
+        ++encoder->data->lastItemID;
+        const uint32_t groupID = encoder->data->lastItemID;
+        AVIF_CHECKRES(avifWriteAltrGroup(&s, groupID, &encoder->data->alternativeItemIDs));
+    }
+
+    // -----------------------------------------------------------------------
+    // Finish meta box
+
+    avifRWStreamFinishBox(&s, meta);
+
+    // -----------------------------------------------------------------------
+    // Write tracks (if an image sequence)
+
+    if (isSequence) {
+        static const uint8_t unityMatrix[9][4] = {
+            /* clang-format off */
+            { 0x00, 0x01, 0x00, 0x00 },
+            { 0 },
+            { 0 },
+            { 0 },
+            { 0x00, 0x01, 0x00, 0x00 },
+            { 0 },
+            { 0 },
+            { 0 },
+            { 0x40, 0x00, 0x00, 0x00 }
+            /* clang-format on */
+        };
+
+        if (encoder->repetitionCount < 0 && encoder->repetitionCount != AVIF_REPETITION_COUNT_INFINITE) {
+            return AVIF_RESULT_INVALID_ARGUMENT;
+        }
+
+        uint64_t framesDurationInTimescales = 0;
+        for (uint32_t frameIndex = 0; frameIndex < encoder->data->frames.count; ++frameIndex) {
+            const avifEncoderFrame * frame = &encoder->data->frames.frame[frameIndex];
+            framesDurationInTimescales += frame->durationInTimescales;
+        }
+        uint64_t durationInTimescales;
+        if (encoder->repetitionCount == AVIF_REPETITION_COUNT_INFINITE) {
+            durationInTimescales = AVIF_INDEFINITE_DURATION64;
+        } else {
+            uint64_t loopCount = encoder->repetitionCount + 1;
+            AVIF_ASSERT_OR_RETURN(framesDurationInTimescales != 0);
+            if (loopCount > UINT64_MAX / framesDurationInTimescales) {
+                // The multiplication will overflow uint64_t.
+                return AVIF_RESULT_INVALID_ARGUMENT;
+            }
+            durationInTimescales = framesDurationInTimescales * loopCount;
+        }
+
+        // -------------------------------------------------------------------
+        // Start moov
+
+        avifBoxMarker moov;
+        AVIF_CHECKRES(avifRWStreamWriteBox(&s, "moov", AVIF_BOX_SIZE_TBD, &moov));
+
+        avifBoxMarker mvhd;
+        AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "mvhd", AVIF_BOX_SIZE_TBD, 1, 0, &mvhd));
+        AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                          // unsigned int(64) creation_time;
+        AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                          // unsigned int(64) modification_time;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)encoder->timescale)); // unsigned int(32) timescale;
+        AVIF_CHECKRES(avifRWStreamWriteU64(&s, durationInTimescales));         // unsigned int(64) duration;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0x00010000)); // template int(32) rate = 0x00010000; // typically 1.0
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0x0100));     // template int(16) volume = 0x0100; // typically, full volume
+        AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));          // const bit(16) reserved = 0;
+        AVIF_CHECKRES(avifRWStreamWriteZeros(&s, 8));        // const unsigned int(32)[2] reserved = 0;
+        AVIF_CHECKRES(avifRWStreamWrite(&s, unityMatrix, sizeof(unityMatrix)));
+        AVIF_CHECKRES(avifRWStreamWriteZeros(&s, 24));                       // bit(32)[6] pre_defined = 0;
+        AVIF_CHECKRES(avifRWStreamWriteU32(&s, encoder->data->items.count)); // unsigned int(32) next_track_ID;
+        avifRWStreamFinishBox(&s, mvhd);
+
+        // -------------------------------------------------------------------
+        // Write tracks
+
+        for (uint32_t itemIndex = 0; itemIndex < encoder->data->items.count; ++itemIndex) {
+            avifEncoderItem * item = &encoder->data->items.item[itemIndex];
+            if (item->encodeOutput->samples.count == 0) {
+                continue;
+            }
+
+            uint32_t syncSamplesCount = 0;
+            for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                avifEncodeSample * sample = &item->encodeOutput->samples.sample[sampleIndex];
+                if (sample->sync) {
+                    ++syncSamplesCount;
+                }
+            }
+
+            avifBoxMarker trak;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "trak", AVIF_BOX_SIZE_TBD, &trak));
+
+            avifBoxMarker tkhd;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "tkhd", AVIF_BOX_SIZE_TBD, 1, 1, &tkhd));
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                    // unsigned int(64) creation_time;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                    // unsigned int(64) modification_time;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, itemIndex + 1));          // unsigned int(32) track_ID;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0));                      // const unsigned int(32) reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, durationInTimescales));   // unsigned int(64) duration;
+            AVIF_CHECKRES(avifRWStreamWriteZeros(&s, sizeof(uint32_t) * 2)); // const unsigned int(32)[2] reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                      // template int(16) layer = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                      // template int(16) alternate_group = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0)); // template int(16) volume = {if track_is_audio 0x0100 else 0};
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0)); // const unsigned int(16) reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWrite(&s, unityMatrix, sizeof(unityMatrix))); // template int(32)[9] matrix= // { 0x00010000,0,0,0,0x00010000,0,0,0,0x40000000 };
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, imageMetadata->width << 16));  // unsigned int(32) width;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, imageMetadata->height << 16)); // unsigned int(32) height;
+            avifRWStreamFinishBox(&s, tkhd);
+
+            if (item->irefToID != 0) {
+                avifBoxMarker tref;
+                AVIF_CHECKRES(avifRWStreamWriteBox(&s, "tref", AVIF_BOX_SIZE_TBD, &tref));
+                avifBoxMarker refType;
+                AVIF_CHECKRES(avifRWStreamWriteBox(&s, item->irefType, AVIF_BOX_SIZE_TBD, &refType));
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)item->irefToID));
+                avifRWStreamFinishBox(&s, refType);
+                avifRWStreamFinishBox(&s, tref);
+            }
+
+            avifBoxMarker edts;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "edts", AVIF_BOX_SIZE_TBD, &edts));
+            uint32_t elstFlags = (encoder->repetitionCount != 0);
+            avifBoxMarker elst;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "elst", AVIF_BOX_SIZE_TBD, 1, elstFlags, &elst));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1));                          // unsigned int(32) entry_count;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, framesDurationInTimescales)); // unsigned int(64) segment_duration;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, 0));                          // int(64) media_time;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 1));                          // int(16) media_rate_integer;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                          // int(16) media_rate_fraction = 0;
+            avifRWStreamFinishBox(&s, elst);
+            avifRWStreamFinishBox(&s, edts);
+
+            if (item->itemCategory != AVIF_ITEM_ALPHA) {
+                AVIF_CHECKRES(avifEncoderWriteTrackMetaBox(encoder, &s));
+            }
+
+            avifBoxMarker mdia;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "mdia", AVIF_BOX_SIZE_TBD, &mdia));
+
+            avifBoxMarker mdhd;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "mdhd", AVIF_BOX_SIZE_TBD, 1, 0, &mdhd));
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                          // unsigned int(64) creation_time;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, now));                          // unsigned int(64) modification_time;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)encoder->timescale)); // unsigned int(32) timescale;
+            AVIF_CHECKRES(avifRWStreamWriteU64(&s, framesDurationInTimescales));   // unsigned int(64) duration;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 21956)); // bit(1) pad = 0; unsigned int(5)[3] language; ("und")
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));     // unsigned int(16) pre_defined = 0;
+            avifRWStreamFinishBox(&s, mdhd);
+
+            AVIF_CHECKRES(avifRWStreamWriteHandlerBox(&s, (item->itemCategory == AVIF_ITEM_ALPHA) ? "auxv" : "pict"));
+
+            avifBoxMarker minf;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "minf", AVIF_BOX_SIZE_TBD, &minf));
+
+            avifBoxMarker vmhd;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "vmhd", AVIF_BOX_SIZE_TBD, 0, 1, &vmhd));
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0)); // template unsigned int(16) graphicsmode = 0; (copy over the existing image)
+            AVIF_CHECKRES(avifRWStreamWriteZeros(&s, 6)); // template unsigned int(16)[3] opcolor = {0, 0, 0};
+            avifRWStreamFinishBox(&s, vmhd);
+
+            avifBoxMarker dinf;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "dinf", AVIF_BOX_SIZE_TBD, &dinf));
+            avifBoxMarker dref;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "dref", AVIF_BOX_SIZE_TBD, 0, 0, &dref));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1)); // unsigned int(32) entry_count;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "url ", /*contentSize=*/0, 0, 1, /*marker=*/NULL)); // flags:1 means data is in this file
+            avifRWStreamFinishBox(&s, dref);
+            avifRWStreamFinishBox(&s, dinf);
+
+            // The boxes within the "stbl" box are ordered using the following recommendation in ISO/IEC 14496-12, Section 6.2.3:
+            // 4) It is recommended that the boxes within the Sample Table Box be in the following order: Sample Description
+            // (stsd), Time to Sample (stts), Sample to Chunk (stsc), Sample Size (stsz), Chunk Offset (stco).
+            //
+            // Any boxes not listed in the above line are placed in the end (after the "stco" box).
+            avifBoxMarker stbl;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, "stbl", AVIF_BOX_SIZE_TBD, &stbl));
+
+            avifBoxMarker stsd;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stsd", AVIF_BOX_SIZE_TBD, 0, 0, &stsd));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1)); // unsigned int(32) entry_count;
+            avifBoxMarker imageItem;
+            AVIF_CHECKRES(avifRWStreamWriteBox(&s, encoder->data->imageItemType, AVIF_BOX_SIZE_TBD, &imageItem));
+            AVIF_CHECKRES(avifRWStreamWriteZeros(&s, 6));                             // const unsigned int(8)[6] reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 1));                               // unsigned int(16) data_reference_index;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                               // unsigned int(16) pre_defined = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0));                               // const unsigned int(16) reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteZeros(&s, sizeof(uint32_t) * 3));          // unsigned int(32)[3] pre_defined = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)imageMetadata->width));  // unsigned int(16) width;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)imageMetadata->height)); // unsigned int(16) height;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0x00480000));                      // template unsigned int(32) horizresolution
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0x00480000));                      // template unsigned int(32) vertresolution
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0));                               // const unsigned int(32) reserved = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 1));                      // template unsigned int(16) frame_count = 1;
+            AVIF_CHECKRES(avifRWStreamWriteChars(&s, "\012AOM Coding", 11)); // string[32] compressorname;
+            AVIF_CHECKRES(avifRWStreamWriteZeros(&s, 32 - 11));              //
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, 0x0018));                 // template unsigned int(16) depth = 0x0018;
+            AVIF_CHECKRES(avifRWStreamWriteU16(&s, (uint16_t)0xffff));       // int(16) pre_defined = -1;
+            AVIF_CHECKRES(writeConfigBox(&s, &item->av1C, encoder->data->configPropName));
+            if (item->itemCategory == AVIF_ITEM_COLOR) {
+                AVIF_CHECKRES(avifEncoderWriteColorProperties(&s, imageMetadata, NULL, NULL));
+                AVIF_CHECKRES(avifEncoderWriteHDRProperties(NULL, &s, imageMetadata, NULL, NULL));
+            }
+
+            avifBoxMarker ccst;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "ccst", AVIF_BOX_SIZE_TBD, 0, 0, &ccst));
+            AVIF_CHECKRES(avifRWStreamWriteBits(&s, 0, /*bitCount=*/1));  // unsigned int(1) all_ref_pics_intra;
+            AVIF_CHECKRES(avifRWStreamWriteBits(&s, 1, /*bitCount=*/1));  // unsigned int(1) intra_pred_used;
+            AVIF_CHECKRES(avifRWStreamWriteBits(&s, 15, /*bitCount=*/4)); // unsigned int(4) max_ref_per_pic;
+            AVIF_CHECKRES(avifRWStreamWriteBits(&s, 0, /*bitCount=*/26)); // unsigned int(26) reserved;
+            avifRWStreamFinishBox(&s, ccst);
+
+            if (item->itemCategory == AVIF_ITEM_ALPHA) {
+                avifBoxMarker auxi;
+                AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "auxi", AVIF_BOX_SIZE_TBD, 0, 0, &auxi));
+                AVIF_CHECKRES(avifRWStreamWriteChars(&s, alphaURN, alphaURNSize)); //  string aux_track_type;
+                avifRWStreamFinishBox(&s, auxi);
+            }
+
+            avifRWStreamFinishBox(&s, imageItem);
+            avifRWStreamFinishBox(&s, stsd);
+
+            avifBoxMarker stts;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stts", AVIF_BOX_SIZE_TBD, 0, 0, &stts));
+            size_t sttsEntryCountOffset = avifRWStreamOffset(&s);
+            uint32_t sttsEntryCount = 0;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0)); // unsigned int(32) entry_count;
+            for (uint32_t sampleCount = 0, frameIndex = 0; frameIndex < encoder->data->frames.count; ++frameIndex) {
+                avifEncoderFrame * frame = &encoder->data->frames.frame[frameIndex];
+                ++sampleCount;
+                if (frameIndex < (encoder->data->frames.count - 1)) {
+                    avifEncoderFrame * nextFrame = &encoder->data->frames.frame[frameIndex + 1];
+                    if (frame->durationInTimescales == nextFrame->durationInTimescales) {
+                        continue;
+                    }
+                }
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, sampleCount));                           // unsigned int(32) sample_count;
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)frame->durationInTimescales)); // unsigned int(32) sample_delta;
+                sampleCount = 0;
+                ++sttsEntryCount;
+            }
+            size_t prevOffset = avifRWStreamOffset(&s);
+            avifRWStreamSetOffset(&s, sttsEntryCountOffset);
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, sttsEntryCount));
+            avifRWStreamSetOffset(&s, prevOffset);
+            avifRWStreamFinishBox(&s, stts);
+
+            avifBoxMarker stsc;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stsc", AVIF_BOX_SIZE_TBD, 0, 0, &stsc));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1));                                 // unsigned int(32) entry_count;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1));                                 // unsigned int(32) first_chunk;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, item->encodeOutput->samples.count)); // unsigned int(32) samples_per_chunk;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1)); // unsigned int(32) sample_description_index;
+            avifRWStreamFinishBox(&s, stsc);
+
+            avifBoxMarker stsz;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stsz", AVIF_BOX_SIZE_TBD, 0, 0, &stsz));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 0));                                 // unsigned int(32) sample_size;
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, item->encodeOutput->samples.count)); // unsigned int(32) sample_count;
+            for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                avifEncodeSample * sample = &item->encodeOutput->samples.sample[sampleIndex];
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, (uint32_t)sample->data.size)); // unsigned int(32) entry_size;
+            }
+            avifRWStreamFinishBox(&s, stsz);
+
+            avifBoxMarker stco;
+            AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stco", AVIF_BOX_SIZE_TBD, 0, 0, &stco));
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1));           // unsigned int(32) entry_count;
+            AVIF_CHECKRES(avifEncoderItemAddMdatFixup(item, &s)); //
+            AVIF_CHECKRES(avifRWStreamWriteU32(&s, 1));           // unsigned int(32) chunk_offset; (set later)
+            avifRWStreamFinishBox(&s, stco);
+
+            avifBool hasNonSyncSample = AVIF_FALSE;
+            for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                if (!item->encodeOutput->samples.sample[sampleIndex].sync) {
+                    hasNonSyncSample = AVIF_TRUE;
+                    break;
+                }
+            }
+            // ISO/IEC 14496-12, Section 8.6.2.1:
+            //   If the SyncSampleBox is not present, every sample is a sync sample.
+            if (hasNonSyncSample) {
+                avifBoxMarker stss;
+                AVIF_CHECKRES(avifRWStreamWriteFullBox(&s, "stss", AVIF_BOX_SIZE_TBD, 0, 0, &stss));
+                AVIF_CHECKRES(avifRWStreamWriteU32(&s, syncSamplesCount)); // unsigned int(32) entry_count;
+                for (uint32_t sampleIndex = 0; sampleIndex < item->encodeOutput->samples.count; ++sampleIndex) {
+                    avifEncodeSample * sample = &item->encodeOutput->samples.sample[sampleIndex];
+                    if (sample->sync) {
+                        AVIF_CHECKRES(avifRWStreamWriteU32(&s, sampleIndex + 1)); // unsigned int(32) sample_number;
+                    }
+                }
+                avifRWStreamFinishBox(&s, stss);
+            }
+
+            avifRWStreamFinishBox(&s, stbl);
+
+            avifRWStreamFinishBox(&s, minf);
+            avifRWStreamFinishBox(&s, mdia);
+            avifRWStreamFinishBox(&s, trak);
+        }
+
+        // -------------------------------------------------------------------
+        // Finish moov box
+
+        avifRWStreamFinishBox(&s, moov);
+    }
+
+    // -----------------------------------------------------------------------
+    // Write mdat
+
+    avifEncoderItemReferenceArray layeredColorItems;
+    avifEncoderItemReferenceArray layeredAlphaItems;
+    if (!avifArrayCreate(&layeredColorItems, sizeof(avifEncoderItemReference), 1)) {
+        result = AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    if (!avifArrayCreate(&layeredAlphaItems, sizeof(avifEncoderItemReference), 1)) {
+        result = AVIF_RESULT_OUT_OF_MEMORY;
+    }
+    if (result == AVIF_RESULT_OK) {
+        result = avifEncoderWriteMediaDataBox(encoder, &s, &layeredColorItems, &layeredAlphaItems);
+    }
+    avifArrayDestroy(&layeredColorItems);
+    avifArrayDestroy(&layeredAlphaItems);
+    AVIF_CHECKRES(result);
+
+    // -----------------------------------------------------------------------
+    // Finish up stream
+
+    avifRWStreamFinishWrite(&s);
+
+#if defined(AVIF_ENABLE_COMPLIANCE_WARDEN)
+    AVIF_CHECKRES(avifIsCompliant(output->data, output->size));
+#endif
+
+    return AVIF_RESULT_OK;
+}
+
+avifResult avifEncoderWrite(avifEncoder * encoder, const avifImage * image, avifRWData * output)
+{
+    avifResult addImageResult = avifEncoderAddImage(encoder, image, 1, AVIF_ADD_IMAGE_FLAG_SINGLE);
+    if (addImageResult != AVIF_RESULT_OK) {
+        return addImageResult;
+    }
+    return avifEncoderFinish(encoder, output);
+}
+
+// Implementation of section 2.3.3 of AV1 Codec ISO Media File Format Binding specification v1.2.0.
+// See https://aomediacodec.github.io/av1-isobmff/v1.2.0.html#av1codecconfigurationbox-syntax.
+static avifResult writeCodecConfig(avifRWStream * s, const avifCodecConfigurationBox * cfg)
+{
+    const size_t av1COffset = s->offset;
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 1, /*bitCount=*/1)); // unsigned int (1) marker = 1;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 1, /*bitCount=*/7)); // unsigned int (7) version = 1;
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->seqProfile, /*bitCount=*/3));   // unsigned int (3) seq_profile;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->seqLevelIdx0, /*bitCount=*/5)); // unsigned int (5) seq_level_idx_0;
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->seqTier0, /*bitCount=*/1));             // unsigned int (1) seq_tier_0;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->highBitdepth, /*bitCount=*/1));         // unsigned int (1) high_bitdepth;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->twelveBit, /*bitCount=*/1));            // unsigned int (1) twelve_bit;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->monochrome, /*bitCount=*/1));           // unsigned int (1) monochrome;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->chromaSubsamplingX, /*bitCount=*/1));   // unsigned int (1) chroma_subsampling_x;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->chromaSubsamplingY, /*bitCount=*/1));   // unsigned int (1) chroma_subsampling_y;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, cfg->chromaSamplePosition, /*bitCount=*/2)); // unsigned int (2) chroma_sample_position;
+
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, /*bitCount=*/3)); // unsigned int (3) reserved = 0;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, /*bitCount=*/1)); // unsigned int (1) initial_presentation_delay_present;
+    AVIF_CHECKRES(avifRWStreamWriteBits(s, 0, /*bitCount=*/4)); // unsigned int (4) reserved = 0;
+
+    // According to section 2.2.1 of AV1 Image File Format specification v1.1.0,
+    // there is no need to write any OBU here.
+    // See https://aomediacodec.github.io/av1-avif/v1.1.0.html#av1-configuration-item-property.
+    // unsigned int (8) configOBUs[];
+
+    AVIF_ASSERT_OR_RETURN(s->offset - av1COffset == 4); // Make sure writeCodecConfig() writes exactly 4 bytes.
+    return AVIF_RESULT_OK;
+}
+
+static avifResult writeConfigBox(avifRWStream * s, const avifCodecConfigurationBox * cfg, const char * configPropName)
+{
+    avifBoxMarker configBox;
+    AVIF_CHECKRES(avifRWStreamWriteBox(s, configPropName, AVIF_BOX_SIZE_TBD, &configBox));
+    AVIF_CHECKRES(writeCodecConfig(s, cfg));
+    avifRWStreamFinishBox(s, configBox);
+    return AVIF_RESULT_OK;
+}
diff --git a/third_party/libavif/src/third_party/README.md b/third_party/libavif/src/third_party/README.md
new file mode 100644
index 0000000000..a625670372
--- /dev/null
+++ b/third_party/libavif/src/third_party/README.md
@@ -0,0 +1,25 @@
+# libavif third party sources
+
+Anything in this directory is imported from third party sources with minimal changes.
+
+See `LICENSE` file of respective subdirectories of this directory for license information.
+
+## libyuv
+
+This subdirectory contains source code imported from libyuv as of `def473f501acbd652cd4593fd2a90a067e8c9f1a`, with
+modifications intended to keep them relatively small and simple.
+
+### Importing from upstream
+
+When importing source code from upstream libyuv, the following changes must be done:
+
+1. Source hierarchy is to be kept the same as in libyuv.
+2. The only APIs that are called by libavif for scaling are `ScalePlane()` and `ScalePlane_12()`. Anything else must be
+   left out.
+3. In function `ScalePlane()` and `ScalePlane_16()`, only the `ScalePlaneVertical()`, `CopyPlane()`, `ScalePlaneBox()`,
+   `ScalePlaneUp2_Linear()`, `ScalePlaneUp2_Bilinear()`, `ScalePlaneBilinearUp()`, `ScalePlaneBilinearDown()` and
+   `ScalePlaneSimple()` paths (and their `_16` equivalents) from libyuv must be kept; any other paths are to be stripped
+   out (including SIMD).
+4. The commit hash of libyuv from where the files got imported in this README.md file must be updated.
+5. `LIBYUV_API` must be removed from any and all imported functions as these files are always built static.
+6. Replace .cc file extension by .c.
diff --git a/third_party/libavif/src/third_party/iccjpeg/iccjpeg.c b/third_party/libavif/src/third_party/iccjpeg/iccjpeg.c
new file mode 100644
index 0000000000..d08b4bd081
--- /dev/null
+++ b/third_party/libavif/src/third_party/iccjpeg/iccjpeg.c
@@ -0,0 +1,248 @@
+/*
+ * iccprofile.c
+ *
+ * This file provides code to read and write International Color Consortium
+ * (ICC) device profiles embedded in JFIF JPEG image files.  The ICC has
+ * defined a standard format for including such data in JPEG "APP2" markers.
+ * The code given here does not know anything about the internal structure
+ * of the ICC profile data; it just knows how to put the profile data into
+ * a JPEG file being written, or get it back out when reading.
+ *
+ * This code depends on new features added to the IJG JPEG library as of
+ * IJG release 6b; it will not compile or work with older IJG versions.
+ *
+ * NOTE: this code would need surgery to work on 16-bit-int machines
+ * with ICC profiles exceeding 64K bytes in size.  If you need to do that,
+ * change all the "unsigned int" variables to "INT32".  You'll also need
+ * to find a malloc() replacement that can allocate more than 64K.
+ */
+
+#include "iccjpeg.h"
+#include <stdlib.h>			/* define malloc() */
+
+
+/*
+ * Since an ICC profile can be larger than the maximum size of a JPEG marker
+ * (64K), we need provisions to split it into multiple markers.  The format
+ * defined by the ICC specifies one or more APP2 markers containing the
+ * following data:
+ *	Identifying string	ASCII "ICC_PROFILE\0"  (12 bytes)
+ *	Marker sequence number	1 for first APP2, 2 for next, etc (1 byte)
+ *	Number of markers	Total number of APP2's used (1 byte)
+ *      Profile data		(remainder of APP2 data)
+ * Decoders should use the marker sequence numbers to reassemble the profile,
+ * rather than assuming that the APP2 markers appear in the correct sequence.
+ */
+
+#define ICC_MARKER  (JPEG_APP0 + 2)	/* JPEG marker code for ICC */
+#define ICC_OVERHEAD_LEN  14		/* size of non-profile data in APP2 */
+#define MAX_BYTES_IN_MARKER  65533	/* maximum data len of a JPEG marker */
+#define MAX_DATA_BYTES_IN_MARKER  (MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN)
+
+
+/*
+ * This routine writes the given ICC profile data into a JPEG file.
+ * It *must* be called AFTER calling jpeg_start_compress() and BEFORE
+ * the first call to jpeg_write_scanlines().
+ * (This ordering ensures that the APP2 marker(s) will appear after the
+ * SOI and JFIF or Adobe markers, but before all else.)
+ */
+
+void
+write_icc_profile (j_compress_ptr cinfo,
+		   const JOCTET *icc_data_ptr,
+		   unsigned int icc_data_len)
+{
+  unsigned int num_markers;	/* total number of markers we'll write */
+  int cur_marker = 1;		/* per spec, counting starts at 1 */
+  unsigned int length;		/* number of bytes to write in this marker */
+
+  /* Calculate the number of markers we'll need, rounding up of course */
+  num_markers = icc_data_len / MAX_DATA_BYTES_IN_MARKER;
+  if (num_markers * MAX_DATA_BYTES_IN_MARKER != icc_data_len)
+    num_markers++;
+
+  while (icc_data_len > 0) {
+    /* length of profile to put in this marker */
+    length = icc_data_len;
+    if (length > MAX_DATA_BYTES_IN_MARKER)
+      length = MAX_DATA_BYTES_IN_MARKER;
+    icc_data_len -= length;
+
+    /* Write the JPEG marker header (APP2 code and marker length) */
+    jpeg_write_m_header(cinfo, ICC_MARKER,
+			(unsigned int) (length + ICC_OVERHEAD_LEN));
+
+    /* Write the marker identifying string "ICC_PROFILE" (null-terminated).
+     * We code it in this less-than-transparent way so that the code works
+     * even if the local character set is not ASCII.
+     */
+    jpeg_write_m_byte(cinfo, 0x49);
+    jpeg_write_m_byte(cinfo, 0x43);
+    jpeg_write_m_byte(cinfo, 0x43);
+    jpeg_write_m_byte(cinfo, 0x5F);
+    jpeg_write_m_byte(cinfo, 0x50);
+    jpeg_write_m_byte(cinfo, 0x52);
+    jpeg_write_m_byte(cinfo, 0x4F);
+    jpeg_write_m_byte(cinfo, 0x46);
+    jpeg_write_m_byte(cinfo, 0x49);
+    jpeg_write_m_byte(cinfo, 0x4C);
+    jpeg_write_m_byte(cinfo, 0x45);
+    jpeg_write_m_byte(cinfo, 0x0);
+
+    /* Add the sequencing info */
+    jpeg_write_m_byte(cinfo, cur_marker);
+    jpeg_write_m_byte(cinfo, (int) num_markers);
+
+    /* Add the profile data */
+    while (length--) {
+      jpeg_write_m_byte(cinfo, *icc_data_ptr);
+      icc_data_ptr++;
+    }
+    cur_marker++;
+  }
+}
+
+
+/*
+ * Prepare for reading an ICC profile
+ */
+
+void
+setup_read_icc_profile (j_decompress_ptr cinfo)
+{
+  /* Tell the library to keep any APP2 data it may find */
+  jpeg_save_markers(cinfo, ICC_MARKER, 0xFFFF);
+}
+
+
+/*
+ * Handy subroutine to test whether a saved marker is an ICC profile marker.
+ */
+
+static boolean
+marker_is_icc (jpeg_saved_marker_ptr marker)
+{
+  return
+    marker->marker == ICC_MARKER &&
+    marker->data_length >= ICC_OVERHEAD_LEN &&
+    /* verify the identifying string */
+    GETJOCTET(marker->data[0]) == 0x49 &&
+    GETJOCTET(marker->data[1]) == 0x43 &&
+    GETJOCTET(marker->data[2]) == 0x43 &&
+    GETJOCTET(marker->data[3]) == 0x5F &&
+    GETJOCTET(marker->data[4]) == 0x50 &&
+    GETJOCTET(marker->data[5]) == 0x52 &&
+    GETJOCTET(marker->data[6]) == 0x4F &&
+    GETJOCTET(marker->data[7]) == 0x46 &&
+    GETJOCTET(marker->data[8]) == 0x49 &&
+    GETJOCTET(marker->data[9]) == 0x4C &&
+    GETJOCTET(marker->data[10]) == 0x45 &&
+    GETJOCTET(marker->data[11]) == 0x0;
+}
+
+
+/*
+ * See if there was an ICC profile in the JPEG file being read;
+ * if so, reassemble and return the profile data.
+ *
+ * TRUE is returned if an ICC profile was found, FALSE if not.
+ * If TRUE is returned, *icc_data_ptr is set to point to the
+ * returned data, and *icc_data_len is set to its length.
+ *
+ * IMPORTANT: the data at **icc_data_ptr has been allocated with malloc()
+ * and must be freed by the caller with free() when the caller no longer
+ * needs it.  (Alternatively, we could write this routine to use the
+ * IJG library's memory allocator, so that the data would be freed implicitly
+ * at jpeg_finish_decompress() time.  But it seems likely that many apps
+ * will prefer to have the data stick around after decompression finishes.)
+ *
+ * NOTE: if the file contains invalid ICC APP2 markers, we just silently
+ * return FALSE.  You might want to issue an error message instead.
+ */
+
+boolean
+read_icc_profile (j_decompress_ptr cinfo,
+		  JOCTET **icc_data_ptr,
+		  unsigned int *icc_data_len)
+{
+  jpeg_saved_marker_ptr marker;
+  int num_markers = 0;
+  int seq_no;
+  JOCTET *icc_data;
+  unsigned int total_length;
+#define MAX_SEQ_NO  255		/* sufficient since marker numbers are bytes */
+  char marker_present[MAX_SEQ_NO+1];	  /* 1 if marker found */
+  unsigned int data_length[MAX_SEQ_NO+1]; /* size of profile data in marker */
+  unsigned int data_offset[MAX_SEQ_NO+1]; /* offset for data in marker */
+
+  *icc_data_ptr = NULL;		/* avoid confusion if FALSE return */
+  *icc_data_len = 0;
+
+  /* This first pass over the saved markers discovers whether there are
+   * any ICC markers and verifies the consistency of the marker numbering.
+   */
+
+  for (seq_no = 1; seq_no <= MAX_SEQ_NO; seq_no++)
+    marker_present[seq_no] = 0;
+
+  for (marker = cinfo->marker_list; marker != NULL; marker = marker->next) {
+    if (marker_is_icc(marker)) {
+      if (num_markers == 0)
+	num_markers = GETJOCTET(marker->data[13]);
+      else if (num_markers != GETJOCTET(marker->data[13]))
+	return FALSE;		/* inconsistent num_markers fields */
+      seq_no = GETJOCTET(marker->data[12]);
+      if (seq_no <= 0 || seq_no > num_markers)
+	return FALSE;		/* bogus sequence number */
+      if (marker_present[seq_no])
+	return FALSE;		/* duplicate sequence numbers */
+      marker_present[seq_no] = 1;
+      data_length[seq_no] = marker->data_length - ICC_OVERHEAD_LEN;
+    }
+  }
+
+  if (num_markers == 0)
+    return FALSE;
+
+  /* Check for missing markers, count total space needed,
+   * compute offset of each marker's part of the data.
+   */
+
+  total_length = 0;
+  for (seq_no = 1; seq_no <= num_markers; seq_no++) {
+    if (marker_present[seq_no] == 0)
+      return FALSE;		/* missing sequence number */
+    data_offset[seq_no] = total_length;
+    total_length += data_length[seq_no];
+  }
+
+  if (total_length == 0)
+    return FALSE;		/* found only empty markers? */
+
+  /* Allocate space for assembled data */
+  icc_data = (JOCTET *) malloc(total_length * sizeof(JOCTET));
+  if (icc_data == NULL)
+    return FALSE;		/* oops, out of memory */
+
+  /* and fill it in */
+  for (marker = cinfo->marker_list; marker != NULL; marker = marker->next) {
+    if (marker_is_icc(marker)) {
+      JOCTET FAR *src_ptr;
+      JOCTET *dst_ptr;
+      unsigned int length;
+      seq_no = GETJOCTET(marker->data[12]);
+      dst_ptr = icc_data + data_offset[seq_no];
+      src_ptr = marker->data + ICC_OVERHEAD_LEN;
+      length = data_length[seq_no];
+      while (length--) {
+	*dst_ptr++ = *src_ptr++;
+      }
+    }
+  }
+
+  *icc_data_ptr = icc_data;
+  *icc_data_len = total_length;
+
+  return TRUE;
+}
diff --git a/third_party/libavif/src/third_party/iccjpeg/iccjpeg.h b/third_party/libavif/src/third_party/iccjpeg/iccjpeg.h
new file mode 100644
index 0000000000..5e1888d9ef
--- /dev/null
+++ b/third_party/libavif/src/third_party/iccjpeg/iccjpeg.h
@@ -0,0 +1,73 @@
+/*
+ * iccprofile.h
+ *
+ * This file provides code to read and write International Color Consortium
+ * (ICC) device profiles embedded in JFIF JPEG image files.  The ICC has
+ * defined a standard format for including such data in JPEG "APP2" markers.
+ * The code given here does not know anything about the internal structure
+ * of the ICC profile data; it just knows how to put the profile data into
+ * a JPEG file being written, or get it back out when reading.
+ *
+ * This code depends on new features added to the IJG JPEG library as of
+ * IJG release 6b; it will not compile or work with older IJG versions.
+ *
+ * NOTE: this code would need surgery to work on 16-bit-int machines
+ * with ICC profiles exceeding 64K bytes in size.  See iccprofile.c
+ * for details.
+ */
+
+#include <stdio.h>		/* needed to define "FILE", "NULL" */
+#include "jpeglib.h"
+
+
+/*
+ * This routine writes the given ICC profile data into a JPEG file.
+ * It *must* be called AFTER calling jpeg_start_compress() and BEFORE
+ * the first call to jpeg_write_scanlines().
+ * (This ordering ensures that the APP2 marker(s) will appear after the
+ * SOI and JFIF or Adobe markers, but before all else.)
+ */
+
+extern void write_icc_profile JPP((j_compress_ptr cinfo,
+				   const JOCTET *icc_data_ptr,
+				   unsigned int icc_data_len));
+
+
+/*
+ * Reading a JPEG file that may contain an ICC profile requires two steps:
+ *
+ * 1. After jpeg_create_decompress() but before jpeg_read_header(),
+ *    call setup_read_icc_profile().  This routine tells the IJG library
+ *    to save in memory any APP2 markers it may find in the file.
+ *
+ * 2. After jpeg_read_header(), call read_icc_profile() to find out
+ *    whether there was a profile and obtain it if so.
+ */
+
+
+/*
+ * Prepare for reading an ICC profile
+ */
+
+extern void setup_read_icc_profile JPP((j_decompress_ptr cinfo));
+
+
+/*
+ * See if there was an ICC profile in the JPEG file being read;
+ * if so, reassemble and return the profile data.
+ *
+ * TRUE is returned if an ICC profile was found, FALSE if not.
+ * If TRUE is returned, *icc_data_ptr is set to point to the
+ * returned data, and *icc_data_len is set to its length.
+ *
+ * IMPORTANT: the data at **icc_data_ptr has been allocated with malloc()
+ * and must be freed by the caller with free() when the caller no longer
+ * needs it.  (Alternatively, we could write this routine to use the
+ * IJG library's memory allocator, so that the data would be freed implicitly
+ * at jpeg_finish_decompress() time.  But it seems likely that many apps
+ * will prefer to have the data stick around after decompression finishes.)
+ */
+
+extern boolean read_icc_profile JPP((j_decompress_ptr cinfo,
+				     JOCTET **icc_data_ptr,
+				     unsigned int *icc_data_len));
diff --git a/third_party/libavif/src/third_party/libyuv/AUTHORS b/third_party/libavif/src/third_party/libyuv/AUTHORS
new file mode 100644
index 0000000000..28c08956a8
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/AUTHORS
@@ -0,0 +1,6 @@
+# Names should be added to this file like so:
+# Name or Organization <email address>
+
+Google Inc.
+
+Ivan Pavlotskiy <ivan.pavlotskiy@lgepartner.com>
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv.h b/third_party/libavif/src/third_party/libyuv/include/libyuv.h
new file mode 100644
index 0000000000..fc0e430d08
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv.h
@@ -0,0 +1,21 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_H_
+#define INCLUDE_LIBYUV_H_
+
+#include "libyuv/basic_types.h"
+#include "libyuv/planar_functions.h"
+#include "libyuv/row.h"
+#include "libyuv/scale.h"
+#include "libyuv/scale_row.h"
+#include "libyuv/version.h"
+
+#endif  // INCLUDE_LIBYUV_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/basic_types.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/basic_types.h
new file mode 100644
index 0000000000..1bea67f2f2
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/basic_types.h
@@ -0,0 +1,68 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_BASIC_TYPES_H_
+#define INCLUDE_LIBYUV_BASIC_TYPES_H_
+
+#include <stddef.h>  // For size_t and NULL
+
+#if !defined(INT_TYPES_DEFINED) && !defined(GG_LONGLONG)
+#define INT_TYPES_DEFINED
+
+#if defined(_MSC_VER) && (_MSC_VER < 1600)
+#include <sys/types.h>  // for uintptr_t on x86
+typedef unsigned __int64 uint64_t;
+typedef __int64 int64_t;
+typedef unsigned int uint32_t;
+typedef int int32_t;
+typedef unsigned short uint16_t;
+typedef short int16_t;
+typedef unsigned char uint8_t;
+typedef signed char int8_t;
+#else
+#include <stdint.h>  // for uintptr_t and C99 types
+#endif               // defined(_MSC_VER) && (_MSC_VER < 1600)
+// Types are deprecated.  Enable this macro for legacy types.
+#ifdef LIBYUV_LEGACY_TYPES
+typedef uint64_t uint64;
+typedef int64_t int64;
+typedef uint32_t uint32;
+typedef int32_t int32;
+typedef uint16_t uint16;
+typedef int16_t int16;
+typedef uint8_t uint8;
+typedef int8_t int8;
+#endif  // LIBYUV_LEGACY_TYPES
+#endif  // INT_TYPES_DEFINED
+
+#if !defined(LIBYUV_API)
+#if defined(_WIN32) || defined(__CYGWIN__)
+#if defined(LIBYUV_BUILDING_SHARED_LIBRARY)
+#define LIBYUV_API __declspec(dllexport)
+#elif defined(LIBYUV_USING_SHARED_LIBRARY)
+#define LIBYUV_API __declspec(dllimport)
+#else
+#define LIBYUV_API
+#endif  // LIBYUV_BUILDING_SHARED_LIBRARY
+#elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__APPLE__) && \
+    (defined(LIBYUV_BUILDING_SHARED_LIBRARY) ||                      \
+     defined(LIBYUV_USING_SHARED_LIBRARY))
+#define LIBYUV_API __attribute__((visibility("default")))
+#else
+#define LIBYUV_API
+#endif  // __GNUC__
+#endif  // LIBYUV_API
+
+// TODO(fbarchard): Remove bool macros.
+#define LIBYUV_BOOL int
+#define LIBYUV_FALSE 0
+#define LIBYUV_TRUE 1
+
+#endif  // INCLUDE_LIBYUV_BASIC_TYPES_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/planar_functions.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/planar_functions.h
new file mode 100644
index 0000000000..3191a77dbd
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/planar_functions.h
@@ -0,0 +1,30 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_PLANAR_FUNCTIONS_H_
+#define INCLUDE_LIBYUV_PLANAR_FUNCTIONS_H_
+
+#include "libyuv/basic_types.h"
+
+void CopyPlane(const uint8_t* src_y,
+               int src_stride_y,
+               uint8_t* dst_y,
+               int dst_stride_y,
+               int width,
+               int height);
+
+void CopyPlane_16(const uint16_t* src_y,
+                  int src_stride_y,
+                  uint16_t* dst_y,
+                  int dst_stride_y,
+                  int width,
+                  int height);
+
+#endif  // INCLUDE_LIBYUV_PLANAR_FUNCTIONS_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/row.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/row.h
new file mode 100644
index 0000000000..b521cde3fd
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/row.h
@@ -0,0 +1,41 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_ROW_H_
+#define INCLUDE_LIBYUV_ROW_H_
+
+#include <stddef.h>  // For NULL
+#include <stdlib.h>  // For malloc
+
+#include "libyuv/basic_types.h"
+
+#define align_buffer_64(var, size)                                         \
+  void* var##_mem = malloc((size) + 63);                      /* NOLINT */ \
+  uint8_t* var = (uint8_t*)(((intptr_t)var##_mem + 63) & ~63) /* NOLINT */
+
+#define free_aligned_buffer_64(var) \
+  free(var##_mem);                  \
+  var = NULL
+
+void CopyRow_C(const uint8_t* src, uint8_t* dst, int count);
+
+void InterpolateRow_C(uint8_t* dst_ptr,
+                      const uint8_t* src_ptr,
+                      ptrdiff_t src_stride,
+                      int width,
+                      int source_y_fraction);
+
+void InterpolateRow_16_C(uint16_t* dst_ptr,
+                         const uint16_t* src_ptr,
+                         ptrdiff_t src_stride,
+                         int width,
+                         int source_y_fraction);
+
+#endif  // INCLUDE_LIBYUV_ROW_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/scale.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/scale.h
new file mode 100644
index 0000000000..cc6284880a
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/scale.h
@@ -0,0 +1,54 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_SCALE_H_
+#define INCLUDE_LIBYUV_SCALE_H_
+
+#include "libyuv/basic_types.h"
+
+// Supported filtering.
+typedef enum FilterMode {
+  kFilterNone = 0,      // Point sample; Fastest.
+  kFilterLinear = 1,    // Filter horizontally only.
+  kFilterBilinear = 2,  // Faster than box, but lower quality scaling down.
+  kFilterBox = 3        // Highest quality.
+} FilterModeEnum;
+
+int ScalePlane(const uint8_t* src,
+               int src_stride,
+               int src_width,
+               int src_height,
+               uint8_t* dst,
+               int dst_stride,
+               int dst_width,
+               int dst_height,
+               enum FilterMode filtering);
+
+int ScalePlane_16(const uint16_t* src,
+                  int src_stride,
+                  int src_width,
+                  int src_height,
+                  uint16_t* dst,
+                  int dst_stride,
+                  int dst_width,
+                  int dst_height,
+                  enum FilterMode filtering);
+
+int ScalePlane_12(const uint16_t* src,
+                  int src_stride,
+                  int src_width,
+                  int src_height,
+                  uint16_t* dst,
+                  int dst_stride,
+                  int dst_width,
+                  int dst_height,
+                  enum FilterMode filtering);
+
+#endif  // INCLUDE_LIBYUV_SCALE_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/scale_row.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/scale_row.h
new file mode 100644
index 0000000000..6fb93ffab5
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/scale_row.h
@@ -0,0 +1,147 @@
+/*
+ *  Copyright 2013 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_SCALE_ROW_H_
+#define INCLUDE_LIBYUV_SCALE_ROW_H_
+
+#include "libyuv/basic_types.h"
+#include "libyuv/scale.h"
+
+// Scale ARGB vertically with bilinear interpolation.
+void ScalePlaneVertical(int src_height,
+                        int dst_width,
+                        int dst_height,
+                        int src_stride,
+                        int dst_stride,
+                        const uint8_t* src_argb,
+                        uint8_t* dst_argb,
+                        int x,
+                        int y,
+                        int dy,
+                        int bpp,
+                        enum FilterMode filtering);
+
+void ScalePlaneVertical_16(int src_height,
+                           int dst_width,
+                           int dst_height,
+                           int src_stride,
+                           int dst_stride,
+                           const uint16_t* src_argb,
+                           uint16_t* dst_argb,
+                           int x,
+                           int y,
+                           int dy,
+                           int wpp,
+                           enum FilterMode filtering);
+
+// Simplify the filtering based on scale factors.
+enum FilterMode ScaleFilterReduce(int src_width,
+                                  int src_height,
+                                  int dst_width,
+                                  int dst_height,
+                                  enum FilterMode filtering);
+
+// Divide num by div and return as 16.16 fixed point result.
+int FixedDiv_C(int num, int div);
+// Divide num - 1 by div - 1 and return as 16.16 fixed point result.
+int FixedDiv1_C(int num, int div);
+#define FixedDiv FixedDiv_C
+#define FixedDiv1 FixedDiv1_C
+
+// Compute slope values for stepping.
+void ScaleSlope(int src_width,
+                int src_height,
+                int dst_width,
+                int dst_height,
+                enum FilterMode filtering,
+                int* x,
+                int* y,
+                int* dx,
+                int* dy);
+
+void ScaleRowUp2_Linear_C(const uint8_t* src_ptr,
+                          uint8_t* dst_ptr,
+                          int dst_width);
+void ScaleRowUp2_Bilinear_C(const uint8_t* src_ptr,
+                            ptrdiff_t src_stride,
+                            uint8_t* dst_ptr,
+                            ptrdiff_t dst_stride,
+                            int dst_width);
+void ScaleRowUp2_Linear_16_C(const uint16_t* src_ptr,
+                             uint16_t* dst_ptr,
+                             int dst_width);
+void ScaleRowUp2_Bilinear_16_C(const uint16_t* src_ptr,
+                               ptrdiff_t src_stride,
+                               uint16_t* dst_ptr,
+                               ptrdiff_t dst_stride,
+                               int dst_width);
+void ScaleRowUp2_Linear_Any_C(const uint8_t* src_ptr,
+                              uint8_t* dst_ptr,
+                              int dst_width);
+void ScaleRowUp2_Bilinear_Any_C(const uint8_t* src_ptr,
+                                ptrdiff_t src_stride,
+                                uint8_t* dst_ptr,
+                                ptrdiff_t dst_stride,
+                                int dst_width);
+void ScaleRowUp2_Linear_16_Any_C(const uint16_t* src_ptr,
+                                 uint16_t* dst_ptr,
+                                 int dst_width);
+void ScaleRowUp2_Bilinear_16_Any_C(const uint16_t* src_ptr,
+                                   ptrdiff_t src_stride,
+                                   uint16_t* dst_ptr,
+                                   ptrdiff_t dst_stride,
+                                   int dst_width);
+
+void ScaleCols_C(uint8_t* dst_ptr,
+                 const uint8_t* src_ptr,
+                 int dst_width,
+                 int x,
+                 int dx);
+void ScaleCols_16_C(uint16_t* dst_ptr,
+                    const uint16_t* src_ptr,
+                    int dst_width,
+                    int x,
+                    int dx);
+void ScaleColsUp2_C(uint8_t* dst_ptr,
+                    const uint8_t* src_ptr,
+                    int dst_width,
+                    int,
+                    int);
+void ScaleColsUp2_16_C(uint16_t* dst_ptr,
+                       const uint16_t* src_ptr,
+                       int dst_width,
+                       int,
+                       int);
+void ScaleFilterCols_C(uint8_t* dst_ptr,
+                       const uint8_t* src_ptr,
+                       int dst_width,
+                       int x,
+                       int dx);
+void ScaleFilterCols_16_C(uint16_t* dst_ptr,
+                          const uint16_t* src_ptr,
+                          int dst_width,
+                          int x,
+                          int dx);
+void ScaleFilterCols64_C(uint8_t* dst_ptr,
+                         const uint8_t* src_ptr,
+                         int dst_width,
+                         int x32,
+                         int dx);
+void ScaleFilterCols64_16_C(uint16_t* dst_ptr,
+                            const uint16_t* src_ptr,
+                            int dst_width,
+                            int x32,
+                            int dx);
+void ScaleAddRow_C(const uint8_t* src_ptr, uint16_t* dst_ptr, int src_width);
+void ScaleAddRow_16_C(const uint16_t* src_ptr,
+                      uint32_t* dst_ptr,
+                      int src_width);
+
+#endif  // INCLUDE_LIBYUV_SCALE_ROW_H_
diff --git a/third_party/libavif/src/third_party/libyuv/include/libyuv/version.h b/third_party/libavif/src/third_party/libyuv/include/libyuv/version.h
new file mode 100644
index 0000000000..bcea000dc2
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/include/libyuv/version.h
@@ -0,0 +1,16 @@
+/*
+ *  Copyright 2012 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef INCLUDE_LIBYUV_VERSION_H_
+#define INCLUDE_LIBYUV_VERSION_H_
+
+#define LIBYUV_VERSION 1880
+
+#endif  // INCLUDE_LIBYUV_VERSION_H_
diff --git a/third_party/libavif/src/third_party/libyuv/source/planar_functions.c b/third_party/libavif/src/third_party/libyuv/source/planar_functions.c
new file mode 100644
index 0000000000..366752d026
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/source/planar_functions.c
@@ -0,0 +1,64 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "libyuv/planar_functions.h"
+
+#include <assert.h>
+#include <string.h>  // for memset()
+
+#include "libyuv/row.h"
+#include "libyuv/scale_row.h"  // for ScaleRowDown2
+
+// Copy a plane of data
+void CopyPlane(const uint8_t* src_y,
+               int src_stride_y,
+               uint8_t* dst_y,
+               int dst_stride_y,
+               int width,
+               int height) {
+  int y;
+  void (*CopyRow)(const uint8_t* src, uint8_t* dst, int width) = CopyRow_C;
+  if (width <= 0 || height == 0) {
+    return;
+  }
+  // Negative height means invert the image.
+  if (height < 0) {
+    height = -height;
+    dst_y = dst_y + (height - 1) * dst_stride_y;
+    dst_stride_y = -dst_stride_y;
+  }
+  // Coalesce rows.
+  if (src_stride_y == width && dst_stride_y == width) {
+    width *= height;
+    height = 1;
+    src_stride_y = dst_stride_y = 0;
+  }
+  // Nothing to do.
+  if (src_y == dst_y && src_stride_y == dst_stride_y) {
+    return;
+  }
+
+  // Copy plane
+  for (y = 0; y < height; ++y) {
+    CopyRow(src_y, dst_y, width);
+    src_y += src_stride_y;
+    dst_y += dst_stride_y;
+  }
+}
+
+void CopyPlane_16(const uint16_t* src_y,
+                  int src_stride_y,
+                  uint16_t* dst_y,
+                  int dst_stride_y,
+                  int width,
+                  int height) {
+  CopyPlane((const uint8_t*)src_y, src_stride_y * 2, (uint8_t*)dst_y,
+            dst_stride_y * 2, width * 2, height);
+}
diff --git a/third_party/libavif/src/third_party/libyuv/source/row_common.c b/third_party/libavif/src/third_party/libyuv/source/row_common.c
new file mode 100644
index 0000000000..a8c4f66716
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/source/row_common.c
@@ -0,0 +1,105 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "libyuv/row.h"
+
+#include <assert.h>
+#include <string.h>  // For memcpy and memset.
+
+#include "libyuv/basic_types.h"
+
+#define STATIC_CAST(type, expr) (type)(expr)
+
+void CopyRow_C(const uint8_t* src, uint8_t* dst, int count) {
+  memcpy(dst, src, count);
+}
+
+// Blend 2 rows into 1.
+static void HalfRow_C(const uint8_t* src_uv,
+                      ptrdiff_t src_uv_stride,
+                      uint8_t* dst_uv,
+                      int width) {
+  int x;
+  for (x = 0; x < width; ++x) {
+    dst_uv[x] = (src_uv[x] + src_uv[src_uv_stride + x] + 1) >> 1;
+  }
+}
+
+static void HalfRow_16_C(const uint16_t* src_uv,
+                         ptrdiff_t src_uv_stride,
+                         uint16_t* dst_uv,
+                         int width) {
+  int x;
+  for (x = 0; x < width; ++x) {
+    dst_uv[x] = (src_uv[x] + src_uv[src_uv_stride + x] + 1) >> 1;
+  }
+}
+
+// C version 2x2 -> 2x1.
+void InterpolateRow_C(uint8_t* dst_ptr,
+                      const uint8_t* src_ptr,
+                      ptrdiff_t src_stride,
+                      int width,
+                      int source_y_fraction) {
+  int y1_fraction = source_y_fraction;
+  int y0_fraction = 256 - y1_fraction;
+  const uint8_t* src_ptr1 = src_ptr + src_stride;
+  int x;
+  assert(source_y_fraction >= 0);
+  assert(source_y_fraction < 256);
+
+  if (y1_fraction == 0) {
+    memcpy(dst_ptr, src_ptr, width);
+    return;
+  }
+  if (y1_fraction == 128) {
+    HalfRow_C(src_ptr, src_stride, dst_ptr, width);
+    return;
+  }
+  for (x = 0; x < width; ++x) {
+    dst_ptr[0] = STATIC_CAST(
+        uint8_t,
+        (src_ptr[0] * y0_fraction + src_ptr1[0] * y1_fraction + 128) >> 8);
+    ++src_ptr;
+    ++src_ptr1;
+    ++dst_ptr;
+  }
+}
+
+// C version 2x2 -> 2x1.
+void InterpolateRow_16_C(uint16_t* dst_ptr,
+                         const uint16_t* src_ptr,
+                         ptrdiff_t src_stride,
+                         int width,
+                         int source_y_fraction) {
+  int y1_fraction = source_y_fraction;
+  int y0_fraction = 256 - y1_fraction;
+  const uint16_t* src_ptr1 = src_ptr + src_stride;
+  int x;
+  assert(source_y_fraction >= 0);
+  assert(source_y_fraction < 256);
+
+  if (y1_fraction == 0) {
+    memcpy(dst_ptr, src_ptr, width * 2);
+    return;
+  }
+  if (y1_fraction == 128) {
+    HalfRow_16_C(src_ptr, src_stride, dst_ptr, width);
+    return;
+  }
+  for (x = 0; x < width; ++x) {
+    dst_ptr[0] = STATIC_CAST(
+        uint16_t,
+        (src_ptr[0] * y0_fraction + src_ptr1[0] * y1_fraction + 128) >> 8);
+    ++src_ptr;
+    ++src_ptr1;
+    ++dst_ptr;
+  }
+}
diff --git a/third_party/libavif/src/third_party/libyuv/source/scale.c b/third_party/libavif/src/third_party/libyuv/source/scale.c
new file mode 100644
index 0000000000..a05c6ffd2e
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/source/scale.c
@@ -0,0 +1,1007 @@
+/*
+ *  Copyright 2011 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "libyuv/scale.h"
+
+#include <assert.h>
+#include <string.h>
+
+#include "libyuv/planar_functions.h"  // For CopyPlane
+#include "libyuv/row.h"
+#include "libyuv/scale_row.h"
+
+static __inline int Abs(int v) {
+  return v >= 0 ? v : -v;
+}
+
+#define CENTERSTART(dx, s) (dx < 0) ? -((-dx >> 1) + s) : ((dx >> 1) + s)
+
+#define MIN1(x) ((x) < 1 ? 1 : (x))
+
+static __inline uint32_t SumPixels(int iboxwidth, const uint16_t* src_ptr) {
+  uint32_t sum = 0u;
+  int x;
+  assert(iboxwidth > 0);
+  for (x = 0; x < iboxwidth; ++x) {
+    sum += src_ptr[x];
+  }
+  return sum;
+}
+
+static __inline uint32_t SumPixels_16(int iboxwidth, const uint32_t* src_ptr) {
+  uint32_t sum = 0u;
+  int x;
+  assert(iboxwidth > 0);
+  for (x = 0; x < iboxwidth; ++x) {
+    sum += src_ptr[x];
+  }
+  return sum;
+}
+
+static void ScaleAddCols2_C(int dst_width,
+                            int boxheight,
+                            int x,
+                            int dx,
+                            const uint16_t* src_ptr,
+                            uint8_t* dst_ptr) {
+  int i;
+  int scaletbl[2];
+  int minboxwidth = dx >> 16;
+  int boxwidth;
+  scaletbl[0] = 65536 / (MIN1(minboxwidth) * boxheight);
+  scaletbl[1] = 65536 / (MIN1(minboxwidth + 1) * boxheight);
+  for (i = 0; i < dst_width; ++i) {
+    int ix = x >> 16;
+    x += dx;
+    boxwidth = MIN1((x >> 16) - ix);
+    int scaletbl_index = boxwidth - minboxwidth;
+    assert((scaletbl_index == 0) || (scaletbl_index == 1));
+    *dst_ptr++ = (uint8_t)(SumPixels(boxwidth, src_ptr + ix) *
+                               scaletbl[scaletbl_index] >>
+                           16);
+  }
+}
+
+static void ScaleAddCols2_16_C(int dst_width,
+                               int boxheight,
+                               int x,
+                               int dx,
+                               const uint32_t* src_ptr,
+                               uint16_t* dst_ptr) {
+  int i;
+  int scaletbl[2];
+  int minboxwidth = dx >> 16;
+  int boxwidth;
+  scaletbl[0] = 65536 / (MIN1(minboxwidth) * boxheight);
+  scaletbl[1] = 65536 / (MIN1(minboxwidth + 1) * boxheight);
+  for (i = 0; i < dst_width; ++i) {
+    int ix = x >> 16;
+    x += dx;
+    boxwidth = MIN1((x >> 16) - ix);
+    int scaletbl_index = boxwidth - minboxwidth;
+    assert((scaletbl_index == 0) || (scaletbl_index == 1));
+    *dst_ptr++ =
+        SumPixels_16(boxwidth, src_ptr + ix) * scaletbl[scaletbl_index] >> 16;
+  }
+}
+
+static void ScaleAddCols0_C(int dst_width,
+                            int boxheight,
+                            int x,
+                            int dx,
+                            const uint16_t* src_ptr,
+                            uint8_t* dst_ptr) {
+  int scaleval = 65536 / boxheight;
+  int i;
+  (void)dx;
+  src_ptr += (x >> 16);
+  for (i = 0; i < dst_width; ++i) {
+    *dst_ptr++ = (uint8_t)(src_ptr[i] * scaleval >> 16);
+  }
+}
+
+static void ScaleAddCols1_C(int dst_width,
+                            int boxheight,
+                            int x,
+                            int dx,
+                            const uint16_t* src_ptr,
+                            uint8_t* dst_ptr) {
+  int boxwidth = MIN1(dx >> 16);
+  int scaleval = 65536 / (boxwidth * boxheight);
+  int i;
+  x >>= 16;
+  for (i = 0; i < dst_width; ++i) {
+    *dst_ptr++ = (uint8_t)(SumPixels(boxwidth, src_ptr + x) * scaleval >> 16);
+    x += boxwidth;
+  }
+}
+
+static void ScaleAddCols1_16_C(int dst_width,
+                               int boxheight,
+                               int x,
+                               int dx,
+                               const uint32_t* src_ptr,
+                               uint16_t* dst_ptr) {
+  int boxwidth = MIN1(dx >> 16);
+  int scaleval = 65536 / (boxwidth * boxheight);
+  int i;
+  for (i = 0; i < dst_width; ++i) {
+    *dst_ptr++ = SumPixels_16(boxwidth, src_ptr + x) * scaleval >> 16;
+    x += boxwidth;
+  }
+}
+
+// Scale plane down to any dimensions, with interpolation.
+// (boxfilter).
+//
+// Same method as SimpleScale, which is fixed point, outputting
+// one pixel of destination using fixed point (16.16) to step
+// through source, sampling a box of pixel with simple
+// averaging.
+static int ScalePlaneBox(int src_width,
+                         int src_height,
+                         int dst_width,
+                         int dst_height,
+                         int src_stride,
+                         int dst_stride,
+                         const uint8_t* src_ptr,
+                         uint8_t* dst_ptr) {
+  int j, k;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  const int max_y = (src_height << 16);
+  ScaleSlope(src_width, src_height, dst_width, dst_height, kFilterBox, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+  {
+    // Allocate a row buffer of uint16_t.
+    align_buffer_64(row16, src_width * 2);
+    if (!row16)
+      return 1;
+    void (*ScaleAddCols)(int dst_width, int boxheight, int x, int dx,
+                         const uint16_t* src_ptr, uint8_t* dst_ptr) =
+        (dx & 0xffff) ? ScaleAddCols2_C
+                      : ((dx != 0x10000) ? ScaleAddCols1_C : ScaleAddCols0_C);
+    void (*ScaleAddRow)(const uint8_t* src_ptr, uint16_t* dst_ptr,
+                        int src_width) = ScaleAddRow_C;
+
+    for (j = 0; j < dst_height; ++j) {
+      int boxheight;
+      int iy = y >> 16;
+      const uint8_t* src = src_ptr + iy * (int64_t)src_stride;
+      y += dy;
+      if (y > max_y) {
+        y = max_y;
+      }
+      boxheight = MIN1((y >> 16) - iy);
+      memset(row16, 0, src_width * 2);
+      for (k = 0; k < boxheight; ++k) {
+        ScaleAddRow(src, (uint16_t*)(row16), src_width);
+        src += src_stride;
+      }
+      ScaleAddCols(dst_width, boxheight, x, dx, (uint16_t*)(row16), dst_ptr);
+      dst_ptr += dst_stride;
+    }
+    free_aligned_buffer_64(row16);
+  }
+  return 0;
+}
+
+static int ScalePlaneBox_16(int src_width,
+                            int src_height,
+                            int dst_width,
+                            int dst_height,
+                            int src_stride,
+                            int dst_stride,
+                            const uint16_t* src_ptr,
+                            uint16_t* dst_ptr) {
+  int j, k;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  const int max_y = (src_height << 16);
+  ScaleSlope(src_width, src_height, dst_width, dst_height, kFilterBox, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+  {
+    // Allocate a row buffer of uint32_t.
+    align_buffer_64(row32, src_width * 4);
+    if (!row32)
+      return 1;
+    void (*ScaleAddCols)(int dst_width, int boxheight, int x, int dx,
+                         const uint32_t* src_ptr, uint16_t* dst_ptr) =
+        (dx & 0xffff) ? ScaleAddCols2_16_C : ScaleAddCols1_16_C;
+    void (*ScaleAddRow)(const uint16_t* src_ptr, uint32_t* dst_ptr,
+                        int src_width) = ScaleAddRow_16_C;
+
+#if defined(HAS_SCALEADDROW_16_SSE2)
+    if (TestCpuFlag(kCpuHasSSE2) && IS_ALIGNED(src_width, 16)) {
+      ScaleAddRow = ScaleAddRow_16_SSE2;
+    }
+#endif
+
+    for (j = 0; j < dst_height; ++j) {
+      int boxheight;
+      int iy = y >> 16;
+      const uint16_t* src = src_ptr + iy * (int64_t)src_stride;
+      y += dy;
+      if (y > max_y) {
+        y = max_y;
+      }
+      boxheight = MIN1((y >> 16) - iy);
+      memset(row32, 0, src_width * 4);
+      for (k = 0; k < boxheight; ++k) {
+        ScaleAddRow(src, (uint32_t*)(row32), src_width);
+        src += src_stride;
+      }
+      ScaleAddCols(dst_width, boxheight, x, dx, (uint32_t*)(row32), dst_ptr);
+      dst_ptr += dst_stride;
+    }
+    free_aligned_buffer_64(row32);
+  }
+  return 0;
+}
+
+// Scale plane down with bilinear interpolation.
+static int ScalePlaneBilinearDown(int src_width,
+                                  int src_height,
+                                  int dst_width,
+                                  int dst_height,
+                                  int src_stride,
+                                  int dst_stride,
+                                  const uint8_t* src_ptr,
+                                  uint8_t* dst_ptr,
+                                  enum FilterMode filtering) {
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  // TODO(fbarchard): Consider not allocating row buffer for kFilterLinear.
+  // Allocate a row buffer.
+  align_buffer_64(row, src_width);
+  if (!row)
+    return 1;
+
+  const int max_y = (src_height - 1) << 16;
+  int j;
+  void (*ScaleFilterCols)(uint8_t* dst_ptr, const uint8_t* src_ptr,
+                          int dst_width, int x, int dx) =
+      (src_width >= 32768) ? ScaleFilterCols64_C : ScaleFilterCols_C;
+  void (*InterpolateRow)(uint8_t* dst_ptr, const uint8_t* src_ptr,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_C;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, filtering, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (y > max_y) {
+    y = max_y;
+  }
+
+  for (j = 0; j < dst_height; ++j) {
+    int yi = y >> 16;
+    const uint8_t* src = src_ptr + yi * (int64_t)src_stride;
+    if (filtering == kFilterLinear) {
+      ScaleFilterCols(dst_ptr, src, dst_width, x, dx);
+    } else {
+      int yf = (y >> 8) & 255;
+      InterpolateRow(row, src, src_stride, src_width, yf);
+      ScaleFilterCols(dst_ptr, row, dst_width, x, dx);
+    }
+    dst_ptr += dst_stride;
+    y += dy;
+    if (y > max_y) {
+      y = max_y;
+    }
+  }
+  free_aligned_buffer_64(row);
+  return 0;
+}
+
+static int ScalePlaneBilinearDown_16(int src_width,
+                                     int src_height,
+                                     int dst_width,
+                                     int dst_height,
+                                     int src_stride,
+                                     int dst_stride,
+                                     const uint16_t* src_ptr,
+                                     uint16_t* dst_ptr,
+                                     enum FilterMode filtering) {
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  // TODO(fbarchard): Consider not allocating row buffer for kFilterLinear.
+  // Allocate a row buffer.
+  align_buffer_64(row, src_width * 2);
+  if (!row)
+    return 1;
+
+  const int max_y = (src_height - 1) << 16;
+  int j;
+  void (*ScaleFilterCols)(uint16_t* dst_ptr, const uint16_t* src_ptr,
+                          int dst_width, int x, int dx) =
+      (src_width >= 32768) ? ScaleFilterCols64_16_C : ScaleFilterCols_16_C;
+  void (*InterpolateRow)(uint16_t* dst_ptr, const uint16_t* src_ptr,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_16_C;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, filtering, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (y > max_y) {
+    y = max_y;
+  }
+
+  for (j = 0; j < dst_height; ++j) {
+    int yi = y >> 16;
+    const uint16_t* src = src_ptr + yi * (int64_t)src_stride;
+    if (filtering == kFilterLinear) {
+      ScaleFilterCols(dst_ptr, src, dst_width, x, dx);
+    } else {
+      int yf = (y >> 8) & 255;
+      InterpolateRow((uint16_t*)row, src, src_stride, src_width, yf);
+      ScaleFilterCols(dst_ptr, (uint16_t*)row, dst_width, x, dx);
+    }
+    dst_ptr += dst_stride;
+    y += dy;
+    if (y > max_y) {
+      y = max_y;
+    }
+  }
+  free_aligned_buffer_64(row);
+  return 0;
+}
+
+// Scale up down with bilinear interpolation.
+static int ScalePlaneBilinearUp(int src_width,
+                                int src_height,
+                                int dst_width,
+                                int dst_height,
+                                int src_stride,
+                                int dst_stride,
+                                const uint8_t* src_ptr,
+                                uint8_t* dst_ptr,
+                                enum FilterMode filtering) {
+  int j;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  const int max_y = (src_height - 1) << 16;
+  void (*InterpolateRow)(uint8_t* dst_ptr, const uint8_t* src_ptr,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_C;
+  void (*ScaleFilterCols)(uint8_t* dst_ptr, const uint8_t* src_ptr,
+                          int dst_width, int x, int dx) =
+      filtering ? ScaleFilterCols_C : ScaleCols_C;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, filtering, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (filtering && src_width >= 32768) {
+    ScaleFilterCols = ScaleFilterCols64_C;
+  }
+  if (!filtering && src_width * 2 == dst_width && x < 0x8000) {
+    ScaleFilterCols = ScaleColsUp2_C;
+  }
+
+  if (y > max_y) {
+    y = max_y;
+  }
+  {
+    int yi = y >> 16;
+    const uint8_t* src = src_ptr + yi * (int64_t)src_stride;
+
+    // Allocate 2 row buffers.
+    const int row_size = (dst_width + 31) & ~31;
+    align_buffer_64(row, row_size * 2);
+    if (!row)
+      return 1;
+
+    uint8_t* rowptr = row;
+    int rowstride = row_size;
+    int lasty = yi;
+
+    ScaleFilterCols(rowptr, src, dst_width, x, dx);
+    if (src_height > 1) {
+      src += src_stride;
+    }
+    ScaleFilterCols(rowptr + rowstride, src, dst_width, x, dx);
+    if (src_height > 2) {
+      src += src_stride;
+    }
+
+    for (j = 0; j < dst_height; ++j) {
+      yi = y >> 16;
+      if (yi != lasty) {
+        if (y > max_y) {
+          y = max_y;
+          yi = y >> 16;
+          src = src_ptr + yi * (int64_t)src_stride;
+        }
+        if (yi != lasty) {
+          ScaleFilterCols(rowptr, src, dst_width, x, dx);
+          rowptr += rowstride;
+          rowstride = -rowstride;
+          lasty = yi;
+          if ((y + 65536) < max_y) {
+            src += src_stride;
+          }
+        }
+      }
+      if (filtering == kFilterLinear) {
+        InterpolateRow(dst_ptr, rowptr, 0, dst_width, 0);
+      } else {
+        int yf = (y >> 8) & 255;
+        InterpolateRow(dst_ptr, rowptr, rowstride, dst_width, yf);
+      }
+      dst_ptr += dst_stride;
+      y += dy;
+    }
+    free_aligned_buffer_64(row);
+  }
+  return 0;
+}
+
+// Scale plane, horizontally up by 2 times.
+// Uses linear filter horizontally, nearest vertically.
+// This is an optimized version for scaling up a plane to 2 times of
+// its original width, using linear interpolation.
+// This is used to scale U and V planes of I422 to I444.
+static void ScalePlaneUp2_Linear(int src_width,
+                                 int src_height,
+                                 int dst_width,
+                                 int dst_height,
+                                 int src_stride,
+                                 int dst_stride,
+                                 const uint8_t* src_ptr,
+                                 uint8_t* dst_ptr) {
+  void (*ScaleRowUp)(const uint8_t* src_ptr, uint8_t* dst_ptr, int dst_width) =
+      ScaleRowUp2_Linear_Any_C;
+  int i;
+  int y;
+  int dy;
+
+  (void)src_width;
+  // This function can only scale up by 2 times horizontally.
+  assert(src_width == ((dst_width + 1) / 2));
+
+  if (dst_height == 1) {
+    ScaleRowUp(src_ptr + ((src_height - 1) / 2) * (int64_t)src_stride, dst_ptr,
+               dst_width);
+  } else {
+    dy = FixedDiv(src_height - 1, dst_height - 1);
+    y = (1 << 15) - 1;
+    for (i = 0; i < dst_height; ++i) {
+      ScaleRowUp(src_ptr + (y >> 16) * (int64_t)src_stride, dst_ptr, dst_width);
+      dst_ptr += dst_stride;
+      y += dy;
+    }
+  }
+}
+
+// Scale plane, up by 2 times.
+// This is an optimized version for scaling up a plane to 2 times of
+// its original size, using bilinear interpolation.
+// This is used to scale U and V planes of I420 to I444.
+static void ScalePlaneUp2_Bilinear(int src_width,
+                                   int src_height,
+                                   int dst_width,
+                                   int dst_height,
+                                   int src_stride,
+                                   int dst_stride,
+                                   const uint8_t* src_ptr,
+                                   uint8_t* dst_ptr) {
+  void (*Scale2RowUp)(const uint8_t* src_ptr, ptrdiff_t src_stride,
+                      uint8_t* dst_ptr, ptrdiff_t dst_stride, int dst_width) =
+      ScaleRowUp2_Bilinear_Any_C;
+  int x;
+
+  (void)src_width;
+  // This function can only scale up by 2 times.
+  assert(src_width == ((dst_width + 1) / 2));
+  assert(src_height == ((dst_height + 1) / 2));
+
+  Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  dst_ptr += dst_stride;
+  for (x = 0; x < src_height - 1; ++x) {
+    Scale2RowUp(src_ptr, src_stride, dst_ptr, dst_stride, dst_width);
+    src_ptr += src_stride;
+    // TODO(fbarchard): Test performance of writing one row of destination at a
+    // time.
+    dst_ptr += 2 * dst_stride;
+  }
+  if (!(dst_height & 1)) {
+    Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  }
+}
+
+// Scale at most 14 bit plane, horizontally up by 2 times.
+// This is an optimized version for scaling up a plane to 2 times of
+// its original width, using linear interpolation.
+// stride is in count of uint16_t.
+// This is used to scale U and V planes of I210 to I410 and I212 to I412.
+static void ScalePlaneUp2_12_Linear(int src_width,
+                                    int src_height,
+                                    int dst_width,
+                                    int dst_height,
+                                    int src_stride,
+                                    int dst_stride,
+                                    const uint16_t* src_ptr,
+                                    uint16_t* dst_ptr) {
+  void (*ScaleRowUp)(const uint16_t* src_ptr, uint16_t* dst_ptr,
+                     int dst_width) = ScaleRowUp2_Linear_16_Any_C;
+  int i;
+  int y;
+  int dy;
+
+  (void)src_width;
+  // This function can only scale up by 2 times horizontally.
+  assert(src_width == ((dst_width + 1) / 2));
+
+  if (dst_height == 1) {
+    ScaleRowUp(src_ptr + ((src_height - 1) / 2) * (int64_t)src_stride, dst_ptr,
+               dst_width);
+  } else {
+    dy = FixedDiv(src_height - 1, dst_height - 1);
+    y = (1 << 15) - 1;
+    for (i = 0; i < dst_height; ++i) {
+      ScaleRowUp(src_ptr + (y >> 16) * (int64_t)src_stride, dst_ptr, dst_width);
+      dst_ptr += dst_stride;
+      y += dy;
+    }
+  }
+}
+
+// Scale at most 12 bit plane, up by 2 times.
+// This is an optimized version for scaling up a plane to 2 times of
+// its original size, using bilinear interpolation.
+// stride is in count of uint16_t.
+// This is used to scale U and V planes of I010 to I410 and I012 to I412.
+static void ScalePlaneUp2_12_Bilinear(int src_width,
+                                      int src_height,
+                                      int dst_width,
+                                      int dst_height,
+                                      int src_stride,
+                                      int dst_stride,
+                                      const uint16_t* src_ptr,
+                                      uint16_t* dst_ptr) {
+  void (*Scale2RowUp)(const uint16_t* src_ptr, ptrdiff_t src_stride,
+                      uint16_t* dst_ptr, ptrdiff_t dst_stride, int dst_width) =
+      ScaleRowUp2_Bilinear_16_Any_C;
+  int x;
+
+  (void)src_width;
+  // This function can only scale up by 2 times.
+  assert(src_width == ((dst_width + 1) / 2));
+  assert(src_height == ((dst_height + 1) / 2));
+
+  Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  dst_ptr += dst_stride;
+  for (x = 0; x < src_height - 1; ++x) {
+    Scale2RowUp(src_ptr, src_stride, dst_ptr, dst_stride, dst_width);
+    src_ptr += src_stride;
+    dst_ptr += 2 * dst_stride;
+  }
+  if (!(dst_height & 1)) {
+    Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  }
+}
+
+static void ScalePlaneUp2_16_Linear(int src_width,
+                                    int src_height,
+                                    int dst_width,
+                                    int dst_height,
+                                    int src_stride,
+                                    int dst_stride,
+                                    const uint16_t* src_ptr,
+                                    uint16_t* dst_ptr) {
+  void (*ScaleRowUp)(const uint16_t* src_ptr, uint16_t* dst_ptr,
+                     int dst_width) = ScaleRowUp2_Linear_16_Any_C;
+  int i;
+  int y;
+  int dy;
+
+  (void)src_width;
+  // This function can only scale up by 2 times horizontally.
+  assert(src_width == ((dst_width + 1) / 2));
+
+  if (dst_height == 1) {
+    ScaleRowUp(src_ptr + ((src_height - 1) / 2) * (int64_t)src_stride, dst_ptr,
+               dst_width);
+  } else {
+    dy = FixedDiv(src_height - 1, dst_height - 1);
+    y = (1 << 15) - 1;
+    for (i = 0; i < dst_height; ++i) {
+      ScaleRowUp(src_ptr + (y >> 16) * (int64_t)src_stride, dst_ptr, dst_width);
+      dst_ptr += dst_stride;
+      y += dy;
+    }
+  }
+}
+
+static void ScalePlaneUp2_16_Bilinear(int src_width,
+                                      int src_height,
+                                      int dst_width,
+                                      int dst_height,
+                                      int src_stride,
+                                      int dst_stride,
+                                      const uint16_t* src_ptr,
+                                      uint16_t* dst_ptr) {
+  void (*Scale2RowUp)(const uint16_t* src_ptr, ptrdiff_t src_stride,
+                      uint16_t* dst_ptr, ptrdiff_t dst_stride, int dst_width) =
+      ScaleRowUp2_Bilinear_16_Any_C;
+  int x;
+
+  (void)src_width;
+  // This function can only scale up by 2 times.
+  assert(src_width == ((dst_width + 1) / 2));
+  assert(src_height == ((dst_height + 1) / 2));
+
+  Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  dst_ptr += dst_stride;
+  for (x = 0; x < src_height - 1; ++x) {
+    Scale2RowUp(src_ptr, src_stride, dst_ptr, dst_stride, dst_width);
+    src_ptr += src_stride;
+    dst_ptr += 2 * dst_stride;
+  }
+  if (!(dst_height & 1)) {
+    Scale2RowUp(src_ptr, 0, dst_ptr, 0, dst_width);
+  }
+}
+
+static int ScalePlaneBilinearUp_16(int src_width,
+                                   int src_height,
+                                   int dst_width,
+                                   int dst_height,
+                                   int src_stride,
+                                   int dst_stride,
+                                   const uint16_t* src_ptr,
+                                   uint16_t* dst_ptr,
+                                   enum FilterMode filtering) {
+  int j;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  const int max_y = (src_height - 1) << 16;
+  void (*InterpolateRow)(uint16_t* dst_ptr, const uint16_t* src_ptr,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_16_C;
+  void (*ScaleFilterCols)(uint16_t* dst_ptr, const uint16_t* src_ptr,
+                          int dst_width, int x, int dx) =
+      filtering ? ScaleFilterCols_16_C : ScaleCols_16_C;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, filtering, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (filtering && src_width >= 32768) {
+    ScaleFilterCols = ScaleFilterCols64_16_C;
+  }
+  if (!filtering && src_width * 2 == dst_width && x < 0x8000) {
+    ScaleFilterCols = ScaleColsUp2_16_C;
+  }
+  if (y > max_y) {
+    y = max_y;
+  }
+  {
+    int yi = y >> 16;
+    const uint16_t* src = src_ptr + yi * (int64_t)src_stride;
+
+    // Allocate 2 row buffers.
+    const int row_size = (dst_width + 31) & ~31;
+    align_buffer_64(row, row_size * 4);
+    int rowstride = row_size;
+    int lasty = yi;
+    uint16_t* rowptr = (uint16_t*)row;
+    if (!row)
+      return 1;
+
+    ScaleFilterCols(rowptr, src, dst_width, x, dx);
+    if (src_height > 1) {
+      src += src_stride;
+    }
+    ScaleFilterCols(rowptr + rowstride, src, dst_width, x, dx);
+    if (src_height > 2) {
+      src += src_stride;
+    }
+
+    for (j = 0; j < dst_height; ++j) {
+      yi = y >> 16;
+      if (yi != lasty) {
+        if (y > max_y) {
+          y = max_y;
+          yi = y >> 16;
+          src = src_ptr + yi * (int64_t)src_stride;
+        }
+        if (yi != lasty) {
+          ScaleFilterCols(rowptr, src, dst_width, x, dx);
+          rowptr += rowstride;
+          rowstride = -rowstride;
+          lasty = yi;
+          if ((y + 65536) < max_y) {
+            src += src_stride;
+          }
+        }
+      }
+      if (filtering == kFilterLinear) {
+        InterpolateRow(dst_ptr, rowptr, 0, dst_width, 0);
+      } else {
+        int yf = (y >> 8) & 255;
+        InterpolateRow(dst_ptr, rowptr, rowstride, dst_width, yf);
+      }
+      dst_ptr += dst_stride;
+      y += dy;
+    }
+    free_aligned_buffer_64(row);
+  }
+  return 0;
+}
+
+// Scale Plane to/from any dimensions, without interpolation.
+// Fixed point math is used for performance: The upper 16 bits
+// of x and dx is the integer part of the source position and
+// the lower 16 bits are the fixed decimal part.
+
+static void ScalePlaneSimple(int src_width,
+                             int src_height,
+                             int dst_width,
+                             int dst_height,
+                             int src_stride,
+                             int dst_stride,
+                             const uint8_t* src_ptr,
+                             uint8_t* dst_ptr) {
+  int i;
+  void (*ScaleCols)(uint8_t* dst_ptr, const uint8_t* src_ptr, int dst_width,
+                    int x, int dx) = ScaleCols_C;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, kFilterNone, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (src_width * 2 == dst_width && x < 0x8000) {
+    ScaleCols = ScaleColsUp2_C;
+  }
+
+  for (i = 0; i < dst_height; ++i) {
+    ScaleCols(dst_ptr, src_ptr + (y >> 16) * (int64_t)src_stride, dst_width, x,
+              dx);
+    dst_ptr += dst_stride;
+    y += dy;
+  }
+}
+
+static void ScalePlaneSimple_16(int src_width,
+                                int src_height,
+                                int dst_width,
+                                int dst_height,
+                                int src_stride,
+                                int dst_stride,
+                                const uint16_t* src_ptr,
+                                uint16_t* dst_ptr) {
+  int i;
+  void (*ScaleCols)(uint16_t* dst_ptr, const uint16_t* src_ptr, int dst_width,
+                    int x, int dx) = ScaleCols_16_C;
+  // Initial source x/y coordinate and step values as 16.16 fixed point.
+  int x = 0;
+  int y = 0;
+  int dx = 0;
+  int dy = 0;
+  ScaleSlope(src_width, src_height, dst_width, dst_height, kFilterNone, &x, &y,
+             &dx, &dy);
+  src_width = Abs(src_width);
+
+  if (src_width * 2 == dst_width && x < 0x8000) {
+    ScaleCols = ScaleColsUp2_16_C;
+  }
+
+  for (i = 0; i < dst_height; ++i) {
+    ScaleCols(dst_ptr, src_ptr + (y >> 16) * (int64_t)src_stride, dst_width, x,
+              dx);
+    dst_ptr += dst_stride;
+    y += dy;
+  }
+}
+
+// Scale a plane.
+// This function dispatches to a specialized scaler based on scale factor.
+int ScalePlane(const uint8_t* src,
+               int src_stride,
+               int src_width,
+               int src_height,
+               uint8_t* dst,
+               int dst_stride,
+               int dst_width,
+               int dst_height,
+               enum FilterMode filtering) {
+  // Simplify filtering when possible.
+  filtering = ScaleFilterReduce(src_width, src_height, dst_width, dst_height,
+                                filtering);
+
+  // Negative height means invert the image.
+  if (src_height < 0) {
+    src_height = -src_height;
+    src = src + (src_height - 1) * (int64_t)src_stride;
+    src_stride = -src_stride;
+  }
+  // Use specialized scales to improve performance for common resolutions.
+  // For example, all the 1/2 scalings will use ScalePlaneDown2()
+  if (dst_width == src_width && dst_height == src_height) {
+    // Straight copy.
+    CopyPlane(src, src_stride, dst, dst_stride, dst_width, dst_height);
+    return 0;
+  }
+  if (dst_width == src_width && filtering != kFilterBox) {
+    int dy = 0;
+    int y = 0;
+    // When scaling down, use the center 2 rows to filter.
+    // When scaling up, last row of destination uses the last 2 source rows.
+    if (dst_height <= src_height) {
+      dy = FixedDiv(src_height, dst_height);
+      y = CENTERSTART(dy, -32768);  // Subtract 0.5 (32768) to center filter.
+    } else if (src_height > 1 && dst_height > 1) {
+      dy = FixedDiv1(src_height, dst_height);
+    }
+    // Arbitrary scale vertically, but unscaled horizontally.
+    ScalePlaneVertical(src_height, dst_width, dst_height, src_stride,
+                       dst_stride, src, dst, 0, y, dy, /*bpp=*/1, filtering);
+    return 0;
+  }
+  if (filtering == kFilterBox && dst_height * 2 < src_height) {
+    return ScalePlaneBox(src_width, src_height, dst_width, dst_height,
+                         src_stride, dst_stride, src, dst);
+  }
+  if ((dst_width + 1) / 2 == src_width && filtering == kFilterLinear) {
+    ScalePlaneUp2_Linear(src_width, src_height, dst_width, dst_height,
+                         src_stride, dst_stride, src, dst);
+    return 0;
+  }
+  if ((dst_height + 1) / 2 == src_height && (dst_width + 1) / 2 == src_width &&
+      (filtering == kFilterBilinear || filtering == kFilterBox)) {
+    ScalePlaneUp2_Bilinear(src_width, src_height, dst_width, dst_height,
+                           src_stride, dst_stride, src, dst);
+    return 0;
+  }
+  if (filtering && dst_height > src_height) {
+    return ScalePlaneBilinearUp(src_width, src_height, dst_width, dst_height,
+                                src_stride, dst_stride, src, dst, filtering);
+  }
+  if (filtering) {
+    return ScalePlaneBilinearDown(src_width, src_height, dst_width, dst_height,
+                                  src_stride, dst_stride, src, dst, filtering);
+  }
+  ScalePlaneSimple(src_width, src_height, dst_width, dst_height, src_stride,
+                   dst_stride, src, dst);
+  return 0;
+}
+
+int ScalePlane_16(const uint16_t* src,
+                  int src_stride,
+                  int src_width,
+                  int src_height,
+                  uint16_t* dst,
+                  int dst_stride,
+                  int dst_width,
+                  int dst_height,
+                  enum FilterMode filtering) {
+  // Simplify filtering when possible.
+  filtering = ScaleFilterReduce(src_width, src_height, dst_width, dst_height,
+                                filtering);
+
+  // Negative height means invert the image.
+  if (src_height < 0) {
+    src_height = -src_height;
+    src = src + (src_height - 1) * (int64_t)src_stride;
+    src_stride = -src_stride;
+  }
+  // Use specialized scales to improve performance for common resolutions.
+  // For example, all the 1/2 scalings will use ScalePlaneDown2()
+  if (dst_width == src_width && dst_height == src_height) {
+    // Straight copy.
+    CopyPlane_16(src, src_stride, dst, dst_stride, dst_width, dst_height);
+    return 0;
+  }
+  if (dst_width == src_width && filtering != kFilterBox) {
+    int dy = 0;
+    int y = 0;
+    // When scaling down, use the center 2 rows to filter.
+    // When scaling up, last row of destination uses the last 2 source rows.
+    if (dst_height <= src_height) {
+      dy = FixedDiv(src_height, dst_height);
+      y = CENTERSTART(dy, -32768);  // Subtract 0.5 (32768) to center filter.
+      // When scaling up, ensure the last row of destination uses the last
+      // source. Avoid divide by zero for dst_height but will do no scaling
+      // later.
+    } else if (src_height > 1 && dst_height > 1) {
+      dy = FixedDiv1(src_height, dst_height);
+    }
+    // Arbitrary scale vertically, but unscaled horizontally.
+    ScalePlaneVertical_16(src_height, dst_width, dst_height, src_stride,
+                          dst_stride, src, dst, 0, y, dy, /*bpp=*/1, filtering);
+    return 0;
+  }
+  if (filtering == kFilterBox && dst_height * 2 < src_height) {
+    return ScalePlaneBox_16(src_width, src_height, dst_width, dst_height,
+                            src_stride, dst_stride, src, dst);
+  }
+  if ((dst_width + 1) / 2 == src_width && filtering == kFilterLinear) {
+    ScalePlaneUp2_16_Linear(src_width, src_height, dst_width, dst_height,
+                            src_stride, dst_stride, src, dst);
+    return 0;
+  }
+  if ((dst_height + 1) / 2 == src_height && (dst_width + 1) / 2 == src_width &&
+      (filtering == kFilterBilinear || filtering == kFilterBox)) {
+    ScalePlaneUp2_16_Bilinear(src_width, src_height, dst_width, dst_height,
+                              src_stride, dst_stride, src, dst);
+    return 0;
+  }
+  if (filtering && dst_height > src_height) {
+    return ScalePlaneBilinearUp_16(src_width, src_height, dst_width, dst_height,
+                                   src_stride, dst_stride, src, dst, filtering);
+  }
+  if (filtering) {
+    return ScalePlaneBilinearDown_16(src_width, src_height, dst_width,
+                                     dst_height, src_stride, dst_stride, src,
+                                     dst, filtering);
+  }
+  ScalePlaneSimple_16(src_width, src_height, dst_width, dst_height, src_stride,
+                      dst_stride, src, dst);
+  return 0;
+}
+
+int ScalePlane_12(const uint16_t* src,
+                  int src_stride,
+                  int src_width,
+                  int src_height,
+                  uint16_t* dst,
+                  int dst_stride,
+                  int dst_width,
+                  int dst_height,
+                  enum FilterMode filtering) {
+  // Simplify filtering when possible.
+  filtering = ScaleFilterReduce(src_width, src_height, dst_width, dst_height,
+                                filtering);
+
+  // Negative height means invert the image.
+  if (src_height < 0) {
+    src_height = -src_height;
+    src = src + (src_height - 1) * (int64_t)src_stride;
+    src_stride = -src_stride;
+  }
+
+  if ((dst_width + 1) / 2 == src_width && filtering == kFilterLinear) {
+    ScalePlaneUp2_12_Linear(src_width, src_height, dst_width, dst_height,
+                            src_stride, dst_stride, src, dst);
+    return 0;
+  }
+  if ((dst_height + 1) / 2 == src_height && (dst_width + 1) / 2 == src_width &&
+      (filtering == kFilterBilinear || filtering == kFilterBox)) {
+    ScalePlaneUp2_12_Bilinear(src_width, src_height, dst_width, dst_height,
+                              src_stride, dst_stride, src, dst);
+    return 0;
+  }
+
+  return ScalePlane_16(src, src_stride, src_width, src_height, dst, dst_stride,
+                       dst_width, dst_height, filtering);
+}
diff --git a/third_party/libavif/src/third_party/libyuv/source/scale_any.c b/third_party/libavif/src/third_party/libyuv/source/scale_any.c
new file mode 100644
index 0000000000..c3aa3701ae
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/source/scale_any.c
@@ -0,0 +1,85 @@
+/*
+ *  Copyright 2015 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <string.h>  // For memset/memcpy
+
+#include "libyuv/scale.h"
+#include "libyuv/scale_row.h"
+
+#include "libyuv/basic_types.h"
+
+// Scale up horizontally 2 times using linear filter.
+#define SUH2LANY(NAME, SIMD, C, MASK, PTYPE)                       \
+  void NAME(const PTYPE* src_ptr, PTYPE* dst_ptr, int dst_width) { \
+    int work_width = (dst_width - 1) & ~1;                         \
+    int r = work_width & MASK;                                     \
+    int n = work_width & ~MASK;                                    \
+    dst_ptr[0] = src_ptr[0];                                       \
+    if (work_width > 0) {                                          \
+      if (n != 0) {                                                \
+        SIMD(src_ptr, dst_ptr + 1, n);                             \
+      }                                                            \
+      C(src_ptr + (n / 2), dst_ptr + n + 1, r);                    \
+    }                                                              \
+    dst_ptr[dst_width - 1] = src_ptr[(dst_width - 1) / 2];         \
+  }
+
+// Even the C versions need to be wrapped, because boundary pixels have to
+// be handled differently
+
+SUH2LANY(ScaleRowUp2_Linear_Any_C,
+         ScaleRowUp2_Linear_C,
+         ScaleRowUp2_Linear_C,
+         0,
+         uint8_t)
+
+SUH2LANY(ScaleRowUp2_Linear_16_Any_C,
+         ScaleRowUp2_Linear_16_C,
+         ScaleRowUp2_Linear_16_C,
+         0,
+         uint16_t)
+
+// Scale up 2 times using bilinear filter.
+// This function produces 2 rows at a time.
+#define SU2BLANY(NAME, SIMD, C, MASK, PTYPE)                              \
+  void NAME(const PTYPE* src_ptr, ptrdiff_t src_stride, PTYPE* dst_ptr,   \
+            ptrdiff_t dst_stride, int dst_width) {                        \
+    int work_width = (dst_width - 1) & ~1;                                \
+    int r = work_width & MASK;                                            \
+    int n = work_width & ~MASK;                                           \
+    const PTYPE* sa = src_ptr;                                            \
+    const PTYPE* sb = src_ptr + src_stride;                               \
+    PTYPE* da = dst_ptr;                                                  \
+    PTYPE* db = dst_ptr + dst_stride;                                     \
+    da[0] = (3 * sa[0] + sb[0] + 2) >> 2;                                 \
+    db[0] = (sa[0] + 3 * sb[0] + 2) >> 2;                                 \
+    if (work_width > 0) {                                                 \
+      if (n != 0) {                                                       \
+        SIMD(sa, sb - sa, da + 1, db - da, n);                            \
+      }                                                                   \
+      C(sa + (n / 2), sb - sa, da + n + 1, db - da, r);                   \
+    }                                                                     \
+    da[dst_width - 1] =                                                   \
+        (3 * sa[(dst_width - 1) / 2] + sb[(dst_width - 1) / 2] + 2) >> 2; \
+    db[dst_width - 1] =                                                   \
+        (sa[(dst_width - 1) / 2] + 3 * sb[(dst_width - 1) / 2] + 2) >> 2; \
+  }
+
+SU2BLANY(ScaleRowUp2_Bilinear_Any_C,
+         ScaleRowUp2_Bilinear_C,
+         ScaleRowUp2_Bilinear_C,
+         0,
+         uint8_t)
+
+SU2BLANY(ScaleRowUp2_Bilinear_16_Any_C,
+         ScaleRowUp2_Bilinear_16_C,
+         ScaleRowUp2_Bilinear_16_C,
+         0,
+         uint16_t)
diff --git a/third_party/libavif/src/third_party/libyuv/source/scale_common.c b/third_party/libavif/src/third_party/libyuv/source/scale_common.c
new file mode 100644
index 0000000000..f2217024db
--- /dev/null
+++ b/third_party/libavif/src/third_party/libyuv/source/scale_common.c
@@ -0,0 +1,555 @@
+/*
+ *  Copyright 2013 The LibYuv Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS. All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "libyuv/scale.h"
+
+#include <assert.h>
+#include <string.h>
+
+#include "libyuv/planar_functions.h"  // For CopyARGB
+#include "libyuv/row.h"
+#include "libyuv/scale_row.h"
+
+static __inline int Abs(int v) {
+  return v >= 0 ? v : -v;
+}
+
+// Sample position: (O is src sample position, X is dst sample position)
+//
+//      v dst_ptr at here           v stop at here
+//  X O X   X O X   X O X   X O X   X O X
+//    ^ src_ptr at here
+void ScaleRowUp2_Linear_C(const uint8_t* src_ptr,
+                          uint8_t* dst_ptr,
+                          int dst_width) {
+  int src_width = dst_width >> 1;
+  int x;
+  assert((dst_width % 2 == 0) && (dst_width >= 0));
+  for (x = 0; x < src_width; ++x) {
+    dst_ptr[2 * x + 0] = (src_ptr[x + 0] * 3 + src_ptr[x + 1] * 1 + 2) >> 2;
+    dst_ptr[2 * x + 1] = (src_ptr[x + 0] * 1 + src_ptr[x + 1] * 3 + 2) >> 2;
+  }
+}
+
+// Sample position: (O is src sample position, X is dst sample position)
+//
+//    src_ptr at here
+//  X v X   X   X   X   X   X   X   X   X
+//    O       O       O       O       O
+//  X   X   X   X   X   X   X   X   X   X
+//      ^ dst_ptr at here           ^ stop at here
+//  X   X   X   X   X   X   X   X   X   X
+//    O       O       O       O       O
+//  X   X   X   X   X   X   X   X   X   X
+void ScaleRowUp2_Bilinear_C(const uint8_t* src_ptr,
+                            ptrdiff_t src_stride,
+                            uint8_t* dst_ptr,
+                            ptrdiff_t dst_stride,
+                            int dst_width) {
+  const uint8_t* s = src_ptr;
+  const uint8_t* t = src_ptr + src_stride;
+  uint8_t* d = dst_ptr;
+  uint8_t* e = dst_ptr + dst_stride;
+  int src_width = dst_width >> 1;
+  int x;
+  assert((dst_width % 2 == 0) && (dst_width >= 0));
+  for (x = 0; x < src_width; ++x) {
+    d[2 * x + 0] =
+        (s[x + 0] * 9 + s[x + 1] * 3 + t[x + 0] * 3 + t[x + 1] * 1 + 8) >> 4;
+    d[2 * x + 1] =
+        (s[x + 0] * 3 + s[x + 1] * 9 + t[x + 0] * 1 + t[x + 1] * 3 + 8) >> 4;
+    e[2 * x + 0] =
+        (s[x + 0] * 3 + s[x + 1] * 1 + t[x + 0] * 9 + t[x + 1] * 3 + 8) >> 4;
+    e[2 * x + 1] =
+        (s[x + 0] * 1 + s[x + 1] * 3 + t[x + 0] * 3 + t[x + 1] * 9 + 8) >> 4;
+  }
+}
+
+// Only suitable for at most 14 bit range.
+void ScaleRowUp2_Linear_16_C(const uint16_t* src_ptr,
+                             uint16_t* dst_ptr,
+                             int dst_width) {
+  int src_width = dst_width >> 1;
+  int x;
+  assert((dst_width % 2 == 0) && (dst_width >= 0));
+  for (x = 0; x < src_width; ++x) {
+    dst_ptr[2 * x + 0] = (src_ptr[x + 0] * 3 + src_ptr[x + 1] * 1 + 2) >> 2;
+    dst_ptr[2 * x + 1] = (src_ptr[x + 0] * 1 + src_ptr[x + 1] * 3 + 2) >> 2;
+  }
+}
+
+// Only suitable for at most 12bit range.
+void ScaleRowUp2_Bilinear_16_C(const uint16_t* src_ptr,
+                               ptrdiff_t src_stride,
+                               uint16_t* dst_ptr,
+                               ptrdiff_t dst_stride,
+                               int dst_width) {
+  const uint16_t* s = src_ptr;
+  const uint16_t* t = src_ptr + src_stride;
+  uint16_t* d = dst_ptr;
+  uint16_t* e = dst_ptr + dst_stride;
+  int src_width = dst_width >> 1;
+  int x;
+  assert((dst_width % 2 == 0) && (dst_width >= 0));
+  for (x = 0; x < src_width; ++x) {
+    d[2 * x + 0] =
+        (s[x + 0] * 9 + s[x + 1] * 3 + t[x + 0] * 3 + t[x + 1] * 1 + 8) >> 4;
+    d[2 * x + 1] =
+        (s[x + 0] * 3 + s[x + 1] * 9 + t[x + 0] * 1 + t[x + 1] * 3 + 8) >> 4;
+    e[2 * x + 0] =
+        (s[x + 0] * 3 + s[x + 1] * 1 + t[x + 0] * 9 + t[x + 1] * 3 + 8) >> 4;
+    e[2 * x + 1] =
+        (s[x + 0] * 1 + s[x + 1] * 3 + t[x + 0] * 3 + t[x + 1] * 9 + 8) >> 4;
+  }
+}
+
+// Scales a single row of pixels using point sampling.
+void ScaleCols_C(uint8_t* dst_ptr,
+                 const uint8_t* src_ptr,
+                 int dst_width,
+                 int x,
+                 int dx) {
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    dst_ptr[0] = src_ptr[x >> 16];
+    x += dx;
+    dst_ptr[1] = src_ptr[x >> 16];
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    dst_ptr[0] = src_ptr[x >> 16];
+  }
+}
+
+void ScaleCols_16_C(uint16_t* dst_ptr,
+                    const uint16_t* src_ptr,
+                    int dst_width,
+                    int x,
+                    int dx) {
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    dst_ptr[0] = src_ptr[x >> 16];
+    x += dx;
+    dst_ptr[1] = src_ptr[x >> 16];
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    dst_ptr[0] = src_ptr[x >> 16];
+  }
+}
+
+// Scales a single row of pixels up by 2x using point sampling.
+void ScaleColsUp2_C(uint8_t* dst_ptr,
+                    const uint8_t* src_ptr,
+                    int dst_width,
+                    int x,
+                    int dx) {
+  int j;
+  (void)x;
+  (void)dx;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    dst_ptr[1] = dst_ptr[0] = src_ptr[0];
+    src_ptr += 1;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    dst_ptr[0] = src_ptr[0];
+  }
+}
+
+void ScaleColsUp2_16_C(uint16_t* dst_ptr,
+                       const uint16_t* src_ptr,
+                       int dst_width,
+                       int x,
+                       int dx) {
+  int j;
+  (void)x;
+  (void)dx;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    dst_ptr[1] = dst_ptr[0] = src_ptr[0];
+    src_ptr += 1;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    dst_ptr[0] = src_ptr[0];
+  }
+}
+
+// (1-f)a + fb can be replaced with a + f(b-a)
+#if defined(__arm__) || defined(__aarch64__)
+#define BLENDER(a, b, f) \
+  (uint8_t)((int)(a) + ((((int)((f)) * ((int)(b) - (int)(a))) + 0x8000) >> 16))
+#else
+// Intel uses 7 bit math with rounding.
+#define BLENDER(a, b, f) \
+  (uint8_t)((int)(a) + (((int)((f) >> 9) * ((int)(b) - (int)(a)) + 0x40) >> 7))
+#endif
+
+void ScaleFilterCols_C(uint8_t* dst_ptr,
+                       const uint8_t* src_ptr,
+                       int dst_width,
+                       int x,
+                       int dx) {
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    int xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    xi = x >> 16;
+    a = src_ptr[xi];
+    b = src_ptr[xi + 1];
+    dst_ptr[1] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    int xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+  }
+}
+
+void ScaleFilterCols64_C(uint8_t* dst_ptr,
+                         const uint8_t* src_ptr,
+                         int dst_width,
+                         int x32,
+                         int dx) {
+  int64_t x = (int64_t)(x32);
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    int64_t xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    xi = x >> 16;
+    a = src_ptr[xi];
+    b = src_ptr[xi + 1];
+    dst_ptr[1] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    int64_t xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+  }
+}
+#undef BLENDER
+
+// Same as 8 bit arm blender but return is cast to uint16_t
+#define BLENDER(a, b, f) \
+  (uint16_t)(            \
+      (int)(a) +         \
+      (int)((((int64_t)((f)) * ((int64_t)(b) - (int)(a))) + 0x8000) >> 16))
+
+void ScaleFilterCols_16_C(uint16_t* dst_ptr,
+                          const uint16_t* src_ptr,
+                          int dst_width,
+                          int x,
+                          int dx) {
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    int xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    xi = x >> 16;
+    a = src_ptr[xi];
+    b = src_ptr[xi + 1];
+    dst_ptr[1] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    int xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+  }
+}
+
+void ScaleFilterCols64_16_C(uint16_t* dst_ptr,
+                            const uint16_t* src_ptr,
+                            int dst_width,
+                            int x32,
+                            int dx) {
+  int64_t x = (int64_t)(x32);
+  int j;
+  for (j = 0; j < dst_width - 1; j += 2) {
+    int64_t xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    xi = x >> 16;
+    a = src_ptr[xi];
+    b = src_ptr[xi + 1];
+    dst_ptr[1] = BLENDER(a, b, x & 0xffff);
+    x += dx;
+    dst_ptr += 2;
+  }
+  if (dst_width & 1) {
+    int64_t xi = x >> 16;
+    int a = src_ptr[xi];
+    int b = src_ptr[xi + 1];
+    dst_ptr[0] = BLENDER(a, b, x & 0xffff);
+  }
+}
+#undef BLENDER
+
+
+void ScaleAddRow_C(const uint8_t* src_ptr, uint16_t* dst_ptr, int src_width) {
+  int x;
+  assert(src_width > 0);
+  for (x = 0; x < src_width - 1; x += 2) {
+    dst_ptr[0] += src_ptr[0];
+    dst_ptr[1] += src_ptr[1];
+    src_ptr += 2;
+    dst_ptr += 2;
+  }
+  if (src_width & 1) {
+    dst_ptr[0] += src_ptr[0];
+  }
+}
+
+void ScaleAddRow_16_C(const uint16_t* src_ptr,
+                      uint32_t* dst_ptr,
+                      int src_width) {
+  int x;
+  assert(src_width > 0);
+  for (x = 0; x < src_width - 1; x += 2) {
+    dst_ptr[0] += src_ptr[0];
+    dst_ptr[1] += src_ptr[1];
+    src_ptr += 2;
+    dst_ptr += 2;
+  }
+  if (src_width & 1) {
+    dst_ptr[0] += src_ptr[0];
+  }
+}
+
+
+// Scale plane vertically with bilinear interpolation.
+void ScalePlaneVertical(int src_height,
+                        int dst_width,
+                        int dst_height,
+                        int src_stride,
+                        int dst_stride,
+                        const uint8_t* src_argb,
+                        uint8_t* dst_argb,
+                        int x,
+                        int y,
+                        int dy,
+                        int bpp,  // bytes per pixel. 4 for ARGB.
+                        enum FilterMode filtering) {
+  // TODO(fbarchard): Allow higher bpp.
+  int dst_width_bytes = dst_width * bpp;
+  void (*InterpolateRow)(uint8_t* dst_argb, const uint8_t* src_argb,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_C;
+  const int max_y = (src_height > 1) ? ((src_height - 1) << 16) - 1 : 0;
+  int j;
+  assert(bpp >= 1 && bpp <= 4);
+  assert(src_height != 0);
+  assert(dst_width > 0);
+  assert(dst_height > 0);
+  src_argb += (x >> 16) * bpp;
+
+  for (j = 0; j < dst_height; ++j) {
+    int yi;
+    int yf;
+    if (y > max_y) {
+      y = max_y;
+    }
+    yi = y >> 16;
+    yf = filtering ? ((y >> 8) & 255) : 0;
+    InterpolateRow(dst_argb, src_argb + yi * src_stride, src_stride,
+                   dst_width_bytes, yf);
+    dst_argb += dst_stride;
+    y += dy;
+  }
+}
+
+void ScalePlaneVertical_16(int src_height,
+                           int dst_width,
+                           int dst_height,
+                           int src_stride,
+                           int dst_stride,
+                           const uint16_t* src_argb,
+                           uint16_t* dst_argb,
+                           int x,
+                           int y,
+                           int dy,
+                           int wpp, /* words per pixel. normally 1 */
+                           enum FilterMode filtering) {
+  // TODO(fbarchard): Allow higher wpp.
+  int dst_width_words = dst_width * wpp;
+  void (*InterpolateRow)(uint16_t* dst_argb, const uint16_t* src_argb,
+                         ptrdiff_t src_stride, int dst_width,
+                         int source_y_fraction) = InterpolateRow_16_C;
+  const int max_y = (src_height > 1) ? ((src_height - 1) << 16) - 1 : 0;
+  int j;
+  assert(wpp >= 1 && wpp <= 2);
+  assert(src_height != 0);
+  assert(dst_width > 0);
+  assert(dst_height > 0);
+  src_argb += (x >> 16) * wpp;
+  for (j = 0; j < dst_height; ++j) {
+    int yi;
+    int yf;
+    if (y > max_y) {
+      y = max_y;
+    }
+    yi = y >> 16;
+    yf = filtering ? ((y >> 8) & 255) : 0;
+    InterpolateRow(dst_argb, src_argb + yi * src_stride, src_stride,
+                   dst_width_words, yf);
+    dst_argb += dst_stride;
+    y += dy;
+  }
+}
+
+// Simplify the filtering based on scale factors.
+enum FilterMode ScaleFilterReduce(int src_width,
+                                  int src_height,
+                                  int dst_width,
+                                  int dst_height,
+                                  enum FilterMode filtering) {
+  if (src_width < 0) {
+    src_width = -src_width;
+  }
+  if (src_height < 0) {
+    src_height = -src_height;
+  }
+  if (filtering == kFilterBox) {
+    // If scaling either axis to 0.5 or larger, switch from Box to Bilinear.
+    if (dst_width * 2 >= src_width || dst_height * 2 >= src_height) {
+      filtering = kFilterBilinear;
+    }
+  }
+  if (filtering == kFilterBilinear) {
+    if (src_height == 1) {
+      filtering = kFilterLinear;
+    }
+    // TODO(fbarchard): Detect any odd scale factor and reduce to Linear.
+    if (dst_height == src_height || dst_height * 3 == src_height) {
+      filtering = kFilterLinear;
+    }
+    // TODO(fbarchard): Remove 1 pixel wide filter restriction, which is to
+    // avoid reading 2 pixels horizontally that causes memory exception.
+    if (src_width == 1) {
+      filtering = kFilterNone;
+    }
+  }
+  if (filtering == kFilterLinear) {
+    if (src_width == 1) {
+      filtering = kFilterNone;
+    }
+    // TODO(fbarchard): Detect any odd scale factor and reduce to None.
+    if (dst_width == src_width || dst_width * 3 == src_width) {
+      filtering = kFilterNone;
+    }
+  }
+  return filtering;
+}
+
+// Divide num by div and return as 16.16 fixed point result.
+int FixedDiv_C(int num, int div) {
+  return (int)(((int64_t)(num) << 16) / div);
+}
+
+// Divide num - 1 by div - 1 and return as 16.16 fixed point result.
+int FixedDiv1_C(int num, int div) {
+  return (int)((((int64_t)(num) << 16) - 0x00010001) / (div - 1));
+}
+
+#define CENTERSTART(dx, s) (dx < 0) ? -((-dx >> 1) + s) : ((dx >> 1) + s)
+
+// Compute slope values for stepping.
+void ScaleSlope(int src_width,
+                int src_height,
+                int dst_width,
+                int dst_height,
+                enum FilterMode filtering,
+                int* x,
+                int* y,
+                int* dx,
+                int* dy) {
+  assert(x != NULL);
+  assert(y != NULL);
+  assert(dx != NULL);
+  assert(dy != NULL);
+  assert(src_width != 0);
+  assert(src_height != 0);
+  assert(dst_width > 0);
+  assert(dst_height > 0);
+  // Check for 1 pixel and avoid FixedDiv overflow.
+  if (dst_width == 1 && src_width >= 32768) {
+    dst_width = src_width;
+  }
+  if (dst_height == 1 && src_height >= 32768) {
+    dst_height = src_height;
+  }
+  if (filtering == kFilterBox) {
+    // Scale step for point sampling duplicates all pixels equally.
+    *dx = FixedDiv(Abs(src_width), dst_width);
+    *dy = FixedDiv(src_height, dst_height);
+    *x = 0;
+    *y = 0;
+  } else if (filtering == kFilterBilinear) {
+    // Scale step for bilinear sampling renders last pixel once for upsample.
+    if (dst_width <= Abs(src_width)) {
+      *dx = FixedDiv(Abs(src_width), dst_width);
+      *x = CENTERSTART(*dx, -32768);  // Subtract 0.5 (32768) to center filter.
+    } else if (src_width > 1 && dst_width > 1) {
+      *dx = FixedDiv1(Abs(src_width), dst_width);
+      *x = 0;
+    }
+    if (dst_height <= src_height) {
+      *dy = FixedDiv(src_height, dst_height);
+      *y = CENTERSTART(*dy, -32768);  // Subtract 0.5 (32768) to center filter.
+    } else if (src_height > 1 && dst_height > 1) {
+      *dy = FixedDiv1(src_height, dst_height);
+      *y = 0;
+    }
+  } else if (filtering == kFilterLinear) {
+    // Scale step for bilinear sampling renders last pixel once for upsample.
+    if (dst_width <= Abs(src_width)) {
+      *dx = FixedDiv(Abs(src_width), dst_width);
+      *x = CENTERSTART(*dx, -32768);  // Subtract 0.5 (32768) to center filter.
+    } else if (src_width > 1 && dst_width > 1) {
+      *dx = FixedDiv1(Abs(src_width), dst_width);
+      *x = 0;
+    }
+    *dy = FixedDiv(src_height, dst_height);
+    *y = *dy >> 1;
+  } else {
+    // Scale step for point sampling duplicates all pixels equally.
+    *dx = FixedDiv(Abs(src_width), dst_width);
+    *dy = FixedDiv(src_height, dst_height);
+    *x = CENTERSTART(*dx, 0);
+    *y = CENTERSTART(*dy, 0);
+  }
+  // Negative src_width means horizontally mirror.
+  if (src_width < 0) {
+    *x += (dst_width - 1) * *dx;
+    *dx = -*dx;
+    // src_width = -src_width;   // Caller must do this.
+  }
+}
+#undef CENTERSTART
